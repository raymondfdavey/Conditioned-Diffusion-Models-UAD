# @package _global_

defaults:
  - _self_
  - model: DDPM_2D.yaml  # This uses your existing model config
  - test/datamodule: IXI_new.yaml  # Your new datamodule for slice-based testing

data_dir: ${oc.env:DATA_DIR}
log_dir: ${oc.env:LOG_DIR}

# Inherit core experiment settings from your DDPM_cond_spark_2D experiment
model:
  cfg:
    noise_ensemble: True
    step_ensemble: [250,500,750]
    test_timesteps: 250
    dim_mults: [1,2,2]
    unet_dim: 128
    backbone: Spark_Encoder_2D
    version: resnet50
    cond_dim: 128
    OpenaiUnet: True
    spatial_transformer: False
    condition: True
    noisetype: simplex
    encoder_path: /home/rd81/projects/full_logs/logs/runs/MAE_2D/Spark_2D_IXI_MAE_2D__2024-11-25_10-25-18/checkpoints/epoch-1089_step-13079_loss-0.00_fold-1.ckpt
    pretrained_encoder: True
    save_to_disc: True

# Keep same data parameters but adjusted for 4-slice approach
datamodule:
  cfg:
    name: IXI
    path:
      pathBase: ${data_dir}
      IXI:
        IDs:
          test: ${data_dir}/Data/splits/IXI_test.csv
    
    # Original image dimensions but modified for 4 slices
    imageDim: [192, 192, 160]  # Changed from [192, 192, 160] to handle 4 slices
    rescaleFactor: 2
    interRes: [8, 8, 5]  # Adjusted for 4 slices
    cropMode: 'isotropic'
    spatialDims: ${model.cfg.spatialDims}
    
    # Testing specific settings
    debugging: True
    resizedEvaluation: True
    unisotropic_sampling: True
    num_workers: 4
    
    # Processing flags (kept from original)
    curvatureFlow: True
    percentile: True
    pad: True
    mode: t1
    lr: 0.0001  # This matches your training configuration


num_folds: 1
logger:
  wandb:
    project: cDDPM

load_checkpoint: "/home/rd81/projects/full_logs/logs/runs/DDPM_cond_2D_spark/DDPM_2D_IXI_DDPM_cond_2D_spark__2024-11-25_13-54-17/checkpoints/epoch-719_step-8639_loss-0.00_fold-1.ckpt"
ckpt_path: best
name: DDPM_cond_2D_spark_slice_test
seed: 3141