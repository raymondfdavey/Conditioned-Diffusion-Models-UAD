syspath ['/home/rd81/projects/diffusion-uad', '/home/rd81/miniconda3/envs/cddpm/lib/python39.zip', '/home/rd81/miniconda3/envs/cddpm/lib/python3.9', '/home/rd81/miniconda3/envs/cddpm/lib/python3.9/lib-dynload', '/home/rd81/miniconda3/envs/cddpm/lib/python3.9/site-packages']
/home/rd81/projects/diffusion-uad
CONFIGGGG
work_dir: ${hydra:runtime.cwd}
data_dir: ${oc.env:DATA_DIR}
log_dir: ${oc.env:LOG_DIR}
name: DDPM_cond_2D_spark
debug: false
print_config: false
ignore_warnings: false
checkpoint: best
new_wandb_run: true
test_after_training: true
onlyEval: true
load_checkpoint: /home/rd81/projects/full_logs/logs/runs/DDPM_cond_2D_spark/DDPM_2D_IXI_DDPM_cond_2D_spark__2024-11-25_13-54-17
trainer:
  _target_: pytorch_lightning.Trainer
  gpus: -1
  min_epochs: 1
  max_epochs: 1200
  log_every_n_steps: 5
  precision: 16
  num_sanity_val_steps: 0
  check_val_every_n_epoch: 10
  benchmark: true
  overfit_batches: false
model:
  _target_: src.models.DDPM_2D.DDPM_2D
  cfg:
    name: DDPM_2D
    imageDim: ${datamodule.cfg.imageDim}
    rescaleFactor: ${datamodule.cfg.rescaleFactor}
    interRes: ${datamodule.cfg.interRes}
    cropMode: ${datamodule.cfg.cropMode}
    spatialDims: 2D
    resizedEvaluation: ${datamodule.cfg.resizedEvaluation}
    unet_dim: 128
    dim_mults:
    - 1
    - 2
    - 2
    learned_variance: false
    learned_sinusoidal_cond: false
    loss: l1
    lossStrategy: mean
    lr: ${datamodule.cfg.lr}
    scheduleLR: false
    patienceLR: 10
    earlyStopping: false
    patienceStopping: 50
    saveOutputImages: true
    evalSeg: true
    pad: ${datamodule.cfg.pad}
    erodeBrainmask: true
    medianFiltering: true
    threshold: auto
    mode: ${datamodule.cfg.mode}
    noise_ensemble: true
    step_ensemble:
    - 250
    - 500
    - 750
    test_timesteps: 250
    backbone: Spark_Encoder_2D
    version: resnet50
    cond_dim: 128
    OpenaiUnet: true
    spatial_transformer: false
    condition: true
    noisetype: simplex
    encoder_path: /home/rd81/projects/full_logs/logs/runs/MAE_2D/Spark_2D_IXI_MAE_2D__2024-11-25_10-25-18/checkpoints/epoch-1089_step-13079_loss-0.00_fold-1.ckpt
    pretrained_encoder: true
    save_to_disc: true
datamodule:
  _target_: src.datamodules.Datamodules_train.IXI
  cfg:
    name: IXI
    path:
      pathBase: ${data_dir}
      IXI:
        IDs:
          train:
          - ${data_dir}/Data/splits/IXI_train_fold0.csv
          - ${data_dir}/Data/splits/IXI_train_fold1.csv
          - ${data_dir}/Data/splits/IXI_train_fold2.csv
          - ${data_dir}/Data/splits/IXI_train_fold3.csv
          - ${data_dir}/Data/splits/IXI_train_fold4.csv
          val:
          - ${data_dir}/Data/splits/IXI_val_fold0.csv
          - ${data_dir}/Data/splits/IXI_val_fold1.csv
          - ${data_dir}/Data/splits/IXI_val_fold2.csv
          - ${data_dir}/Data/splits/IXI_val_fold3.csv
          - ${data_dir}/Data/splits/IXI_val_fold4.csv
          test: ${data_dir}/Data/splits/IXI_test.csv
        keep_t2: ${data_dir}/Data/splits/avail_t2.csv
      Brats21:
        IDs:
          test: ${data_dir}/Data/splits/Brats21_test.csv
          val: ${data_dir}/Data/splits/Brats21_val.csv
      MSLUB:
        IDs:
          test: ${data_dir}/Data/splits/MSLUB_test.csv
          val: ${data_dir}/Data/splits/MSLUB_val.csv
    imageDim:
    - 192
    - 192
    - 100
    rescaleFactor: 2
    interRes:
    - 8
    - 8
    - 5
    cropMode: isotropic
    spatialDims: ${model.cfg.spatialDims}
    unisotropic_sampling: true
    sample_set: false
    preLoad: true
    curvatureFlow: true
    percentile: true
    pad: true
    permute: false
    randomRotate: false
    rotateDegree: 5
    horizontalFlip: false
    randomBrightness: false
    brightnessRange: (0.75,1.25)
    randomContrast: false
    contrastRange: (0.75,1.25)
    modelpath: ${data_dir}/Data/pretrained_2D_model/
    num_workers: 4
    batch_size: 32
    lr: 0.0001
    droplast: true
    mode: t1
    resizedEvaluation: true
    testsets:
    - Datamodules_eval.MSLUB
    aug_intensity: true
callbacks:
  model_checkpoint:
    _target_: pytorch_lightning.callbacks.model_checkpoint.ModelCheckpoint
    monitor: val/Loss_comb
    save_top_k: 1
    auto_insert_metric_name: false
    save_last: true
    mode: min
    dirpath: checkpoints/
    filename: epoch-{epoch}_step-{step}_loss-{val/Loss_comb:.2f}
logger:
  wandb:
    _target_: pytorch_lightning.loggers.wandb.WandbLogger
    project: cDDPM
    name: ${hydra:job.name}
    save_dir: .
    offline: false
    id: null
    resume: false
    log_model: false
    prefix: ''
    job_type: ''
    group: ''
    tags: []
  csv:
    _target_: pytorch_lightning.loggers.csv_logs.CSVLogger
    save_dir: .
    name: csv/
    version: ''
    prefix: ''
num_folds: 1
ckpt_path: best
seed: 3141
default_mode: true

END CONFIGGGG
/home/rd81/projects/full_logs/logs/runs/DDPM_cond_2D_spark/DDPM_2D_IXI_DDPM_cond_2D_spark__2024-11-25_13-54-17
---------------
GETTING CHECKPOINT from /home/rd81/projects/full_logs/logs/runs/DDPM_cond_2D_spark/DDPM_2D_IXI_DDPM_cond_2D_spark__2024-11-25_13-54-17 !!!!!!!!!!!!!!!!!!
/home/rd81/projects/full_logs/logs/runs/DDPM_cond_2D_spark/DDPM_2D_IXI_DDPM_cond_2D_spark__2024-11-25_13-54-17
best
['last_fold-1.ckpt', 'epoch-719_step-8639_loss-0.00_fold-1.ckpt']
/home/rd81/projects/full_logs/logs/runs/DDPM_cond_2D_spark/DDPM_2D_IXI_DDPM_cond_2D_spark__2024-11-25_13-54-17
gu3elgat
{'fold-1': '/home/rd81/projects/full_logs/logs/runs/DDPM_cond_2D_spark/DDPM_2D_IXI_DDPM_cond_2D_spark__2024-11-25_13-54-17/checkpoints/epoch-719_step-8639_loss-0.00_fold-1.ckpt'}
---------------
[[36m2024-11-27 18:57:09,203[0m][[34msrc.train[0m][[32mINFO[0m] - Seed specified to 3141 by config[0m
[[36m2024-11-27 18:57:09,203[0m][[34mpytorch_lightning.utilities.seed[0m][[32mINFO[0m] - Global seed set to 3141[0m
0
1
[[36m2024-11-27 18:57:09,203[0m][[34msrc.train[0m][[32mINFO[0m] - Training Fold 1 of 1 in the WandB group DDPM_cond_2D_spark[0m
[[36m2024-11-27 18:57:09,203[0m][[34msrc.train[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodules.Datamodules_train.IXI>[0m
IN DATAMODULES_TRAIN.IXI
[[36m2024-11-27 18:57:09,449[0m][[34msrc.train[0m][[32mINFO[0m] - Instantiating model <src.models.DDPM_2D.DDPM_2D>[0m
MAKING THE ACTUAL MODEL HERE INCLUDING LOADING THE PRETRAINED ENCODER
==========
INITIALISING DDPM_2D
==========
[[36m2024-11-27 18:57:10,258[0m][[34mtorch.distributed.nn.jit.instantiator[0m][[32mINFO[0m] - Created a temporary directory at /tmp/tmp79hp57nu[0m
[[36m2024-11-27 18:57:10,258[0m][[34mtorch.distributed.nn.jit.instantiator[0m][[32mINFO[0m] - Writing /tmp/tmp79hp57nu/_remote_module_non_scriptable.py[0m
==========
IN get encoder
==========
INITIALISING SPARK ENCODER
[sparse_cnn] model kwargs={'drop_path_rate': 0.05, 'pretrained': False, 'num_classes': 512}
encoder out features: 512
==========
INITIALISING UNET
==========
image_size: (96, 96)
in_channels: 1
model_channels: 128
out_channels: 1
num_res_blocks: 3
attention_resolutions: (3, 6, 12)
dropout: 0
channel_mult: [1, 2, 2]
conv_resample: True
dims: 2
num_classes: 512
use_checkpoint: False
use_fp16: True
num_heads: 1
num_head_channels: 64
num_heads_upsample: -1
use_scale_shift_norm: True
resblock_updown: True
use_new_attention_order: True
use_spatial_transformer: False
transformer_depth: 1
context_dim: None
legacy: True
num_mem_kv: 0
__class__: <class 'src.models.modules.OpenAI_Unet.UNetModel'>
==========
making time_embed layer
==========
resb=0
resb=1
resb=2
resb=0
resb=1
resb=2
resb=0
resb=1
resb=2
==========
INITIALISING GAUSSIAN DIFFUSION
==========
Loading pretrained encoder from:  /home/rd81/projects/full_logs/logs/runs/MAE_2D/Spark_2D_IXI_MAE_2D__2024-11-25_10-25-18/checkpoints/epoch-1089_step-13079_loss-0.00_fold-1.ckpt
encoder path,  /home/rd81/projects/full_logs/logs/runs/MAE_2D/Spark_2D_IXI_MAE_2D__2024-11-25_10-25-18/checkpoints/epoch-1089_step-13079_loss-0.00_fold-1.ckpt
[[36m2024-11-27 18:57:11,576[0m][[34msrc.train[0m][[32mINFO[0m] - Instantiating callback <pytorch_lightning.callbacks.model_checkpoint.ModelCheckpoint>[0m
[[36m2024-11-27 18:57:11,577[0m][[34msrc.train[0m][[32mINFO[0m] - Instantiating logger <pytorch_lightning.loggers.wandb.WandbLogger>[0m
[[36m2024-11-27 18:57:11,579[0m][[34msrc.train[0m][[32mINFO[0m] - Instantiating logger <pytorch_lightning.loggers.csv_logs.CSVLogger>[0m
[[36m2024-11-27 18:57:11,580[0m][[34msrc.train[0m][[32mINFO[0m] - Restoring Trainer State of loaded checkpoint: /home/rd81/projects/full_logs/logs/runs/DDPM_cond_2D_spark/DDPM_2D_IXI_DDPM_cond_2D_spark__2024-11-25_13-54-17/checkpoints/epoch-719_step-8639_loss-0.00_fold-1.ckpt[0m
[[36m2024-11-27 18:57:11,580[0m][[34msrc.train[0m][[32mINFO[0m] - Instantiating trainer <pytorch_lightning.Trainer>[0m
[[36m2024-11-27 18:57:11,582[0m][[34mpytorch_lightning.utilities.distributed[0m][[32mINFO[0m] - Using 16bit native Automatic Mixed Precision (AMP)[0m
[[36m2024-11-27 18:57:11,582[0m][[34mpytorch_lightning.utilities.distributed[0m][[32mINFO[0m] - GPU available: True, used: True[0m
[[36m2024-11-27 18:57:11,583[0m][[34mpytorch_lightning.utilities.distributed[0m][[32mINFO[0m] - TPU available: False, using: 0 TPU cores[0m
[[36m2024-11-27 18:57:11,583[0m][[34mpytorch_lightning.utilities.distributed[0m][[32mINFO[0m] - IPU available: False, using: 0 IPUs[0m
[[36m2024-11-27 18:57:11,583[0m][[34msrc.train[0m][[32mINFO[0m] - Logging hyperparameters![0m
loading model from checkpoint
done loading model from checkpoint
[[36m2024-11-27 18:57:13,048[0m][[34msrc.train[0m][[32mINFO[0m] - Starting evaluation phase of fold 1![0m
[[36m2024-11-27 18:57:13,048[0m][[34msrc.train[0m][[32mINFO[0m] - Instantiating datamodule <src.datamodules.Datamodules_eval.MSLUB>[0m
[[36m2024-11-27 18:57:15,872[0m][[34msrc.train[0m][[32mINFO[0m] - Validation of Datamodules_eval.MSLUB![0m
!!!!! None
[[36m2024-11-27 18:57:15,876[0m][[34mpytorch_lightning.accelerators.gpu[0m][[32mINFO[0m] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0][0m
Testing: 0it [00:00, ?it/s]==========
IN DDPM ON TEST START DDPM2D
==========
==========
IN DDPM ON TEST STEP
==========
THE WEIRD CONDITION BIT CALLED "features" in DDPM_2D
IN SPARK ENCODER FORWARDDD
x in shape torch.Size([50, 1, 96, 96])
out features torch.Size([50, 512])
i'm i DDPM2d forward block (whch is basically the encoder)
Context vector c shape: torch.Size([50, 512])
shape features:  torch.Size([50, 512])
additng features to latern space
latent space: []
iAM IN THE FORWARD METHOD OF THE WEIRD GUASSIAN IN cond_DDPM.py. I WILL BE CALLING p_losses
i am in p_losses in guassian which seems to be crucial to everything
conditioning vector shape:  torch.Size([50, 512])
in plosses i am getting a noisy image x
x shape:  torch.Size([50, 1, 96, 96])
getting model out
Initial input shape: torch.Size([50, 1, 96, 96])

inputblocks
Before block 0, shape: torch.Size([50, 1, 96, 96])
After block 0, shape: torch.Size([50, 128, 96, 96])
-
Before block 1, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 1, shape: torch.Size([50, 128, 96, 96])
-
Before block 2, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 2, shape: torch.Size([50, 128, 96, 96])
-
Before block 3, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 3, shape: torch.Size([50, 128, 96, 96])
-
Before block 4, shape: torch.Size([50, 128, 96, 96])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 256])
After block 4, shape: torch.Size([50, 128, 48, 48])
-
Before block 5, shape: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 48, 48])
-
Before block 8, shape: torch.Size([50, 256, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 8, shape: torch.Size([50, 256, 24, 24])
-
Before block 9, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 9, shape: torch.Size([50, 256, 24, 24])
-
Before block 10, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 10, shape: torch.Size([50, 256, 24, 24])
-
Before block 11, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 11, shape: torch.Size([50, 256, 24, 24])
-

Before middle block, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
in unet attention block!
x shape torch.Size([50, 256, 24, 24])
out dims torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])


After middle block, shape: torch.Size([50, 256, 24, 24])
-



outputblocks
Before block 0, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 0, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 0, shape: torch.Size([50, 256, 24, 24])
-
Before block 1, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 1, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 1, shape: torch.Size([50, 256, 24, 24])
-
Before block 2, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 2, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 2, shape: torch.Size([50, 256, 24, 24])
-
Before block 3, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 3, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 3, shape: torch.Size([50, 256, 48, 48])
-
Before block 4, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 4, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 4, shape: torch.Size([50, 256, 48, 48])
-
Before block 5, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 5, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 6, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 7, shape: torch.Size([50, 384, 48, 48])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 96, 96])
-
Before block 8, shape: torch.Size([50, 256, 96, 96])
After concatenation in upsampling block 8, shape: torch.Size([50, 384, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 8, shape: torch.Size([50, 128, 96, 96])
-
Before block 9, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 9, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 9, shape: torch.Size([50, 128, 96, 96])
-
Before block 10, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 10, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 10, shape: torch.Size([50, 128, 96, 96])
-
Before block 11, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 11, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 11, shape: torch.Size([50, 128, 96, 96])
-

Before Final layer shape: torch.Size([50, 128, 96, 96])
Final output shape: torch.Size([50, 1, 96, 96])
model out shape:  torch.Size([50, 1, 96, 96])
iAM IN THE FORWARD METHOD OF THE WEIRD GUASSIAN IN cond_DDPM.py. I WILL BE CALLING p_losses
i am in p_losses in guassian which seems to be crucial to everything
conditioning vector shape:  torch.Size([50, 512])
in plosses i am getting a noisy image x
x shape:  torch.Size([50, 1, 96, 96])
getting model out
Initial input shape: torch.Size([50, 1, 96, 96])

inputblocks
Before block 0, shape: torch.Size([50, 1, 96, 96])
After block 0, shape: torch.Size([50, 128, 96, 96])
-
Before block 1, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 1, shape: torch.Size([50, 128, 96, 96])
-
Before block 2, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 2, shape: torch.Size([50, 128, 96, 96])
-
Before block 3, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 3, shape: torch.Size([50, 128, 96, 96])
-
Before block 4, shape: torch.Size([50, 128, 96, 96])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 256])
After block 4, shape: torch.Size([50, 128, 48, 48])
-
Before block 5, shape: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 48, 48])
-
Before block 8, shape: torch.Size([50, 256, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 8, shape: torch.Size([50, 256, 24, 24])
-
Before block 9, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 9, shape: torch.Size([50, 256, 24, 24])
-
Before block 10, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 10, shape: torch.Size([50, 256, 24, 24])
-
Before block 11, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 11, shape: torch.Size([50, 256, 24, 24])
-

Before middle block, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
in unet attention block!
x shape torch.Size([50, 256, 24, 24])
out dims torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])


After middle block, shape: torch.Size([50, 256, 24, 24])
-



outputblocks
Before block 0, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 0, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 0, shape: torch.Size([50, 256, 24, 24])
-
Before block 1, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 1, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 1, shape: torch.Size([50, 256, 24, 24])
-
Before block 2, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 2, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 2, shape: torch.Size([50, 256, 24, 24])
-
Before block 3, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 3, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 3, shape: torch.Size([50, 256, 48, 48])
-
Before block 4, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 4, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 4, shape: torch.Size([50, 256, 48, 48])
-
Before block 5, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 5, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 6, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 7, shape: torch.Size([50, 384, 48, 48])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 96, 96])
-
Before block 8, shape: torch.Size([50, 256, 96, 96])
After concatenation in upsampling block 8, shape: torch.Size([50, 384, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 8, shape: torch.Size([50, 128, 96, 96])
-
Before block 9, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 9, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 9, shape: torch.Size([50, 128, 96, 96])
-
Before block 10, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 10, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 10, shape: torch.Size([50, 128, 96, 96])
-
Before block 11, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 11, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 11, shape: torch.Size([50, 128, 96, 96])
-

Before Final layer shape: torch.Size([50, 128, 96, 96])
Final output shape: torch.Size([50, 1, 96, 96])
model out shape:  torch.Size([50, 1, 96, 96])
iAM IN THE FORWARD METHOD OF THE WEIRD GUASSIAN IN cond_DDPM.py. I WILL BE CALLING p_losses
i am in p_losses in guassian which seems to be crucial to everything
conditioning vector shape:  torch.Size([50, 512])
in plosses i am getting a noisy image x
x shape:  torch.Size([50, 1, 96, 96])
getting model out
Initial input shape: torch.Size([50, 1, 96, 96])

inputblocks
Before block 0, shape: torch.Size([50, 1, 96, 96])
After block 0, shape: torch.Size([50, 128, 96, 96])
-
Before block 1, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 1, shape: torch.Size([50, 128, 96, 96])
-
Before block 2, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 2, shape: torch.Size([50, 128, 96, 96])
-
Before block 3, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 3, shape: torch.Size([50, 128, 96, 96])
-
Before block 4, shape: torch.Size([50, 128, 96, 96])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 256])
After block 4, shape: torch.Size([50, 128, 48, 48])
-
Before block 5, shape: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 48, 48])
-
Before block 8, shape: torch.Size([50, 256, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 8, shape: torch.Size([50, 256, 24, 24])
-
Before block 9, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 9, shape: torch.Size([50, 256, 24, 24])
-
Before block 10, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 10, shape: torch.Size([50, 256, 24, 24])
-
Before block 11, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 11, shape: torch.Size([50, 256, 24, 24])
-

Before middle block, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
in unet attention block!
x shape torch.Size([50, 256, 24, 24])
out dims torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])


After middle block, shape: torch.Size([50, 256, 24, 24])
-



outputblocks
Before block 0, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 0, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 0, shape: torch.Size([50, 256, 24, 24])
-
Before block 1, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 1, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 1, shape: torch.Size([50, 256, 24, 24])
-
Before block 2, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 2, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 2, shape: torch.Size([50, 256, 24, 24])
-
Before block 3, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 3, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 3, shape: torch.Size([50, 256, 48, 48])
-
Before block 4, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 4, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 4, shape: torch.Size([50, 256, 48, 48])
-
Before block 5, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 5, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 6, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 7, shape: torch.Size([50, 384, 48, 48])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 96, 96])
-
Before block 8, shape: torch.Size([50, 256, 96, 96])
After concatenation in upsampling block 8, shape: torch.Size([50, 384, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 8, shape: torch.Size([50, 128, 96, 96])
-
Before block 9, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 9, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 9, shape: torch.Size([50, 128, 96, 96])
-
Before block 10, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 10, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 10, shape: torch.Size([50, 128, 96, 96])
-
Before block 11, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 11, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 11, shape: torch.Size([50, 128, 96, 96])
-

Before Final layer shape: torch.Size([50, 128, 96, 96])
Final output shape: torch.Size([50, 1, 96, 96])
model out shape:  torch.Size([50, 1, 96, 96])
reconstruction shape torch.Size([50, 1, 96, 96])
reconstruction tensor([[[[0.0196, 0.0213, 0.0233,  ..., 0.0251, 0.0311, 0.0240],
          [0.0316, 0.0238, 0.0197,  ..., 0.0155, 0.0251, 0.0221],
          [0.0198, 0.0137, 0.0220,  ..., 0.0190, 0.0141, 0.0120],
          ...,
          [0.0212, 0.0136, 0.0204,  ..., 0.0288, 0.0235, 0.0211],
          [0.0274, 0.0234, 0.0141,  ..., 0.0235, 0.0321, 0.0229],
          [0.0168, 0.0158, 0.0146,  ..., 0.0221, 0.0268, 0.0225]]],


        [[[0.0196, 0.0208, 0.0229,  ..., 0.0252, 0.0312, 0.0237],
          [0.0315, 0.0229, 0.0191,  ..., 0.0155, 0.0250, 0.0218],
          [0.0197, 0.0134, 0.0219,  ..., 0.0192, 0.0141, 0.0119],
          ...,
          [0.0212, 0.0133, 0.0205,  ..., 0.0290, 0.0236, 0.0212],
          [0.0272, 0.0226, 0.0139,  ..., 0.0234, 0.0321, 0.0227],
          [0.0168, 0.0152, 0.0144,  ..., 0.0224, 0.0269, 0.0226]]],


        [[[0.0198, 0.0206, 0.0232,  ..., 0.0260, 0.0314, 0.0240],
          [0.0308, 0.0217, 0.0187,  ..., 0.0159, 0.0246, 0.0214],
          [0.0199, 0.0133, 0.0221,  ..., 0.0202, 0.0144, 0.0120],
          ...,
          [0.0216, 0.0136, 0.0213,  ..., 0.0296, 0.0237, 0.0211],
          [0.0270, 0.0219, 0.0141,  ..., 0.0236, 0.0313, 0.0223],
          [0.0171, 0.0148, 0.0150,  ..., 0.0225, 0.0264, 0.0225]]],


        ...,


        [[[0.0205, 0.0182, 0.0194,  ..., 0.0238, 0.0286, 0.0268],
          [0.0277, 0.0149, 0.0136,  ..., 0.0138, 0.0186, 0.0184],
          [0.0212, 0.0117, 0.0208,  ..., 0.0216, 0.0138, 0.0122],
          ...,
          [0.0239, 0.0159, 0.0271,  ..., 0.0286, 0.0209, 0.0189],
          [0.0301, 0.0221, 0.0185,  ..., 0.0208, 0.0248, 0.0181],
          [0.0229, 0.0199, 0.0192,  ..., 0.0233, 0.0264, 0.0233]]],


        [[[0.0200, 0.0185, 0.0200,  ..., 0.0245, 0.0296, 0.0268],
          [0.0286, 0.0160, 0.0148,  ..., 0.0147, 0.0197, 0.0190],
          [0.0222, 0.0132, 0.0218,  ..., 0.0222, 0.0146, 0.0129],
          ...,
          [0.0230, 0.0142, 0.0252,  ..., 0.0291, 0.0216, 0.0196],
          [0.0293, 0.0208, 0.0168,  ..., 0.0225, 0.0264, 0.0187],
          [0.0206, 0.0181, 0.0169,  ..., 0.0242, 0.0269, 0.0228]]],


        [[[0.0197, 0.0185, 0.0197,  ..., 0.0238, 0.0296, 0.0259],
          [0.0291, 0.0172, 0.0155,  ..., 0.0142, 0.0200, 0.0186],
          [0.0225, 0.0134, 0.0223,  ..., 0.0210, 0.0140, 0.0120],
          ...,
          [0.0226, 0.0135, 0.0238,  ..., 0.0300, 0.0238, 0.0211],
          [0.0292, 0.0213, 0.0164,  ..., 0.0249, 0.0308, 0.0210],
          [0.0195, 0.0175, 0.0163,  ..., 0.0259, 0.0296, 0.0234]]]],
       device='cuda:0')
FINAL VOLUME (DDPM) shape torch.Size([96, 96, 50])
FINAL VOLUME tensor([[[0.0196, 0.0196, 0.0198,  ..., 0.0205, 0.0200, 0.0197],
         [0.0213, 0.0208, 0.0206,  ..., 0.0182, 0.0185, 0.0185],
         [0.0233, 0.0229, 0.0232,  ..., 0.0194, 0.0200, 0.0197],
         ...,
         [0.0251, 0.0252, 0.0260,  ..., 0.0238, 0.0245, 0.0238],
         [0.0311, 0.0312, 0.0314,  ..., 0.0286, 0.0296, 0.0296],
         [0.0240, 0.0237, 0.0240,  ..., 0.0268, 0.0268, 0.0259]],

        [[0.0316, 0.0315, 0.0308,  ..., 0.0277, 0.0286, 0.0291],
         [0.0238, 0.0229, 0.0217,  ..., 0.0149, 0.0160, 0.0172],
         [0.0197, 0.0191, 0.0187,  ..., 0.0136, 0.0148, 0.0155],
         ...,
         [0.0155, 0.0155, 0.0159,  ..., 0.0138, 0.0147, 0.0142],
         [0.0251, 0.0250, 0.0246,  ..., 0.0186, 0.0197, 0.0200],
         [0.0221, 0.0218, 0.0214,  ..., 0.0184, 0.0190, 0.0186]],

        [[0.0198, 0.0197, 0.0199,  ..., 0.0212, 0.0222, 0.0225],
         [0.0137, 0.0134, 0.0133,  ..., 0.0117, 0.0132, 0.0134],
         [0.0220, 0.0219, 0.0221,  ..., 0.0208, 0.0218, 0.0223],
         ...,
         [0.0190, 0.0192, 0.0202,  ..., 0.0216, 0.0222, 0.0210],
         [0.0141, 0.0141, 0.0144,  ..., 0.0138, 0.0146, 0.0140],
         [0.0120, 0.0119, 0.0120,  ..., 0.0122, 0.0129, 0.0120]],

        ...,

        [[0.0212, 0.0212, 0.0216,  ..., 0.0239, 0.0230, 0.0226],
         [0.0136, 0.0133, 0.0136,  ..., 0.0159, 0.0142, 0.0135],
         [0.0204, 0.0205, 0.0213,  ..., 0.0271, 0.0252, 0.0238],
         ...,
         [0.0288, 0.0290, 0.0296,  ..., 0.0286, 0.0291, 0.0300],
         [0.0235, 0.0236, 0.0237,  ..., 0.0209, 0.0216, 0.0238],
         [0.0211, 0.0212, 0.0211,  ..., 0.0189, 0.0196, 0.0211]],

        [[0.0274, 0.0272, 0.0270,  ..., 0.0301, 0.0293, 0.0292],
         [0.0234, 0.0226, 0.0219,  ..., 0.0221, 0.0208, 0.0213],
         [0.0141, 0.0139, 0.0141,  ..., 0.0185, 0.0168, 0.0164],
         ...,
         [0.0235, 0.0234, 0.0236,  ..., 0.0208, 0.0225, 0.0249],
         [0.0321, 0.0321, 0.0313,  ..., 0.0248, 0.0264, 0.0308],
         [0.0229, 0.0227, 0.0223,  ..., 0.0181, 0.0187, 0.0210]],

        [[0.0168, 0.0168, 0.0171,  ..., 0.0229, 0.0206, 0.0195],
         [0.0158, 0.0152, 0.0148,  ..., 0.0199, 0.0181, 0.0175],
         [0.0146, 0.0144, 0.0150,  ..., 0.0192, 0.0169, 0.0163],
         ...,
         [0.0221, 0.0224, 0.0225,  ..., 0.0233, 0.0242, 0.0259],
         [0.0268, 0.0269, 0.0264,  ..., 0.0264, 0.0269, 0.0296],
         [0.0225, 0.0226, 0.0225,  ..., 0.0233, 0.0228, 0.0234]]],
       device='cuda:0')
unsqueeze final volume shape (DDPM2d) torch.Size([1, 1, 96, 96, 50])
unsqueeze final volume (DDPM 2D) tensor([[[[[0.0196, 0.0196, 0.0198,  ..., 0.0205, 0.0200, 0.0197],
           [0.0213, 0.0208, 0.0206,  ..., 0.0182, 0.0185, 0.0185],
           [0.0233, 0.0229, 0.0232,  ..., 0.0194, 0.0200, 0.0197],
           ...,
           [0.0251, 0.0252, 0.0260,  ..., 0.0238, 0.0245, 0.0238],
           [0.0311, 0.0312, 0.0314,  ..., 0.0286, 0.0296, 0.0296],
           [0.0240, 0.0237, 0.0240,  ..., 0.0268, 0.0268, 0.0259]],

          [[0.0316, 0.0315, 0.0308,  ..., 0.0277, 0.0286, 0.0291],
           [0.0238, 0.0229, 0.0217,  ..., 0.0149, 0.0160, 0.0172],
           [0.0197, 0.0191, 0.0187,  ..., 0.0136, 0.0148, 0.0155],
           ...,
           [0.0155, 0.0155, 0.0159,  ..., 0.0138, 0.0147, 0.0142],
           [0.0251, 0.0250, 0.0246,  ..., 0.0186, 0.0197, 0.0200],
           [0.0221, 0.0218, 0.0214,  ..., 0.0184, 0.0190, 0.0186]],

          [[0.0198, 0.0197, 0.0199,  ..., 0.0212, 0.0222, 0.0225],
           [0.0137, 0.0134, 0.0133,  ..., 0.0117, 0.0132, 0.0134],
           [0.0220, 0.0219, 0.0221,  ..., 0.0208, 0.0218, 0.0223],
           ...,
           [0.0190, 0.0192, 0.0202,  ..., 0.0216, 0.0222, 0.0210],
           [0.0141, 0.0141, 0.0144,  ..., 0.0138, 0.0146, 0.0140],
           [0.0120, 0.0119, 0.0120,  ..., 0.0122, 0.0129, 0.0120]],

          ...,

          [[0.0212, 0.0212, 0.0216,  ..., 0.0239, 0.0230, 0.0226],
           [0.0136, 0.0133, 0.0136,  ..., 0.0159, 0.0142, 0.0135],
           [0.0204, 0.0205, 0.0213,  ..., 0.0271, 0.0252, 0.0238],
           ...,
           [0.0288, 0.0290, 0.0296,  ..., 0.0286, 0.0291, 0.0300],
           [0.0235, 0.0236, 0.0237,  ..., 0.0209, 0.0216, 0.0238],
           [0.0211, 0.0212, 0.0211,  ..., 0.0189, 0.0196, 0.0211]],

          [[0.0274, 0.0272, 0.0270,  ..., 0.0301, 0.0293, 0.0292],
           [0.0234, 0.0226, 0.0219,  ..., 0.0221, 0.0208, 0.0213],
           [0.0141, 0.0139, 0.0141,  ..., 0.0185, 0.0168, 0.0164],
           ...,
           [0.0235, 0.0234, 0.0236,  ..., 0.0208, 0.0225, 0.0249],
           [0.0321, 0.0321, 0.0313,  ..., 0.0248, 0.0264, 0.0308],
           [0.0229, 0.0227, 0.0223,  ..., 0.0181, 0.0187, 0.0210]],

          [[0.0168, 0.0168, 0.0171,  ..., 0.0229, 0.0206, 0.0195],
           [0.0158, 0.0152, 0.0148,  ..., 0.0199, 0.0181, 0.0175],
           [0.0146, 0.0144, 0.0150,  ..., 0.0192, 0.0169, 0.0163],
           ...,
           [0.0221, 0.0224, 0.0225,  ..., 0.0233, 0.0242, 0.0259],
           [0.0268, 0.0269, 0.0264,  ..., 0.0264, 0.0269, 0.0296],
           [0.0225, 0.0226, 0.0225,  ..., 0.0233, 0.0228, 0.0234]]]]],
       device='cuda:0')
==========
IN _TEST_STEP
==========
ERODING BRAIN MASK
MEDIAN FILTERING
SAVING OUTPUT - ORIGINAL, FINAL, MASK ETC
SAVING IMAGES!
Testing:  10%|â–ˆ         | 1/10 [00:12<01:55, 12.84s/it]==========
IN DDPM ON TEST STEP
==========
THE WEIRD CONDITION BIT CALLED "features" in DDPM_2D
IN SPARK ENCODER FORWARDDD
x in shape torch.Size([50, 1, 96, 96])
out features torch.Size([50, 512])
i'm i DDPM2d forward block (whch is basically the encoder)
Context vector c shape: torch.Size([50, 512])
shape features:  torch.Size([50, 512])
additng features to latern space
latent space: []
iAM IN THE FORWARD METHOD OF THE WEIRD GUASSIAN IN cond_DDPM.py. I WILL BE CALLING p_losses
i am in p_losses in guassian which seems to be crucial to everything
conditioning vector shape:  torch.Size([50, 512])
in plosses i am getting a noisy image x
x shape:  torch.Size([50, 1, 96, 96])
getting model out
Initial input shape: torch.Size([50, 1, 96, 96])

inputblocks
Before block 0, shape: torch.Size([50, 1, 96, 96])
After block 0, shape: torch.Size([50, 128, 96, 96])
-
Before block 1, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 1, shape: torch.Size([50, 128, 96, 96])
-
Before block 2, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 2, shape: torch.Size([50, 128, 96, 96])
-
Before block 3, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 3, shape: torch.Size([50, 128, 96, 96])
-
Before block 4, shape: torch.Size([50, 128, 96, 96])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 256])
After block 4, shape: torch.Size([50, 128, 48, 48])
-
Before block 5, shape: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 48, 48])
-
Before block 8, shape: torch.Size([50, 256, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 8, shape: torch.Size([50, 256, 24, 24])
-
Before block 9, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 9, shape: torch.Size([50, 256, 24, 24])
-
Before block 10, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 10, shape: torch.Size([50, 256, 24, 24])
-
Before block 11, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 11, shape: torch.Size([50, 256, 24, 24])
-

Before middle block, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
in unet attention block!
x shape torch.Size([50, 256, 24, 24])
out dims torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])


After middle block, shape: torch.Size([50, 256, 24, 24])
-



outputblocks
Before block 0, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 0, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 0, shape: torch.Size([50, 256, 24, 24])
-
Before block 1, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 1, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 1, shape: torch.Size([50, 256, 24, 24])
-
Before block 2, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 2, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 2, shape: torch.Size([50, 256, 24, 24])
-
Before block 3, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 3, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 3, shape: torch.Size([50, 256, 48, 48])
-
Before block 4, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 4, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 4, shape: torch.Size([50, 256, 48, 48])
-
Before block 5, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 5, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 6, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 7, shape: torch.Size([50, 384, 48, 48])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 96, 96])
-
Before block 8, shape: torch.Size([50, 256, 96, 96])
After concatenation in upsampling block 8, shape: torch.Size([50, 384, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 8, shape: torch.Size([50, 128, 96, 96])
-
Before block 9, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 9, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 9, shape: torch.Size([50, 128, 96, 96])
-
Before block 10, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 10, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 10, shape: torch.Size([50, 128, 96, 96])
-
Before block 11, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 11, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 11, shape: torch.Size([50, 128, 96, 96])
-

Before Final layer shape: torch.Size([50, 128, 96, 96])
Final output shape: torch.Size([50, 1, 96, 96])
model out shape:  torch.Size([50, 1, 96, 96])
iAM IN THE FORWARD METHOD OF THE WEIRD GUASSIAN IN cond_DDPM.py. I WILL BE CALLING p_losses
i am in p_losses in guassian which seems to be crucial to everything
conditioning vector shape:  torch.Size([50, 512])
in plosses i am getting a noisy image x
x shape:  torch.Size([50, 1, 96, 96])
getting model out
Initial input shape: torch.Size([50, 1, 96, 96])

inputblocks
Before block 0, shape: torch.Size([50, 1, 96, 96])
After block 0, shape: torch.Size([50, 128, 96, 96])
-
Before block 1, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 1, shape: torch.Size([50, 128, 96, 96])
-
Before block 2, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 2, shape: torch.Size([50, 128, 96, 96])
-
Before block 3, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 3, shape: torch.Size([50, 128, 96, 96])
-
Before block 4, shape: torch.Size([50, 128, 96, 96])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 256])
After block 4, shape: torch.Size([50, 128, 48, 48])
-
Before block 5, shape: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 48, 48])
-
Before block 8, shape: torch.Size([50, 256, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 8, shape: torch.Size([50, 256, 24, 24])
-
Before block 9, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 9, shape: torch.Size([50, 256, 24, 24])
-
Before block 10, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 10, shape: torch.Size([50, 256, 24, 24])
-
Before block 11, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 11, shape: torch.Size([50, 256, 24, 24])
-

Before middle block, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
in unet attention block!
x shape torch.Size([50, 256, 24, 24])
out dims torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])


After middle block, shape: torch.Size([50, 256, 24, 24])
-



outputblocks
Before block 0, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 0, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 0, shape: torch.Size([50, 256, 24, 24])
-
Before block 1, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 1, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 1, shape: torch.Size([50, 256, 24, 24])
-
Before block 2, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 2, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 2, shape: torch.Size([50, 256, 24, 24])
-
Before block 3, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 3, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 3, shape: torch.Size([50, 256, 48, 48])
-
Before block 4, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 4, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 4, shape: torch.Size([50, 256, 48, 48])
-
Before block 5, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 5, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 6, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 7, shape: torch.Size([50, 384, 48, 48])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 96, 96])
-
Before block 8, shape: torch.Size([50, 256, 96, 96])
After concatenation in upsampling block 8, shape: torch.Size([50, 384, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 8, shape: torch.Size([50, 128, 96, 96])
-
Before block 9, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 9, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 9, shape: torch.Size([50, 128, 96, 96])
-
Before block 10, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 10, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 10, shape: torch.Size([50, 128, 96, 96])
-
Before block 11, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 11, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 11, shape: torch.Size([50, 128, 96, 96])
-

Before Final layer shape: torch.Size([50, 128, 96, 96])
Final output shape: torch.Size([50, 1, 96, 96])
model out shape:  torch.Size([50, 1, 96, 96])
iAM IN THE FORWARD METHOD OF THE WEIRD GUASSIAN IN cond_DDPM.py. I WILL BE CALLING p_losses
i am in p_losses in guassian which seems to be crucial to everything
conditioning vector shape:  torch.Size([50, 512])
in plosses i am getting a noisy image x
x shape:  torch.Size([50, 1, 96, 96])
getting model out
Initial input shape: torch.Size([50, 1, 96, 96])

inputblocks
Before block 0, shape: torch.Size([50, 1, 96, 96])
After block 0, shape: torch.Size([50, 128, 96, 96])
-
Before block 1, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 1, shape: torch.Size([50, 128, 96, 96])
-
Before block 2, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 2, shape: torch.Size([50, 128, 96, 96])
-
Before block 3, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 3, shape: torch.Size([50, 128, 96, 96])
-
Before block 4, shape: torch.Size([50, 128, 96, 96])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 256])
After block 4, shape: torch.Size([50, 128, 48, 48])
-
Before block 5, shape: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 48, 48])
-
Before block 8, shape: torch.Size([50, 256, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 8, shape: torch.Size([50, 256, 24, 24])
-
Before block 9, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 9, shape: torch.Size([50, 256, 24, 24])
-
Before block 10, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 10, shape: torch.Size([50, 256, 24, 24])
-
Before block 11, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 11, shape: torch.Size([50, 256, 24, 24])
-

Before middle block, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
in unet attention block!
x shape torch.Size([50, 256, 24, 24])
out dims torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])


After middle block, shape: torch.Size([50, 256, 24, 24])
-



outputblocks
Before block 0, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 0, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 0, shape: torch.Size([50, 256, 24, 24])
-
Before block 1, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 1, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 1, shape: torch.Size([50, 256, 24, 24])
-
Before block 2, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 2, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 2, shape: torch.Size([50, 256, 24, 24])
-
Before block 3, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 3, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 3, shape: torch.Size([50, 256, 48, 48])
-
Before block 4, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 4, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 4, shape: torch.Size([50, 256, 48, 48])
-
Before block 5, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 5, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 6, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 7, shape: torch.Size([50, 384, 48, 48])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 96, 96])
-
Before block 8, shape: torch.Size([50, 256, 96, 96])
After concatenation in upsampling block 8, shape: torch.Size([50, 384, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 8, shape: torch.Size([50, 128, 96, 96])
-
Before block 9, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 9, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 9, shape: torch.Size([50, 128, 96, 96])
-
Before block 10, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 10, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 10, shape: torch.Size([50, 128, 96, 96])
-
Before block 11, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 11, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 11, shape: torch.Size([50, 128, 96, 96])
-

Before Final layer shape: torch.Size([50, 128, 96, 96])
Final output shape: torch.Size([50, 1, 96, 96])
model out shape:  torch.Size([50, 1, 96, 96])
reconstruction shape torch.Size([50, 1, 96, 96])
reconstruction tensor([[[[0.0184, 0.0156, 0.0198,  ..., 0.0185, 0.0219, 0.0226],
          [0.0231, 0.0134, 0.0125,  ..., 0.0133, 0.0221, 0.0144],
          [0.0173, 0.0111, 0.0180,  ..., 0.0166, 0.0104, 0.0094],
          ...,
          [0.0195, 0.0081, 0.0167,  ..., 0.0198, 0.0135, 0.0116],
          [0.0211, 0.0142, 0.0089,  ..., 0.0155, 0.0215, 0.0112],
          [0.0108, 0.0095, 0.0084,  ..., 0.0132, 0.0170, 0.0071]]],


        [[[0.0186, 0.0155, 0.0207,  ..., 0.0194, 0.0217, 0.0229],
          [0.0229, 0.0129, 0.0128,  ..., 0.0138, 0.0213, 0.0137],
          [0.0177, 0.0112, 0.0186,  ..., 0.0175, 0.0104, 0.0092],
          ...,
          [0.0209, 0.0092, 0.0179,  ..., 0.0205, 0.0138, 0.0116],
          [0.0212, 0.0139, 0.0093,  ..., 0.0160, 0.0215, 0.0113],
          [0.0110, 0.0085, 0.0083,  ..., 0.0133, 0.0168, 0.0072]]],


        [[[0.0195, 0.0162, 0.0214,  ..., 0.0205, 0.0225, 0.0237],
          [0.0234, 0.0126, 0.0131,  ..., 0.0146, 0.0221, 0.0146],
          [0.0181, 0.0111, 0.0194,  ..., 0.0185, 0.0112, 0.0102],
          ...,
          [0.0208, 0.0094, 0.0185,  ..., 0.0212, 0.0145, 0.0126],
          [0.0215, 0.0141, 0.0100,  ..., 0.0166, 0.0229, 0.0128],
          [0.0118, 0.0093, 0.0099,  ..., 0.0143, 0.0187, 0.0088]]],


        ...,


        [[[0.0232, 0.0186, 0.0210,  ..., 0.0198, 0.0196, 0.0247],
          [0.0251, 0.0102, 0.0094,  ..., 0.0107, 0.0134, 0.0103],
          [0.0212, 0.0102, 0.0170,  ..., 0.0182, 0.0109, 0.0103],
          ...,
          [0.0224, 0.0095, 0.0227,  ..., 0.0243, 0.0142, 0.0121],
          [0.0241, 0.0118, 0.0102,  ..., 0.0150, 0.0138, 0.0076],
          [0.0177, 0.0130, 0.0122,  ..., 0.0163, 0.0146, 0.0093]]],


        [[[0.0224, 0.0180, 0.0209,  ..., 0.0197, 0.0198, 0.0239],
          [0.0245, 0.0101, 0.0093,  ..., 0.0104, 0.0137, 0.0099],
          [0.0209, 0.0102, 0.0168,  ..., 0.0181, 0.0108, 0.0098],
          ...,
          [0.0209, 0.0072, 0.0195,  ..., 0.0239, 0.0135, 0.0115],
          [0.0227, 0.0101, 0.0081,  ..., 0.0146, 0.0138, 0.0070],
          [0.0162, 0.0111, 0.0106,  ..., 0.0155, 0.0137, 0.0076]]],


        [[[0.0215, 0.0176, 0.0207,  ..., 0.0197, 0.0200, 0.0232],
          [0.0243, 0.0108, 0.0098,  ..., 0.0108, 0.0149, 0.0098],
          [0.0205, 0.0107, 0.0168,  ..., 0.0181, 0.0110, 0.0093],
          ...,
          [0.0203, 0.0067, 0.0182,  ..., 0.0234, 0.0133, 0.0107],
          [0.0223, 0.0103, 0.0075,  ..., 0.0146, 0.0145, 0.0066],
          [0.0146, 0.0103, 0.0093,  ..., 0.0145, 0.0131, 0.0060]]]],
       device='cuda:0')
FINAL VOLUME (DDPM) shape torch.Size([96, 96, 50])
FINAL VOLUME tensor([[[0.0184, 0.0186, 0.0195,  ..., 0.0232, 0.0224, 0.0215],
         [0.0156, 0.0155, 0.0162,  ..., 0.0186, 0.0180, 0.0176],
         [0.0198, 0.0207, 0.0214,  ..., 0.0210, 0.0209, 0.0207],
         ...,
         [0.0185, 0.0194, 0.0205,  ..., 0.0198, 0.0197, 0.0197],
         [0.0219, 0.0217, 0.0225,  ..., 0.0196, 0.0198, 0.0200],
         [0.0226, 0.0229, 0.0237,  ..., 0.0247, 0.0239, 0.0232]],

        [[0.0231, 0.0229, 0.0234,  ..., 0.0251, 0.0245, 0.0243],
         [0.0134, 0.0129, 0.0126,  ..., 0.0102, 0.0101, 0.0108],
         [0.0125, 0.0128, 0.0131,  ..., 0.0094, 0.0093, 0.0098],
         ...,
         [0.0133, 0.0138, 0.0146,  ..., 0.0107, 0.0104, 0.0108],
         [0.0221, 0.0213, 0.0221,  ..., 0.0134, 0.0137, 0.0149],
         [0.0144, 0.0137, 0.0146,  ..., 0.0103, 0.0099, 0.0098]],

        [[0.0173, 0.0177, 0.0181,  ..., 0.0212, 0.0209, 0.0205],
         [0.0111, 0.0112, 0.0111,  ..., 0.0102, 0.0102, 0.0107],
         [0.0180, 0.0186, 0.0194,  ..., 0.0170, 0.0168, 0.0168],
         ...,
         [0.0166, 0.0175, 0.0185,  ..., 0.0182, 0.0181, 0.0181],
         [0.0104, 0.0104, 0.0112,  ..., 0.0109, 0.0108, 0.0110],
         [0.0094, 0.0092, 0.0102,  ..., 0.0103, 0.0098, 0.0093]],

        ...,

        [[0.0195, 0.0209, 0.0208,  ..., 0.0224, 0.0209, 0.0203],
         [0.0081, 0.0092, 0.0094,  ..., 0.0095, 0.0072, 0.0067],
         [0.0167, 0.0179, 0.0185,  ..., 0.0227, 0.0195, 0.0182],
         ...,
         [0.0198, 0.0205, 0.0212,  ..., 0.0243, 0.0239, 0.0234],
         [0.0135, 0.0138, 0.0145,  ..., 0.0142, 0.0135, 0.0133],
         [0.0116, 0.0116, 0.0126,  ..., 0.0121, 0.0115, 0.0107]],

        [[0.0211, 0.0212, 0.0215,  ..., 0.0241, 0.0227, 0.0223],
         [0.0142, 0.0139, 0.0141,  ..., 0.0118, 0.0101, 0.0103],
         [0.0089, 0.0093, 0.0100,  ..., 0.0102, 0.0081, 0.0075],
         ...,
         [0.0155, 0.0160, 0.0166,  ..., 0.0150, 0.0146, 0.0146],
         [0.0215, 0.0215, 0.0229,  ..., 0.0138, 0.0138, 0.0145],
         [0.0112, 0.0113, 0.0128,  ..., 0.0076, 0.0070, 0.0066]],

        [[0.0108, 0.0110, 0.0118,  ..., 0.0177, 0.0162, 0.0146],
         [0.0095, 0.0085, 0.0093,  ..., 0.0130, 0.0111, 0.0103],
         [0.0084, 0.0083, 0.0099,  ..., 0.0122, 0.0106, 0.0093],
         ...,
         [0.0132, 0.0133, 0.0143,  ..., 0.0163, 0.0155, 0.0145],
         [0.0170, 0.0168, 0.0187,  ..., 0.0146, 0.0137, 0.0131],
         [0.0071, 0.0072, 0.0088,  ..., 0.0093, 0.0076, 0.0060]]],
       device='cuda:0')
unsqueeze final volume shape (DDPM2d) torch.Size([1, 1, 96, 96, 50])
unsqueeze final volume (DDPM 2D) tensor([[[[[0.0184, 0.0186, 0.0195,  ..., 0.0232, 0.0224, 0.0215],
           [0.0156, 0.0155, 0.0162,  ..., 0.0186, 0.0180, 0.0176],
           [0.0198, 0.0207, 0.0214,  ..., 0.0210, 0.0209, 0.0207],
           ...,
           [0.0185, 0.0194, 0.0205,  ..., 0.0198, 0.0197, 0.0197],
           [0.0219, 0.0217, 0.0225,  ..., 0.0196, 0.0198, 0.0200],
           [0.0226, 0.0229, 0.0237,  ..., 0.0247, 0.0239, 0.0232]],

          [[0.0231, 0.0229, 0.0234,  ..., 0.0251, 0.0245, 0.0243],
           [0.0134, 0.0129, 0.0126,  ..., 0.0102, 0.0101, 0.0108],
           [0.0125, 0.0128, 0.0131,  ..., 0.0094, 0.0093, 0.0098],
           ...,
           [0.0133, 0.0138, 0.0146,  ..., 0.0107, 0.0104, 0.0108],
           [0.0221, 0.0213, 0.0221,  ..., 0.0134, 0.0137, 0.0149],
           [0.0144, 0.0137, 0.0146,  ..., 0.0103, 0.0099, 0.0098]],

          [[0.0173, 0.0177, 0.0181,  ..., 0.0212, 0.0209, 0.0205],
           [0.0111, 0.0112, 0.0111,  ..., 0.0102, 0.0102, 0.0107],
           [0.0180, 0.0186, 0.0194,  ..., 0.0170, 0.0168, 0.0168],
           ...,
           [0.0166, 0.0175, 0.0185,  ..., 0.0182, 0.0181, 0.0181],
           [0.0104, 0.0104, 0.0112,  ..., 0.0109, 0.0108, 0.0110],
           [0.0094, 0.0092, 0.0102,  ..., 0.0103, 0.0098, 0.0093]],

          ...,

          [[0.0195, 0.0209, 0.0208,  ..., 0.0224, 0.0209, 0.0203],
           [0.0081, 0.0092, 0.0094,  ..., 0.0095, 0.0072, 0.0067],
           [0.0167, 0.0179, 0.0185,  ..., 0.0227, 0.0195, 0.0182],
           ...,
           [0.0198, 0.0205, 0.0212,  ..., 0.0243, 0.0239, 0.0234],
           [0.0135, 0.0138, 0.0145,  ..., 0.0142, 0.0135, 0.0133],
           [0.0116, 0.0116, 0.0126,  ..., 0.0121, 0.0115, 0.0107]],

          [[0.0211, 0.0212, 0.0215,  ..., 0.0241, 0.0227, 0.0223],
           [0.0142, 0.0139, 0.0141,  ..., 0.0118, 0.0101, 0.0103],
           [0.0089, 0.0093, 0.0100,  ..., 0.0102, 0.0081, 0.0075],
           ...,
           [0.0155, 0.0160, 0.0166,  ..., 0.0150, 0.0146, 0.0146],
           [0.0215, 0.0215, 0.0229,  ..., 0.0138, 0.0138, 0.0145],
           [0.0112, 0.0113, 0.0128,  ..., 0.0076, 0.0070, 0.0066]],

          [[0.0108, 0.0110, 0.0118,  ..., 0.0177, 0.0162, 0.0146],
           [0.0095, 0.0085, 0.0093,  ..., 0.0130, 0.0111, 0.0103],
           [0.0084, 0.0083, 0.0099,  ..., 0.0122, 0.0106, 0.0093],
           ...,
           [0.0132, 0.0133, 0.0143,  ..., 0.0163, 0.0155, 0.0145],
           [0.0170, 0.0168, 0.0187,  ..., 0.0146, 0.0137, 0.0131],
           [0.0071, 0.0072, 0.0088,  ..., 0.0093, 0.0076, 0.0060]]]]],
       device='cuda:0')
==========
IN _TEST_STEP
==========
ERODING BRAIN MASK
MEDIAN FILTERING
SAVING OUTPUT - ORIGINAL, FINAL, MASK ETC
SAVING IMAGES!
Testing:  20%|â–ˆâ–ˆ        | 2/10 [00:16<00:57,  7.23s/it]==========
IN DDPM ON TEST STEP
==========
THE WEIRD CONDITION BIT CALLED "features" in DDPM_2D
IN SPARK ENCODER FORWARDDD
x in shape torch.Size([50, 1, 96, 96])
out features torch.Size([50, 512])
i'm i DDPM2d forward block (whch is basically the encoder)
Context vector c shape: torch.Size([50, 512])
shape features:  torch.Size([50, 512])
additng features to latern space
latent space: []
iAM IN THE FORWARD METHOD OF THE WEIRD GUASSIAN IN cond_DDPM.py. I WILL BE CALLING p_losses
i am in p_losses in guassian which seems to be crucial to everything
conditioning vector shape:  torch.Size([50, 512])
in plosses i am getting a noisy image x
x shape:  torch.Size([50, 1, 96, 96])
getting model out
Initial input shape: torch.Size([50, 1, 96, 96])

inputblocks
Before block 0, shape: torch.Size([50, 1, 96, 96])
After block 0, shape: torch.Size([50, 128, 96, 96])
-
Before block 1, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 1, shape: torch.Size([50, 128, 96, 96])
-
Before block 2, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 2, shape: torch.Size([50, 128, 96, 96])
-
Before block 3, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 3, shape: torch.Size([50, 128, 96, 96])
-
Before block 4, shape: torch.Size([50, 128, 96, 96])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 256])
After block 4, shape: torch.Size([50, 128, 48, 48])
-
Before block 5, shape: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 48, 48])
-
Before block 8, shape: torch.Size([50, 256, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 8, shape: torch.Size([50, 256, 24, 24])
-
Before block 9, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 9, shape: torch.Size([50, 256, 24, 24])
-
Before block 10, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 10, shape: torch.Size([50, 256, 24, 24])
-
Before block 11, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 11, shape: torch.Size([50, 256, 24, 24])
-

Before middle block, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
in unet attention block!
x shape torch.Size([50, 256, 24, 24])
out dims torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])


After middle block, shape: torch.Size([50, 256, 24, 24])
-



outputblocks
Before block 0, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 0, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 0, shape: torch.Size([50, 256, 24, 24])
-
Before block 1, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 1, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 1, shape: torch.Size([50, 256, 24, 24])
-
Before block 2, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 2, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 2, shape: torch.Size([50, 256, 24, 24])
-
Before block 3, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 3, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 3, shape: torch.Size([50, 256, 48, 48])
-
Before block 4, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 4, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 4, shape: torch.Size([50, 256, 48, 48])
-
Before block 5, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 5, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 6, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 7, shape: torch.Size([50, 384, 48, 48])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 96, 96])
-
Before block 8, shape: torch.Size([50, 256, 96, 96])
After concatenation in upsampling block 8, shape: torch.Size([50, 384, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 8, shape: torch.Size([50, 128, 96, 96])
-
Before block 9, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 9, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 9, shape: torch.Size([50, 128, 96, 96])
-
Before block 10, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 10, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 10, shape: torch.Size([50, 128, 96, 96])
-
Before block 11, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 11, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 11, shape: torch.Size([50, 128, 96, 96])
-

Before Final layer shape: torch.Size([50, 128, 96, 96])
Final output shape: torch.Size([50, 1, 96, 96])
model out shape:  torch.Size([50, 1, 96, 96])
iAM IN THE FORWARD METHOD OF THE WEIRD GUASSIAN IN cond_DDPM.py. I WILL BE CALLING p_losses
i am in p_losses in guassian which seems to be crucial to everything
conditioning vector shape:  torch.Size([50, 512])
in plosses i am getting a noisy image x
x shape:  torch.Size([50, 1, 96, 96])
getting model out
Initial input shape: torch.Size([50, 1, 96, 96])

inputblocks
Before block 0, shape: torch.Size([50, 1, 96, 96])
After block 0, shape: torch.Size([50, 128, 96, 96])
-
Before block 1, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 1, shape: torch.Size([50, 128, 96, 96])
-
Before block 2, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 2, shape: torch.Size([50, 128, 96, 96])
-
Before block 3, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 3, shape: torch.Size([50, 128, 96, 96])
-
Before block 4, shape: torch.Size([50, 128, 96, 96])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 256])
After block 4, shape: torch.Size([50, 128, 48, 48])
-
Before block 5, shape: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 48, 48])
-
Before block 8, shape: torch.Size([50, 256, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 8, shape: torch.Size([50, 256, 24, 24])
-
Before block 9, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 9, shape: torch.Size([50, 256, 24, 24])
-
Before block 10, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 10, shape: torch.Size([50, 256, 24, 24])
-
Before block 11, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 11, shape: torch.Size([50, 256, 24, 24])
-

Before middle block, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
in unet attention block!
x shape torch.Size([50, 256, 24, 24])
out dims torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])


After middle block, shape: torch.Size([50, 256, 24, 24])
-



outputblocks
Before block 0, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 0, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 0, shape: torch.Size([50, 256, 24, 24])
-
Before block 1, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 1, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 1, shape: torch.Size([50, 256, 24, 24])
-
Before block 2, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 2, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 2, shape: torch.Size([50, 256, 24, 24])
-
Before block 3, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 3, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 3, shape: torch.Size([50, 256, 48, 48])
-
Before block 4, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 4, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 4, shape: torch.Size([50, 256, 48, 48])
-
Before block 5, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 5, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 6, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 7, shape: torch.Size([50, 384, 48, 48])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 96, 96])
-
Before block 8, shape: torch.Size([50, 256, 96, 96])
After concatenation in upsampling block 8, shape: torch.Size([50, 384, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 8, shape: torch.Size([50, 128, 96, 96])
-
Before block 9, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 9, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 9, shape: torch.Size([50, 128, 96, 96])
-
Before block 10, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 10, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 10, shape: torch.Size([50, 128, 96, 96])
-
Before block 11, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 11, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 11, shape: torch.Size([50, 128, 96, 96])
-

Before Final layer shape: torch.Size([50, 128, 96, 96])
Final output shape: torch.Size([50, 1, 96, 96])
model out shape:  torch.Size([50, 1, 96, 96])
iAM IN THE FORWARD METHOD OF THE WEIRD GUASSIAN IN cond_DDPM.py. I WILL BE CALLING p_losses
i am in p_losses in guassian which seems to be crucial to everything
conditioning vector shape:  torch.Size([50, 512])
in plosses i am getting a noisy image x
x shape:  torch.Size([50, 1, 96, 96])
getting model out
Initial input shape: torch.Size([50, 1, 96, 96])

inputblocks
Before block 0, shape: torch.Size([50, 1, 96, 96])
After block 0, shape: torch.Size([50, 128, 96, 96])
-
Before block 1, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 1, shape: torch.Size([50, 128, 96, 96])
-
Before block 2, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 2, shape: torch.Size([50, 128, 96, 96])
-
Before block 3, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 3, shape: torch.Size([50, 128, 96, 96])
-
Before block 4, shape: torch.Size([50, 128, 96, 96])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 256])
After block 4, shape: torch.Size([50, 128, 48, 48])
-
Before block 5, shape: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 48, 48])
-
Before block 8, shape: torch.Size([50, 256, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 8, shape: torch.Size([50, 256, 24, 24])
-
Before block 9, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 9, shape: torch.Size([50, 256, 24, 24])
-
Before block 10, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 10, shape: torch.Size([50, 256, 24, 24])
-
Before block 11, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 11, shape: torch.Size([50, 256, 24, 24])
-

Before middle block, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
in unet attention block!
x shape torch.Size([50, 256, 24, 24])
out dims torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])


After middle block, shape: torch.Size([50, 256, 24, 24])
-



outputblocks
Before block 0, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 0, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 0, shape: torch.Size([50, 256, 24, 24])
-
Before block 1, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 1, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 1, shape: torch.Size([50, 256, 24, 24])
-
Before block 2, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 2, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 2, shape: torch.Size([50, 256, 24, 24])
-
Before block 3, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 3, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 3, shape: torch.Size([50, 256, 48, 48])
-
Before block 4, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 4, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 4, shape: torch.Size([50, 256, 48, 48])
-
Before block 5, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 5, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 6, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 7, shape: torch.Size([50, 384, 48, 48])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 96, 96])
-
Before block 8, shape: torch.Size([50, 256, 96, 96])
After concatenation in upsampling block 8, shape: torch.Size([50, 384, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 8, shape: torch.Size([50, 128, 96, 96])
-
Before block 9, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 9, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 9, shape: torch.Size([50, 128, 96, 96])
-
Before block 10, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 10, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 10, shape: torch.Size([50, 128, 96, 96])
-
Before block 11, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 11, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 11, shape: torch.Size([50, 128, 96, 96])
-

Before Final layer shape: torch.Size([50, 128, 96, 96])
Final output shape: torch.Size([50, 1, 96, 96])
model out shape:  torch.Size([50, 1, 96, 96])
reconstruction shape torch.Size([50, 1, 96, 96])
reconstruction tensor([[[[0.0291, 0.0215, 0.0188,  ..., 0.0253, 0.0265, 0.0255],
          [0.0207, 0.0139, 0.0123,  ..., 0.0156, 0.0191, 0.0169],
          [0.0153, 0.0111, 0.0216,  ..., 0.0241, 0.0097, 0.0121],
          ...,
          [0.0190, 0.0092, 0.0221,  ..., 0.0285, 0.0211, 0.0160],
          [0.0247, 0.0164, 0.0151,  ..., 0.0235, 0.0268, 0.0136],
          [0.0143, 0.0144, 0.0180,  ..., 0.0234, 0.0261, 0.0151]]],


        [[[0.0295, 0.0217, 0.0190,  ..., 0.0256, 0.0265, 0.0258],
          [0.0211, 0.0142, 0.0128,  ..., 0.0160, 0.0190, 0.0170],
          [0.0158, 0.0117, 0.0223,  ..., 0.0247, 0.0100, 0.0125],
          ...,
          [0.0194, 0.0096, 0.0225,  ..., 0.0291, 0.0218, 0.0168],
          [0.0246, 0.0164, 0.0152,  ..., 0.0241, 0.0273, 0.0143],
          [0.0144, 0.0147, 0.0184,  ..., 0.0239, 0.0267, 0.0161]]],


        [[[0.0293, 0.0214, 0.0190,  ..., 0.0260, 0.0268, 0.0260],
          [0.0212, 0.0139, 0.0129,  ..., 0.0162, 0.0190, 0.0169],
          [0.0162, 0.0120, 0.0227,  ..., 0.0251, 0.0102, 0.0125],
          ...,
          [0.0195, 0.0098, 0.0230,  ..., 0.0298, 0.0222, 0.0171],
          [0.0246, 0.0164, 0.0155,  ..., 0.0243, 0.0274, 0.0143],
          [0.0146, 0.0146, 0.0187,  ..., 0.0243, 0.0271, 0.0166]]],


        ...,


        [[[0.0343, 0.0247, 0.0187,  ..., 0.0219, 0.0224, 0.0248],
          [0.0199, 0.0102, 0.0093,  ..., 0.0138, 0.0135, 0.0117],
          [0.0155, 0.0090, 0.0193,  ..., 0.0273, 0.0133, 0.0117],
          ...,
          [0.0186, 0.0084, 0.0210,  ..., 0.0273, 0.0204, 0.0152],
          [0.0234, 0.0129, 0.0131,  ..., 0.0179, 0.0195, 0.0101],
          [0.0177, 0.0165, 0.0178,  ..., 0.0216, 0.0258, 0.0199]]],


        [[[0.0347, 0.0251, 0.0194,  ..., 0.0228, 0.0235, 0.0252],
          [0.0198, 0.0107, 0.0100,  ..., 0.0145, 0.0147, 0.0125],
          [0.0155, 0.0096, 0.0198,  ..., 0.0277, 0.0134, 0.0119],
          ...,
          [0.0189, 0.0085, 0.0206,  ..., 0.0275, 0.0208, 0.0154],
          [0.0236, 0.0130, 0.0131,  ..., 0.0188, 0.0209, 0.0106],
          [0.0172, 0.0159, 0.0174,  ..., 0.0217, 0.0260, 0.0191]]],


        [[[0.0344, 0.0253, 0.0194,  ..., 0.0232, 0.0244, 0.0245],
          [0.0198, 0.0116, 0.0103,  ..., 0.0152, 0.0164, 0.0129],
          [0.0152, 0.0100, 0.0195,  ..., 0.0276, 0.0133, 0.0113],
          ...,
          [0.0188, 0.0085, 0.0199,  ..., 0.0270, 0.0210, 0.0156],
          [0.0239, 0.0141, 0.0130,  ..., 0.0192, 0.0224, 0.0115],
          [0.0159, 0.0153, 0.0166,  ..., 0.0212, 0.0261, 0.0181]]]],
       device='cuda:0')
FINAL VOLUME (DDPM) shape torch.Size([96, 96, 50])
FINAL VOLUME tensor([[[0.0291, 0.0295, 0.0293,  ..., 0.0343, 0.0347, 0.0344],
         [0.0215, 0.0217, 0.0214,  ..., 0.0247, 0.0251, 0.0253],
         [0.0188, 0.0190, 0.0190,  ..., 0.0187, 0.0194, 0.0194],
         ...,
         [0.0253, 0.0256, 0.0260,  ..., 0.0219, 0.0228, 0.0232],
         [0.0265, 0.0265, 0.0268,  ..., 0.0224, 0.0235, 0.0244],
         [0.0255, 0.0258, 0.0260,  ..., 0.0248, 0.0252, 0.0245]],

        [[0.0207, 0.0211, 0.0212,  ..., 0.0199, 0.0198, 0.0198],
         [0.0139, 0.0142, 0.0139,  ..., 0.0102, 0.0107, 0.0116],
         [0.0123, 0.0128, 0.0129,  ..., 0.0093, 0.0100, 0.0103],
         ...,
         [0.0156, 0.0160, 0.0162,  ..., 0.0138, 0.0145, 0.0152],
         [0.0191, 0.0190, 0.0190,  ..., 0.0135, 0.0147, 0.0164],
         [0.0169, 0.0170, 0.0169,  ..., 0.0117, 0.0125, 0.0129]],

        [[0.0153, 0.0158, 0.0162,  ..., 0.0155, 0.0155, 0.0152],
         [0.0111, 0.0117, 0.0120,  ..., 0.0090, 0.0096, 0.0100],
         [0.0216, 0.0223, 0.0227,  ..., 0.0193, 0.0198, 0.0195],
         ...,
         [0.0241, 0.0247, 0.0251,  ..., 0.0273, 0.0277, 0.0276],
         [0.0097, 0.0100, 0.0102,  ..., 0.0133, 0.0134, 0.0133],
         [0.0121, 0.0125, 0.0125,  ..., 0.0117, 0.0119, 0.0113]],

        ...,

        [[0.0190, 0.0194, 0.0195,  ..., 0.0186, 0.0189, 0.0188],
         [0.0092, 0.0096, 0.0098,  ..., 0.0084, 0.0085, 0.0085],
         [0.0221, 0.0225, 0.0230,  ..., 0.0210, 0.0206, 0.0199],
         ...,
         [0.0285, 0.0291, 0.0298,  ..., 0.0273, 0.0275, 0.0270],
         [0.0211, 0.0218, 0.0222,  ..., 0.0204, 0.0208, 0.0210],
         [0.0160, 0.0168, 0.0171,  ..., 0.0152, 0.0154, 0.0156]],

        [[0.0247, 0.0246, 0.0246,  ..., 0.0234, 0.0236, 0.0239],
         [0.0164, 0.0164, 0.0164,  ..., 0.0129, 0.0130, 0.0141],
         [0.0151, 0.0152, 0.0155,  ..., 0.0131, 0.0131, 0.0130],
         ...,
         [0.0235, 0.0241, 0.0243,  ..., 0.0179, 0.0188, 0.0192],
         [0.0268, 0.0273, 0.0274,  ..., 0.0195, 0.0209, 0.0224],
         [0.0136, 0.0143, 0.0143,  ..., 0.0101, 0.0106, 0.0115]],

        [[0.0143, 0.0144, 0.0146,  ..., 0.0177, 0.0172, 0.0159],
         [0.0144, 0.0147, 0.0146,  ..., 0.0165, 0.0159, 0.0153],
         [0.0180, 0.0184, 0.0187,  ..., 0.0178, 0.0174, 0.0166],
         ...,
         [0.0234, 0.0239, 0.0243,  ..., 0.0216, 0.0217, 0.0212],
         [0.0261, 0.0267, 0.0271,  ..., 0.0258, 0.0260, 0.0261],
         [0.0151, 0.0161, 0.0166,  ..., 0.0199, 0.0191, 0.0181]]],
       device='cuda:0')
unsqueeze final volume shape (DDPM2d) torch.Size([1, 1, 96, 96, 50])
unsqueeze final volume (DDPM 2D) tensor([[[[[0.0291, 0.0295, 0.0293,  ..., 0.0343, 0.0347, 0.0344],
           [0.0215, 0.0217, 0.0214,  ..., 0.0247, 0.0251, 0.0253],
           [0.0188, 0.0190, 0.0190,  ..., 0.0187, 0.0194, 0.0194],
           ...,
           [0.0253, 0.0256, 0.0260,  ..., 0.0219, 0.0228, 0.0232],
           [0.0265, 0.0265, 0.0268,  ..., 0.0224, 0.0235, 0.0244],
           [0.0255, 0.0258, 0.0260,  ..., 0.0248, 0.0252, 0.0245]],

          [[0.0207, 0.0211, 0.0212,  ..., 0.0199, 0.0198, 0.0198],
           [0.0139, 0.0142, 0.0139,  ..., 0.0102, 0.0107, 0.0116],
           [0.0123, 0.0128, 0.0129,  ..., 0.0093, 0.0100, 0.0103],
           ...,
           [0.0156, 0.0160, 0.0162,  ..., 0.0138, 0.0145, 0.0152],
           [0.0191, 0.0190, 0.0190,  ..., 0.0135, 0.0147, 0.0164],
           [0.0169, 0.0170, 0.0169,  ..., 0.0117, 0.0125, 0.0129]],

          [[0.0153, 0.0158, 0.0162,  ..., 0.0155, 0.0155, 0.0152],
           [0.0111, 0.0117, 0.0120,  ..., 0.0090, 0.0096, 0.0100],
           [0.0216, 0.0223, 0.0227,  ..., 0.0193, 0.0198, 0.0195],
           ...,
           [0.0241, 0.0247, 0.0251,  ..., 0.0273, 0.0277, 0.0276],
           [0.0097, 0.0100, 0.0102,  ..., 0.0133, 0.0134, 0.0133],
           [0.0121, 0.0125, 0.0125,  ..., 0.0117, 0.0119, 0.0113]],

          ...,

          [[0.0190, 0.0194, 0.0195,  ..., 0.0186, 0.0189, 0.0188],
           [0.0092, 0.0096, 0.0098,  ..., 0.0084, 0.0085, 0.0085],
           [0.0221, 0.0225, 0.0230,  ..., 0.0210, 0.0206, 0.0199],
           ...,
           [0.0285, 0.0291, 0.0298,  ..., 0.0273, 0.0275, 0.0270],
           [0.0211, 0.0218, 0.0222,  ..., 0.0204, 0.0208, 0.0210],
           [0.0160, 0.0168, 0.0171,  ..., 0.0152, 0.0154, 0.0156]],

          [[0.0247, 0.0246, 0.0246,  ..., 0.0234, 0.0236, 0.0239],
           [0.0164, 0.0164, 0.0164,  ..., 0.0129, 0.0130, 0.0141],
           [0.0151, 0.0152, 0.0155,  ..., 0.0131, 0.0131, 0.0130],
           ...,
           [0.0235, 0.0241, 0.0243,  ..., 0.0179, 0.0188, 0.0192],
           [0.0268, 0.0273, 0.0274,  ..., 0.0195, 0.0209, 0.0224],
           [0.0136, 0.0143, 0.0143,  ..., 0.0101, 0.0106, 0.0115]],

          [[0.0143, 0.0144, 0.0146,  ..., 0.0177, 0.0172, 0.0159],
           [0.0144, 0.0147, 0.0146,  ..., 0.0165, 0.0159, 0.0153],
           [0.0180, 0.0184, 0.0187,  ..., 0.0178, 0.0174, 0.0166],
           ...,
           [0.0234, 0.0239, 0.0243,  ..., 0.0216, 0.0217, 0.0212],
           [0.0261, 0.0267, 0.0271,  ..., 0.0258, 0.0260, 0.0261],
           [0.0151, 0.0161, 0.0166,  ..., 0.0199, 0.0191, 0.0181]]]]],
       device='cuda:0')
==========
IN _TEST_STEP
==========
ERODING BRAIN MASK
MEDIAN FILTERING
SAVING OUTPUT - ORIGINAL, FINAL, MASK ETC
SAVING IMAGES!
Testing:  30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:19<00:37,  5.36s/it]==========
IN DDPM ON TEST STEP
==========
THE WEIRD CONDITION BIT CALLED "features" in DDPM_2D
IN SPARK ENCODER FORWARDDD
x in shape torch.Size([50, 1, 96, 96])
out features torch.Size([50, 512])
i'm i DDPM2d forward block (whch is basically the encoder)
Context vector c shape: torch.Size([50, 512])
shape features:  torch.Size([50, 512])
additng features to latern space
latent space: []
iAM IN THE FORWARD METHOD OF THE WEIRD GUASSIAN IN cond_DDPM.py. I WILL BE CALLING p_losses
i am in p_losses in guassian which seems to be crucial to everything
conditioning vector shape:  torch.Size([50, 512])
in plosses i am getting a noisy image x
x shape:  torch.Size([50, 1, 96, 96])
getting model out
Initial input shape: torch.Size([50, 1, 96, 96])

inputblocks
Before block 0, shape: torch.Size([50, 1, 96, 96])
After block 0, shape: torch.Size([50, 128, 96, 96])
-
Before block 1, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 1, shape: torch.Size([50, 128, 96, 96])
-
Before block 2, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 2, shape: torch.Size([50, 128, 96, 96])
-
Before block 3, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 3, shape: torch.Size([50, 128, 96, 96])
-
Before block 4, shape: torch.Size([50, 128, 96, 96])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 256])
After block 4, shape: torch.Size([50, 128, 48, 48])
-
Before block 5, shape: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 48, 48])
-
Before block 8, shape: torch.Size([50, 256, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 8, shape: torch.Size([50, 256, 24, 24])
-
Before block 9, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 9, shape: torch.Size([50, 256, 24, 24])
-
Before block 10, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 10, shape: torch.Size([50, 256, 24, 24])
-
Before block 11, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 11, shape: torch.Size([50, 256, 24, 24])
-

Before middle block, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
in unet attention block!
x shape torch.Size([50, 256, 24, 24])
out dims torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])


After middle block, shape: torch.Size([50, 256, 24, 24])
-



outputblocks
Before block 0, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 0, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 0, shape: torch.Size([50, 256, 24, 24])
-
Before block 1, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 1, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 1, shape: torch.Size([50, 256, 24, 24])
-
Before block 2, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 2, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 2, shape: torch.Size([50, 256, 24, 24])
-
Before block 3, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 3, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 3, shape: torch.Size([50, 256, 48, 48])
-
Before block 4, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 4, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 4, shape: torch.Size([50, 256, 48, 48])
-
Before block 5, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 5, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 6, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 7, shape: torch.Size([50, 384, 48, 48])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 96, 96])
-
Before block 8, shape: torch.Size([50, 256, 96, 96])
After concatenation in upsampling block 8, shape: torch.Size([50, 384, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 8, shape: torch.Size([50, 128, 96, 96])
-
Before block 9, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 9, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 9, shape: torch.Size([50, 128, 96, 96])
-
Before block 10, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 10, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 10, shape: torch.Size([50, 128, 96, 96])
-
Before block 11, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 11, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 11, shape: torch.Size([50, 128, 96, 96])
-

Before Final layer shape: torch.Size([50, 128, 96, 96])
Final output shape: torch.Size([50, 1, 96, 96])
model out shape:  torch.Size([50, 1, 96, 96])
iAM IN THE FORWARD METHOD OF THE WEIRD GUASSIAN IN cond_DDPM.py. I WILL BE CALLING p_losses
i am in p_losses in guassian which seems to be crucial to everything
conditioning vector shape:  torch.Size([50, 512])
in plosses i am getting a noisy image x
x shape:  torch.Size([50, 1, 96, 96])
getting model out
Initial input shape: torch.Size([50, 1, 96, 96])

inputblocks
Before block 0, shape: torch.Size([50, 1, 96, 96])
After block 0, shape: torch.Size([50, 128, 96, 96])
-
Before block 1, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 1, shape: torch.Size([50, 128, 96, 96])
-
Before block 2, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 2, shape: torch.Size([50, 128, 96, 96])
-
Before block 3, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 3, shape: torch.Size([50, 128, 96, 96])
-
Before block 4, shape: torch.Size([50, 128, 96, 96])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 256])
After block 4, shape: torch.Size([50, 128, 48, 48])
-
Before block 5, shape: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 48, 48])
-
Before block 8, shape: torch.Size([50, 256, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 8, shape: torch.Size([50, 256, 24, 24])
-
Before block 9, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 9, shape: torch.Size([50, 256, 24, 24])
-
Before block 10, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 10, shape: torch.Size([50, 256, 24, 24])
-
Before block 11, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 11, shape: torch.Size([50, 256, 24, 24])
-

Before middle block, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
in unet attention block!
x shape torch.Size([50, 256, 24, 24])
out dims torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])


After middle block, shape: torch.Size([50, 256, 24, 24])
-



outputblocks
Before block 0, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 0, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 0, shape: torch.Size([50, 256, 24, 24])
-
Before block 1, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 1, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 1, shape: torch.Size([50, 256, 24, 24])
-
Before block 2, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 2, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 2, shape: torch.Size([50, 256, 24, 24])
-
Before block 3, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 3, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 3, shape: torch.Size([50, 256, 48, 48])
-
Before block 4, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 4, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 4, shape: torch.Size([50, 256, 48, 48])
-
Before block 5, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 5, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 6, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 7, shape: torch.Size([50, 384, 48, 48])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 96, 96])
-
Before block 8, shape: torch.Size([50, 256, 96, 96])
After concatenation in upsampling block 8, shape: torch.Size([50, 384, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 8, shape: torch.Size([50, 128, 96, 96])
-
Before block 9, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 9, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 9, shape: torch.Size([50, 128, 96, 96])
-
Before block 10, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 10, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 10, shape: torch.Size([50, 128, 96, 96])
-
Before block 11, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 11, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 11, shape: torch.Size([50, 128, 96, 96])
-

Before Final layer shape: torch.Size([50, 128, 96, 96])
Final output shape: torch.Size([50, 1, 96, 96])
model out shape:  torch.Size([50, 1, 96, 96])
iAM IN THE FORWARD METHOD OF THE WEIRD GUASSIAN IN cond_DDPM.py. I WILL BE CALLING p_losses
i am in p_losses in guassian which seems to be crucial to everything
conditioning vector shape:  torch.Size([50, 512])
in plosses i am getting a noisy image x
x shape:  torch.Size([50, 1, 96, 96])
getting model out
Initial input shape: torch.Size([50, 1, 96, 96])

inputblocks
Before block 0, shape: torch.Size([50, 1, 96, 96])
After block 0, shape: torch.Size([50, 128, 96, 96])
-
Before block 1, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 1, shape: torch.Size([50, 128, 96, 96])
-
Before block 2, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 2, shape: torch.Size([50, 128, 96, 96])
-
Before block 3, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 3, shape: torch.Size([50, 128, 96, 96])
-
Before block 4, shape: torch.Size([50, 128, 96, 96])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 256])
After block 4, shape: torch.Size([50, 128, 48, 48])
-
Before block 5, shape: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 48, 48])
-
Before block 8, shape: torch.Size([50, 256, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 8, shape: torch.Size([50, 256, 24, 24])
-
Before block 9, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 9, shape: torch.Size([50, 256, 24, 24])
-
Before block 10, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 10, shape: torch.Size([50, 256, 24, 24])
-
Before block 11, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 11, shape: torch.Size([50, 256, 24, 24])
-

Before middle block, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
in unet attention block!
x shape torch.Size([50, 256, 24, 24])
out dims torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])


After middle block, shape: torch.Size([50, 256, 24, 24])
-



outputblocks
Before block 0, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 0, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 0, shape: torch.Size([50, 256, 24, 24])
-
Before block 1, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 1, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 1, shape: torch.Size([50, 256, 24, 24])
-
Before block 2, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 2, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 2, shape: torch.Size([50, 256, 24, 24])
-
Before block 3, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 3, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 3, shape: torch.Size([50, 256, 48, 48])
-
Before block 4, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 4, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 4, shape: torch.Size([50, 256, 48, 48])
-
Before block 5, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 5, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 6, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 7, shape: torch.Size([50, 384, 48, 48])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 96, 96])
-
Before block 8, shape: torch.Size([50, 256, 96, 96])
After concatenation in upsampling block 8, shape: torch.Size([50, 384, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 8, shape: torch.Size([50, 128, 96, 96])
-
Before block 9, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 9, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 9, shape: torch.Size([50, 128, 96, 96])
-
Before block 10, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 10, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 10, shape: torch.Size([50, 128, 96, 96])
-
Before block 11, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 11, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 11, shape: torch.Size([50, 128, 96, 96])
-

Before Final layer shape: torch.Size([50, 128, 96, 96])
Final output shape: torch.Size([50, 1, 96, 96])
model out shape:  torch.Size([50, 1, 96, 96])
reconstruction shape torch.Size([50, 1, 96, 96])
reconstruction tensor([[[[0.0280, 0.0197, 0.0203,  ..., 0.0234, 0.0282, 0.0207],
          [0.0295, 0.0165, 0.0149,  ..., 0.0173, 0.0245, 0.0203],
          [0.0215, 0.0106, 0.0197,  ..., 0.0213, 0.0173, 0.0182],
          ...,
          [0.0229, 0.0117, 0.0229,  ..., 0.0246, 0.0184, 0.0161],
          [0.0330, 0.0194, 0.0168,  ..., 0.0212, 0.0307, 0.0214],
          [0.0216, 0.0216, 0.0198,  ..., 0.0187, 0.0245, 0.0183]]],


        [[[0.0278, 0.0185, 0.0203,  ..., 0.0230, 0.0272, 0.0208],
          [0.0286, 0.0147, 0.0144,  ..., 0.0165, 0.0227, 0.0190],
          [0.0212, 0.0096, 0.0195,  ..., 0.0208, 0.0160, 0.0173],
          ...,
          [0.0227, 0.0107, 0.0227,  ..., 0.0247, 0.0178, 0.0159],
          [0.0320, 0.0177, 0.0164,  ..., 0.0208, 0.0293, 0.0203],
          [0.0215, 0.0206, 0.0194,  ..., 0.0184, 0.0233, 0.0180]]],


        [[[0.0290, 0.0197, 0.0212,  ..., 0.0241, 0.0284, 0.0221],
          [0.0296, 0.0157, 0.0154,  ..., 0.0175, 0.0238, 0.0203],
          [0.0223, 0.0108, 0.0211,  ..., 0.0219, 0.0170, 0.0182],
          ...,
          [0.0237, 0.0119, 0.0238,  ..., 0.0260, 0.0190, 0.0173],
          [0.0330, 0.0186, 0.0175,  ..., 0.0219, 0.0303, 0.0217],
          [0.0226, 0.0217, 0.0205,  ..., 0.0197, 0.0246, 0.0191]]],


        ...,


        [[[0.0303, 0.0190, 0.0192,  ..., 0.0229, 0.0245, 0.0204],
          [0.0254, 0.0089, 0.0098,  ..., 0.0146, 0.0173, 0.0146],
          [0.0211, 0.0076, 0.0176,  ..., 0.0223, 0.0162, 0.0164],
          ...,
          [0.0208, 0.0085, 0.0231,  ..., 0.0285, 0.0182, 0.0162],
          [0.0291, 0.0126, 0.0146,  ..., 0.0209, 0.0243, 0.0205],
          [0.0229, 0.0199, 0.0199,  ..., 0.0232, 0.0260, 0.0246]]],


        [[[0.0306, 0.0194, 0.0201,  ..., 0.0237, 0.0256, 0.0207],
          [0.0258, 0.0097, 0.0108,  ..., 0.0155, 0.0188, 0.0153],
          [0.0218, 0.0085, 0.0182,  ..., 0.0227, 0.0170, 0.0169],
          ...,
          [0.0212, 0.0089, 0.0227,  ..., 0.0273, 0.0176, 0.0155],
          [0.0295, 0.0134, 0.0151,  ..., 0.0203, 0.0244, 0.0202],
          [0.0225, 0.0196, 0.0198,  ..., 0.0221, 0.0251, 0.0234]]],


        [[[0.0290, 0.0185, 0.0194,  ..., 0.0237, 0.0262, 0.0194],
          [0.0250, 0.0101, 0.0106,  ..., 0.0161, 0.0209, 0.0160],
          [0.0210, 0.0081, 0.0175,  ..., 0.0226, 0.0179, 0.0173],
          ...,
          [0.0207, 0.0088, 0.0222,  ..., 0.0258, 0.0170, 0.0143],
          [0.0294, 0.0142, 0.0150,  ..., 0.0200, 0.0251, 0.0194],
          [0.0211, 0.0190, 0.0191,  ..., 0.0208, 0.0243, 0.0214]]]],
       device='cuda:0')
FINAL VOLUME (DDPM) shape torch.Size([96, 96, 50])
FINAL VOLUME tensor([[[0.0280, 0.0278, 0.0290,  ..., 0.0303, 0.0306, 0.0290],
         [0.0197, 0.0185, 0.0197,  ..., 0.0190, 0.0194, 0.0185],
         [0.0203, 0.0203, 0.0212,  ..., 0.0192, 0.0201, 0.0194],
         ...,
         [0.0234, 0.0230, 0.0241,  ..., 0.0229, 0.0237, 0.0237],
         [0.0282, 0.0272, 0.0284,  ..., 0.0245, 0.0256, 0.0262],
         [0.0207, 0.0208, 0.0221,  ..., 0.0204, 0.0207, 0.0194]],

        [[0.0295, 0.0286, 0.0296,  ..., 0.0254, 0.0258, 0.0250],
         [0.0165, 0.0147, 0.0157,  ..., 0.0089, 0.0097, 0.0101],
         [0.0149, 0.0144, 0.0154,  ..., 0.0098, 0.0108, 0.0106],
         ...,
         [0.0173, 0.0165, 0.0175,  ..., 0.0146, 0.0155, 0.0161],
         [0.0245, 0.0227, 0.0238,  ..., 0.0173, 0.0188, 0.0209],
         [0.0203, 0.0190, 0.0203,  ..., 0.0146, 0.0153, 0.0160]],

        [[0.0215, 0.0212, 0.0223,  ..., 0.0211, 0.0218, 0.0210],
         [0.0106, 0.0096, 0.0108,  ..., 0.0076, 0.0085, 0.0081],
         [0.0197, 0.0195, 0.0211,  ..., 0.0176, 0.0182, 0.0175],
         ...,
         [0.0213, 0.0208, 0.0219,  ..., 0.0223, 0.0227, 0.0226],
         [0.0173, 0.0160, 0.0170,  ..., 0.0162, 0.0170, 0.0179],
         [0.0182, 0.0173, 0.0182,  ..., 0.0164, 0.0169, 0.0173]],

        ...,

        [[0.0229, 0.0227, 0.0237,  ..., 0.0208, 0.0212, 0.0207],
         [0.0117, 0.0107, 0.0119,  ..., 0.0085, 0.0089, 0.0088],
         [0.0229, 0.0227, 0.0238,  ..., 0.0231, 0.0227, 0.0222],
         ...,
         [0.0246, 0.0247, 0.0260,  ..., 0.0285, 0.0273, 0.0258],
         [0.0184, 0.0178, 0.0190,  ..., 0.0182, 0.0176, 0.0170],
         [0.0161, 0.0159, 0.0173,  ..., 0.0162, 0.0155, 0.0143]],

        [[0.0330, 0.0320, 0.0330,  ..., 0.0291, 0.0295, 0.0294],
         [0.0194, 0.0177, 0.0186,  ..., 0.0126, 0.0134, 0.0142],
         [0.0168, 0.0164, 0.0175,  ..., 0.0146, 0.0151, 0.0150],
         ...,
         [0.0212, 0.0208, 0.0219,  ..., 0.0209, 0.0203, 0.0200],
         [0.0307, 0.0293, 0.0303,  ..., 0.0243, 0.0244, 0.0251],
         [0.0214, 0.0203, 0.0217,  ..., 0.0205, 0.0202, 0.0194]],

        [[0.0216, 0.0215, 0.0226,  ..., 0.0229, 0.0225, 0.0211],
         [0.0216, 0.0206, 0.0217,  ..., 0.0199, 0.0196, 0.0190],
         [0.0198, 0.0194, 0.0205,  ..., 0.0199, 0.0198, 0.0191],
         ...,
         [0.0187, 0.0184, 0.0197,  ..., 0.0232, 0.0221, 0.0208],
         [0.0245, 0.0233, 0.0246,  ..., 0.0260, 0.0251, 0.0243],
         [0.0183, 0.0180, 0.0191,  ..., 0.0246, 0.0234, 0.0214]]],
       device='cuda:0')
unsqueeze final volume shape (DDPM2d) torch.Size([1, 1, 96, 96, 50])
unsqueeze final volume (DDPM 2D) tensor([[[[[0.0280, 0.0278, 0.0290,  ..., 0.0303, 0.0306, 0.0290],
           [0.0197, 0.0185, 0.0197,  ..., 0.0190, 0.0194, 0.0185],
           [0.0203, 0.0203, 0.0212,  ..., 0.0192, 0.0201, 0.0194],
           ...,
           [0.0234, 0.0230, 0.0241,  ..., 0.0229, 0.0237, 0.0237],
           [0.0282, 0.0272, 0.0284,  ..., 0.0245, 0.0256, 0.0262],
           [0.0207, 0.0208, 0.0221,  ..., 0.0204, 0.0207, 0.0194]],

          [[0.0295, 0.0286, 0.0296,  ..., 0.0254, 0.0258, 0.0250],
           [0.0165, 0.0147, 0.0157,  ..., 0.0089, 0.0097, 0.0101],
           [0.0149, 0.0144, 0.0154,  ..., 0.0098, 0.0108, 0.0106],
           ...,
           [0.0173, 0.0165, 0.0175,  ..., 0.0146, 0.0155, 0.0161],
           [0.0245, 0.0227, 0.0238,  ..., 0.0173, 0.0188, 0.0209],
           [0.0203, 0.0190, 0.0203,  ..., 0.0146, 0.0153, 0.0160]],

          [[0.0215, 0.0212, 0.0223,  ..., 0.0211, 0.0218, 0.0210],
           [0.0106, 0.0096, 0.0108,  ..., 0.0076, 0.0085, 0.0081],
           [0.0197, 0.0195, 0.0211,  ..., 0.0176, 0.0182, 0.0175],
           ...,
           [0.0213, 0.0208, 0.0219,  ..., 0.0223, 0.0227, 0.0226],
           [0.0173, 0.0160, 0.0170,  ..., 0.0162, 0.0170, 0.0179],
           [0.0182, 0.0173, 0.0182,  ..., 0.0164, 0.0169, 0.0173]],

          ...,

          [[0.0229, 0.0227, 0.0237,  ..., 0.0208, 0.0212, 0.0207],
           [0.0117, 0.0107, 0.0119,  ..., 0.0085, 0.0089, 0.0088],
           [0.0229, 0.0227, 0.0238,  ..., 0.0231, 0.0227, 0.0222],
           ...,
           [0.0246, 0.0247, 0.0260,  ..., 0.0285, 0.0273, 0.0258],
           [0.0184, 0.0178, 0.0190,  ..., 0.0182, 0.0176, 0.0170],
           [0.0161, 0.0159, 0.0173,  ..., 0.0162, 0.0155, 0.0143]],

          [[0.0330, 0.0320, 0.0330,  ..., 0.0291, 0.0295, 0.0294],
           [0.0194, 0.0177, 0.0186,  ..., 0.0126, 0.0134, 0.0142],
           [0.0168, 0.0164, 0.0175,  ..., 0.0146, 0.0151, 0.0150],
           ...,
           [0.0212, 0.0208, 0.0219,  ..., 0.0209, 0.0203, 0.0200],
           [0.0307, 0.0293, 0.0303,  ..., 0.0243, 0.0244, 0.0251],
           [0.0214, 0.0203, 0.0217,  ..., 0.0205, 0.0202, 0.0194]],

          [[0.0216, 0.0215, 0.0226,  ..., 0.0229, 0.0225, 0.0211],
           [0.0216, 0.0206, 0.0217,  ..., 0.0199, 0.0196, 0.0190],
           [0.0198, 0.0194, 0.0205,  ..., 0.0199, 0.0198, 0.0191],
           ...,
           [0.0187, 0.0184, 0.0197,  ..., 0.0232, 0.0221, 0.0208],
           [0.0245, 0.0233, 0.0246,  ..., 0.0260, 0.0251, 0.0243],
           [0.0183, 0.0180, 0.0191,  ..., 0.0246, 0.0234, 0.0214]]]]],
       device='cuda:0')
==========
IN _TEST_STEP
==========
ERODING BRAIN MASK
MEDIAN FILTERING
SAVING OUTPUT - ORIGINAL, FINAL, MASK ETC
SAVING IMAGES!
Testing:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:22<00:26,  4.36s/it]==========
IN DDPM ON TEST STEP
==========
THE WEIRD CONDITION BIT CALLED "features" in DDPM_2D
IN SPARK ENCODER FORWARDDD
x in shape torch.Size([50, 1, 96, 96])
out features torch.Size([50, 512])
i'm i DDPM2d forward block (whch is basically the encoder)
Context vector c shape: torch.Size([50, 512])
shape features:  torch.Size([50, 512])
additng features to latern space
latent space: []
iAM IN THE FORWARD METHOD OF THE WEIRD GUASSIAN IN cond_DDPM.py. I WILL BE CALLING p_losses
i am in p_losses in guassian which seems to be crucial to everything
conditioning vector shape:  torch.Size([50, 512])
in plosses i am getting a noisy image x
x shape:  torch.Size([50, 1, 96, 96])
getting model out
Initial input shape: torch.Size([50, 1, 96, 96])

inputblocks
Before block 0, shape: torch.Size([50, 1, 96, 96])
After block 0, shape: torch.Size([50, 128, 96, 96])
-
Before block 1, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 1, shape: torch.Size([50, 128, 96, 96])
-
Before block 2, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 2, shape: torch.Size([50, 128, 96, 96])
-
Before block 3, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 3, shape: torch.Size([50, 128, 96, 96])
-
Before block 4, shape: torch.Size([50, 128, 96, 96])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 256])
After block 4, shape: torch.Size([50, 128, 48, 48])
-
Before block 5, shape: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 48, 48])
-
Before block 8, shape: torch.Size([50, 256, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 8, shape: torch.Size([50, 256, 24, 24])
-
Before block 9, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 9, shape: torch.Size([50, 256, 24, 24])
-
Before block 10, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 10, shape: torch.Size([50, 256, 24, 24])
-
Before block 11, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 11, shape: torch.Size([50, 256, 24, 24])
-

Before middle block, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
in unet attention block!
x shape torch.Size([50, 256, 24, 24])
out dims torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])


After middle block, shape: torch.Size([50, 256, 24, 24])
-



outputblocks
Before block 0, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 0, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 0, shape: torch.Size([50, 256, 24, 24])
-
Before block 1, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 1, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 1, shape: torch.Size([50, 256, 24, 24])
-
Before block 2, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 2, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 2, shape: torch.Size([50, 256, 24, 24])
-
Before block 3, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 3, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 3, shape: torch.Size([50, 256, 48, 48])
-
Before block 4, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 4, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 4, shape: torch.Size([50, 256, 48, 48])
-
Before block 5, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 5, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 6, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 7, shape: torch.Size([50, 384, 48, 48])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 96, 96])
-
Before block 8, shape: torch.Size([50, 256, 96, 96])
After concatenation in upsampling block 8, shape: torch.Size([50, 384, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 8, shape: torch.Size([50, 128, 96, 96])
-
Before block 9, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 9, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 9, shape: torch.Size([50, 128, 96, 96])
-
Before block 10, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 10, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 10, shape: torch.Size([50, 128, 96, 96])
-
Before block 11, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 11, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 11, shape: torch.Size([50, 128, 96, 96])
-

Before Final layer shape: torch.Size([50, 128, 96, 96])
Final output shape: torch.Size([50, 1, 96, 96])
model out shape:  torch.Size([50, 1, 96, 96])
iAM IN THE FORWARD METHOD OF THE WEIRD GUASSIAN IN cond_DDPM.py. I WILL BE CALLING p_losses
i am in p_losses in guassian which seems to be crucial to everything
conditioning vector shape:  torch.Size([50, 512])
in plosses i am getting a noisy image x
x shape:  torch.Size([50, 1, 96, 96])
getting model out
Initial input shape: torch.Size([50, 1, 96, 96])

inputblocks
Before block 0, shape: torch.Size([50, 1, 96, 96])
After block 0, shape: torch.Size([50, 128, 96, 96])
-
Before block 1, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 1, shape: torch.Size([50, 128, 96, 96])
-
Before block 2, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 2, shape: torch.Size([50, 128, 96, 96])
-
Before block 3, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 3, shape: torch.Size([50, 128, 96, 96])
-
Before block 4, shape: torch.Size([50, 128, 96, 96])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 256])
After block 4, shape: torch.Size([50, 128, 48, 48])
-
Before block 5, shape: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 48, 48])
-
Before block 8, shape: torch.Size([50, 256, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 8, shape: torch.Size([50, 256, 24, 24])
-
Before block 9, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 9, shape: torch.Size([50, 256, 24, 24])
-
Before block 10, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 10, shape: torch.Size([50, 256, 24, 24])
-
Before block 11, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 11, shape: torch.Size([50, 256, 24, 24])
-

Before middle block, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
in unet attention block!
x shape torch.Size([50, 256, 24, 24])
out dims torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])


After middle block, shape: torch.Size([50, 256, 24, 24])
-



outputblocks
Before block 0, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 0, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 0, shape: torch.Size([50, 256, 24, 24])
-
Before block 1, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 1, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 1, shape: torch.Size([50, 256, 24, 24])
-
Before block 2, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 2, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 2, shape: torch.Size([50, 256, 24, 24])
-
Before block 3, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 3, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 3, shape: torch.Size([50, 256, 48, 48])
-
Before block 4, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 4, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 4, shape: torch.Size([50, 256, 48, 48])
-
Before block 5, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 5, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 6, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 7, shape: torch.Size([50, 384, 48, 48])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 96, 96])
-
Before block 8, shape: torch.Size([50, 256, 96, 96])
After concatenation in upsampling block 8, shape: torch.Size([50, 384, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 8, shape: torch.Size([50, 128, 96, 96])
-
Before block 9, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 9, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 9, shape: torch.Size([50, 128, 96, 96])
-
Before block 10, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 10, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 10, shape: torch.Size([50, 128, 96, 96])
-
Before block 11, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 11, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 11, shape: torch.Size([50, 128, 96, 96])
-

Before Final layer shape: torch.Size([50, 128, 96, 96])
Final output shape: torch.Size([50, 1, 96, 96])
model out shape:  torch.Size([50, 1, 96, 96])
iAM IN THE FORWARD METHOD OF THE WEIRD GUASSIAN IN cond_DDPM.py. I WILL BE CALLING p_losses
i am in p_losses in guassian which seems to be crucial to everything
conditioning vector shape:  torch.Size([50, 512])
in plosses i am getting a noisy image x
x shape:  torch.Size([50, 1, 96, 96])
getting model out
Initial input shape: torch.Size([50, 1, 96, 96])

inputblocks
Before block 0, shape: torch.Size([50, 1, 96, 96])
After block 0, shape: torch.Size([50, 128, 96, 96])
-
Before block 1, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 1, shape: torch.Size([50, 128, 96, 96])
-
Before block 2, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 2, shape: torch.Size([50, 128, 96, 96])
-
Before block 3, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 3, shape: torch.Size([50, 128, 96, 96])
-
Before block 4, shape: torch.Size([50, 128, 96, 96])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 256])
After block 4, shape: torch.Size([50, 128, 48, 48])
-
Before block 5, shape: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 48, 48])
-
Before block 8, shape: torch.Size([50, 256, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 8, shape: torch.Size([50, 256, 24, 24])
-
Before block 9, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 9, shape: torch.Size([50, 256, 24, 24])
-
Before block 10, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 10, shape: torch.Size([50, 256, 24, 24])
-
Before block 11, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 11, shape: torch.Size([50, 256, 24, 24])
-

Before middle block, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
in unet attention block!
x shape torch.Size([50, 256, 24, 24])
out dims torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])


After middle block, shape: torch.Size([50, 256, 24, 24])
-



outputblocks
Before block 0, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 0, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 0, shape: torch.Size([50, 256, 24, 24])
-
Before block 1, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 1, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 1, shape: torch.Size([50, 256, 24, 24])
-
Before block 2, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 2, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 2, shape: torch.Size([50, 256, 24, 24])
-
Before block 3, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 3, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 3, shape: torch.Size([50, 256, 48, 48])
-
Before block 4, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 4, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 4, shape: torch.Size([50, 256, 48, 48])
-
Before block 5, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 5, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 6, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 7, shape: torch.Size([50, 384, 48, 48])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 96, 96])
-
Before block 8, shape: torch.Size([50, 256, 96, 96])
After concatenation in upsampling block 8, shape: torch.Size([50, 384, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 8, shape: torch.Size([50, 128, 96, 96])
-
Before block 9, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 9, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 9, shape: torch.Size([50, 128, 96, 96])
-
Before block 10, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 10, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 10, shape: torch.Size([50, 128, 96, 96])
-
Before block 11, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 11, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 11, shape: torch.Size([50, 128, 96, 96])
-

Before Final layer shape: torch.Size([50, 128, 96, 96])
Final output shape: torch.Size([50, 1, 96, 96])
model out shape:  torch.Size([50, 1, 96, 96])
reconstruction shape torch.Size([50, 1, 96, 96])
reconstruction tensor([[[[0.0300, 0.0259, 0.0251,  ..., 0.0317, 0.0344, 0.0282],
          [0.0348, 0.0237, 0.0229,  ..., 0.0243, 0.0313, 0.0253],
          [0.0263, 0.0188, 0.0292,  ..., 0.0298, 0.0168, 0.0131],
          ...,
          [0.0273, 0.0181, 0.0279,  ..., 0.0301, 0.0237, 0.0237],
          [0.0312, 0.0261, 0.0209,  ..., 0.0275, 0.0318, 0.0226],
          [0.0177, 0.0223, 0.0219,  ..., 0.0242, 0.0282, 0.0178]]],


        [[[0.0313, 0.0278, 0.0260,  ..., 0.0328, 0.0359, 0.0294],
          [0.0365, 0.0255, 0.0238,  ..., 0.0256, 0.0330, 0.0268],
          [0.0273, 0.0198, 0.0298,  ..., 0.0309, 0.0180, 0.0142],
          ...,
          [0.0282, 0.0194, 0.0291,  ..., 0.0311, 0.0248, 0.0247],
          [0.0326, 0.0277, 0.0218,  ..., 0.0285, 0.0333, 0.0243],
          [0.0186, 0.0238, 0.0230,  ..., 0.0251, 0.0299, 0.0193]]],


        [[[0.0314, 0.0278, 0.0258,  ..., 0.0324, 0.0355, 0.0291],
          [0.0365, 0.0254, 0.0234,  ..., 0.0254, 0.0326, 0.0266],
          [0.0270, 0.0196, 0.0295,  ..., 0.0309, 0.0175, 0.0140],
          ...,
          [0.0278, 0.0188, 0.0285,  ..., 0.0307, 0.0247, 0.0247],
          [0.0326, 0.0277, 0.0216,  ..., 0.0284, 0.0337, 0.0247],
          [0.0186, 0.0239, 0.0229,  ..., 0.0251, 0.0302, 0.0194]]],


        ...,


        [[[0.0328, 0.0280, 0.0252,  ..., 0.0255, 0.0286, 0.0306],
          [0.0312, 0.0180, 0.0184,  ..., 0.0188, 0.0208, 0.0169],
          [0.0256, 0.0164, 0.0271,  ..., 0.0319, 0.0177, 0.0113],
          ...,
          [0.0235, 0.0152, 0.0277,  ..., 0.0308, 0.0209, 0.0194],
          [0.0285, 0.0204, 0.0188,  ..., 0.0234, 0.0243, 0.0180],
          [0.0194, 0.0215, 0.0204,  ..., 0.0243, 0.0259, 0.0173]]],


        [[[0.0319, 0.0274, 0.0251,  ..., 0.0247, 0.0284, 0.0299],
          [0.0303, 0.0175, 0.0178,  ..., 0.0178, 0.0203, 0.0164],
          [0.0251, 0.0159, 0.0267,  ..., 0.0308, 0.0167, 0.0104],
          ...,
          [0.0232, 0.0142, 0.0265,  ..., 0.0295, 0.0197, 0.0186],
          [0.0282, 0.0202, 0.0182,  ..., 0.0229, 0.0239, 0.0173],
          [0.0186, 0.0208, 0.0201,  ..., 0.0237, 0.0250, 0.0158]]],


        [[[0.0311, 0.0268, 0.0250,  ..., 0.0243, 0.0282, 0.0293],
          [0.0298, 0.0173, 0.0175,  ..., 0.0170, 0.0204, 0.0160],
          [0.0249, 0.0155, 0.0257,  ..., 0.0299, 0.0160, 0.0098],
          ...,
          [0.0230, 0.0133, 0.0251,  ..., 0.0282, 0.0187, 0.0178],
          [0.0282, 0.0203, 0.0177,  ..., 0.0220, 0.0238, 0.0167],
          [0.0174, 0.0200, 0.0193,  ..., 0.0229, 0.0239, 0.0142]]]],
       device='cuda:0')
FINAL VOLUME (DDPM) shape torch.Size([96, 96, 50])
FINAL VOLUME tensor([[[0.0300, 0.0313, 0.0314,  ..., 0.0328, 0.0319, 0.0311],
         [0.0259, 0.0278, 0.0278,  ..., 0.0280, 0.0274, 0.0268],
         [0.0251, 0.0260, 0.0258,  ..., 0.0252, 0.0251, 0.0250],
         ...,
         [0.0317, 0.0328, 0.0324,  ..., 0.0255, 0.0247, 0.0243],
         [0.0344, 0.0359, 0.0355,  ..., 0.0286, 0.0284, 0.0282],
         [0.0282, 0.0294, 0.0291,  ..., 0.0306, 0.0299, 0.0293]],

        [[0.0348, 0.0365, 0.0365,  ..., 0.0312, 0.0303, 0.0298],
         [0.0237, 0.0255, 0.0254,  ..., 0.0180, 0.0175, 0.0173],
         [0.0229, 0.0238, 0.0234,  ..., 0.0184, 0.0178, 0.0175],
         ...,
         [0.0243, 0.0256, 0.0254,  ..., 0.0188, 0.0178, 0.0170],
         [0.0313, 0.0330, 0.0326,  ..., 0.0208, 0.0203, 0.0204],
         [0.0253, 0.0268, 0.0266,  ..., 0.0169, 0.0164, 0.0160]],

        [[0.0263, 0.0273, 0.0270,  ..., 0.0256, 0.0251, 0.0249],
         [0.0188, 0.0198, 0.0196,  ..., 0.0164, 0.0159, 0.0155],
         [0.0292, 0.0298, 0.0295,  ..., 0.0271, 0.0267, 0.0257],
         ...,
         [0.0298, 0.0309, 0.0309,  ..., 0.0319, 0.0308, 0.0299],
         [0.0168, 0.0180, 0.0175,  ..., 0.0177, 0.0167, 0.0160],
         [0.0131, 0.0142, 0.0140,  ..., 0.0113, 0.0104, 0.0098]],

        ...,

        [[0.0273, 0.0282, 0.0278,  ..., 0.0235, 0.0232, 0.0230],
         [0.0181, 0.0194, 0.0188,  ..., 0.0152, 0.0142, 0.0133],
         [0.0279, 0.0291, 0.0285,  ..., 0.0277, 0.0265, 0.0251],
         ...,
         [0.0301, 0.0311, 0.0307,  ..., 0.0308, 0.0295, 0.0282],
         [0.0237, 0.0248, 0.0247,  ..., 0.0209, 0.0197, 0.0187],
         [0.0237, 0.0247, 0.0247,  ..., 0.0194, 0.0186, 0.0178]],

        [[0.0312, 0.0326, 0.0326,  ..., 0.0285, 0.0282, 0.0282],
         [0.0261, 0.0277, 0.0277,  ..., 0.0204, 0.0202, 0.0203],
         [0.0209, 0.0218, 0.0216,  ..., 0.0188, 0.0182, 0.0177],
         ...,
         [0.0275, 0.0285, 0.0284,  ..., 0.0234, 0.0229, 0.0220],
         [0.0318, 0.0333, 0.0337,  ..., 0.0243, 0.0239, 0.0238],
         [0.0226, 0.0243, 0.0247,  ..., 0.0180, 0.0173, 0.0167]],

        [[0.0177, 0.0186, 0.0186,  ..., 0.0194, 0.0186, 0.0174],
         [0.0223, 0.0238, 0.0239,  ..., 0.0215, 0.0208, 0.0200],
         [0.0219, 0.0230, 0.0229,  ..., 0.0204, 0.0201, 0.0193],
         ...,
         [0.0242, 0.0251, 0.0251,  ..., 0.0243, 0.0237, 0.0229],
         [0.0282, 0.0299, 0.0302,  ..., 0.0259, 0.0250, 0.0239],
         [0.0178, 0.0193, 0.0194,  ..., 0.0173, 0.0158, 0.0142]]],
       device='cuda:0')
unsqueeze final volume shape (DDPM2d) torch.Size([1, 1, 96, 96, 50])
unsqueeze final volume (DDPM 2D) tensor([[[[[0.0300, 0.0313, 0.0314,  ..., 0.0328, 0.0319, 0.0311],
           [0.0259, 0.0278, 0.0278,  ..., 0.0280, 0.0274, 0.0268],
           [0.0251, 0.0260, 0.0258,  ..., 0.0252, 0.0251, 0.0250],
           ...,
           [0.0317, 0.0328, 0.0324,  ..., 0.0255, 0.0247, 0.0243],
           [0.0344, 0.0359, 0.0355,  ..., 0.0286, 0.0284, 0.0282],
           [0.0282, 0.0294, 0.0291,  ..., 0.0306, 0.0299, 0.0293]],

          [[0.0348, 0.0365, 0.0365,  ..., 0.0312, 0.0303, 0.0298],
           [0.0237, 0.0255, 0.0254,  ..., 0.0180, 0.0175, 0.0173],
           [0.0229, 0.0238, 0.0234,  ..., 0.0184, 0.0178, 0.0175],
           ...,
           [0.0243, 0.0256, 0.0254,  ..., 0.0188, 0.0178, 0.0170],
           [0.0313, 0.0330, 0.0326,  ..., 0.0208, 0.0203, 0.0204],
           [0.0253, 0.0268, 0.0266,  ..., 0.0169, 0.0164, 0.0160]],

          [[0.0263, 0.0273, 0.0270,  ..., 0.0256, 0.0251, 0.0249],
           [0.0188, 0.0198, 0.0196,  ..., 0.0164, 0.0159, 0.0155],
           [0.0292, 0.0298, 0.0295,  ..., 0.0271, 0.0267, 0.0257],
           ...,
           [0.0298, 0.0309, 0.0309,  ..., 0.0319, 0.0308, 0.0299],
           [0.0168, 0.0180, 0.0175,  ..., 0.0177, 0.0167, 0.0160],
           [0.0131, 0.0142, 0.0140,  ..., 0.0113, 0.0104, 0.0098]],

          ...,

          [[0.0273, 0.0282, 0.0278,  ..., 0.0235, 0.0232, 0.0230],
           [0.0181, 0.0194, 0.0188,  ..., 0.0152, 0.0142, 0.0133],
           [0.0279, 0.0291, 0.0285,  ..., 0.0277, 0.0265, 0.0251],
           ...,
           [0.0301, 0.0311, 0.0307,  ..., 0.0308, 0.0295, 0.0282],
           [0.0237, 0.0248, 0.0247,  ..., 0.0209, 0.0197, 0.0187],
           [0.0237, 0.0247, 0.0247,  ..., 0.0194, 0.0186, 0.0178]],

          [[0.0312, 0.0326, 0.0326,  ..., 0.0285, 0.0282, 0.0282],
           [0.0261, 0.0277, 0.0277,  ..., 0.0204, 0.0202, 0.0203],
           [0.0209, 0.0218, 0.0216,  ..., 0.0188, 0.0182, 0.0177],
           ...,
           [0.0275, 0.0285, 0.0284,  ..., 0.0234, 0.0229, 0.0220],
           [0.0318, 0.0333, 0.0337,  ..., 0.0243, 0.0239, 0.0238],
           [0.0226, 0.0243, 0.0247,  ..., 0.0180, 0.0173, 0.0167]],

          [[0.0177, 0.0186, 0.0186,  ..., 0.0194, 0.0186, 0.0174],
           [0.0223, 0.0238, 0.0239,  ..., 0.0215, 0.0208, 0.0200],
           [0.0219, 0.0230, 0.0229,  ..., 0.0204, 0.0201, 0.0193],
           ...,
           [0.0242, 0.0251, 0.0251,  ..., 0.0243, 0.0237, 0.0229],
           [0.0282, 0.0299, 0.0302,  ..., 0.0259, 0.0250, 0.0239],
           [0.0178, 0.0193, 0.0194,  ..., 0.0173, 0.0158, 0.0142]]]]],
       device='cuda:0')
==========
IN _TEST_STEP
==========
ERODING BRAIN MASK
MEDIAN FILTERING
SAVING OUTPUT - ORIGINAL, FINAL, MASK ETC
SAVING IMAGES!
Testing:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:24<00:19,  3.82s/it]==========
IN DDPM ON TEST STEP
==========
THE WEIRD CONDITION BIT CALLED "features" in DDPM_2D
IN SPARK ENCODER FORWARDDD
x in shape torch.Size([50, 1, 96, 96])
out features torch.Size([50, 512])
i'm i DDPM2d forward block (whch is basically the encoder)
Context vector c shape: torch.Size([50, 512])
shape features:  torch.Size([50, 512])
additng features to latern space
latent space: []
iAM IN THE FORWARD METHOD OF THE WEIRD GUASSIAN IN cond_DDPM.py. I WILL BE CALLING p_losses
i am in p_losses in guassian which seems to be crucial to everything
conditioning vector shape:  torch.Size([50, 512])
in plosses i am getting a noisy image x
x shape:  torch.Size([50, 1, 96, 96])
getting model out
Initial input shape: torch.Size([50, 1, 96, 96])

inputblocks
Before block 0, shape: torch.Size([50, 1, 96, 96])
After block 0, shape: torch.Size([50, 128, 96, 96])
-
Before block 1, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 1, shape: torch.Size([50, 128, 96, 96])
-
Before block 2, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 2, shape: torch.Size([50, 128, 96, 96])
-
Before block 3, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 3, shape: torch.Size([50, 128, 96, 96])
-
Before block 4, shape: torch.Size([50, 128, 96, 96])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 256])
After block 4, shape: torch.Size([50, 128, 48, 48])
-
Before block 5, shape: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 48, 48])
-
Before block 8, shape: torch.Size([50, 256, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 8, shape: torch.Size([50, 256, 24, 24])
-
Before block 9, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 9, shape: torch.Size([50, 256, 24, 24])
-
Before block 10, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 10, shape: torch.Size([50, 256, 24, 24])
-
Before block 11, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 11, shape: torch.Size([50, 256, 24, 24])
-

Before middle block, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
in unet attention block!
x shape torch.Size([50, 256, 24, 24])
out dims torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])


After middle block, shape: torch.Size([50, 256, 24, 24])
-



outputblocks
Before block 0, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 0, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 0, shape: torch.Size([50, 256, 24, 24])
-
Before block 1, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 1, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 1, shape: torch.Size([50, 256, 24, 24])
-
Before block 2, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 2, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 2, shape: torch.Size([50, 256, 24, 24])
-
Before block 3, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 3, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 3, shape: torch.Size([50, 256, 48, 48])
-
Before block 4, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 4, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 4, shape: torch.Size([50, 256, 48, 48])
-
Before block 5, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 5, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 6, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 7, shape: torch.Size([50, 384, 48, 48])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 96, 96])
-
Before block 8, shape: torch.Size([50, 256, 96, 96])
After concatenation in upsampling block 8, shape: torch.Size([50, 384, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 8, shape: torch.Size([50, 128, 96, 96])
-
Before block 9, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 9, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 9, shape: torch.Size([50, 128, 96, 96])
-
Before block 10, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 10, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 10, shape: torch.Size([50, 128, 96, 96])
-
Before block 11, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 11, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 11, shape: torch.Size([50, 128, 96, 96])
-

Before Final layer shape: torch.Size([50, 128, 96, 96])
Final output shape: torch.Size([50, 1, 96, 96])
model out shape:  torch.Size([50, 1, 96, 96])
iAM IN THE FORWARD METHOD OF THE WEIRD GUASSIAN IN cond_DDPM.py. I WILL BE CALLING p_losses
i am in p_losses in guassian which seems to be crucial to everything
conditioning vector shape:  torch.Size([50, 512])
in plosses i am getting a noisy image x
x shape:  torch.Size([50, 1, 96, 96])
getting model out
Initial input shape: torch.Size([50, 1, 96, 96])

inputblocks
Before block 0, shape: torch.Size([50, 1, 96, 96])
After block 0, shape: torch.Size([50, 128, 96, 96])
-
Before block 1, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 1, shape: torch.Size([50, 128, 96, 96])
-
Before block 2, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 2, shape: torch.Size([50, 128, 96, 96])
-
Before block 3, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 3, shape: torch.Size([50, 128, 96, 96])
-
Before block 4, shape: torch.Size([50, 128, 96, 96])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 256])
After block 4, shape: torch.Size([50, 128, 48, 48])
-
Before block 5, shape: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 48, 48])
-
Before block 8, shape: torch.Size([50, 256, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 8, shape: torch.Size([50, 256, 24, 24])
-
Before block 9, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 9, shape: torch.Size([50, 256, 24, 24])
-
Before block 10, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 10, shape: torch.Size([50, 256, 24, 24])
-
Before block 11, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 11, shape: torch.Size([50, 256, 24, 24])
-

Before middle block, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
in unet attention block!
x shape torch.Size([50, 256, 24, 24])
out dims torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])


After middle block, shape: torch.Size([50, 256, 24, 24])
-



outputblocks
Before block 0, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 0, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 0, shape: torch.Size([50, 256, 24, 24])
-
Before block 1, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 1, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 1, shape: torch.Size([50, 256, 24, 24])
-
Before block 2, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 2, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 2, shape: torch.Size([50, 256, 24, 24])
-
Before block 3, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 3, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 3, shape: torch.Size([50, 256, 48, 48])
-
Before block 4, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 4, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 4, shape: torch.Size([50, 256, 48, 48])
-
Before block 5, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 5, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 6, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 7, shape: torch.Size([50, 384, 48, 48])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 96, 96])
-
Before block 8, shape: torch.Size([50, 256, 96, 96])
After concatenation in upsampling block 8, shape: torch.Size([50, 384, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 8, shape: torch.Size([50, 128, 96, 96])
-
Before block 9, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 9, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 9, shape: torch.Size([50, 128, 96, 96])
-
Before block 10, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 10, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 10, shape: torch.Size([50, 128, 96, 96])
-
Before block 11, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 11, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 11, shape: torch.Size([50, 128, 96, 96])
-

Before Final layer shape: torch.Size([50, 128, 96, 96])
Final output shape: torch.Size([50, 1, 96, 96])
model out shape:  torch.Size([50, 1, 96, 96])
iAM IN THE FORWARD METHOD OF THE WEIRD GUASSIAN IN cond_DDPM.py. I WILL BE CALLING p_losses
i am in p_losses in guassian which seems to be crucial to everything
conditioning vector shape:  torch.Size([50, 512])
in plosses i am getting a noisy image x
x shape:  torch.Size([50, 1, 96, 96])
getting model out
Initial input shape: torch.Size([50, 1, 96, 96])

inputblocks
Before block 0, shape: torch.Size([50, 1, 96, 96])
After block 0, shape: torch.Size([50, 128, 96, 96])
-
Before block 1, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 1, shape: torch.Size([50, 128, 96, 96])
-
Before block 2, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 2, shape: torch.Size([50, 128, 96, 96])
-
Before block 3, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 3, shape: torch.Size([50, 128, 96, 96])
-
Before block 4, shape: torch.Size([50, 128, 96, 96])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 256])
After block 4, shape: torch.Size([50, 128, 48, 48])
-
Before block 5, shape: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 48, 48])
-
Before block 8, shape: torch.Size([50, 256, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 8, shape: torch.Size([50, 256, 24, 24])
-
Before block 9, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 9, shape: torch.Size([50, 256, 24, 24])
-
Before block 10, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 10, shape: torch.Size([50, 256, 24, 24])
-
Before block 11, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 11, shape: torch.Size([50, 256, 24, 24])
-

Before middle block, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
in unet attention block!
x shape torch.Size([50, 256, 24, 24])
out dims torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])


After middle block, shape: torch.Size([50, 256, 24, 24])
-



outputblocks
Before block 0, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 0, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 0, shape: torch.Size([50, 256, 24, 24])
-
Before block 1, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 1, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 1, shape: torch.Size([50, 256, 24, 24])
-
Before block 2, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 2, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 2, shape: torch.Size([50, 256, 24, 24])
-
Before block 3, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 3, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 3, shape: torch.Size([50, 256, 48, 48])
-
Before block 4, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 4, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 4, shape: torch.Size([50, 256, 48, 48])
-
Before block 5, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 5, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 6, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 7, shape: torch.Size([50, 384, 48, 48])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 96, 96])
-
Before block 8, shape: torch.Size([50, 256, 96, 96])
After concatenation in upsampling block 8, shape: torch.Size([50, 384, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 8, shape: torch.Size([50, 128, 96, 96])
-
Before block 9, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 9, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 9, shape: torch.Size([50, 128, 96, 96])
-
Before block 10, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 10, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 10, shape: torch.Size([50, 128, 96, 96])
-
Before block 11, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 11, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 11, shape: torch.Size([50, 128, 96, 96])
-

Before Final layer shape: torch.Size([50, 128, 96, 96])
Final output shape: torch.Size([50, 1, 96, 96])
model out shape:  torch.Size([50, 1, 96, 96])
reconstruction shape torch.Size([50, 1, 96, 96])
reconstruction tensor([[[[0.0345, 0.0286, 0.0291,  ..., 0.0321, 0.0388, 0.0297],
          [0.0376, 0.0279, 0.0260,  ..., 0.0260, 0.0335, 0.0273],
          [0.0309, 0.0209, 0.0321,  ..., 0.0305, 0.0208, 0.0190],
          ...,
          [0.0316, 0.0204, 0.0325,  ..., 0.0330, 0.0303, 0.0261],
          [0.0374, 0.0303, 0.0271,  ..., 0.0296, 0.0409, 0.0328],
          [0.0264, 0.0258, 0.0267,  ..., 0.0323, 0.0414, 0.0326]]],


        [[[0.0337, 0.0279, 0.0282,  ..., 0.0309, 0.0374, 0.0286],
          [0.0361, 0.0267, 0.0249,  ..., 0.0245, 0.0315, 0.0256],
          [0.0297, 0.0200, 0.0314,  ..., 0.0293, 0.0198, 0.0175],
          ...,
          [0.0308, 0.0201, 0.0317,  ..., 0.0320, 0.0291, 0.0249],
          [0.0365, 0.0297, 0.0263,  ..., 0.0286, 0.0391, 0.0312],
          [0.0256, 0.0253, 0.0259,  ..., 0.0310, 0.0399, 0.0314]]],


        [[[0.0358, 0.0309, 0.0308,  ..., 0.0330, 0.0393, 0.0308],
          [0.0379, 0.0287, 0.0270,  ..., 0.0264, 0.0330, 0.0273],
          [0.0318, 0.0221, 0.0336,  ..., 0.0315, 0.0217, 0.0193],
          ...,
          [0.0328, 0.0220, 0.0338,  ..., 0.0344, 0.0314, 0.0273],
          [0.0387, 0.0318, 0.0282,  ..., 0.0304, 0.0409, 0.0335],
          [0.0278, 0.0282, 0.0281,  ..., 0.0333, 0.0426, 0.0343]]],


        ...,


        [[[0.0358, 0.0299, 0.0291,  ..., 0.0294, 0.0355, 0.0299],
          [0.0327, 0.0234, 0.0233,  ..., 0.0229, 0.0269, 0.0214],
          [0.0286, 0.0209, 0.0327,  ..., 0.0315, 0.0212, 0.0158],
          ...,
          [0.0295, 0.0199, 0.0301,  ..., 0.0389, 0.0351, 0.0279],
          [0.0373, 0.0299, 0.0251,  ..., 0.0374, 0.0496, 0.0381],
          [0.0291, 0.0288, 0.0254,  ..., 0.0412, 0.0501, 0.0388]]],


        [[[0.0356, 0.0299, 0.0287,  ..., 0.0291, 0.0360, 0.0295],
          [0.0332, 0.0243, 0.0235,  ..., 0.0229, 0.0278, 0.0220],
          [0.0285, 0.0208, 0.0324,  ..., 0.0310, 0.0209, 0.0156],
          ...,
          [0.0303, 0.0206, 0.0307,  ..., 0.0427, 0.0396, 0.0309],
          [0.0386, 0.0321, 0.0262,  ..., 0.0457, 0.0581, 0.0424],
          [0.0291, 0.0296, 0.0264,  ..., 0.0496, 0.0575, 0.0420]]],


        [[[0.0343, 0.0288, 0.0276,  ..., 0.0276, 0.0355, 0.0276],
          [0.0329, 0.0242, 0.0226,  ..., 0.0216, 0.0283, 0.0216],
          [0.0271, 0.0193, 0.0304,  ..., 0.0284, 0.0195, 0.0140],
          ...,
          [0.0292, 0.0192, 0.0288,  ..., 0.0492, 0.0477, 0.0361],
          [0.0388, 0.0334, 0.0258,  ..., 0.0598, 0.0739, 0.0510],
          [0.0275, 0.0295, 0.0260,  ..., 0.0616, 0.0693, 0.0478]]]],
       device='cuda:0')
FINAL VOLUME (DDPM) shape torch.Size([96, 96, 50])
FINAL VOLUME tensor([[[0.0345, 0.0337, 0.0358,  ..., 0.0358, 0.0356, 0.0343],
         [0.0286, 0.0279, 0.0309,  ..., 0.0299, 0.0299, 0.0288],
         [0.0291, 0.0282, 0.0308,  ..., 0.0291, 0.0287, 0.0276],
         ...,
         [0.0321, 0.0309, 0.0330,  ..., 0.0294, 0.0291, 0.0276],
         [0.0388, 0.0374, 0.0393,  ..., 0.0355, 0.0360, 0.0355],
         [0.0297, 0.0286, 0.0308,  ..., 0.0299, 0.0295, 0.0276]],

        [[0.0376, 0.0361, 0.0379,  ..., 0.0327, 0.0332, 0.0329],
         [0.0279, 0.0267, 0.0287,  ..., 0.0234, 0.0243, 0.0242],
         [0.0260, 0.0249, 0.0270,  ..., 0.0233, 0.0235, 0.0226],
         ...,
         [0.0260, 0.0245, 0.0264,  ..., 0.0229, 0.0229, 0.0216],
         [0.0335, 0.0315, 0.0330,  ..., 0.0269, 0.0278, 0.0283],
         [0.0273, 0.0256, 0.0273,  ..., 0.0214, 0.0220, 0.0216]],

        [[0.0309, 0.0297, 0.0318,  ..., 0.0286, 0.0285, 0.0271],
         [0.0209, 0.0200, 0.0221,  ..., 0.0209, 0.0208, 0.0193],
         [0.0321, 0.0314, 0.0336,  ..., 0.0327, 0.0324, 0.0304],
         ...,
         [0.0305, 0.0293, 0.0315,  ..., 0.0315, 0.0310, 0.0284],
         [0.0208, 0.0198, 0.0217,  ..., 0.0212, 0.0209, 0.0195],
         [0.0190, 0.0175, 0.0193,  ..., 0.0158, 0.0156, 0.0140]],

        ...,

        [[0.0316, 0.0308, 0.0328,  ..., 0.0295, 0.0303, 0.0292],
         [0.0204, 0.0201, 0.0220,  ..., 0.0199, 0.0206, 0.0192],
         [0.0325, 0.0317, 0.0338,  ..., 0.0301, 0.0307, 0.0288],
         ...,
         [0.0330, 0.0320, 0.0344,  ..., 0.0389, 0.0427, 0.0492],
         [0.0303, 0.0291, 0.0314,  ..., 0.0351, 0.0396, 0.0477],
         [0.0261, 0.0249, 0.0273,  ..., 0.0279, 0.0309, 0.0361]],

        [[0.0374, 0.0365, 0.0387,  ..., 0.0373, 0.0386, 0.0388],
         [0.0303, 0.0297, 0.0318,  ..., 0.0299, 0.0321, 0.0334],
         [0.0271, 0.0263, 0.0282,  ..., 0.0251, 0.0262, 0.0258],
         ...,
         [0.0296, 0.0286, 0.0304,  ..., 0.0374, 0.0457, 0.0598],
         [0.0409, 0.0391, 0.0409,  ..., 0.0496, 0.0581, 0.0739],
         [0.0328, 0.0312, 0.0335,  ..., 0.0381, 0.0424, 0.0510]],

        [[0.0264, 0.0256, 0.0278,  ..., 0.0291, 0.0291, 0.0275],
         [0.0258, 0.0253, 0.0282,  ..., 0.0288, 0.0296, 0.0295],
         [0.0267, 0.0259, 0.0281,  ..., 0.0254, 0.0264, 0.0260],
         ...,
         [0.0323, 0.0310, 0.0333,  ..., 0.0412, 0.0496, 0.0616],
         [0.0414, 0.0399, 0.0426,  ..., 0.0501, 0.0575, 0.0693],
         [0.0326, 0.0314, 0.0343,  ..., 0.0388, 0.0420, 0.0478]]],
       device='cuda:0')
unsqueeze final volume shape (DDPM2d) torch.Size([1, 1, 96, 96, 50])
unsqueeze final volume (DDPM 2D) tensor([[[[[0.0345, 0.0337, 0.0358,  ..., 0.0358, 0.0356, 0.0343],
           [0.0286, 0.0279, 0.0309,  ..., 0.0299, 0.0299, 0.0288],
           [0.0291, 0.0282, 0.0308,  ..., 0.0291, 0.0287, 0.0276],
           ...,
           [0.0321, 0.0309, 0.0330,  ..., 0.0294, 0.0291, 0.0276],
           [0.0388, 0.0374, 0.0393,  ..., 0.0355, 0.0360, 0.0355],
           [0.0297, 0.0286, 0.0308,  ..., 0.0299, 0.0295, 0.0276]],

          [[0.0376, 0.0361, 0.0379,  ..., 0.0327, 0.0332, 0.0329],
           [0.0279, 0.0267, 0.0287,  ..., 0.0234, 0.0243, 0.0242],
           [0.0260, 0.0249, 0.0270,  ..., 0.0233, 0.0235, 0.0226],
           ...,
           [0.0260, 0.0245, 0.0264,  ..., 0.0229, 0.0229, 0.0216],
           [0.0335, 0.0315, 0.0330,  ..., 0.0269, 0.0278, 0.0283],
           [0.0273, 0.0256, 0.0273,  ..., 0.0214, 0.0220, 0.0216]],

          [[0.0309, 0.0297, 0.0318,  ..., 0.0286, 0.0285, 0.0271],
           [0.0209, 0.0200, 0.0221,  ..., 0.0209, 0.0208, 0.0193],
           [0.0321, 0.0314, 0.0336,  ..., 0.0327, 0.0324, 0.0304],
           ...,
           [0.0305, 0.0293, 0.0315,  ..., 0.0315, 0.0310, 0.0284],
           [0.0208, 0.0198, 0.0217,  ..., 0.0212, 0.0209, 0.0195],
           [0.0190, 0.0175, 0.0193,  ..., 0.0158, 0.0156, 0.0140]],

          ...,

          [[0.0316, 0.0308, 0.0328,  ..., 0.0295, 0.0303, 0.0292],
           [0.0204, 0.0201, 0.0220,  ..., 0.0199, 0.0206, 0.0192],
           [0.0325, 0.0317, 0.0338,  ..., 0.0301, 0.0307, 0.0288],
           ...,
           [0.0330, 0.0320, 0.0344,  ..., 0.0389, 0.0427, 0.0492],
           [0.0303, 0.0291, 0.0314,  ..., 0.0351, 0.0396, 0.0477],
           [0.0261, 0.0249, 0.0273,  ..., 0.0279, 0.0309, 0.0361]],

          [[0.0374, 0.0365, 0.0387,  ..., 0.0373, 0.0386, 0.0388],
           [0.0303, 0.0297, 0.0318,  ..., 0.0299, 0.0321, 0.0334],
           [0.0271, 0.0263, 0.0282,  ..., 0.0251, 0.0262, 0.0258],
           ...,
           [0.0296, 0.0286, 0.0304,  ..., 0.0374, 0.0457, 0.0598],
           [0.0409, 0.0391, 0.0409,  ..., 0.0496, 0.0581, 0.0739],
           [0.0328, 0.0312, 0.0335,  ..., 0.0381, 0.0424, 0.0510]],

          [[0.0264, 0.0256, 0.0278,  ..., 0.0291, 0.0291, 0.0275],
           [0.0258, 0.0253, 0.0282,  ..., 0.0288, 0.0296, 0.0295],
           [0.0267, 0.0259, 0.0281,  ..., 0.0254, 0.0264, 0.0260],
           ...,
           [0.0323, 0.0310, 0.0333,  ..., 0.0412, 0.0496, 0.0616],
           [0.0414, 0.0399, 0.0426,  ..., 0.0501, 0.0575, 0.0693],
           [0.0326, 0.0314, 0.0343,  ..., 0.0388, 0.0420, 0.0478]]]]],
       device='cuda:0')
==========
IN _TEST_STEP
==========
ERODING BRAIN MASK
MEDIAN FILTERING
SAVING OUTPUT - ORIGINAL, FINAL, MASK ETC
SAVING IMAGES!
Testing:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:28<00:14,  3.61s/it]==========
IN DDPM ON TEST STEP
==========
THE WEIRD CONDITION BIT CALLED "features" in DDPM_2D
IN SPARK ENCODER FORWARDDD
x in shape torch.Size([50, 1, 96, 96])
out features torch.Size([50, 512])
i'm i DDPM2d forward block (whch is basically the encoder)
Context vector c shape: torch.Size([50, 512])
shape features:  torch.Size([50, 512])
additng features to latern space
latent space: []
iAM IN THE FORWARD METHOD OF THE WEIRD GUASSIAN IN cond_DDPM.py. I WILL BE CALLING p_losses
i am in p_losses in guassian which seems to be crucial to everything
conditioning vector shape:  torch.Size([50, 512])
in plosses i am getting a noisy image x
x shape:  torch.Size([50, 1, 96, 96])
getting model out
Initial input shape: torch.Size([50, 1, 96, 96])

inputblocks
Before block 0, shape: torch.Size([50, 1, 96, 96])
After block 0, shape: torch.Size([50, 128, 96, 96])
-
Before block 1, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 1, shape: torch.Size([50, 128, 96, 96])
-
Before block 2, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 2, shape: torch.Size([50, 128, 96, 96])
-
Before block 3, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 3, shape: torch.Size([50, 128, 96, 96])
-
Before block 4, shape: torch.Size([50, 128, 96, 96])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 256])
After block 4, shape: torch.Size([50, 128, 48, 48])
-
Before block 5, shape: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 48, 48])
-
Before block 8, shape: torch.Size([50, 256, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 8, shape: torch.Size([50, 256, 24, 24])
-
Before block 9, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 9, shape: torch.Size([50, 256, 24, 24])
-
Before block 10, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 10, shape: torch.Size([50, 256, 24, 24])
-
Before block 11, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 11, shape: torch.Size([50, 256, 24, 24])
-

Before middle block, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
in unet attention block!
x shape torch.Size([50, 256, 24, 24])
out dims torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])


After middle block, shape: torch.Size([50, 256, 24, 24])
-



outputblocks
Before block 0, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 0, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 0, shape: torch.Size([50, 256, 24, 24])
-
Before block 1, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 1, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 1, shape: torch.Size([50, 256, 24, 24])
-
Before block 2, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 2, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 2, shape: torch.Size([50, 256, 24, 24])
-
Before block 3, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 3, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 3, shape: torch.Size([50, 256, 48, 48])
-
Before block 4, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 4, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 4, shape: torch.Size([50, 256, 48, 48])
-
Before block 5, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 5, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 6, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 7, shape: torch.Size([50, 384, 48, 48])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 96, 96])
-
Before block 8, shape: torch.Size([50, 256, 96, 96])
After concatenation in upsampling block 8, shape: torch.Size([50, 384, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 8, shape: torch.Size([50, 128, 96, 96])
-
Before block 9, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 9, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 9, shape: torch.Size([50, 128, 96, 96])
-
Before block 10, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 10, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 10, shape: torch.Size([50, 128, 96, 96])
-
Before block 11, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 11, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 11, shape: torch.Size([50, 128, 96, 96])
-

Before Final layer shape: torch.Size([50, 128, 96, 96])
Final output shape: torch.Size([50, 1, 96, 96])
model out shape:  torch.Size([50, 1, 96, 96])
iAM IN THE FORWARD METHOD OF THE WEIRD GUASSIAN IN cond_DDPM.py. I WILL BE CALLING p_losses
i am in p_losses in guassian which seems to be crucial to everything
conditioning vector shape:  torch.Size([50, 512])
in plosses i am getting a noisy image x
x shape:  torch.Size([50, 1, 96, 96])
getting model out
Initial input shape: torch.Size([50, 1, 96, 96])

inputblocks
Before block 0, shape: torch.Size([50, 1, 96, 96])
After block 0, shape: torch.Size([50, 128, 96, 96])
-
Before block 1, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 1, shape: torch.Size([50, 128, 96, 96])
-
Before block 2, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 2, shape: torch.Size([50, 128, 96, 96])
-
Before block 3, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 3, shape: torch.Size([50, 128, 96, 96])
-
Before block 4, shape: torch.Size([50, 128, 96, 96])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 256])
After block 4, shape: torch.Size([50, 128, 48, 48])
-
Before block 5, shape: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 48, 48])
-
Before block 8, shape: torch.Size([50, 256, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 8, shape: torch.Size([50, 256, 24, 24])
-
Before block 9, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 9, shape: torch.Size([50, 256, 24, 24])
-
Before block 10, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 10, shape: torch.Size([50, 256, 24, 24])
-
Before block 11, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 11, shape: torch.Size([50, 256, 24, 24])
-

Before middle block, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
in unet attention block!
x shape torch.Size([50, 256, 24, 24])
out dims torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])


After middle block, shape: torch.Size([50, 256, 24, 24])
-



outputblocks
Before block 0, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 0, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 0, shape: torch.Size([50, 256, 24, 24])
-
Before block 1, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 1, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 1, shape: torch.Size([50, 256, 24, 24])
-
Before block 2, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 2, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 2, shape: torch.Size([50, 256, 24, 24])
-
Before block 3, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 3, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 3, shape: torch.Size([50, 256, 48, 48])
-
Before block 4, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 4, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 4, shape: torch.Size([50, 256, 48, 48])
-
Before block 5, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 5, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 6, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 7, shape: torch.Size([50, 384, 48, 48])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 96, 96])
-
Before block 8, shape: torch.Size([50, 256, 96, 96])
After concatenation in upsampling block 8, shape: torch.Size([50, 384, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 8, shape: torch.Size([50, 128, 96, 96])
-
Before block 9, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 9, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 9, shape: torch.Size([50, 128, 96, 96])
-
Before block 10, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 10, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 10, shape: torch.Size([50, 128, 96, 96])
-
Before block 11, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 11, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 11, shape: torch.Size([50, 128, 96, 96])
-

Before Final layer shape: torch.Size([50, 128, 96, 96])
Final output shape: torch.Size([50, 1, 96, 96])
model out shape:  torch.Size([50, 1, 96, 96])
iAM IN THE FORWARD METHOD OF THE WEIRD GUASSIAN IN cond_DDPM.py. I WILL BE CALLING p_losses
i am in p_losses in guassian which seems to be crucial to everything
conditioning vector shape:  torch.Size([50, 512])
in plosses i am getting a noisy image x
x shape:  torch.Size([50, 1, 96, 96])
getting model out
Initial input shape: torch.Size([50, 1, 96, 96])

inputblocks
Before block 0, shape: torch.Size([50, 1, 96, 96])
After block 0, shape: torch.Size([50, 128, 96, 96])
-
Before block 1, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 1, shape: torch.Size([50, 128, 96, 96])
-
Before block 2, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 2, shape: torch.Size([50, 128, 96, 96])
-
Before block 3, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 3, shape: torch.Size([50, 128, 96, 96])
-
Before block 4, shape: torch.Size([50, 128, 96, 96])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 256])
After block 4, shape: torch.Size([50, 128, 48, 48])
-
Before block 5, shape: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 48, 48])
-
Before block 8, shape: torch.Size([50, 256, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 8, shape: torch.Size([50, 256, 24, 24])
-
Before block 9, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 9, shape: torch.Size([50, 256, 24, 24])
-
Before block 10, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 10, shape: torch.Size([50, 256, 24, 24])
-
Before block 11, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 11, shape: torch.Size([50, 256, 24, 24])
-

Before middle block, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
in unet attention block!
x shape torch.Size([50, 256, 24, 24])
out dims torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])


After middle block, shape: torch.Size([50, 256, 24, 24])
-



outputblocks
Before block 0, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 0, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 0, shape: torch.Size([50, 256, 24, 24])
-
Before block 1, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 1, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 1, shape: torch.Size([50, 256, 24, 24])
-
Before block 2, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 2, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 2, shape: torch.Size([50, 256, 24, 24])
-
Before block 3, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 3, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 3, shape: torch.Size([50, 256, 48, 48])
-
Before block 4, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 4, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 4, shape: torch.Size([50, 256, 48, 48])
-
Before block 5, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 5, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 6, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 7, shape: torch.Size([50, 384, 48, 48])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 96, 96])
-
Before block 8, shape: torch.Size([50, 256, 96, 96])
After concatenation in upsampling block 8, shape: torch.Size([50, 384, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 8, shape: torch.Size([50, 128, 96, 96])
-
Before block 9, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 9, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 9, shape: torch.Size([50, 128, 96, 96])
-
Before block 10, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 10, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 10, shape: torch.Size([50, 128, 96, 96])
-
Before block 11, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 11, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 11, shape: torch.Size([50, 128, 96, 96])
-

Before Final layer shape: torch.Size([50, 128, 96, 96])
Final output shape: torch.Size([50, 1, 96, 96])
model out shape:  torch.Size([50, 1, 96, 96])
reconstruction shape torch.Size([50, 1, 96, 96])
reconstruction tensor([[[[0.0286, 0.0238, 0.0231,  ..., 0.0304, 0.0306, 0.0243],
          [0.0287, 0.0230, 0.0216,  ..., 0.0271, 0.0319, 0.0238],
          [0.0231, 0.0147, 0.0262,  ..., 0.0245, 0.0210, 0.0223],
          ...,
          [0.0195, 0.0108, 0.0184,  ..., 0.0248, 0.0188, 0.0194],
          [0.0290, 0.0199, 0.0118,  ..., 0.0191, 0.0291, 0.0209],
          [0.0156, 0.0106, 0.0086,  ..., 0.0187, 0.0230, 0.0175]]],


        [[[0.0282, 0.0232, 0.0230,  ..., 0.0302, 0.0296, 0.0238],
          [0.0278, 0.0218, 0.0210,  ..., 0.0264, 0.0304, 0.0226],
          [0.0225, 0.0141, 0.0260,  ..., 0.0246, 0.0204, 0.0221],
          ...,
          [0.0192, 0.0099, 0.0182,  ..., 0.0248, 0.0178, 0.0188],
          [0.0284, 0.0184, 0.0113,  ..., 0.0177, 0.0262, 0.0194],
          [0.0161, 0.0104, 0.0089,  ..., 0.0183, 0.0216, 0.0173]]],


        [[[0.0294, 0.0247, 0.0246,  ..., 0.0317, 0.0308, 0.0253],
          [0.0286, 0.0226, 0.0225,  ..., 0.0278, 0.0312, 0.0237],
          [0.0238, 0.0155, 0.0282,  ..., 0.0269, 0.0223, 0.0235],
          ...,
          [0.0212, 0.0120, 0.0210,  ..., 0.0270, 0.0196, 0.0208],
          [0.0297, 0.0199, 0.0136,  ..., 0.0193, 0.0273, 0.0208],
          [0.0178, 0.0128, 0.0116,  ..., 0.0204, 0.0236, 0.0193]]],


        ...,


        [[[0.0303, 0.0246, 0.0264,  ..., 0.0315, 0.0278, 0.0269],
          [0.0225, 0.0148, 0.0199,  ..., 0.0224, 0.0225, 0.0191],
          [0.0237, 0.0139, 0.0284,  ..., 0.0259, 0.0208, 0.0237],
          ...,
          [0.0192, 0.0057, 0.0171,  ..., 0.0305, 0.0189, 0.0194],
          [0.0255, 0.0087, 0.0058,  ..., 0.0159, 0.0199, 0.0171],
          [0.0189, 0.0103, 0.0097,  ..., 0.0164, 0.0179, 0.0204]]],


        [[[0.0295, 0.0241, 0.0257,  ..., 0.0312, 0.0277, 0.0260],
          [0.0221, 0.0150, 0.0194,  ..., 0.0222, 0.0229, 0.0194],
          [0.0232, 0.0133, 0.0274,  ..., 0.0252, 0.0207, 0.0237],
          ...,
          [0.0180, 0.0041, 0.0150,  ..., 0.0300, 0.0186, 0.0186],
          [0.0247, 0.0072, 0.0037,  ..., 0.0155, 0.0202, 0.0164],
          [0.0175, 0.0081, 0.0070,  ..., 0.0151, 0.0170, 0.0190]]],


        [[[0.0290, 0.0241, 0.0252,  ..., 0.0308, 0.0278, 0.0251],
          [0.0221, 0.0154, 0.0190,  ..., 0.0222, 0.0238, 0.0196],
          [0.0228, 0.0128, 0.0260,  ..., 0.0243, 0.0205, 0.0234],
          ...,
          [0.0165, 0.0017, 0.0121,  ..., 0.0283, 0.0177, 0.0177],
          [0.0230, 0.0050, 0.0010,  ..., 0.0147, 0.0200, 0.0156],
          [0.0156, 0.0055, 0.0038,  ..., 0.0138, 0.0155, 0.0173]]]],
       device='cuda:0')
FINAL VOLUME (DDPM) shape torch.Size([96, 96, 50])
FINAL VOLUME tensor([[[0.0286, 0.0282, 0.0294,  ..., 0.0303, 0.0295, 0.0290],
         [0.0238, 0.0232, 0.0247,  ..., 0.0246, 0.0241, 0.0241],
         [0.0231, 0.0230, 0.0246,  ..., 0.0264, 0.0257, 0.0252],
         ...,
         [0.0304, 0.0302, 0.0317,  ..., 0.0315, 0.0312, 0.0308],
         [0.0306, 0.0296, 0.0308,  ..., 0.0278, 0.0277, 0.0278],
         [0.0243, 0.0238, 0.0253,  ..., 0.0269, 0.0260, 0.0251]],

        [[0.0287, 0.0278, 0.0286,  ..., 0.0225, 0.0221, 0.0221],
         [0.0230, 0.0218, 0.0226,  ..., 0.0148, 0.0150, 0.0154],
         [0.0216, 0.0210, 0.0225,  ..., 0.0199, 0.0194, 0.0190],
         ...,
         [0.0271, 0.0264, 0.0278,  ..., 0.0224, 0.0222, 0.0222],
         [0.0319, 0.0304, 0.0312,  ..., 0.0225, 0.0229, 0.0238],
         [0.0238, 0.0226, 0.0237,  ..., 0.0191, 0.0194, 0.0196]],

        [[0.0231, 0.0225, 0.0238,  ..., 0.0237, 0.0232, 0.0228],
         [0.0147, 0.0141, 0.0155,  ..., 0.0139, 0.0133, 0.0128],
         [0.0262, 0.0260, 0.0282,  ..., 0.0284, 0.0274, 0.0260],
         ...,
         [0.0245, 0.0246, 0.0269,  ..., 0.0259, 0.0252, 0.0243],
         [0.0210, 0.0204, 0.0223,  ..., 0.0208, 0.0207, 0.0205],
         [0.0223, 0.0221, 0.0235,  ..., 0.0237, 0.0237, 0.0234]],

        ...,

        [[0.0195, 0.0192, 0.0212,  ..., 0.0192, 0.0180, 0.0165],
         [0.0108, 0.0099, 0.0120,  ..., 0.0057, 0.0041, 0.0017],
         [0.0184, 0.0182, 0.0210,  ..., 0.0171, 0.0150, 0.0121],
         ...,
         [0.0248, 0.0248, 0.0270,  ..., 0.0305, 0.0300, 0.0283],
         [0.0188, 0.0178, 0.0196,  ..., 0.0189, 0.0186, 0.0177],
         [0.0194, 0.0188, 0.0208,  ..., 0.0194, 0.0186, 0.0177]],

        [[0.0290, 0.0284, 0.0297,  ..., 0.0255, 0.0247, 0.0230],
         [0.0199, 0.0184, 0.0199,  ..., 0.0087, 0.0072, 0.0050],
         [0.0118, 0.0113, 0.0136,  ..., 0.0058, 0.0037, 0.0010],
         ...,
         [0.0191, 0.0177, 0.0193,  ..., 0.0159, 0.0155, 0.0147],
         [0.0291, 0.0262, 0.0273,  ..., 0.0199, 0.0202, 0.0200],
         [0.0209, 0.0194, 0.0208,  ..., 0.0171, 0.0164, 0.0156]],

        [[0.0156, 0.0161, 0.0178,  ..., 0.0189, 0.0175, 0.0156],
         [0.0106, 0.0104, 0.0128,  ..., 0.0103, 0.0081, 0.0055],
         [0.0086, 0.0089, 0.0116,  ..., 0.0097, 0.0070, 0.0038],
         ...,
         [0.0187, 0.0183, 0.0204,  ..., 0.0164, 0.0151, 0.0138],
         [0.0230, 0.0216, 0.0236,  ..., 0.0179, 0.0170, 0.0155],
         [0.0175, 0.0173, 0.0193,  ..., 0.0204, 0.0190, 0.0173]]],
       device='cuda:0')
unsqueeze final volume shape (DDPM2d) torch.Size([1, 1, 96, 96, 50])
unsqueeze final volume (DDPM 2D) tensor([[[[[0.0286, 0.0282, 0.0294,  ..., 0.0303, 0.0295, 0.0290],
           [0.0238, 0.0232, 0.0247,  ..., 0.0246, 0.0241, 0.0241],
           [0.0231, 0.0230, 0.0246,  ..., 0.0264, 0.0257, 0.0252],
           ...,
           [0.0304, 0.0302, 0.0317,  ..., 0.0315, 0.0312, 0.0308],
           [0.0306, 0.0296, 0.0308,  ..., 0.0278, 0.0277, 0.0278],
           [0.0243, 0.0238, 0.0253,  ..., 0.0269, 0.0260, 0.0251]],

          [[0.0287, 0.0278, 0.0286,  ..., 0.0225, 0.0221, 0.0221],
           [0.0230, 0.0218, 0.0226,  ..., 0.0148, 0.0150, 0.0154],
           [0.0216, 0.0210, 0.0225,  ..., 0.0199, 0.0194, 0.0190],
           ...,
           [0.0271, 0.0264, 0.0278,  ..., 0.0224, 0.0222, 0.0222],
           [0.0319, 0.0304, 0.0312,  ..., 0.0225, 0.0229, 0.0238],
           [0.0238, 0.0226, 0.0237,  ..., 0.0191, 0.0194, 0.0196]],

          [[0.0231, 0.0225, 0.0238,  ..., 0.0237, 0.0232, 0.0228],
           [0.0147, 0.0141, 0.0155,  ..., 0.0139, 0.0133, 0.0128],
           [0.0262, 0.0260, 0.0282,  ..., 0.0284, 0.0274, 0.0260],
           ...,
           [0.0245, 0.0246, 0.0269,  ..., 0.0259, 0.0252, 0.0243],
           [0.0210, 0.0204, 0.0223,  ..., 0.0208, 0.0207, 0.0205],
           [0.0223, 0.0221, 0.0235,  ..., 0.0237, 0.0237, 0.0234]],

          ...,

          [[0.0195, 0.0192, 0.0212,  ..., 0.0192, 0.0180, 0.0165],
           [0.0108, 0.0099, 0.0120,  ..., 0.0057, 0.0041, 0.0017],
           [0.0184, 0.0182, 0.0210,  ..., 0.0171, 0.0150, 0.0121],
           ...,
           [0.0248, 0.0248, 0.0270,  ..., 0.0305, 0.0300, 0.0283],
           [0.0188, 0.0178, 0.0196,  ..., 0.0189, 0.0186, 0.0177],
           [0.0194, 0.0188, 0.0208,  ..., 0.0194, 0.0186, 0.0177]],

          [[0.0290, 0.0284, 0.0297,  ..., 0.0255, 0.0247, 0.0230],
           [0.0199, 0.0184, 0.0199,  ..., 0.0087, 0.0072, 0.0050],
           [0.0118, 0.0113, 0.0136,  ..., 0.0058, 0.0037, 0.0010],
           ...,
           [0.0191, 0.0177, 0.0193,  ..., 0.0159, 0.0155, 0.0147],
           [0.0291, 0.0262, 0.0273,  ..., 0.0199, 0.0202, 0.0200],
           [0.0209, 0.0194, 0.0208,  ..., 0.0171, 0.0164, 0.0156]],

          [[0.0156, 0.0161, 0.0178,  ..., 0.0189, 0.0175, 0.0156],
           [0.0106, 0.0104, 0.0128,  ..., 0.0103, 0.0081, 0.0055],
           [0.0086, 0.0089, 0.0116,  ..., 0.0097, 0.0070, 0.0038],
           ...,
           [0.0187, 0.0183, 0.0204,  ..., 0.0164, 0.0151, 0.0138],
           [0.0230, 0.0216, 0.0236,  ..., 0.0179, 0.0170, 0.0155],
           [0.0175, 0.0173, 0.0193,  ..., 0.0204, 0.0190, 0.0173]]]]],
       device='cuda:0')
==========
IN _TEST_STEP
==========
ERODING BRAIN MASK
MEDIAN FILTERING
SAVING OUTPUT - ORIGINAL, FINAL, MASK ETC
SAVING IMAGES!
Testing:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:31<00:10,  3.46s/it]==========
IN DDPM ON TEST STEP
==========
THE WEIRD CONDITION BIT CALLED "features" in DDPM_2D
IN SPARK ENCODER FORWARDDD
x in shape torch.Size([50, 1, 96, 96])
out features torch.Size([50, 512])
i'm i DDPM2d forward block (whch is basically the encoder)
Context vector c shape: torch.Size([50, 512])
shape features:  torch.Size([50, 512])
additng features to latern space
latent space: []
iAM IN THE FORWARD METHOD OF THE WEIRD GUASSIAN IN cond_DDPM.py. I WILL BE CALLING p_losses
i am in p_losses in guassian which seems to be crucial to everything
conditioning vector shape:  torch.Size([50, 512])
in plosses i am getting a noisy image x
x shape:  torch.Size([50, 1, 96, 96])
getting model out
Initial input shape: torch.Size([50, 1, 96, 96])

inputblocks
Before block 0, shape: torch.Size([50, 1, 96, 96])
After block 0, shape: torch.Size([50, 128, 96, 96])
-
Before block 1, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 1, shape: torch.Size([50, 128, 96, 96])
-
Before block 2, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 2, shape: torch.Size([50, 128, 96, 96])
-
Before block 3, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 3, shape: torch.Size([50, 128, 96, 96])
-
Before block 4, shape: torch.Size([50, 128, 96, 96])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 256])
After block 4, shape: torch.Size([50, 128, 48, 48])
-
Before block 5, shape: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 48, 48])
-
Before block 8, shape: torch.Size([50, 256, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 8, shape: torch.Size([50, 256, 24, 24])
-
Before block 9, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 9, shape: torch.Size([50, 256, 24, 24])
-
Before block 10, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 10, shape: torch.Size([50, 256, 24, 24])
-
Before block 11, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 11, shape: torch.Size([50, 256, 24, 24])
-

Before middle block, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
in unet attention block!
x shape torch.Size([50, 256, 24, 24])
out dims torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])


After middle block, shape: torch.Size([50, 256, 24, 24])
-



outputblocks
Before block 0, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 0, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 0, shape: torch.Size([50, 256, 24, 24])
-
Before block 1, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 1, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 1, shape: torch.Size([50, 256, 24, 24])
-
Before block 2, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 2, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 2, shape: torch.Size([50, 256, 24, 24])
-
Before block 3, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 3, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 3, shape: torch.Size([50, 256, 48, 48])
-
Before block 4, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 4, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 4, shape: torch.Size([50, 256, 48, 48])
-
Before block 5, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 5, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 6, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 7, shape: torch.Size([50, 384, 48, 48])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 96, 96])
-
Before block 8, shape: torch.Size([50, 256, 96, 96])
After concatenation in upsampling block 8, shape: torch.Size([50, 384, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 8, shape: torch.Size([50, 128, 96, 96])
-
Before block 9, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 9, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 9, shape: torch.Size([50, 128, 96, 96])
-
Before block 10, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 10, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 10, shape: torch.Size([50, 128, 96, 96])
-
Before block 11, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 11, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 11, shape: torch.Size([50, 128, 96, 96])
-

Before Final layer shape: torch.Size([50, 128, 96, 96])
Final output shape: torch.Size([50, 1, 96, 96])
model out shape:  torch.Size([50, 1, 96, 96])
iAM IN THE FORWARD METHOD OF THE WEIRD GUASSIAN IN cond_DDPM.py. I WILL BE CALLING p_losses
i am in p_losses in guassian which seems to be crucial to everything
conditioning vector shape:  torch.Size([50, 512])
in plosses i am getting a noisy image x
x shape:  torch.Size([50, 1, 96, 96])
getting model out
Initial input shape: torch.Size([50, 1, 96, 96])

inputblocks
Before block 0, shape: torch.Size([50, 1, 96, 96])
After block 0, shape: torch.Size([50, 128, 96, 96])
-
Before block 1, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 1, shape: torch.Size([50, 128, 96, 96])
-
Before block 2, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 2, shape: torch.Size([50, 128, 96, 96])
-
Before block 3, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 3, shape: torch.Size([50, 128, 96, 96])
-
Before block 4, shape: torch.Size([50, 128, 96, 96])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 256])
After block 4, shape: torch.Size([50, 128, 48, 48])
-
Before block 5, shape: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 48, 48])
-
Before block 8, shape: torch.Size([50, 256, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 8, shape: torch.Size([50, 256, 24, 24])
-
Before block 9, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 9, shape: torch.Size([50, 256, 24, 24])
-
Before block 10, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 10, shape: torch.Size([50, 256, 24, 24])
-
Before block 11, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 11, shape: torch.Size([50, 256, 24, 24])
-

Before middle block, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
in unet attention block!
x shape torch.Size([50, 256, 24, 24])
out dims torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])


After middle block, shape: torch.Size([50, 256, 24, 24])
-



outputblocks
Before block 0, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 0, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 0, shape: torch.Size([50, 256, 24, 24])
-
Before block 1, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 1, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 1, shape: torch.Size([50, 256, 24, 24])
-
Before block 2, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 2, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 2, shape: torch.Size([50, 256, 24, 24])
-
Before block 3, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 3, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 3, shape: torch.Size([50, 256, 48, 48])
-
Before block 4, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 4, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 4, shape: torch.Size([50, 256, 48, 48])
-
Before block 5, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 5, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 6, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 7, shape: torch.Size([50, 384, 48, 48])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 96, 96])
-
Before block 8, shape: torch.Size([50, 256, 96, 96])
After concatenation in upsampling block 8, shape: torch.Size([50, 384, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 8, shape: torch.Size([50, 128, 96, 96])
-
Before block 9, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 9, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 9, shape: torch.Size([50, 128, 96, 96])
-
Before block 10, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 10, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 10, shape: torch.Size([50, 128, 96, 96])
-
Before block 11, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 11, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 11, shape: torch.Size([50, 128, 96, 96])
-

Before Final layer shape: torch.Size([50, 128, 96, 96])
Final output shape: torch.Size([50, 1, 96, 96])
model out shape:  torch.Size([50, 1, 96, 96])
iAM IN THE FORWARD METHOD OF THE WEIRD GUASSIAN IN cond_DDPM.py. I WILL BE CALLING p_losses
i am in p_losses in guassian which seems to be crucial to everything
conditioning vector shape:  torch.Size([50, 512])
in plosses i am getting a noisy image x
x shape:  torch.Size([50, 1, 96, 96])
getting model out
Initial input shape: torch.Size([50, 1, 96, 96])

inputblocks
Before block 0, shape: torch.Size([50, 1, 96, 96])
After block 0, shape: torch.Size([50, 128, 96, 96])
-
Before block 1, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 1, shape: torch.Size([50, 128, 96, 96])
-
Before block 2, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 2, shape: torch.Size([50, 128, 96, 96])
-
Before block 3, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 3, shape: torch.Size([50, 128, 96, 96])
-
Before block 4, shape: torch.Size([50, 128, 96, 96])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 256])
After block 4, shape: torch.Size([50, 128, 48, 48])
-
Before block 5, shape: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 48, 48])
-
Before block 8, shape: torch.Size([50, 256, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 8, shape: torch.Size([50, 256, 24, 24])
-
Before block 9, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 9, shape: torch.Size([50, 256, 24, 24])
-
Before block 10, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 10, shape: torch.Size([50, 256, 24, 24])
-
Before block 11, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 11, shape: torch.Size([50, 256, 24, 24])
-

Before middle block, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
in unet attention block!
x shape torch.Size([50, 256, 24, 24])
out dims torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])


After middle block, shape: torch.Size([50, 256, 24, 24])
-



outputblocks
Before block 0, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 0, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 0, shape: torch.Size([50, 256, 24, 24])
-
Before block 1, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 1, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 1, shape: torch.Size([50, 256, 24, 24])
-
Before block 2, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 2, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 2, shape: torch.Size([50, 256, 24, 24])
-
Before block 3, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 3, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 3, shape: torch.Size([50, 256, 48, 48])
-
Before block 4, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 4, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 4, shape: torch.Size([50, 256, 48, 48])
-
Before block 5, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 5, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 6, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 7, shape: torch.Size([50, 384, 48, 48])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 96, 96])
-
Before block 8, shape: torch.Size([50, 256, 96, 96])
After concatenation in upsampling block 8, shape: torch.Size([50, 384, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 8, shape: torch.Size([50, 128, 96, 96])
-
Before block 9, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 9, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 9, shape: torch.Size([50, 128, 96, 96])
-
Before block 10, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 10, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 10, shape: torch.Size([50, 128, 96, 96])
-
Before block 11, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 11, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 11, shape: torch.Size([50, 128, 96, 96])
-

Before Final layer shape: torch.Size([50, 128, 96, 96])
Final output shape: torch.Size([50, 1, 96, 96])
model out shape:  torch.Size([50, 1, 96, 96])
reconstruction shape torch.Size([50, 1, 96, 96])
reconstruction tensor([[[[0.0251, 0.0212, 0.0203,  ..., 0.0223, 0.0242, 0.0203],
          [0.0247, 0.0163, 0.0131,  ..., 0.0145, 0.0202, 0.0173],
          [0.0216, 0.0105, 0.0168,  ..., 0.0186, 0.0133, 0.0155],
          ...,
          [0.0202, 0.0089, 0.0199,  ..., 0.0239, 0.0167, 0.0164],
          [0.0275, 0.0180, 0.0154,  ..., 0.0177, 0.0228, 0.0170],
          [0.0171, 0.0165, 0.0168,  ..., 0.0141, 0.0164, 0.0084]]],


        [[[0.0269, 0.0232, 0.0221,  ..., 0.0251, 0.0267, 0.0222],
          [0.0264, 0.0186, 0.0155,  ..., 0.0177, 0.0230, 0.0190],
          [0.0238, 0.0133, 0.0194,  ..., 0.0213, 0.0160, 0.0175],
          ...,
          [0.0221, 0.0116, 0.0224,  ..., 0.0267, 0.0195, 0.0184],
          [0.0295, 0.0203, 0.0177,  ..., 0.0208, 0.0258, 0.0193],
          [0.0186, 0.0181, 0.0187,  ..., 0.0164, 0.0189, 0.0098]]],


        [[[0.0276, 0.0239, 0.0225,  ..., 0.0260, 0.0276, 0.0225],
          [0.0273, 0.0194, 0.0162,  ..., 0.0189, 0.0241, 0.0198],
          [0.0245, 0.0140, 0.0203,  ..., 0.0224, 0.0169, 0.0181],
          ...,
          [0.0228, 0.0125, 0.0232,  ..., 0.0278, 0.0208, 0.0194],
          [0.0303, 0.0214, 0.0188,  ..., 0.0217, 0.0271, 0.0203],
          [0.0194, 0.0192, 0.0196,  ..., 0.0174, 0.0199, 0.0107]]],


        ...,


        [[[0.0291, 0.0252, 0.0230,  ..., 0.0212, 0.0199, 0.0207],
          [0.0231, 0.0135, 0.0132,  ..., 0.0133, 0.0135, 0.0109],
          [0.0204, 0.0099, 0.0194,  ..., 0.0208, 0.0132, 0.0126],
          ...,
          [0.0203, 0.0094, 0.0214,  ..., 0.0285, 0.0201, 0.0168],
          [0.0278, 0.0160, 0.0148,  ..., 0.0194, 0.0208, 0.0144],
          [0.0234, 0.0205, 0.0185,  ..., 0.0170, 0.0189, 0.0119]]],


        [[[0.0278, 0.0248, 0.0232,  ..., 0.0218, 0.0200, 0.0208],
          [0.0212, 0.0125, 0.0130,  ..., 0.0133, 0.0129, 0.0109],
          [0.0199, 0.0101, 0.0199,  ..., 0.0221, 0.0135, 0.0134],
          ...,
          [0.0201, 0.0092, 0.0212,  ..., 0.0291, 0.0198, 0.0166],
          [0.0273, 0.0156, 0.0144,  ..., 0.0193, 0.0196, 0.0134],
          [0.0223, 0.0193, 0.0177,  ..., 0.0164, 0.0177, 0.0106]]],


        [[[0.0281, 0.0253, 0.0243,  ..., 0.0240, 0.0218, 0.0221],
          [0.0210, 0.0128, 0.0135,  ..., 0.0146, 0.0138, 0.0120],
          [0.0203, 0.0107, 0.0203,  ..., 0.0238, 0.0146, 0.0146],
          ...,
          [0.0216, 0.0103, 0.0219,  ..., 0.0293, 0.0196, 0.0168],
          [0.0288, 0.0167, 0.0153,  ..., 0.0192, 0.0194, 0.0132],
          [0.0226, 0.0199, 0.0185,  ..., 0.0163, 0.0171, 0.0093]]]],
       device='cuda:0')
FINAL VOLUME (DDPM) shape torch.Size([96, 96, 50])
FINAL VOLUME tensor([[[0.0251, 0.0269, 0.0276,  ..., 0.0291, 0.0278, 0.0281],
         [0.0212, 0.0232, 0.0239,  ..., 0.0252, 0.0248, 0.0253],
         [0.0203, 0.0221, 0.0225,  ..., 0.0230, 0.0232, 0.0243],
         ...,
         [0.0223, 0.0251, 0.0260,  ..., 0.0212, 0.0218, 0.0240],
         [0.0242, 0.0267, 0.0276,  ..., 0.0199, 0.0200, 0.0218],
         [0.0203, 0.0222, 0.0225,  ..., 0.0207, 0.0208, 0.0221]],

        [[0.0247, 0.0264, 0.0273,  ..., 0.0231, 0.0212, 0.0210],
         [0.0163, 0.0186, 0.0194,  ..., 0.0135, 0.0125, 0.0128],
         [0.0131, 0.0155, 0.0162,  ..., 0.0132, 0.0130, 0.0135],
         ...,
         [0.0145, 0.0177, 0.0189,  ..., 0.0133, 0.0133, 0.0146],
         [0.0202, 0.0230, 0.0241,  ..., 0.0135, 0.0129, 0.0138],
         [0.0173, 0.0190, 0.0198,  ..., 0.0109, 0.0109, 0.0120]],

        [[0.0216, 0.0238, 0.0245,  ..., 0.0204, 0.0199, 0.0203],
         [0.0105, 0.0133, 0.0140,  ..., 0.0099, 0.0101, 0.0107],
         [0.0168, 0.0194, 0.0203,  ..., 0.0194, 0.0199, 0.0203],
         ...,
         [0.0186, 0.0213, 0.0224,  ..., 0.0208, 0.0221, 0.0238],
         [0.0133, 0.0160, 0.0169,  ..., 0.0132, 0.0135, 0.0146],
         [0.0155, 0.0175, 0.0181,  ..., 0.0126, 0.0134, 0.0146]],

        ...,

        [[0.0202, 0.0221, 0.0228,  ..., 0.0203, 0.0201, 0.0216],
         [0.0089, 0.0116, 0.0125,  ..., 0.0094, 0.0092, 0.0103],
         [0.0199, 0.0224, 0.0232,  ..., 0.0214, 0.0212, 0.0219],
         ...,
         [0.0239, 0.0267, 0.0278,  ..., 0.0285, 0.0291, 0.0293],
         [0.0167, 0.0195, 0.0208,  ..., 0.0201, 0.0198, 0.0196],
         [0.0164, 0.0184, 0.0194,  ..., 0.0168, 0.0166, 0.0168]],

        [[0.0275, 0.0295, 0.0303,  ..., 0.0278, 0.0273, 0.0288],
         [0.0180, 0.0203, 0.0214,  ..., 0.0160, 0.0156, 0.0167],
         [0.0154, 0.0177, 0.0188,  ..., 0.0148, 0.0144, 0.0153],
         ...,
         [0.0177, 0.0208, 0.0217,  ..., 0.0194, 0.0193, 0.0192],
         [0.0228, 0.0258, 0.0271,  ..., 0.0208, 0.0196, 0.0194],
         [0.0170, 0.0193, 0.0203,  ..., 0.0144, 0.0134, 0.0132]],

        [[0.0171, 0.0186, 0.0194,  ..., 0.0234, 0.0223, 0.0226],
         [0.0165, 0.0181, 0.0192,  ..., 0.0205, 0.0193, 0.0199],
         [0.0168, 0.0187, 0.0196,  ..., 0.0185, 0.0177, 0.0185],
         ...,
         [0.0141, 0.0164, 0.0174,  ..., 0.0170, 0.0164, 0.0163],
         [0.0164, 0.0189, 0.0199,  ..., 0.0189, 0.0177, 0.0171],
         [0.0084, 0.0098, 0.0107,  ..., 0.0119, 0.0106, 0.0093]]],
       device='cuda:0')
unsqueeze final volume shape (DDPM2d) torch.Size([1, 1, 96, 96, 50])
unsqueeze final volume (DDPM 2D) tensor([[[[[0.0251, 0.0269, 0.0276,  ..., 0.0291, 0.0278, 0.0281],
           [0.0212, 0.0232, 0.0239,  ..., 0.0252, 0.0248, 0.0253],
           [0.0203, 0.0221, 0.0225,  ..., 0.0230, 0.0232, 0.0243],
           ...,
           [0.0223, 0.0251, 0.0260,  ..., 0.0212, 0.0218, 0.0240],
           [0.0242, 0.0267, 0.0276,  ..., 0.0199, 0.0200, 0.0218],
           [0.0203, 0.0222, 0.0225,  ..., 0.0207, 0.0208, 0.0221]],

          [[0.0247, 0.0264, 0.0273,  ..., 0.0231, 0.0212, 0.0210],
           [0.0163, 0.0186, 0.0194,  ..., 0.0135, 0.0125, 0.0128],
           [0.0131, 0.0155, 0.0162,  ..., 0.0132, 0.0130, 0.0135],
           ...,
           [0.0145, 0.0177, 0.0189,  ..., 0.0133, 0.0133, 0.0146],
           [0.0202, 0.0230, 0.0241,  ..., 0.0135, 0.0129, 0.0138],
           [0.0173, 0.0190, 0.0198,  ..., 0.0109, 0.0109, 0.0120]],

          [[0.0216, 0.0238, 0.0245,  ..., 0.0204, 0.0199, 0.0203],
           [0.0105, 0.0133, 0.0140,  ..., 0.0099, 0.0101, 0.0107],
           [0.0168, 0.0194, 0.0203,  ..., 0.0194, 0.0199, 0.0203],
           ...,
           [0.0186, 0.0213, 0.0224,  ..., 0.0208, 0.0221, 0.0238],
           [0.0133, 0.0160, 0.0169,  ..., 0.0132, 0.0135, 0.0146],
           [0.0155, 0.0175, 0.0181,  ..., 0.0126, 0.0134, 0.0146]],

          ...,

          [[0.0202, 0.0221, 0.0228,  ..., 0.0203, 0.0201, 0.0216],
           [0.0089, 0.0116, 0.0125,  ..., 0.0094, 0.0092, 0.0103],
           [0.0199, 0.0224, 0.0232,  ..., 0.0214, 0.0212, 0.0219],
           ...,
           [0.0239, 0.0267, 0.0278,  ..., 0.0285, 0.0291, 0.0293],
           [0.0167, 0.0195, 0.0208,  ..., 0.0201, 0.0198, 0.0196],
           [0.0164, 0.0184, 0.0194,  ..., 0.0168, 0.0166, 0.0168]],

          [[0.0275, 0.0295, 0.0303,  ..., 0.0278, 0.0273, 0.0288],
           [0.0180, 0.0203, 0.0214,  ..., 0.0160, 0.0156, 0.0167],
           [0.0154, 0.0177, 0.0188,  ..., 0.0148, 0.0144, 0.0153],
           ...,
           [0.0177, 0.0208, 0.0217,  ..., 0.0194, 0.0193, 0.0192],
           [0.0228, 0.0258, 0.0271,  ..., 0.0208, 0.0196, 0.0194],
           [0.0170, 0.0193, 0.0203,  ..., 0.0144, 0.0134, 0.0132]],

          [[0.0171, 0.0186, 0.0194,  ..., 0.0234, 0.0223, 0.0226],
           [0.0165, 0.0181, 0.0192,  ..., 0.0205, 0.0193, 0.0199],
           [0.0168, 0.0187, 0.0196,  ..., 0.0185, 0.0177, 0.0185],
           ...,
           [0.0141, 0.0164, 0.0174,  ..., 0.0170, 0.0164, 0.0163],
           [0.0164, 0.0189, 0.0199,  ..., 0.0189, 0.0177, 0.0171],
           [0.0084, 0.0098, 0.0107,  ..., 0.0119, 0.0106, 0.0093]]]]],
       device='cuda:0')
==========
IN _TEST_STEP
==========
ERODING BRAIN MASK
MEDIAN FILTERING
SAVING OUTPUT - ORIGINAL, FINAL, MASK ETC
SAVING IMAGES!
Testing:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:34<00:06,  3.37s/it]==========
IN DDPM ON TEST STEP
==========
THE WEIRD CONDITION BIT CALLED "features" in DDPM_2D
IN SPARK ENCODER FORWARDDD
x in shape torch.Size([50, 1, 96, 96])
out features torch.Size([50, 512])
i'm i DDPM2d forward block (whch is basically the encoder)
Context vector c shape: torch.Size([50, 512])
shape features:  torch.Size([50, 512])
additng features to latern space
latent space: []
iAM IN THE FORWARD METHOD OF THE WEIRD GUASSIAN IN cond_DDPM.py. I WILL BE CALLING p_losses
i am in p_losses in guassian which seems to be crucial to everything
conditioning vector shape:  torch.Size([50, 512])
in plosses i am getting a noisy image x
x shape:  torch.Size([50, 1, 96, 96])
getting model out
Initial input shape: torch.Size([50, 1, 96, 96])

inputblocks
Before block 0, shape: torch.Size([50, 1, 96, 96])
After block 0, shape: torch.Size([50, 128, 96, 96])
-
Before block 1, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 1, shape: torch.Size([50, 128, 96, 96])
-
Before block 2, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 2, shape: torch.Size([50, 128, 96, 96])
-
Before block 3, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 3, shape: torch.Size([50, 128, 96, 96])
-
Before block 4, shape: torch.Size([50, 128, 96, 96])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 256])
After block 4, shape: torch.Size([50, 128, 48, 48])
-
Before block 5, shape: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 48, 48])
-
Before block 8, shape: torch.Size([50, 256, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 8, shape: torch.Size([50, 256, 24, 24])
-
Before block 9, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 9, shape: torch.Size([50, 256, 24, 24])
-
Before block 10, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 10, shape: torch.Size([50, 256, 24, 24])
-
Before block 11, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 11, shape: torch.Size([50, 256, 24, 24])
-

Before middle block, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
in unet attention block!
x shape torch.Size([50, 256, 24, 24])
out dims torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])


After middle block, shape: torch.Size([50, 256, 24, 24])
-



outputblocks
Before block 0, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 0, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 0, shape: torch.Size([50, 256, 24, 24])
-
Before block 1, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 1, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 1, shape: torch.Size([50, 256, 24, 24])
-
Before block 2, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 2, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 2, shape: torch.Size([50, 256, 24, 24])
-
Before block 3, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 3, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 3, shape: torch.Size([50, 256, 48, 48])
-
Before block 4, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 4, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 4, shape: torch.Size([50, 256, 48, 48])
-
Before block 5, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 5, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 6, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 7, shape: torch.Size([50, 384, 48, 48])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 96, 96])
-
Before block 8, shape: torch.Size([50, 256, 96, 96])
After concatenation in upsampling block 8, shape: torch.Size([50, 384, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 8, shape: torch.Size([50, 128, 96, 96])
-
Before block 9, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 9, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 9, shape: torch.Size([50, 128, 96, 96])
-
Before block 10, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 10, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 10, shape: torch.Size([50, 128, 96, 96])
-
Before block 11, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 11, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 11, shape: torch.Size([50, 128, 96, 96])
-

Before Final layer shape: torch.Size([50, 128, 96, 96])
Final output shape: torch.Size([50, 1, 96, 96])
model out shape:  torch.Size([50, 1, 96, 96])
iAM IN THE FORWARD METHOD OF THE WEIRD GUASSIAN IN cond_DDPM.py. I WILL BE CALLING p_losses
i am in p_losses in guassian which seems to be crucial to everything
conditioning vector shape:  torch.Size([50, 512])
in plosses i am getting a noisy image x
x shape:  torch.Size([50, 1, 96, 96])
getting model out
Initial input shape: torch.Size([50, 1, 96, 96])

inputblocks
Before block 0, shape: torch.Size([50, 1, 96, 96])
After block 0, shape: torch.Size([50, 128, 96, 96])
-
Before block 1, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 1, shape: torch.Size([50, 128, 96, 96])
-
Before block 2, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 2, shape: torch.Size([50, 128, 96, 96])
-
Before block 3, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 3, shape: torch.Size([50, 128, 96, 96])
-
Before block 4, shape: torch.Size([50, 128, 96, 96])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 256])
After block 4, shape: torch.Size([50, 128, 48, 48])
-
Before block 5, shape: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 48, 48])
-
Before block 8, shape: torch.Size([50, 256, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 8, shape: torch.Size([50, 256, 24, 24])
-
Before block 9, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 9, shape: torch.Size([50, 256, 24, 24])
-
Before block 10, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 10, shape: torch.Size([50, 256, 24, 24])
-
Before block 11, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 11, shape: torch.Size([50, 256, 24, 24])
-

Before middle block, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
in unet attention block!
x shape torch.Size([50, 256, 24, 24])
out dims torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])


After middle block, shape: torch.Size([50, 256, 24, 24])
-



outputblocks
Before block 0, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 0, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 0, shape: torch.Size([50, 256, 24, 24])
-
Before block 1, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 1, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 1, shape: torch.Size([50, 256, 24, 24])
-
Before block 2, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 2, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 2, shape: torch.Size([50, 256, 24, 24])
-
Before block 3, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 3, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 3, shape: torch.Size([50, 256, 48, 48])
-
Before block 4, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 4, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 4, shape: torch.Size([50, 256, 48, 48])
-
Before block 5, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 5, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 6, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 7, shape: torch.Size([50, 384, 48, 48])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 96, 96])
-
Before block 8, shape: torch.Size([50, 256, 96, 96])
After concatenation in upsampling block 8, shape: torch.Size([50, 384, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 8, shape: torch.Size([50, 128, 96, 96])
-
Before block 9, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 9, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 9, shape: torch.Size([50, 128, 96, 96])
-
Before block 10, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 10, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 10, shape: torch.Size([50, 128, 96, 96])
-
Before block 11, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 11, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 11, shape: torch.Size([50, 128, 96, 96])
-

Before Final layer shape: torch.Size([50, 128, 96, 96])
Final output shape: torch.Size([50, 1, 96, 96])
model out shape:  torch.Size([50, 1, 96, 96])
iAM IN THE FORWARD METHOD OF THE WEIRD GUASSIAN IN cond_DDPM.py. I WILL BE CALLING p_losses
i am in p_losses in guassian which seems to be crucial to everything
conditioning vector shape:  torch.Size([50, 512])
in plosses i am getting a noisy image x
x shape:  torch.Size([50, 1, 96, 96])
getting model out
Initial input shape: torch.Size([50, 1, 96, 96])

inputblocks
Before block 0, shape: torch.Size([50, 1, 96, 96])
After block 0, shape: torch.Size([50, 128, 96, 96])
-
Before block 1, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 1, shape: torch.Size([50, 128, 96, 96])
-
Before block 2, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 2, shape: torch.Size([50, 128, 96, 96])
-
Before block 3, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 3, shape: torch.Size([50, 128, 96, 96])
-
Before block 4, shape: torch.Size([50, 128, 96, 96])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 256])
After block 4, shape: torch.Size([50, 128, 48, 48])
-
Before block 5, shape: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 48, 48])
-
Before block 8, shape: torch.Size([50, 256, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 8, shape: torch.Size([50, 256, 24, 24])
-
Before block 9, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 9, shape: torch.Size([50, 256, 24, 24])
-
Before block 10, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 10, shape: torch.Size([50, 256, 24, 24])
-
Before block 11, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 11, shape: torch.Size([50, 256, 24, 24])
-

Before middle block, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
in unet attention block!
x shape torch.Size([50, 256, 24, 24])
out dims torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])


After middle block, shape: torch.Size([50, 256, 24, 24])
-



outputblocks
Before block 0, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 0, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 0, shape: torch.Size([50, 256, 24, 24])
-
Before block 1, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 1, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 1, shape: torch.Size([50, 256, 24, 24])
-
Before block 2, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 2, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 2, shape: torch.Size([50, 256, 24, 24])
-
Before block 3, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 3, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 3, shape: torch.Size([50, 256, 48, 48])
-
Before block 4, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 4, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 4, shape: torch.Size([50, 256, 48, 48])
-
Before block 5, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 5, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 6, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 7, shape: torch.Size([50, 384, 48, 48])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 96, 96])
-
Before block 8, shape: torch.Size([50, 256, 96, 96])
After concatenation in upsampling block 8, shape: torch.Size([50, 384, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 8, shape: torch.Size([50, 128, 96, 96])
-
Before block 9, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 9, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 9, shape: torch.Size([50, 128, 96, 96])
-
Before block 10, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 10, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 10, shape: torch.Size([50, 128, 96, 96])
-
Before block 11, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 11, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 11, shape: torch.Size([50, 128, 96, 96])
-

Before Final layer shape: torch.Size([50, 128, 96, 96])
Final output shape: torch.Size([50, 1, 96, 96])
model out shape:  torch.Size([50, 1, 96, 96])
reconstruction shape torch.Size([50, 1, 96, 96])
reconstruction tensor([[[[0.0116, 0.0146, 0.0139,  ..., 0.0160, 0.0216, 0.0214],
          [0.0224, 0.0149, 0.0098,  ..., 0.0106, 0.0166, 0.0148],
          [0.0173, 0.0070, 0.0116,  ..., 0.0119, 0.0082, 0.0110],
          ...,
          [0.0120, 0.0036, 0.0177,  ..., 0.0156, 0.0125, 0.0111],
          [0.0168, 0.0119, 0.0098,  ..., 0.0146, 0.0226, 0.0153],
          [0.0107, 0.0115, 0.0130,  ..., 0.0153, 0.0181, 0.0091]]],


        [[[0.0108, 0.0137, 0.0137,  ..., 0.0155, 0.0210, 0.0208],
          [0.0216, 0.0137, 0.0094,  ..., 0.0098, 0.0155, 0.0138],
          [0.0170, 0.0063, 0.0115,  ..., 0.0119, 0.0080, 0.0104],
          ...,
          [0.0114, 0.0033, 0.0180,  ..., 0.0157, 0.0125, 0.0105],
          [0.0155, 0.0103, 0.0095,  ..., 0.0139, 0.0214, 0.0140],
          [0.0107, 0.0099, 0.0128,  ..., 0.0146, 0.0169, 0.0079]]],


        [[[0.0128, 0.0147, 0.0148,  ..., 0.0163, 0.0216, 0.0216],
          [0.0226, 0.0138, 0.0101,  ..., 0.0105, 0.0159, 0.0139],
          [0.0181, 0.0069, 0.0127,  ..., 0.0128, 0.0089, 0.0109],
          ...,
          [0.0127, 0.0046, 0.0198,  ..., 0.0177, 0.0153, 0.0128],
          [0.0161, 0.0114, 0.0116,  ..., 0.0159, 0.0237, 0.0155],
          [0.0122, 0.0115, 0.0149,  ..., 0.0164, 0.0186, 0.0095]]],


        ...,


        [[[0.0103, 0.0129, 0.0133,  ..., 0.0165, 0.0194, 0.0204],
          [0.0174, 0.0082, 0.0061,  ..., 0.0108, 0.0130, 0.0118],
          [0.0149, 0.0034, 0.0101,  ..., 0.0148, 0.0095, 0.0129],
          ...,
          [0.0146, 0.0082, 0.0221,  ..., 0.0291, 0.0261, 0.0216],
          [0.0193, 0.0151, 0.0142,  ..., 0.0272, 0.0356, 0.0249],
          [0.0135, 0.0127, 0.0138,  ..., 0.0286, 0.0309, 0.0175]]],


        [[[0.0100, 0.0129, 0.0137,  ..., 0.0170, 0.0203, 0.0205],
          [0.0172, 0.0090, 0.0067,  ..., 0.0112, 0.0139, 0.0122],
          [0.0149, 0.0043, 0.0105,  ..., 0.0158, 0.0103, 0.0132],
          ...,
          [0.0141, 0.0074, 0.0211,  ..., 0.0259, 0.0229, 0.0188],
          [0.0187, 0.0142, 0.0130,  ..., 0.0239, 0.0329, 0.0231],
          [0.0116, 0.0116, 0.0123,  ..., 0.0249, 0.0284, 0.0160]]],


        [[[0.0090, 0.0125, 0.0133,  ..., 0.0159, 0.0197, 0.0195],
          [0.0170, 0.0097, 0.0068,  ..., 0.0105, 0.0137, 0.0113],
          [0.0146, 0.0044, 0.0101,  ..., 0.0146, 0.0097, 0.0120],
          ...,
          [0.0132, 0.0065, 0.0197,  ..., 0.0225, 0.0195, 0.0155],
          [0.0177, 0.0137, 0.0121,  ..., 0.0204, 0.0296, 0.0200],
          [0.0104, 0.0106, 0.0112,  ..., 0.0208, 0.0247, 0.0129]]]],
       device='cuda:0')
FINAL VOLUME (DDPM) shape torch.Size([96, 96, 50])
FINAL VOLUME tensor([[[0.0116, 0.0108, 0.0128,  ..., 0.0103, 0.0100, 0.0090],
         [0.0146, 0.0137, 0.0147,  ..., 0.0129, 0.0129, 0.0125],
         [0.0139, 0.0137, 0.0148,  ..., 0.0133, 0.0137, 0.0133],
         ...,
         [0.0160, 0.0155, 0.0163,  ..., 0.0165, 0.0170, 0.0159],
         [0.0216, 0.0210, 0.0216,  ..., 0.0194, 0.0203, 0.0197],
         [0.0214, 0.0208, 0.0216,  ..., 0.0204, 0.0205, 0.0195]],

        [[0.0224, 0.0216, 0.0226,  ..., 0.0174, 0.0172, 0.0170],
         [0.0149, 0.0137, 0.0138,  ..., 0.0082, 0.0090, 0.0097],
         [0.0098, 0.0094, 0.0101,  ..., 0.0061, 0.0067, 0.0068],
         ...,
         [0.0106, 0.0098, 0.0105,  ..., 0.0108, 0.0112, 0.0105],
         [0.0166, 0.0155, 0.0159,  ..., 0.0130, 0.0139, 0.0137],
         [0.0148, 0.0138, 0.0139,  ..., 0.0118, 0.0122, 0.0113]],

        [[0.0173, 0.0170, 0.0181,  ..., 0.0149, 0.0149, 0.0146],
         [0.0070, 0.0063, 0.0069,  ..., 0.0034, 0.0043, 0.0044],
         [0.0116, 0.0115, 0.0127,  ..., 0.0101, 0.0105, 0.0101],
         ...,
         [0.0119, 0.0119, 0.0128,  ..., 0.0148, 0.0158, 0.0146],
         [0.0082, 0.0080, 0.0089,  ..., 0.0095, 0.0103, 0.0097],
         [0.0110, 0.0104, 0.0109,  ..., 0.0129, 0.0132, 0.0120]],

        ...,

        [[0.0120, 0.0114, 0.0127,  ..., 0.0146, 0.0141, 0.0132],
         [0.0036, 0.0033, 0.0046,  ..., 0.0082, 0.0074, 0.0065],
         [0.0177, 0.0180, 0.0198,  ..., 0.0221, 0.0211, 0.0197],
         ...,
         [0.0156, 0.0157, 0.0177,  ..., 0.0291, 0.0259, 0.0225],
         [0.0125, 0.0125, 0.0153,  ..., 0.0261, 0.0229, 0.0195],
         [0.0111, 0.0105, 0.0128,  ..., 0.0216, 0.0188, 0.0155]],

        [[0.0168, 0.0155, 0.0161,  ..., 0.0193, 0.0187, 0.0177],
         [0.0119, 0.0103, 0.0114,  ..., 0.0151, 0.0142, 0.0137],
         [0.0098, 0.0095, 0.0116,  ..., 0.0142, 0.0130, 0.0121],
         ...,
         [0.0146, 0.0139, 0.0159,  ..., 0.0272, 0.0239, 0.0204],
         [0.0226, 0.0214, 0.0237,  ..., 0.0356, 0.0329, 0.0296],
         [0.0153, 0.0140, 0.0155,  ..., 0.0249, 0.0231, 0.0200]],

        [[0.0107, 0.0107, 0.0122,  ..., 0.0135, 0.0116, 0.0104],
         [0.0115, 0.0099, 0.0115,  ..., 0.0127, 0.0116, 0.0106],
         [0.0130, 0.0128, 0.0149,  ..., 0.0138, 0.0123, 0.0112],
         ...,
         [0.0153, 0.0146, 0.0164,  ..., 0.0286, 0.0249, 0.0208],
         [0.0181, 0.0169, 0.0186,  ..., 0.0309, 0.0284, 0.0247],
         [0.0091, 0.0079, 0.0095,  ..., 0.0175, 0.0160, 0.0129]]],
       device='cuda:0')
unsqueeze final volume shape (DDPM2d) torch.Size([1, 1, 96, 96, 50])
unsqueeze final volume (DDPM 2D) tensor([[[[[0.0116, 0.0108, 0.0128,  ..., 0.0103, 0.0100, 0.0090],
           [0.0146, 0.0137, 0.0147,  ..., 0.0129, 0.0129, 0.0125],
           [0.0139, 0.0137, 0.0148,  ..., 0.0133, 0.0137, 0.0133],
           ...,
           [0.0160, 0.0155, 0.0163,  ..., 0.0165, 0.0170, 0.0159],
           [0.0216, 0.0210, 0.0216,  ..., 0.0194, 0.0203, 0.0197],
           [0.0214, 0.0208, 0.0216,  ..., 0.0204, 0.0205, 0.0195]],

          [[0.0224, 0.0216, 0.0226,  ..., 0.0174, 0.0172, 0.0170],
           [0.0149, 0.0137, 0.0138,  ..., 0.0082, 0.0090, 0.0097],
           [0.0098, 0.0094, 0.0101,  ..., 0.0061, 0.0067, 0.0068],
           ...,
           [0.0106, 0.0098, 0.0105,  ..., 0.0108, 0.0112, 0.0105],
           [0.0166, 0.0155, 0.0159,  ..., 0.0130, 0.0139, 0.0137],
           [0.0148, 0.0138, 0.0139,  ..., 0.0118, 0.0122, 0.0113]],

          [[0.0173, 0.0170, 0.0181,  ..., 0.0149, 0.0149, 0.0146],
           [0.0070, 0.0063, 0.0069,  ..., 0.0034, 0.0043, 0.0044],
           [0.0116, 0.0115, 0.0127,  ..., 0.0101, 0.0105, 0.0101],
           ...,
           [0.0119, 0.0119, 0.0128,  ..., 0.0148, 0.0158, 0.0146],
           [0.0082, 0.0080, 0.0089,  ..., 0.0095, 0.0103, 0.0097],
           [0.0110, 0.0104, 0.0109,  ..., 0.0129, 0.0132, 0.0120]],

          ...,

          [[0.0120, 0.0114, 0.0127,  ..., 0.0146, 0.0141, 0.0132],
           [0.0036, 0.0033, 0.0046,  ..., 0.0082, 0.0074, 0.0065],
           [0.0177, 0.0180, 0.0198,  ..., 0.0221, 0.0211, 0.0197],
           ...,
           [0.0156, 0.0157, 0.0177,  ..., 0.0291, 0.0259, 0.0225],
           [0.0125, 0.0125, 0.0153,  ..., 0.0261, 0.0229, 0.0195],
           [0.0111, 0.0105, 0.0128,  ..., 0.0216, 0.0188, 0.0155]],

          [[0.0168, 0.0155, 0.0161,  ..., 0.0193, 0.0187, 0.0177],
           [0.0119, 0.0103, 0.0114,  ..., 0.0151, 0.0142, 0.0137],
           [0.0098, 0.0095, 0.0116,  ..., 0.0142, 0.0130, 0.0121],
           ...,
           [0.0146, 0.0139, 0.0159,  ..., 0.0272, 0.0239, 0.0204],
           [0.0226, 0.0214, 0.0237,  ..., 0.0356, 0.0329, 0.0296],
           [0.0153, 0.0140, 0.0155,  ..., 0.0249, 0.0231, 0.0200]],

          [[0.0107, 0.0107, 0.0122,  ..., 0.0135, 0.0116, 0.0104],
           [0.0115, 0.0099, 0.0115,  ..., 0.0127, 0.0116, 0.0106],
           [0.0130, 0.0128, 0.0149,  ..., 0.0138, 0.0123, 0.0112],
           ...,
           [0.0153, 0.0146, 0.0164,  ..., 0.0286, 0.0249, 0.0208],
           [0.0181, 0.0169, 0.0186,  ..., 0.0309, 0.0284, 0.0247],
           [0.0091, 0.0079, 0.0095,  ..., 0.0175, 0.0160, 0.0129]]]]],
       device='cuda:0')
==========
IN _TEST_STEP
==========
ERODING BRAIN MASK
MEDIAN FILTERING
SAVING OUTPUT - ORIGINAL, FINAL, MASK ETC
SAVING IMAGES!
Testing:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:37<00:03,  3.29s/it]==========
IN DDPM ON TEST STEP
==========
THE WEIRD CONDITION BIT CALLED "features" in DDPM_2D
IN SPARK ENCODER FORWARDDD
x in shape torch.Size([50, 1, 96, 96])
out features torch.Size([50, 512])
i'm i DDPM2d forward block (whch is basically the encoder)
Context vector c shape: torch.Size([50, 512])
shape features:  torch.Size([50, 512])
additng features to latern space
latent space: []
iAM IN THE FORWARD METHOD OF THE WEIRD GUASSIAN IN cond_DDPM.py. I WILL BE CALLING p_losses
i am in p_losses in guassian which seems to be crucial to everything
conditioning vector shape:  torch.Size([50, 512])
in plosses i am getting a noisy image x
x shape:  torch.Size([50, 1, 96, 96])
getting model out
Initial input shape: torch.Size([50, 1, 96, 96])

inputblocks
Before block 0, shape: torch.Size([50, 1, 96, 96])
After block 0, shape: torch.Size([50, 128, 96, 96])
-
Before block 1, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 1, shape: torch.Size([50, 128, 96, 96])
-
Before block 2, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 2, shape: torch.Size([50, 128, 96, 96])
-
Before block 3, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 3, shape: torch.Size([50, 128, 96, 96])
-
Before block 4, shape: torch.Size([50, 128, 96, 96])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 256])
After block 4, shape: torch.Size([50, 128, 48, 48])
-
Before block 5, shape: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 48, 48])
-
Before block 8, shape: torch.Size([50, 256, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 8, shape: torch.Size([50, 256, 24, 24])
-
Before block 9, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 9, shape: torch.Size([50, 256, 24, 24])
-
Before block 10, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 10, shape: torch.Size([50, 256, 24, 24])
-
Before block 11, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 11, shape: torch.Size([50, 256, 24, 24])
-

Before middle block, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
in unet attention block!
x shape torch.Size([50, 256, 24, 24])
out dims torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])


After middle block, shape: torch.Size([50, 256, 24, 24])
-



outputblocks
Before block 0, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 0, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 0, shape: torch.Size([50, 256, 24, 24])
-
Before block 1, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 1, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 1, shape: torch.Size([50, 256, 24, 24])
-
Before block 2, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 2, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 2, shape: torch.Size([50, 256, 24, 24])
-
Before block 3, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 3, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 3, shape: torch.Size([50, 256, 48, 48])
-
Before block 4, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 4, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 4, shape: torch.Size([50, 256, 48, 48])
-
Before block 5, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 5, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 6, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 7, shape: torch.Size([50, 384, 48, 48])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 96, 96])
-
Before block 8, shape: torch.Size([50, 256, 96, 96])
After concatenation in upsampling block 8, shape: torch.Size([50, 384, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 8, shape: torch.Size([50, 128, 96, 96])
-
Before block 9, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 9, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 9, shape: torch.Size([50, 128, 96, 96])
-
Before block 10, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 10, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 10, shape: torch.Size([50, 128, 96, 96])
-
Before block 11, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 11, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 11, shape: torch.Size([50, 128, 96, 96])
-

Before Final layer shape: torch.Size([50, 128, 96, 96])
Final output shape: torch.Size([50, 1, 96, 96])
model out shape:  torch.Size([50, 1, 96, 96])
iAM IN THE FORWARD METHOD OF THE WEIRD GUASSIAN IN cond_DDPM.py. I WILL BE CALLING p_losses
i am in p_losses in guassian which seems to be crucial to everything
conditioning vector shape:  torch.Size([50, 512])
in plosses i am getting a noisy image x
x shape:  torch.Size([50, 1, 96, 96])
getting model out
Initial input shape: torch.Size([50, 1, 96, 96])

inputblocks
Before block 0, shape: torch.Size([50, 1, 96, 96])
After block 0, shape: torch.Size([50, 128, 96, 96])
-
Before block 1, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 1, shape: torch.Size([50, 128, 96, 96])
-
Before block 2, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 2, shape: torch.Size([50, 128, 96, 96])
-
Before block 3, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 3, shape: torch.Size([50, 128, 96, 96])
-
Before block 4, shape: torch.Size([50, 128, 96, 96])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 256])
After block 4, shape: torch.Size([50, 128, 48, 48])
-
Before block 5, shape: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 48, 48])
-
Before block 8, shape: torch.Size([50, 256, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 8, shape: torch.Size([50, 256, 24, 24])
-
Before block 9, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 9, shape: torch.Size([50, 256, 24, 24])
-
Before block 10, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 10, shape: torch.Size([50, 256, 24, 24])
-
Before block 11, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 11, shape: torch.Size([50, 256, 24, 24])
-

Before middle block, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
in unet attention block!
x shape torch.Size([50, 256, 24, 24])
out dims torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])


After middle block, shape: torch.Size([50, 256, 24, 24])
-



outputblocks
Before block 0, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 0, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 0, shape: torch.Size([50, 256, 24, 24])
-
Before block 1, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 1, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 1, shape: torch.Size([50, 256, 24, 24])
-
Before block 2, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 2, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 2, shape: torch.Size([50, 256, 24, 24])
-
Before block 3, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 3, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 3, shape: torch.Size([50, 256, 48, 48])
-
Before block 4, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 4, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 4, shape: torch.Size([50, 256, 48, 48])
-
Before block 5, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 5, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 6, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 7, shape: torch.Size([50, 384, 48, 48])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 96, 96])
-
Before block 8, shape: torch.Size([50, 256, 96, 96])
After concatenation in upsampling block 8, shape: torch.Size([50, 384, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 8, shape: torch.Size([50, 128, 96, 96])
-
Before block 9, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 9, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 9, shape: torch.Size([50, 128, 96, 96])
-
Before block 10, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 10, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 10, shape: torch.Size([50, 128, 96, 96])
-
Before block 11, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 11, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 11, shape: torch.Size([50, 128, 96, 96])
-

Before Final layer shape: torch.Size([50, 128, 96, 96])
Final output shape: torch.Size([50, 1, 96, 96])
model out shape:  torch.Size([50, 1, 96, 96])
iAM IN THE FORWARD METHOD OF THE WEIRD GUASSIAN IN cond_DDPM.py. I WILL BE CALLING p_losses
i am in p_losses in guassian which seems to be crucial to everything
conditioning vector shape:  torch.Size([50, 512])
in plosses i am getting a noisy image x
x shape:  torch.Size([50, 1, 96, 96])
getting model out
Initial input shape: torch.Size([50, 1, 96, 96])

inputblocks
Before block 0, shape: torch.Size([50, 1, 96, 96])
After block 0, shape: torch.Size([50, 128, 96, 96])
-
Before block 1, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 1, shape: torch.Size([50, 128, 96, 96])
-
Before block 2, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 2, shape: torch.Size([50, 128, 96, 96])
-
Before block 3, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 3, shape: torch.Size([50, 128, 96, 96])
-
Before block 4, shape: torch.Size([50, 128, 96, 96])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 256])
After block 4, shape: torch.Size([50, 128, 48, 48])
-
Before block 5, shape: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 48, 48])
-
Before block 8, shape: torch.Size([50, 256, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 8, shape: torch.Size([50, 256, 24, 24])
-
Before block 9, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 9, shape: torch.Size([50, 256, 24, 24])
-
Before block 10, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 10, shape: torch.Size([50, 256, 24, 24])
-
Before block 11, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 11, shape: torch.Size([50, 256, 24, 24])
-

Before middle block, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
in unet attention block!
x shape torch.Size([50, 256, 24, 24])
out dims torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])


After middle block, shape: torch.Size([50, 256, 24, 24])
-



outputblocks
Before block 0, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 0, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 0, shape: torch.Size([50, 256, 24, 24])
-
Before block 1, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 1, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 1, shape: torch.Size([50, 256, 24, 24])
-
Before block 2, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 2, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 2, shape: torch.Size([50, 256, 24, 24])
-
Before block 3, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 3, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 3, shape: torch.Size([50, 256, 48, 48])
-
Before block 4, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 4, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 4, shape: torch.Size([50, 256, 48, 48])
-
Before block 5, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 5, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 6, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 7, shape: torch.Size([50, 384, 48, 48])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 96, 96])
-
Before block 8, shape: torch.Size([50, 256, 96, 96])
After concatenation in upsampling block 8, shape: torch.Size([50, 384, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 8, shape: torch.Size([50, 128, 96, 96])
-
Before block 9, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 9, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 9, shape: torch.Size([50, 128, 96, 96])
-
Before block 10, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 10, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 10, shape: torch.Size([50, 128, 96, 96])
-
Before block 11, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 11, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 11, shape: torch.Size([50, 128, 96, 96])
-

Before Final layer shape: torch.Size([50, 128, 96, 96])
Final output shape: torch.Size([50, 1, 96, 96])
model out shape:  torch.Size([50, 1, 96, 96])
reconstruction shape torch.Size([50, 1, 96, 96])
reconstruction tensor([[[[0.0306, 0.0295, 0.0289,  ..., 0.0289, 0.0380, 0.0306],
          [0.0300, 0.0251, 0.0243,  ..., 0.0239, 0.0330, 0.0244],
          [0.0234, 0.0176, 0.0258,  ..., 0.0264, 0.0247, 0.0215],
          ...,
          [0.0250, 0.0171, 0.0298,  ..., 0.0302, 0.0221, 0.0173],
          [0.0304, 0.0264, 0.0243,  ..., 0.0272, 0.0339, 0.0214],
          [0.0192, 0.0227, 0.0249,  ..., 0.0221, 0.0264, 0.0119]]],


        [[[0.0310, 0.0304, 0.0294,  ..., 0.0299, 0.0388, 0.0316],
          [0.0303, 0.0254, 0.0246,  ..., 0.0250, 0.0334, 0.0247],
          [0.0243, 0.0184, 0.0267,  ..., 0.0278, 0.0259, 0.0224],
          ...,
          [0.0259, 0.0181, 0.0305,  ..., 0.0312, 0.0227, 0.0183],
          [0.0309, 0.0269, 0.0247,  ..., 0.0273, 0.0340, 0.0221],
          [0.0195, 0.0233, 0.0257,  ..., 0.0229, 0.0271, 0.0125]]],


        [[[0.0315, 0.0306, 0.0295,  ..., 0.0297, 0.0391, 0.0312],
          [0.0310, 0.0254, 0.0246,  ..., 0.0248, 0.0334, 0.0248],
          [0.0248, 0.0191, 0.0274,  ..., 0.0282, 0.0260, 0.0224],
          ...,
          [0.0262, 0.0190, 0.0310,  ..., 0.0317, 0.0233, 0.0188],
          [0.0311, 0.0276, 0.0248,  ..., 0.0277, 0.0346, 0.0228],
          [0.0193, 0.0241, 0.0259,  ..., 0.0236, 0.0282, 0.0134]]],


        ...,


        [[[0.0359, 0.0323, 0.0301,  ..., 0.0315, 0.0402, 0.0387],
          [0.0282, 0.0196, 0.0215,  ..., 0.0229, 0.0294, 0.0259],
          [0.0244, 0.0172, 0.0273,  ..., 0.0285, 0.0244, 0.0223],
          ...,
          [0.0254, 0.0177, 0.0308,  ..., 0.0361, 0.0236, 0.0171],
          [0.0311, 0.0247, 0.0244,  ..., 0.0256, 0.0260, 0.0181],
          [0.0239, 0.0257, 0.0290,  ..., 0.0235, 0.0225, 0.0149]]],


        [[[0.0347, 0.0313, 0.0297,  ..., 0.0316, 0.0408, 0.0383],
          [0.0269, 0.0187, 0.0207,  ..., 0.0224, 0.0296, 0.0257],
          [0.0233, 0.0164, 0.0267,  ..., 0.0283, 0.0242, 0.0217],
          ...,
          [0.0245, 0.0157, 0.0288,  ..., 0.0338, 0.0209, 0.0154],
          [0.0293, 0.0223, 0.0221,  ..., 0.0227, 0.0238, 0.0163],
          [0.0208, 0.0229, 0.0269,  ..., 0.0208, 0.0202, 0.0120]]],


        [[[0.0334, 0.0304, 0.0293,  ..., 0.0310, 0.0406, 0.0373],
          [0.0260, 0.0179, 0.0201,  ..., 0.0216, 0.0294, 0.0251],
          [0.0225, 0.0153, 0.0258,  ..., 0.0270, 0.0233, 0.0210],
          ...,
          [0.0234, 0.0140, 0.0272,  ..., 0.0317, 0.0193, 0.0142],
          [0.0280, 0.0211, 0.0209,  ..., 0.0215, 0.0229, 0.0151],
          [0.0183, 0.0209, 0.0256,  ..., 0.0193, 0.0185, 0.0094]]]],
       device='cuda:0')
FINAL VOLUME (DDPM) shape torch.Size([96, 96, 50])
FINAL VOLUME tensor([[[0.0306, 0.0310, 0.0315,  ..., 0.0359, 0.0347, 0.0334],
         [0.0295, 0.0304, 0.0306,  ..., 0.0323, 0.0313, 0.0304],
         [0.0289, 0.0294, 0.0295,  ..., 0.0301, 0.0297, 0.0293],
         ...,
         [0.0289, 0.0299, 0.0297,  ..., 0.0315, 0.0316, 0.0310],
         [0.0380, 0.0388, 0.0391,  ..., 0.0402, 0.0408, 0.0406],
         [0.0306, 0.0316, 0.0312,  ..., 0.0387, 0.0383, 0.0373]],

        [[0.0300, 0.0303, 0.0310,  ..., 0.0282, 0.0269, 0.0260],
         [0.0251, 0.0254, 0.0254,  ..., 0.0196, 0.0187, 0.0179],
         [0.0243, 0.0246, 0.0246,  ..., 0.0215, 0.0207, 0.0201],
         ...,
         [0.0239, 0.0250, 0.0248,  ..., 0.0229, 0.0224, 0.0216],
         [0.0330, 0.0334, 0.0334,  ..., 0.0294, 0.0296, 0.0294],
         [0.0244, 0.0247, 0.0248,  ..., 0.0259, 0.0257, 0.0251]],

        [[0.0234, 0.0243, 0.0248,  ..., 0.0244, 0.0233, 0.0225],
         [0.0176, 0.0184, 0.0191,  ..., 0.0172, 0.0164, 0.0153],
         [0.0258, 0.0267, 0.0274,  ..., 0.0273, 0.0267, 0.0258],
         ...,
         [0.0264, 0.0278, 0.0282,  ..., 0.0285, 0.0283, 0.0270],
         [0.0247, 0.0259, 0.0260,  ..., 0.0244, 0.0242, 0.0233],
         [0.0215, 0.0224, 0.0224,  ..., 0.0223, 0.0217, 0.0210]],

        ...,

        [[0.0250, 0.0259, 0.0262,  ..., 0.0254, 0.0245, 0.0234],
         [0.0171, 0.0181, 0.0190,  ..., 0.0177, 0.0157, 0.0140],
         [0.0298, 0.0305, 0.0310,  ..., 0.0308, 0.0288, 0.0272],
         ...,
         [0.0302, 0.0312, 0.0317,  ..., 0.0361, 0.0338, 0.0317],
         [0.0221, 0.0227, 0.0233,  ..., 0.0236, 0.0209, 0.0193],
         [0.0173, 0.0183, 0.0188,  ..., 0.0171, 0.0154, 0.0142]],

        [[0.0304, 0.0309, 0.0311,  ..., 0.0311, 0.0293, 0.0280],
         [0.0264, 0.0269, 0.0276,  ..., 0.0247, 0.0223, 0.0211],
         [0.0243, 0.0247, 0.0248,  ..., 0.0244, 0.0221, 0.0209],
         ...,
         [0.0272, 0.0273, 0.0277,  ..., 0.0256, 0.0227, 0.0215],
         [0.0339, 0.0340, 0.0346,  ..., 0.0260, 0.0238, 0.0229],
         [0.0214, 0.0221, 0.0228,  ..., 0.0181, 0.0163, 0.0151]],

        [[0.0192, 0.0195, 0.0193,  ..., 0.0239, 0.0208, 0.0183],
         [0.0227, 0.0233, 0.0241,  ..., 0.0257, 0.0229, 0.0209],
         [0.0249, 0.0257, 0.0259,  ..., 0.0290, 0.0269, 0.0256],
         ...,
         [0.0221, 0.0229, 0.0236,  ..., 0.0235, 0.0208, 0.0193],
         [0.0264, 0.0271, 0.0282,  ..., 0.0225, 0.0202, 0.0185],
         [0.0119, 0.0125, 0.0134,  ..., 0.0149, 0.0120, 0.0094]]],
       device='cuda:0')
unsqueeze final volume shape (DDPM2d) torch.Size([1, 1, 96, 96, 50])
unsqueeze final volume (DDPM 2D) tensor([[[[[0.0306, 0.0310, 0.0315,  ..., 0.0359, 0.0347, 0.0334],
           [0.0295, 0.0304, 0.0306,  ..., 0.0323, 0.0313, 0.0304],
           [0.0289, 0.0294, 0.0295,  ..., 0.0301, 0.0297, 0.0293],
           ...,
           [0.0289, 0.0299, 0.0297,  ..., 0.0315, 0.0316, 0.0310],
           [0.0380, 0.0388, 0.0391,  ..., 0.0402, 0.0408, 0.0406],
           [0.0306, 0.0316, 0.0312,  ..., 0.0387, 0.0383, 0.0373]],

          [[0.0300, 0.0303, 0.0310,  ..., 0.0282, 0.0269, 0.0260],
           [0.0251, 0.0254, 0.0254,  ..., 0.0196, 0.0187, 0.0179],
           [0.0243, 0.0246, 0.0246,  ..., 0.0215, 0.0207, 0.0201],
           ...,
           [0.0239, 0.0250, 0.0248,  ..., 0.0229, 0.0224, 0.0216],
           [0.0330, 0.0334, 0.0334,  ..., 0.0294, 0.0296, 0.0294],
           [0.0244, 0.0247, 0.0248,  ..., 0.0259, 0.0257, 0.0251]],

          [[0.0234, 0.0243, 0.0248,  ..., 0.0244, 0.0233, 0.0225],
           [0.0176, 0.0184, 0.0191,  ..., 0.0172, 0.0164, 0.0153],
           [0.0258, 0.0267, 0.0274,  ..., 0.0273, 0.0267, 0.0258],
           ...,
           [0.0264, 0.0278, 0.0282,  ..., 0.0285, 0.0283, 0.0270],
           [0.0247, 0.0259, 0.0260,  ..., 0.0244, 0.0242, 0.0233],
           [0.0215, 0.0224, 0.0224,  ..., 0.0223, 0.0217, 0.0210]],

          ...,

          [[0.0250, 0.0259, 0.0262,  ..., 0.0254, 0.0245, 0.0234],
           [0.0171, 0.0181, 0.0190,  ..., 0.0177, 0.0157, 0.0140],
           [0.0298, 0.0305, 0.0310,  ..., 0.0308, 0.0288, 0.0272],
           ...,
           [0.0302, 0.0312, 0.0317,  ..., 0.0361, 0.0338, 0.0317],
           [0.0221, 0.0227, 0.0233,  ..., 0.0236, 0.0209, 0.0193],
           [0.0173, 0.0183, 0.0188,  ..., 0.0171, 0.0154, 0.0142]],

          [[0.0304, 0.0309, 0.0311,  ..., 0.0311, 0.0293, 0.0280],
           [0.0264, 0.0269, 0.0276,  ..., 0.0247, 0.0223, 0.0211],
           [0.0243, 0.0247, 0.0248,  ..., 0.0244, 0.0221, 0.0209],
           ...,
           [0.0272, 0.0273, 0.0277,  ..., 0.0256, 0.0227, 0.0215],
           [0.0339, 0.0340, 0.0346,  ..., 0.0260, 0.0238, 0.0229],
           [0.0214, 0.0221, 0.0228,  ..., 0.0181, 0.0163, 0.0151]],

          [[0.0192, 0.0195, 0.0193,  ..., 0.0239, 0.0208, 0.0183],
           [0.0227, 0.0233, 0.0241,  ..., 0.0257, 0.0229, 0.0209],
           [0.0249, 0.0257, 0.0259,  ..., 0.0290, 0.0269, 0.0256],
           ...,
           [0.0221, 0.0229, 0.0236,  ..., 0.0235, 0.0208, 0.0193],
           [0.0264, 0.0271, 0.0282,  ..., 0.0225, 0.0202, 0.0185],
           [0.0119, 0.0125, 0.0134,  ..., 0.0149, 0.0120, 0.0094]]]]],
       device='cuda:0')
==========
IN _TEST_STEP
==========
ERODING BRAIN MASK
MEDIAN FILTERING
SAVING OUTPUT - ORIGINAL, FINAL, MASK ETC
SAVING IMAGES!
Testing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:40<00:00,  3.28s/it]--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{}
--------------------------------------------------------------------------------
Testing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:40<00:00,  4.09s/it]
IN TEST END
[[36m2024-11-27 18:57:57,154[0m][[34msrc.train[0m][[32mINFO[0m] - Test of Datamodules_eval.MSLUB![0m
[[36m2024-11-27 18:57:57,156[0m][[34mpytorch_lightning.accelerators.gpu[0m][[32mINFO[0m] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0][0m
Testing: 0it [00:00, ?it/s]==========
IN DDPM ON TEST START DDPM2D
==========
==========
IN DDPM ON TEST STEP
==========
THE WEIRD CONDITION BIT CALLED "features" in DDPM_2D
IN SPARK ENCODER FORWARDDD
x in shape torch.Size([50, 1, 96, 96])
out features torch.Size([50, 512])
i'm i DDPM2d forward block (whch is basically the encoder)
Context vector c shape: torch.Size([50, 512])
shape features:  torch.Size([50, 512])
additng features to latern space
latent space: []
iAM IN THE FORWARD METHOD OF THE WEIRD GUASSIAN IN cond_DDPM.py. I WILL BE CALLING p_losses
i am in p_losses in guassian which seems to be crucial to everything
conditioning vector shape:  torch.Size([50, 512])
in plosses i am getting a noisy image x
x shape:  torch.Size([50, 1, 96, 96])
getting model out
Initial input shape: torch.Size([50, 1, 96, 96])

inputblocks
Before block 0, shape: torch.Size([50, 1, 96, 96])
After block 0, shape: torch.Size([50, 128, 96, 96])
-
Before block 1, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 1, shape: torch.Size([50, 128, 96, 96])
-
Before block 2, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 2, shape: torch.Size([50, 128, 96, 96])
-
Before block 3, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 3, shape: torch.Size([50, 128, 96, 96])
-
Before block 4, shape: torch.Size([50, 128, 96, 96])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 256])
After block 4, shape: torch.Size([50, 128, 48, 48])
-
Before block 5, shape: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 48, 48])
-
Before block 8, shape: torch.Size([50, 256, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 8, shape: torch.Size([50, 256, 24, 24])
-
Before block 9, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 9, shape: torch.Size([50, 256, 24, 24])
-
Before block 10, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 10, shape: torch.Size([50, 256, 24, 24])
-
Before block 11, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 11, shape: torch.Size([50, 256, 24, 24])
-

Before middle block, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
in unet attention block!
x shape torch.Size([50, 256, 24, 24])
out dims torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])


After middle block, shape: torch.Size([50, 256, 24, 24])
-



outputblocks
Before block 0, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 0, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 0, shape: torch.Size([50, 256, 24, 24])
-
Before block 1, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 1, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 1, shape: torch.Size([50, 256, 24, 24])
-
Before block 2, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 2, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 2, shape: torch.Size([50, 256, 24, 24])
-
Before block 3, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 3, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 3, shape: torch.Size([50, 256, 48, 48])
-
Before block 4, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 4, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 4, shape: torch.Size([50, 256, 48, 48])
-
Before block 5, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 5, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 6, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 7, shape: torch.Size([50, 384, 48, 48])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 96, 96])
-
Before block 8, shape: torch.Size([50, 256, 96, 96])
After concatenation in upsampling block 8, shape: torch.Size([50, 384, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 8, shape: torch.Size([50, 128, 96, 96])
-
Before block 9, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 9, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 9, shape: torch.Size([50, 128, 96, 96])
-
Before block 10, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 10, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 10, shape: torch.Size([50, 128, 96, 96])
-
Before block 11, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 11, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 11, shape: torch.Size([50, 128, 96, 96])
-

Before Final layer shape: torch.Size([50, 128, 96, 96])
Final output shape: torch.Size([50, 1, 96, 96])
model out shape:  torch.Size([50, 1, 96, 96])
iAM IN THE FORWARD METHOD OF THE WEIRD GUASSIAN IN cond_DDPM.py. I WILL BE CALLING p_losses
i am in p_losses in guassian which seems to be crucial to everything
conditioning vector shape:  torch.Size([50, 512])
in plosses i am getting a noisy image x
x shape:  torch.Size([50, 1, 96, 96])
getting model out
Initial input shape: torch.Size([50, 1, 96, 96])

inputblocks
Before block 0, shape: torch.Size([50, 1, 96, 96])
After block 0, shape: torch.Size([50, 128, 96, 96])
-
Before block 1, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 1, shape: torch.Size([50, 128, 96, 96])
-
Before block 2, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 2, shape: torch.Size([50, 128, 96, 96])
-
Before block 3, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 3, shape: torch.Size([50, 128, 96, 96])
-
Before block 4, shape: torch.Size([50, 128, 96, 96])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 256])
After block 4, shape: torch.Size([50, 128, 48, 48])
-
Before block 5, shape: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 48, 48])
-
Before block 8, shape: torch.Size([50, 256, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 8, shape: torch.Size([50, 256, 24, 24])
-
Before block 9, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 9, shape: torch.Size([50, 256, 24, 24])
-
Before block 10, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 10, shape: torch.Size([50, 256, 24, 24])
-
Before block 11, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 11, shape: torch.Size([50, 256, 24, 24])
-

Before middle block, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
in unet attention block!
x shape torch.Size([50, 256, 24, 24])
out dims torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])


After middle block, shape: torch.Size([50, 256, 24, 24])
-



outputblocks
Before block 0, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 0, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 0, shape: torch.Size([50, 256, 24, 24])
-
Before block 1, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 1, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 1, shape: torch.Size([50, 256, 24, 24])
-
Before block 2, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 2, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 2, shape: torch.Size([50, 256, 24, 24])
-
Before block 3, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 3, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 3, shape: torch.Size([50, 256, 48, 48])
-
Before block 4, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 4, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 4, shape: torch.Size([50, 256, 48, 48])
-
Before block 5, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 5, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 6, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 7, shape: torch.Size([50, 384, 48, 48])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 96, 96])
-
Before block 8, shape: torch.Size([50, 256, 96, 96])
After concatenation in upsampling block 8, shape: torch.Size([50, 384, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 8, shape: torch.Size([50, 128, 96, 96])
-
Before block 9, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 9, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 9, shape: torch.Size([50, 128, 96, 96])
-
Before block 10, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 10, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 10, shape: torch.Size([50, 128, 96, 96])
-
Before block 11, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 11, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 11, shape: torch.Size([50, 128, 96, 96])
-

Before Final layer shape: torch.Size([50, 128, 96, 96])
Final output shape: torch.Size([50, 1, 96, 96])
model out shape:  torch.Size([50, 1, 96, 96])
iAM IN THE FORWARD METHOD OF THE WEIRD GUASSIAN IN cond_DDPM.py. I WILL BE CALLING p_losses
i am in p_losses in guassian which seems to be crucial to everything
conditioning vector shape:  torch.Size([50, 512])
in plosses i am getting a noisy image x
x shape:  torch.Size([50, 1, 96, 96])
getting model out
Initial input shape: torch.Size([50, 1, 96, 96])

inputblocks
Before block 0, shape: torch.Size([50, 1, 96, 96])
After block 0, shape: torch.Size([50, 128, 96, 96])
-
Before block 1, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 1, shape: torch.Size([50, 128, 96, 96])
-
Before block 2, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 2, shape: torch.Size([50, 128, 96, 96])
-
Before block 3, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 3, shape: torch.Size([50, 128, 96, 96])
-
Before block 4, shape: torch.Size([50, 128, 96, 96])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 256])
After block 4, shape: torch.Size([50, 128, 48, 48])
-
Before block 5, shape: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 48, 48])
-
Before block 8, shape: torch.Size([50, 256, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 8, shape: torch.Size([50, 256, 24, 24])
-
Before block 9, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 9, shape: torch.Size([50, 256, 24, 24])
-
Before block 10, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 10, shape: torch.Size([50, 256, 24, 24])
-
Before block 11, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 11, shape: torch.Size([50, 256, 24, 24])
-

Before middle block, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
in unet attention block!
x shape torch.Size([50, 256, 24, 24])
out dims torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])


After middle block, shape: torch.Size([50, 256, 24, 24])
-



outputblocks
Before block 0, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 0, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 0, shape: torch.Size([50, 256, 24, 24])
-
Before block 1, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 1, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 1, shape: torch.Size([50, 256, 24, 24])
-
Before block 2, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 2, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 2, shape: torch.Size([50, 256, 24, 24])
-
Before block 3, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 3, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 3, shape: torch.Size([50, 256, 48, 48])
-
Before block 4, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 4, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 4, shape: torch.Size([50, 256, 48, 48])
-
Before block 5, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 5, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 6, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 7, shape: torch.Size([50, 384, 48, 48])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 96, 96])
-
Before block 8, shape: torch.Size([50, 256, 96, 96])
After concatenation in upsampling block 8, shape: torch.Size([50, 384, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 8, shape: torch.Size([50, 128, 96, 96])
-
Before block 9, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 9, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 9, shape: torch.Size([50, 128, 96, 96])
-
Before block 10, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 10, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 10, shape: torch.Size([50, 128, 96, 96])
-
Before block 11, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 11, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 11, shape: torch.Size([50, 128, 96, 96])
-

Before Final layer shape: torch.Size([50, 128, 96, 96])
Final output shape: torch.Size([50, 1, 96, 96])
model out shape:  torch.Size([50, 1, 96, 96])
reconstruction shape torch.Size([50, 1, 96, 96])
reconstruction tensor([[[[0.0209, 0.0213, 0.0212,  ..., 0.0237, 0.0276, 0.0196],
          [0.0283, 0.0182, 0.0146,  ..., 0.0166, 0.0236, 0.0203],
          [0.0213, 0.0113, 0.0203,  ..., 0.0220, 0.0142, 0.0144],
          ...,
          [0.0238, 0.0144, 0.0239,  ..., 0.0238, 0.0167, 0.0177],
          [0.0299, 0.0200, 0.0177,  ..., 0.0165, 0.0234, 0.0172],
          [0.0207, 0.0206, 0.0204,  ..., 0.0164, 0.0229, 0.0165]]],


        [[[0.0205, 0.0211, 0.0209,  ..., 0.0237, 0.0273, 0.0195],
          [0.0278, 0.0177, 0.0146,  ..., 0.0166, 0.0229, 0.0196],
          [0.0215, 0.0116, 0.0209,  ..., 0.0224, 0.0144, 0.0143],
          ...,
          [0.0239, 0.0148, 0.0244,  ..., 0.0243, 0.0169, 0.0177],
          [0.0300, 0.0202, 0.0180,  ..., 0.0164, 0.0226, 0.0165],
          [0.0207, 0.0208, 0.0207,  ..., 0.0168, 0.0228, 0.0164]]],


        [[[0.0206, 0.0208, 0.0209,  ..., 0.0238, 0.0272, 0.0194],
          [0.0276, 0.0168, 0.0142,  ..., 0.0165, 0.0225, 0.0194],
          [0.0212, 0.0114, 0.0212,  ..., 0.0228, 0.0141, 0.0141],
          ...,
          [0.0239, 0.0146, 0.0245,  ..., 0.0242, 0.0167, 0.0176],
          [0.0295, 0.0194, 0.0177,  ..., 0.0164, 0.0226, 0.0165],
          [0.0208, 0.0204, 0.0207,  ..., 0.0168, 0.0229, 0.0168]]],


        ...,


        [[[0.0234, 0.0228, 0.0205,  ..., 0.0213, 0.0243, 0.0207],
          [0.0264, 0.0146, 0.0129,  ..., 0.0138, 0.0163, 0.0141],
          [0.0225, 0.0121, 0.0219,  ..., 0.0234, 0.0141, 0.0129],
          ...,
          [0.0263, 0.0182, 0.0279,  ..., 0.0287, 0.0193, 0.0187],
          [0.0368, 0.0284, 0.0237,  ..., 0.0168, 0.0208, 0.0143],
          [0.0287, 0.0318, 0.0292,  ..., 0.0194, 0.0247, 0.0157]]],


        [[[0.0234, 0.0229, 0.0203,  ..., 0.0215, 0.0250, 0.0203],
          [0.0273, 0.0157, 0.0135,  ..., 0.0142, 0.0174, 0.0146],
          [0.0228, 0.0124, 0.0216,  ..., 0.0230, 0.0142, 0.0128],
          ...,
          [0.0270, 0.0189, 0.0275,  ..., 0.0281, 0.0194, 0.0188],
          [0.0387, 0.0309, 0.0246,  ..., 0.0168, 0.0216, 0.0145],
          [0.0292, 0.0331, 0.0296,  ..., 0.0193, 0.0250, 0.0151]]],


        [[[0.0225, 0.0224, 0.0199,  ..., 0.0211, 0.0247, 0.0194],
          [0.0269, 0.0155, 0.0129,  ..., 0.0135, 0.0173, 0.0143],
          [0.0223, 0.0118, 0.0208,  ..., 0.0222, 0.0137, 0.0123],
          ...,
          [0.0258, 0.0165, 0.0247,  ..., 0.0265, 0.0184, 0.0179],
          [0.0366, 0.0279, 0.0218,  ..., 0.0155, 0.0205, 0.0133],
          [0.0273, 0.0303, 0.0272,  ..., 0.0178, 0.0235, 0.0136]]]],
       device='cuda:0')
FINAL VOLUME (DDPM) shape torch.Size([96, 96, 50])
FINAL VOLUME tensor([[[0.0209, 0.0205, 0.0206,  ..., 0.0234, 0.0234, 0.0225],
         [0.0213, 0.0211, 0.0208,  ..., 0.0228, 0.0229, 0.0224],
         [0.0212, 0.0209, 0.0209,  ..., 0.0205, 0.0203, 0.0199],
         ...,
         [0.0237, 0.0237, 0.0238,  ..., 0.0213, 0.0215, 0.0211],
         [0.0276, 0.0273, 0.0272,  ..., 0.0243, 0.0250, 0.0247],
         [0.0196, 0.0195, 0.0194,  ..., 0.0207, 0.0203, 0.0194]],

        [[0.0283, 0.0278, 0.0276,  ..., 0.0264, 0.0273, 0.0269],
         [0.0182, 0.0177, 0.0168,  ..., 0.0146, 0.0157, 0.0155],
         [0.0146, 0.0146, 0.0142,  ..., 0.0129, 0.0135, 0.0129],
         ...,
         [0.0166, 0.0166, 0.0165,  ..., 0.0138, 0.0142, 0.0135],
         [0.0236, 0.0229, 0.0225,  ..., 0.0163, 0.0174, 0.0173],
         [0.0203, 0.0196, 0.0194,  ..., 0.0141, 0.0146, 0.0143]],

        [[0.0213, 0.0215, 0.0212,  ..., 0.0225, 0.0228, 0.0223],
         [0.0113, 0.0116, 0.0114,  ..., 0.0121, 0.0124, 0.0118],
         [0.0203, 0.0209, 0.0212,  ..., 0.0219, 0.0216, 0.0208],
         ...,
         [0.0220, 0.0224, 0.0228,  ..., 0.0234, 0.0230, 0.0222],
         [0.0142, 0.0144, 0.0141,  ..., 0.0141, 0.0142, 0.0137],
         [0.0144, 0.0143, 0.0141,  ..., 0.0129, 0.0128, 0.0123]],

        ...,

        [[0.0238, 0.0239, 0.0239,  ..., 0.0263, 0.0270, 0.0258],
         [0.0144, 0.0148, 0.0146,  ..., 0.0182, 0.0189, 0.0165],
         [0.0239, 0.0244, 0.0245,  ..., 0.0279, 0.0275, 0.0247],
         ...,
         [0.0238, 0.0243, 0.0242,  ..., 0.0287, 0.0281, 0.0265],
         [0.0167, 0.0169, 0.0167,  ..., 0.0193, 0.0194, 0.0184],
         [0.0177, 0.0177, 0.0176,  ..., 0.0187, 0.0188, 0.0179]],

        [[0.0299, 0.0300, 0.0295,  ..., 0.0368, 0.0387, 0.0366],
         [0.0200, 0.0202, 0.0194,  ..., 0.0284, 0.0309, 0.0279],
         [0.0177, 0.0180, 0.0177,  ..., 0.0237, 0.0246, 0.0218],
         ...,
         [0.0165, 0.0164, 0.0164,  ..., 0.0168, 0.0168, 0.0155],
         [0.0234, 0.0226, 0.0226,  ..., 0.0208, 0.0216, 0.0205],
         [0.0172, 0.0165, 0.0165,  ..., 0.0143, 0.0145, 0.0133]],

        [[0.0207, 0.0207, 0.0208,  ..., 0.0287, 0.0292, 0.0273],
         [0.0206, 0.0208, 0.0204,  ..., 0.0318, 0.0331, 0.0303],
         [0.0204, 0.0207, 0.0207,  ..., 0.0292, 0.0296, 0.0272],
         ...,
         [0.0164, 0.0168, 0.0168,  ..., 0.0194, 0.0193, 0.0178],
         [0.0229, 0.0228, 0.0229,  ..., 0.0247, 0.0250, 0.0235],
         [0.0165, 0.0164, 0.0168,  ..., 0.0157, 0.0151, 0.0136]]],
       device='cuda:0')
unsqueeze final volume shape (DDPM2d) torch.Size([1, 1, 96, 96, 50])
unsqueeze final volume (DDPM 2D) tensor([[[[[0.0209, 0.0205, 0.0206,  ..., 0.0234, 0.0234, 0.0225],
           [0.0213, 0.0211, 0.0208,  ..., 0.0228, 0.0229, 0.0224],
           [0.0212, 0.0209, 0.0209,  ..., 0.0205, 0.0203, 0.0199],
           ...,
           [0.0237, 0.0237, 0.0238,  ..., 0.0213, 0.0215, 0.0211],
           [0.0276, 0.0273, 0.0272,  ..., 0.0243, 0.0250, 0.0247],
           [0.0196, 0.0195, 0.0194,  ..., 0.0207, 0.0203, 0.0194]],

          [[0.0283, 0.0278, 0.0276,  ..., 0.0264, 0.0273, 0.0269],
           [0.0182, 0.0177, 0.0168,  ..., 0.0146, 0.0157, 0.0155],
           [0.0146, 0.0146, 0.0142,  ..., 0.0129, 0.0135, 0.0129],
           ...,
           [0.0166, 0.0166, 0.0165,  ..., 0.0138, 0.0142, 0.0135],
           [0.0236, 0.0229, 0.0225,  ..., 0.0163, 0.0174, 0.0173],
           [0.0203, 0.0196, 0.0194,  ..., 0.0141, 0.0146, 0.0143]],

          [[0.0213, 0.0215, 0.0212,  ..., 0.0225, 0.0228, 0.0223],
           [0.0113, 0.0116, 0.0114,  ..., 0.0121, 0.0124, 0.0118],
           [0.0203, 0.0209, 0.0212,  ..., 0.0219, 0.0216, 0.0208],
           ...,
           [0.0220, 0.0224, 0.0228,  ..., 0.0234, 0.0230, 0.0222],
           [0.0142, 0.0144, 0.0141,  ..., 0.0141, 0.0142, 0.0137],
           [0.0144, 0.0143, 0.0141,  ..., 0.0129, 0.0128, 0.0123]],

          ...,

          [[0.0238, 0.0239, 0.0239,  ..., 0.0263, 0.0270, 0.0258],
           [0.0144, 0.0148, 0.0146,  ..., 0.0182, 0.0189, 0.0165],
           [0.0239, 0.0244, 0.0245,  ..., 0.0279, 0.0275, 0.0247],
           ...,
           [0.0238, 0.0243, 0.0242,  ..., 0.0287, 0.0281, 0.0265],
           [0.0167, 0.0169, 0.0167,  ..., 0.0193, 0.0194, 0.0184],
           [0.0177, 0.0177, 0.0176,  ..., 0.0187, 0.0188, 0.0179]],

          [[0.0299, 0.0300, 0.0295,  ..., 0.0368, 0.0387, 0.0366],
           [0.0200, 0.0202, 0.0194,  ..., 0.0284, 0.0309, 0.0279],
           [0.0177, 0.0180, 0.0177,  ..., 0.0237, 0.0246, 0.0218],
           ...,
           [0.0165, 0.0164, 0.0164,  ..., 0.0168, 0.0168, 0.0155],
           [0.0234, 0.0226, 0.0226,  ..., 0.0208, 0.0216, 0.0205],
           [0.0172, 0.0165, 0.0165,  ..., 0.0143, 0.0145, 0.0133]],

          [[0.0207, 0.0207, 0.0208,  ..., 0.0287, 0.0292, 0.0273],
           [0.0206, 0.0208, 0.0204,  ..., 0.0318, 0.0331, 0.0303],
           [0.0204, 0.0207, 0.0207,  ..., 0.0292, 0.0296, 0.0272],
           ...,
           [0.0164, 0.0168, 0.0168,  ..., 0.0194, 0.0193, 0.0178],
           [0.0229, 0.0228, 0.0229,  ..., 0.0247, 0.0250, 0.0235],
           [0.0165, 0.0164, 0.0168,  ..., 0.0157, 0.0151, 0.0136]]]]],
       device='cuda:0')
==========
IN _TEST_STEP
==========
ERODING BRAIN MASK
MEDIAN FILTERING
SAVING OUTPUT - ORIGINAL, FINAL, MASK ETC
SAVING IMAGES!
Testing:   5%|â–Œ         | 1/20 [00:04<01:29,  4.72s/it]==========
IN DDPM ON TEST STEP
==========
THE WEIRD CONDITION BIT CALLED "features" in DDPM_2D
IN SPARK ENCODER FORWARDDD
x in shape torch.Size([50, 1, 96, 96])
out features torch.Size([50, 512])
i'm i DDPM2d forward block (whch is basically the encoder)
Context vector c shape: torch.Size([50, 512])
shape features:  torch.Size([50, 512])
additng features to latern space
latent space: []
iAM IN THE FORWARD METHOD OF THE WEIRD GUASSIAN IN cond_DDPM.py. I WILL BE CALLING p_losses
i am in p_losses in guassian which seems to be crucial to everything
conditioning vector shape:  torch.Size([50, 512])
in plosses i am getting a noisy image x
x shape:  torch.Size([50, 1, 96, 96])
getting model out
Initial input shape: torch.Size([50, 1, 96, 96])

inputblocks
Before block 0, shape: torch.Size([50, 1, 96, 96])
After block 0, shape: torch.Size([50, 128, 96, 96])
-
Before block 1, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 1, shape: torch.Size([50, 128, 96, 96])
-
Before block 2, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 2, shape: torch.Size([50, 128, 96, 96])
-
Before block 3, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 3, shape: torch.Size([50, 128, 96, 96])
-
Before block 4, shape: torch.Size([50, 128, 96, 96])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 256])
After block 4, shape: torch.Size([50, 128, 48, 48])
-
Before block 5, shape: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 48, 48])
-
Before block 8, shape: torch.Size([50, 256, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 8, shape: torch.Size([50, 256, 24, 24])
-
Before block 9, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 9, shape: torch.Size([50, 256, 24, 24])
-
Before block 10, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 10, shape: torch.Size([50, 256, 24, 24])
-
Before block 11, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 11, shape: torch.Size([50, 256, 24, 24])
-

Before middle block, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
in unet attention block!
x shape torch.Size([50, 256, 24, 24])
out dims torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])


After middle block, shape: torch.Size([50, 256, 24, 24])
-



outputblocks
Before block 0, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 0, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 0, shape: torch.Size([50, 256, 24, 24])
-
Before block 1, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 1, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 1, shape: torch.Size([50, 256, 24, 24])
-
Before block 2, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 2, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 2, shape: torch.Size([50, 256, 24, 24])
-
Before block 3, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 3, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 3, shape: torch.Size([50, 256, 48, 48])
-
Before block 4, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 4, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 4, shape: torch.Size([50, 256, 48, 48])
-
Before block 5, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 5, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 6, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 7, shape: torch.Size([50, 384, 48, 48])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 96, 96])
-
Before block 8, shape: torch.Size([50, 256, 96, 96])
After concatenation in upsampling block 8, shape: torch.Size([50, 384, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 8, shape: torch.Size([50, 128, 96, 96])
-
Before block 9, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 9, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 9, shape: torch.Size([50, 128, 96, 96])
-
Before block 10, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 10, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 10, shape: torch.Size([50, 128, 96, 96])
-
Before block 11, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 11, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 11, shape: torch.Size([50, 128, 96, 96])
-

Before Final layer shape: torch.Size([50, 128, 96, 96])
Final output shape: torch.Size([50, 1, 96, 96])
model out shape:  torch.Size([50, 1, 96, 96])
iAM IN THE FORWARD METHOD OF THE WEIRD GUASSIAN IN cond_DDPM.py. I WILL BE CALLING p_losses
i am in p_losses in guassian which seems to be crucial to everything
conditioning vector shape:  torch.Size([50, 512])
in plosses i am getting a noisy image x
x shape:  torch.Size([50, 1, 96, 96])
getting model out
Initial input shape: torch.Size([50, 1, 96, 96])

inputblocks
Before block 0, shape: torch.Size([50, 1, 96, 96])
After block 0, shape: torch.Size([50, 128, 96, 96])
-
Before block 1, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 1, shape: torch.Size([50, 128, 96, 96])
-
Before block 2, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 2, shape: torch.Size([50, 128, 96, 96])
-
Before block 3, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 3, shape: torch.Size([50, 128, 96, 96])
-
Before block 4, shape: torch.Size([50, 128, 96, 96])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 256])
After block 4, shape: torch.Size([50, 128, 48, 48])
-
Before block 5, shape: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 48, 48])
-
Before block 8, shape: torch.Size([50, 256, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 8, shape: torch.Size([50, 256, 24, 24])
-
Before block 9, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 9, shape: torch.Size([50, 256, 24, 24])
-
Before block 10, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 10, shape: torch.Size([50, 256, 24, 24])
-
Before block 11, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 11, shape: torch.Size([50, 256, 24, 24])
-

Before middle block, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
in unet attention block!
x shape torch.Size([50, 256, 24, 24])
out dims torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])


After middle block, shape: torch.Size([50, 256, 24, 24])
-



outputblocks
Before block 0, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 0, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 0, shape: torch.Size([50, 256, 24, 24])
-
Before block 1, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 1, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 1, shape: torch.Size([50, 256, 24, 24])
-
Before block 2, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 2, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 2, shape: torch.Size([50, 256, 24, 24])
-
Before block 3, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 3, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 3, shape: torch.Size([50, 256, 48, 48])
-
Before block 4, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 4, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 4, shape: torch.Size([50, 256, 48, 48])
-
Before block 5, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 5, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 6, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 7, shape: torch.Size([50, 384, 48, 48])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 96, 96])
-
Before block 8, shape: torch.Size([50, 256, 96, 96])
After concatenation in upsampling block 8, shape: torch.Size([50, 384, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 8, shape: torch.Size([50, 128, 96, 96])
-
Before block 9, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 9, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 9, shape: torch.Size([50, 128, 96, 96])
-
Before block 10, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 10, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 10, shape: torch.Size([50, 128, 96, 96])
-
Before block 11, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 11, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 11, shape: torch.Size([50, 128, 96, 96])
-

Before Final layer shape: torch.Size([50, 128, 96, 96])
Final output shape: torch.Size([50, 1, 96, 96])
model out shape:  torch.Size([50, 1, 96, 96])
iAM IN THE FORWARD METHOD OF THE WEIRD GUASSIAN IN cond_DDPM.py. I WILL BE CALLING p_losses
i am in p_losses in guassian which seems to be crucial to everything
conditioning vector shape:  torch.Size([50, 512])
in plosses i am getting a noisy image x
x shape:  torch.Size([50, 1, 96, 96])
getting model out
Initial input shape: torch.Size([50, 1, 96, 96])

inputblocks
Before block 0, shape: torch.Size([50, 1, 96, 96])
After block 0, shape: torch.Size([50, 128, 96, 96])
-
Before block 1, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 1, shape: torch.Size([50, 128, 96, 96])
-
Before block 2, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 2, shape: torch.Size([50, 128, 96, 96])
-
Before block 3, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 3, shape: torch.Size([50, 128, 96, 96])
-
Before block 4, shape: torch.Size([50, 128, 96, 96])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 256])
After block 4, shape: torch.Size([50, 128, 48, 48])
-
Before block 5, shape: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 48, 48])
-
Before block 8, shape: torch.Size([50, 256, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 8, shape: torch.Size([50, 256, 24, 24])
-
Before block 9, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 9, shape: torch.Size([50, 256, 24, 24])
-
Before block 10, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 10, shape: torch.Size([50, 256, 24, 24])
-
Before block 11, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 11, shape: torch.Size([50, 256, 24, 24])
-

Before middle block, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
in unet attention block!
x shape torch.Size([50, 256, 24, 24])
out dims torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])


After middle block, shape: torch.Size([50, 256, 24, 24])
-



outputblocks
Before block 0, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 0, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 0, shape: torch.Size([50, 256, 24, 24])
-
Before block 1, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 1, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 1, shape: torch.Size([50, 256, 24, 24])
-
Before block 2, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 2, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 2, shape: torch.Size([50, 256, 24, 24])
-
Before block 3, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 3, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 3, shape: torch.Size([50, 256, 48, 48])
-
Before block 4, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 4, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 4, shape: torch.Size([50, 256, 48, 48])
-
Before block 5, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 5, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 6, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 7, shape: torch.Size([50, 384, 48, 48])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 96, 96])
-
Before block 8, shape: torch.Size([50, 256, 96, 96])
After concatenation in upsampling block 8, shape: torch.Size([50, 384, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 8, shape: torch.Size([50, 128, 96, 96])
-
Before block 9, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 9, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 9, shape: torch.Size([50, 128, 96, 96])
-
Before block 10, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 10, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 10, shape: torch.Size([50, 128, 96, 96])
-
Before block 11, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 11, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 11, shape: torch.Size([50, 128, 96, 96])
-

Before Final layer shape: torch.Size([50, 128, 96, 96])
Final output shape: torch.Size([50, 1, 96, 96])
model out shape:  torch.Size([50, 1, 96, 96])
reconstruction shape torch.Size([50, 1, 96, 96])
reconstruction tensor([[[[ 0.0240,  0.0132,  0.0190,  ...,  0.0199,  0.0230,  0.0181],
          [ 0.0290,  0.0159,  0.0115,  ...,  0.0132,  0.0176,  0.0142],
          [ 0.0168,  0.0129,  0.0181,  ...,  0.0163,  0.0112,  0.0142],
          ...,
          [ 0.0155,  0.0059,  0.0192,  ...,  0.0274,  0.0178,  0.0129],
          [ 0.0146,  0.0133,  0.0071,  ...,  0.0186,  0.0193,  0.0162],
          [ 0.0038,  0.0043,  0.0053,  ...,  0.0174,  0.0182,  0.0181]]],


        [[[ 0.0262,  0.0152,  0.0208,  ...,  0.0216,  0.0247,  0.0199],
          [ 0.0299,  0.0170,  0.0130,  ...,  0.0151,  0.0189,  0.0151],
          [ 0.0181,  0.0146,  0.0202,  ...,  0.0186,  0.0130,  0.0160],
          ...,
          [ 0.0172,  0.0078,  0.0214,  ...,  0.0295,  0.0201,  0.0144],
          [ 0.0166,  0.0152,  0.0095,  ...,  0.0206,  0.0214,  0.0179],
          [ 0.0057,  0.0061,  0.0077,  ...,  0.0192,  0.0199,  0.0195]]],


        [[[ 0.0308,  0.0199,  0.0248,  ...,  0.0258,  0.0294,  0.0242],
          [ 0.0339,  0.0210,  0.0169,  ...,  0.0191,  0.0238,  0.0194],
          [ 0.0223,  0.0188,  0.0238,  ...,  0.0225,  0.0173,  0.0200],
          ...,
          [ 0.0212,  0.0122,  0.0256,  ...,  0.0343,  0.0263,  0.0197],
          [ 0.0197,  0.0184,  0.0132,  ...,  0.0258,  0.0284,  0.0244],
          [ 0.0090,  0.0092,  0.0118,  ...,  0.0249,  0.0272,  0.0261]]],


        ...,


        [[[ 0.0288,  0.0125,  0.0189,  ...,  0.0232,  0.0239,  0.0224],
          [ 0.0255,  0.0063,  0.0060,  ...,  0.0129,  0.0132,  0.0126],
          [ 0.0208,  0.0120,  0.0176,  ...,  0.0206,  0.0131,  0.0171],
          ...,
          [ 0.0145,  0.0046,  0.0229,  ...,  0.0330,  0.0222,  0.0160],
          [ 0.0139,  0.0059,  0.0076,  ...,  0.0224,  0.0228,  0.0196],
          [ 0.0050,  0.0003,  0.0050,  ...,  0.0222,  0.0228,  0.0245]]],


        [[[ 0.0287,  0.0126,  0.0186,  ...,  0.0231,  0.0243,  0.0222],
          [ 0.0260,  0.0072,  0.0059,  ...,  0.0129,  0.0140,  0.0129],
          [ 0.0208,  0.0120,  0.0169,  ...,  0.0198,  0.0128,  0.0168],
          ...,
          [ 0.0143,  0.0042,  0.0216,  ...,  0.0367,  0.0261,  0.0185],
          [ 0.0139,  0.0062,  0.0068,  ...,  0.0273,  0.0285,  0.0232],
          [ 0.0038, -0.0004,  0.0038,  ...,  0.0260,  0.0264,  0.0264]]],


        [[[ 0.0281,  0.0127,  0.0177,  ...,  0.0225,  0.0244,  0.0211],
          [ 0.0269,  0.0086,  0.0056,  ...,  0.0127,  0.0150,  0.0130],
          [ 0.0212,  0.0126,  0.0161,  ...,  0.0186,  0.0122,  0.0160],
          ...,
          [ 0.0140,  0.0042,  0.0208,  ...,  0.0394,  0.0297,  0.0206],
          [ 0.0142,  0.0075,  0.0067,  ...,  0.0323,  0.0348,  0.0269],
          [ 0.0021, -0.0011,  0.0024,  ...,  0.0292,  0.0300,  0.0278]]]],
       device='cuda:0')
FINAL VOLUME (DDPM) shape torch.Size([96, 96, 50])
FINAL VOLUME tensor([[[ 0.0240,  0.0262,  0.0308,  ...,  0.0288,  0.0287,  0.0281],
         [ 0.0132,  0.0152,  0.0199,  ...,  0.0125,  0.0126,  0.0127],
         [ 0.0190,  0.0208,  0.0248,  ...,  0.0189,  0.0186,  0.0177],
         ...,
         [ 0.0199,  0.0216,  0.0258,  ...,  0.0232,  0.0231,  0.0225],
         [ 0.0230,  0.0247,  0.0294,  ...,  0.0239,  0.0243,  0.0244],
         [ 0.0181,  0.0199,  0.0242,  ...,  0.0224,  0.0222,  0.0211]],

        [[ 0.0290,  0.0299,  0.0339,  ...,  0.0255,  0.0260,  0.0269],
         [ 0.0159,  0.0170,  0.0210,  ...,  0.0063,  0.0072,  0.0086],
         [ 0.0115,  0.0130,  0.0169,  ...,  0.0060,  0.0059,  0.0056],
         ...,
         [ 0.0132,  0.0151,  0.0191,  ...,  0.0129,  0.0129,  0.0127],
         [ 0.0176,  0.0189,  0.0238,  ...,  0.0132,  0.0140,  0.0150],
         [ 0.0142,  0.0151,  0.0194,  ...,  0.0126,  0.0129,  0.0130]],

        [[ 0.0168,  0.0181,  0.0223,  ...,  0.0208,  0.0208,  0.0212],
         [ 0.0129,  0.0146,  0.0188,  ...,  0.0120,  0.0120,  0.0126],
         [ 0.0181,  0.0202,  0.0238,  ...,  0.0176,  0.0169,  0.0161],
         ...,
         [ 0.0163,  0.0186,  0.0225,  ...,  0.0206,  0.0198,  0.0186],
         [ 0.0112,  0.0130,  0.0173,  ...,  0.0131,  0.0128,  0.0122],
         [ 0.0142,  0.0160,  0.0200,  ...,  0.0171,  0.0168,  0.0160]],

        ...,

        [[ 0.0155,  0.0172,  0.0212,  ...,  0.0145,  0.0143,  0.0140],
         [ 0.0059,  0.0078,  0.0122,  ...,  0.0046,  0.0042,  0.0042],
         [ 0.0192,  0.0214,  0.0256,  ...,  0.0229,  0.0216,  0.0208],
         ...,
         [ 0.0274,  0.0295,  0.0343,  ...,  0.0330,  0.0367,  0.0394],
         [ 0.0178,  0.0201,  0.0263,  ...,  0.0222,  0.0261,  0.0297],
         [ 0.0129,  0.0144,  0.0197,  ...,  0.0160,  0.0185,  0.0206]],

        [[ 0.0146,  0.0166,  0.0197,  ...,  0.0139,  0.0139,  0.0142],
         [ 0.0133,  0.0152,  0.0184,  ...,  0.0059,  0.0062,  0.0075],
         [ 0.0071,  0.0095,  0.0132,  ...,  0.0076,  0.0068,  0.0067],
         ...,
         [ 0.0186,  0.0206,  0.0258,  ...,  0.0224,  0.0273,  0.0323],
         [ 0.0193,  0.0214,  0.0284,  ...,  0.0228,  0.0285,  0.0348],
         [ 0.0162,  0.0179,  0.0244,  ...,  0.0196,  0.0232,  0.0269]],

        [[ 0.0038,  0.0057,  0.0090,  ...,  0.0050,  0.0038,  0.0021],
         [ 0.0043,  0.0061,  0.0092,  ...,  0.0003, -0.0004, -0.0011],
         [ 0.0053,  0.0077,  0.0118,  ...,  0.0050,  0.0038,  0.0024],
         ...,
         [ 0.0174,  0.0192,  0.0249,  ...,  0.0222,  0.0260,  0.0292],
         [ 0.0182,  0.0199,  0.0272,  ...,  0.0228,  0.0264,  0.0300],
         [ 0.0181,  0.0195,  0.0261,  ...,  0.0245,  0.0264,  0.0278]]],
       device='cuda:0')
unsqueeze final volume shape (DDPM2d) torch.Size([1, 1, 96, 96, 50])
unsqueeze final volume (DDPM 2D) tensor([[[[[ 0.0240,  0.0262,  0.0308,  ...,  0.0288,  0.0287,  0.0281],
           [ 0.0132,  0.0152,  0.0199,  ...,  0.0125,  0.0126,  0.0127],
           [ 0.0190,  0.0208,  0.0248,  ...,  0.0189,  0.0186,  0.0177],
           ...,
           [ 0.0199,  0.0216,  0.0258,  ...,  0.0232,  0.0231,  0.0225],
           [ 0.0230,  0.0247,  0.0294,  ...,  0.0239,  0.0243,  0.0244],
           [ 0.0181,  0.0199,  0.0242,  ...,  0.0224,  0.0222,  0.0211]],

          [[ 0.0290,  0.0299,  0.0339,  ...,  0.0255,  0.0260,  0.0269],
           [ 0.0159,  0.0170,  0.0210,  ...,  0.0063,  0.0072,  0.0086],
           [ 0.0115,  0.0130,  0.0169,  ...,  0.0060,  0.0059,  0.0056],
           ...,
           [ 0.0132,  0.0151,  0.0191,  ...,  0.0129,  0.0129,  0.0127],
           [ 0.0176,  0.0189,  0.0238,  ...,  0.0132,  0.0140,  0.0150],
           [ 0.0142,  0.0151,  0.0194,  ...,  0.0126,  0.0129,  0.0130]],

          [[ 0.0168,  0.0181,  0.0223,  ...,  0.0208,  0.0208,  0.0212],
           [ 0.0129,  0.0146,  0.0188,  ...,  0.0120,  0.0120,  0.0126],
           [ 0.0181,  0.0202,  0.0238,  ...,  0.0176,  0.0169,  0.0161],
           ...,
           [ 0.0163,  0.0186,  0.0225,  ...,  0.0206,  0.0198,  0.0186],
           [ 0.0112,  0.0130,  0.0173,  ...,  0.0131,  0.0128,  0.0122],
           [ 0.0142,  0.0160,  0.0200,  ...,  0.0171,  0.0168,  0.0160]],

          ...,

          [[ 0.0155,  0.0172,  0.0212,  ...,  0.0145,  0.0143,  0.0140],
           [ 0.0059,  0.0078,  0.0122,  ...,  0.0046,  0.0042,  0.0042],
           [ 0.0192,  0.0214,  0.0256,  ...,  0.0229,  0.0216,  0.0208],
           ...,
           [ 0.0274,  0.0295,  0.0343,  ...,  0.0330,  0.0367,  0.0394],
           [ 0.0178,  0.0201,  0.0263,  ...,  0.0222,  0.0261,  0.0297],
           [ 0.0129,  0.0144,  0.0197,  ...,  0.0160,  0.0185,  0.0206]],

          [[ 0.0146,  0.0166,  0.0197,  ...,  0.0139,  0.0139,  0.0142],
           [ 0.0133,  0.0152,  0.0184,  ...,  0.0059,  0.0062,  0.0075],
           [ 0.0071,  0.0095,  0.0132,  ...,  0.0076,  0.0068,  0.0067],
           ...,
           [ 0.0186,  0.0206,  0.0258,  ...,  0.0224,  0.0273,  0.0323],
           [ 0.0193,  0.0214,  0.0284,  ...,  0.0228,  0.0285,  0.0348],
           [ 0.0162,  0.0179,  0.0244,  ...,  0.0196,  0.0232,  0.0269]],

          [[ 0.0038,  0.0057,  0.0090,  ...,  0.0050,  0.0038,  0.0021],
           [ 0.0043,  0.0061,  0.0092,  ...,  0.0003, -0.0004, -0.0011],
           [ 0.0053,  0.0077,  0.0118,  ...,  0.0050,  0.0038,  0.0024],
           ...,
           [ 0.0174,  0.0192,  0.0249,  ...,  0.0222,  0.0260,  0.0292],
           [ 0.0182,  0.0199,  0.0272,  ...,  0.0228,  0.0264,  0.0300],
           [ 0.0181,  0.0195,  0.0261,  ...,  0.0245,  0.0264,  0.0278]]]]],
       device='cuda:0')
==========
IN _TEST_STEP
==========
ERODING BRAIN MASK
MEDIAN FILTERING
SAVING OUTPUT - ORIGINAL, FINAL, MASK ETC
SAVING IMAGES!
Testing:  10%|â–ˆ         | 2/20 [00:07<01:07,  3.77s/it]==========
IN DDPM ON TEST STEP
==========
THE WEIRD CONDITION BIT CALLED "features" in DDPM_2D
IN SPARK ENCODER FORWARDDD
x in shape torch.Size([50, 1, 96, 96])
out features torch.Size([50, 512])
i'm i DDPM2d forward block (whch is basically the encoder)
Context vector c shape: torch.Size([50, 512])
shape features:  torch.Size([50, 512])
additng features to latern space
latent space: []
iAM IN THE FORWARD METHOD OF THE WEIRD GUASSIAN IN cond_DDPM.py. I WILL BE CALLING p_losses
i am in p_losses in guassian which seems to be crucial to everything
conditioning vector shape:  torch.Size([50, 512])
in plosses i am getting a noisy image x
x shape:  torch.Size([50, 1, 96, 96])
getting model out
Initial input shape: torch.Size([50, 1, 96, 96])

inputblocks
Before block 0, shape: torch.Size([50, 1, 96, 96])
After block 0, shape: torch.Size([50, 128, 96, 96])
-
Before block 1, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 1, shape: torch.Size([50, 128, 96, 96])
-
Before block 2, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 2, shape: torch.Size([50, 128, 96, 96])
-
Before block 3, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 3, shape: torch.Size([50, 128, 96, 96])
-
Before block 4, shape: torch.Size([50, 128, 96, 96])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 256])
After block 4, shape: torch.Size([50, 128, 48, 48])
-
Before block 5, shape: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 48, 48])
-
Before block 8, shape: torch.Size([50, 256, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 8, shape: torch.Size([50, 256, 24, 24])
-
Before block 9, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 9, shape: torch.Size([50, 256, 24, 24])
-
Before block 10, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 10, shape: torch.Size([50, 256, 24, 24])
-
Before block 11, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 11, shape: torch.Size([50, 256, 24, 24])
-

Before middle block, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
in unet attention block!
x shape torch.Size([50, 256, 24, 24])
out dims torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])


After middle block, shape: torch.Size([50, 256, 24, 24])
-



outputblocks
Before block 0, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 0, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 0, shape: torch.Size([50, 256, 24, 24])
-
Before block 1, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 1, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 1, shape: torch.Size([50, 256, 24, 24])
-
Before block 2, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 2, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 2, shape: torch.Size([50, 256, 24, 24])
-
Before block 3, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 3, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 3, shape: torch.Size([50, 256, 48, 48])
-
Before block 4, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 4, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 4, shape: torch.Size([50, 256, 48, 48])
-
Before block 5, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 5, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 6, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 7, shape: torch.Size([50, 384, 48, 48])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 96, 96])
-
Before block 8, shape: torch.Size([50, 256, 96, 96])
After concatenation in upsampling block 8, shape: torch.Size([50, 384, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 8, shape: torch.Size([50, 128, 96, 96])
-
Before block 9, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 9, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 9, shape: torch.Size([50, 128, 96, 96])
-
Before block 10, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 10, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 10, shape: torch.Size([50, 128, 96, 96])
-
Before block 11, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 11, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 11, shape: torch.Size([50, 128, 96, 96])
-

Before Final layer shape: torch.Size([50, 128, 96, 96])
Final output shape: torch.Size([50, 1, 96, 96])
model out shape:  torch.Size([50, 1, 96, 96])
iAM IN THE FORWARD METHOD OF THE WEIRD GUASSIAN IN cond_DDPM.py. I WILL BE CALLING p_losses
i am in p_losses in guassian which seems to be crucial to everything
conditioning vector shape:  torch.Size([50, 512])
in plosses i am getting a noisy image x
x shape:  torch.Size([50, 1, 96, 96])
getting model out
Initial input shape: torch.Size([50, 1, 96, 96])

inputblocks
Before block 0, shape: torch.Size([50, 1, 96, 96])
After block 0, shape: torch.Size([50, 128, 96, 96])
-
Before block 1, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 1, shape: torch.Size([50, 128, 96, 96])
-
Before block 2, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 2, shape: torch.Size([50, 128, 96, 96])
-
Before block 3, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 3, shape: torch.Size([50, 128, 96, 96])
-
Before block 4, shape: torch.Size([50, 128, 96, 96])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 256])
After block 4, shape: torch.Size([50, 128, 48, 48])
-
Before block 5, shape: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 48, 48])
-
Before block 8, shape: torch.Size([50, 256, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 8, shape: torch.Size([50, 256, 24, 24])
-
Before block 9, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 9, shape: torch.Size([50, 256, 24, 24])
-
Before block 10, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 10, shape: torch.Size([50, 256, 24, 24])
-
Before block 11, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 11, shape: torch.Size([50, 256, 24, 24])
-

Before middle block, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
in unet attention block!
x shape torch.Size([50, 256, 24, 24])
out dims torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])


After middle block, shape: torch.Size([50, 256, 24, 24])
-



outputblocks
Before block 0, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 0, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 0, shape: torch.Size([50, 256, 24, 24])
-
Before block 1, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 1, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 1, shape: torch.Size([50, 256, 24, 24])
-
Before block 2, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 2, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 2, shape: torch.Size([50, 256, 24, 24])
-
Before block 3, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 3, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 3, shape: torch.Size([50, 256, 48, 48])
-
Before block 4, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 4, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 4, shape: torch.Size([50, 256, 48, 48])
-
Before block 5, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 5, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 6, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 7, shape: torch.Size([50, 384, 48, 48])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 96, 96])
-
Before block 8, shape: torch.Size([50, 256, 96, 96])
After concatenation in upsampling block 8, shape: torch.Size([50, 384, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 8, shape: torch.Size([50, 128, 96, 96])
-
Before block 9, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 9, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 9, shape: torch.Size([50, 128, 96, 96])
-
Before block 10, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 10, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 10, shape: torch.Size([50, 128, 96, 96])
-
Before block 11, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 11, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 11, shape: torch.Size([50, 128, 96, 96])
-

Before Final layer shape: torch.Size([50, 128, 96, 96])
Final output shape: torch.Size([50, 1, 96, 96])
model out shape:  torch.Size([50, 1, 96, 96])
iAM IN THE FORWARD METHOD OF THE WEIRD GUASSIAN IN cond_DDPM.py. I WILL BE CALLING p_losses
i am in p_losses in guassian which seems to be crucial to everything
conditioning vector shape:  torch.Size([50, 512])
in plosses i am getting a noisy image x
x shape:  torch.Size([50, 1, 96, 96])
getting model out
Initial input shape: torch.Size([50, 1, 96, 96])

inputblocks
Before block 0, shape: torch.Size([50, 1, 96, 96])
After block 0, shape: torch.Size([50, 128, 96, 96])
-
Before block 1, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 1, shape: torch.Size([50, 128, 96, 96])
-
Before block 2, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 2, shape: torch.Size([50, 128, 96, 96])
-
Before block 3, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 3, shape: torch.Size([50, 128, 96, 96])
-
Before block 4, shape: torch.Size([50, 128, 96, 96])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 256])
After block 4, shape: torch.Size([50, 128, 48, 48])
-
Before block 5, shape: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 48, 48])
-
Before block 8, shape: torch.Size([50, 256, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 8, shape: torch.Size([50, 256, 24, 24])
-
Before block 9, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 9, shape: torch.Size([50, 256, 24, 24])
-
Before block 10, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 10, shape: torch.Size([50, 256, 24, 24])
-
Before block 11, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 11, shape: torch.Size([50, 256, 24, 24])
-

Before middle block, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
in unet attention block!
x shape torch.Size([50, 256, 24, 24])
out dims torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])


After middle block, shape: torch.Size([50, 256, 24, 24])
-



outputblocks
Before block 0, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 0, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 0, shape: torch.Size([50, 256, 24, 24])
-
Before block 1, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 1, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 1, shape: torch.Size([50, 256, 24, 24])
-
Before block 2, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 2, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 2, shape: torch.Size([50, 256, 24, 24])
-
Before block 3, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 3, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 3, shape: torch.Size([50, 256, 48, 48])
-
Before block 4, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 4, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 4, shape: torch.Size([50, 256, 48, 48])
-
Before block 5, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 5, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 6, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 7, shape: torch.Size([50, 384, 48, 48])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 96, 96])
-
Before block 8, shape: torch.Size([50, 256, 96, 96])
After concatenation in upsampling block 8, shape: torch.Size([50, 384, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 8, shape: torch.Size([50, 128, 96, 96])
-
Before block 9, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 9, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 9, shape: torch.Size([50, 128, 96, 96])
-
Before block 10, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 10, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 10, shape: torch.Size([50, 128, 96, 96])
-
Before block 11, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 11, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 11, shape: torch.Size([50, 128, 96, 96])
-

Before Final layer shape: torch.Size([50, 128, 96, 96])
Final output shape: torch.Size([50, 1, 96, 96])
model out shape:  torch.Size([50, 1, 96, 96])
reconstruction shape torch.Size([50, 1, 96, 96])
reconstruction tensor([[[[0.0218, 0.0185, 0.0208,  ..., 0.0189, 0.0236, 0.0187],
          [0.0213, 0.0139, 0.0125,  ..., 0.0133, 0.0183, 0.0131],
          [0.0158, 0.0083, 0.0151,  ..., 0.0177, 0.0102, 0.0120],
          ...,
          [0.0176, 0.0072, 0.0181,  ..., 0.0225, 0.0151, 0.0109],
          [0.0254, 0.0161, 0.0122,  ..., 0.0180, 0.0218, 0.0081],
          [0.0184, 0.0170, 0.0139,  ..., 0.0154, 0.0181, 0.0114]]],


        [[[0.0222, 0.0182, 0.0210,  ..., 0.0193, 0.0238, 0.0191],
          [0.0210, 0.0129, 0.0124,  ..., 0.0133, 0.0177, 0.0127],
          [0.0161, 0.0083, 0.0156,  ..., 0.0185, 0.0104, 0.0121],
          ...,
          [0.0180, 0.0075, 0.0190,  ..., 0.0232, 0.0157, 0.0115],
          [0.0250, 0.0151, 0.0120,  ..., 0.0185, 0.0221, 0.0085],
          [0.0180, 0.0164, 0.0138,  ..., 0.0156, 0.0181, 0.0115]]],


        [[[0.0239, 0.0201, 0.0225,  ..., 0.0212, 0.0256, 0.0208],
          [0.0226, 0.0143, 0.0141,  ..., 0.0154, 0.0195, 0.0141],
          [0.0180, 0.0100, 0.0177,  ..., 0.0205, 0.0123, 0.0138],
          ...,
          [0.0197, 0.0094, 0.0211,  ..., 0.0250, 0.0177, 0.0134],
          [0.0269, 0.0169, 0.0142,  ..., 0.0203, 0.0240, 0.0103],
          [0.0198, 0.0182, 0.0159,  ..., 0.0179, 0.0205, 0.0137]]],


        ...,


        [[[0.0256, 0.0228, 0.0251,  ..., 0.0216, 0.0234, 0.0201],
          [0.0193, 0.0112, 0.0142,  ..., 0.0146, 0.0139, 0.0095],
          [0.0183, 0.0106, 0.0210,  ..., 0.0224, 0.0130, 0.0125],
          ...,
          [0.0239, 0.0142, 0.0287,  ..., 0.0361, 0.0242, 0.0163],
          [0.0349, 0.0269, 0.0276,  ..., 0.0205, 0.0207, 0.0081],
          [0.0296, 0.0315, 0.0300,  ..., 0.0205, 0.0245, 0.0175]]],


        [[[0.0254, 0.0227, 0.0254,  ..., 0.0209, 0.0229, 0.0195],
          [0.0193, 0.0113, 0.0144,  ..., 0.0137, 0.0133, 0.0093],
          [0.0179, 0.0103, 0.0208,  ..., 0.0216, 0.0122, 0.0122],
          ...,
          [0.0237, 0.0137, 0.0279,  ..., 0.0347, 0.0229, 0.0154],
          [0.0350, 0.0271, 0.0276,  ..., 0.0195, 0.0200, 0.0072],
          [0.0295, 0.0317, 0.0304,  ..., 0.0193, 0.0234, 0.0164]]],


        [[[0.0250, 0.0229, 0.0263,  ..., 0.0202, 0.0225, 0.0186],
          [0.0194, 0.0117, 0.0151,  ..., 0.0130, 0.0133, 0.0091],
          [0.0176, 0.0098, 0.0206,  ..., 0.0203, 0.0112, 0.0113],
          ...,
          [0.0229, 0.0123, 0.0259,  ..., 0.0327, 0.0208, 0.0135],
          [0.0340, 0.0258, 0.0254,  ..., 0.0181, 0.0186, 0.0056],
          [0.0280, 0.0302, 0.0282,  ..., 0.0179, 0.0217, 0.0146]]]],
       device='cuda:0')
FINAL VOLUME (DDPM) shape torch.Size([96, 96, 50])
FINAL VOLUME tensor([[[0.0218, 0.0222, 0.0239,  ..., 0.0256, 0.0254, 0.0250],
         [0.0185, 0.0182, 0.0201,  ..., 0.0228, 0.0227, 0.0229],
         [0.0208, 0.0210, 0.0225,  ..., 0.0251, 0.0254, 0.0263],
         ...,
         [0.0189, 0.0193, 0.0212,  ..., 0.0216, 0.0209, 0.0202],
         [0.0236, 0.0238, 0.0256,  ..., 0.0234, 0.0229, 0.0225],
         [0.0187, 0.0191, 0.0208,  ..., 0.0201, 0.0195, 0.0186]],

        [[0.0213, 0.0210, 0.0226,  ..., 0.0193, 0.0193, 0.0194],
         [0.0139, 0.0129, 0.0143,  ..., 0.0112, 0.0113, 0.0117],
         [0.0125, 0.0124, 0.0141,  ..., 0.0142, 0.0144, 0.0151],
         ...,
         [0.0133, 0.0133, 0.0154,  ..., 0.0146, 0.0137, 0.0130],
         [0.0183, 0.0177, 0.0195,  ..., 0.0139, 0.0133, 0.0133],
         [0.0131, 0.0127, 0.0141,  ..., 0.0095, 0.0093, 0.0091]],

        [[0.0158, 0.0161, 0.0180,  ..., 0.0183, 0.0179, 0.0176],
         [0.0083, 0.0083, 0.0100,  ..., 0.0106, 0.0103, 0.0098],
         [0.0151, 0.0156, 0.0177,  ..., 0.0210, 0.0208, 0.0206],
         ...,
         [0.0177, 0.0185, 0.0205,  ..., 0.0224, 0.0216, 0.0203],
         [0.0102, 0.0104, 0.0123,  ..., 0.0130, 0.0122, 0.0112],
         [0.0120, 0.0121, 0.0138,  ..., 0.0125, 0.0122, 0.0113]],

        ...,

        [[0.0176, 0.0180, 0.0197,  ..., 0.0239, 0.0237, 0.0229],
         [0.0072, 0.0075, 0.0094,  ..., 0.0142, 0.0137, 0.0123],
         [0.0181, 0.0190, 0.0211,  ..., 0.0287, 0.0279, 0.0259],
         ...,
         [0.0225, 0.0232, 0.0250,  ..., 0.0361, 0.0347, 0.0327],
         [0.0151, 0.0157, 0.0177,  ..., 0.0242, 0.0229, 0.0208],
         [0.0109, 0.0115, 0.0134,  ..., 0.0163, 0.0154, 0.0135]],

        [[0.0254, 0.0250, 0.0269,  ..., 0.0349, 0.0350, 0.0340],
         [0.0161, 0.0151, 0.0169,  ..., 0.0269, 0.0271, 0.0258],
         [0.0122, 0.0120, 0.0142,  ..., 0.0276, 0.0276, 0.0254],
         ...,
         [0.0180, 0.0185, 0.0203,  ..., 0.0205, 0.0195, 0.0181],
         [0.0218, 0.0221, 0.0240,  ..., 0.0207, 0.0200, 0.0186],
         [0.0081, 0.0085, 0.0103,  ..., 0.0081, 0.0072, 0.0056]],

        [[0.0184, 0.0180, 0.0198,  ..., 0.0296, 0.0295, 0.0280],
         [0.0170, 0.0164, 0.0182,  ..., 0.0315, 0.0317, 0.0302],
         [0.0139, 0.0138, 0.0159,  ..., 0.0300, 0.0304, 0.0282],
         ...,
         [0.0154, 0.0156, 0.0179,  ..., 0.0205, 0.0193, 0.0179],
         [0.0181, 0.0181, 0.0205,  ..., 0.0245, 0.0234, 0.0217],
         [0.0114, 0.0115, 0.0137,  ..., 0.0175, 0.0164, 0.0146]]],
       device='cuda:0')
unsqueeze final volume shape (DDPM2d) torch.Size([1, 1, 96, 96, 50])
unsqueeze final volume (DDPM 2D) tensor([[[[[0.0218, 0.0222, 0.0239,  ..., 0.0256, 0.0254, 0.0250],
           [0.0185, 0.0182, 0.0201,  ..., 0.0228, 0.0227, 0.0229],
           [0.0208, 0.0210, 0.0225,  ..., 0.0251, 0.0254, 0.0263],
           ...,
           [0.0189, 0.0193, 0.0212,  ..., 0.0216, 0.0209, 0.0202],
           [0.0236, 0.0238, 0.0256,  ..., 0.0234, 0.0229, 0.0225],
           [0.0187, 0.0191, 0.0208,  ..., 0.0201, 0.0195, 0.0186]],

          [[0.0213, 0.0210, 0.0226,  ..., 0.0193, 0.0193, 0.0194],
           [0.0139, 0.0129, 0.0143,  ..., 0.0112, 0.0113, 0.0117],
           [0.0125, 0.0124, 0.0141,  ..., 0.0142, 0.0144, 0.0151],
           ...,
           [0.0133, 0.0133, 0.0154,  ..., 0.0146, 0.0137, 0.0130],
           [0.0183, 0.0177, 0.0195,  ..., 0.0139, 0.0133, 0.0133],
           [0.0131, 0.0127, 0.0141,  ..., 0.0095, 0.0093, 0.0091]],

          [[0.0158, 0.0161, 0.0180,  ..., 0.0183, 0.0179, 0.0176],
           [0.0083, 0.0083, 0.0100,  ..., 0.0106, 0.0103, 0.0098],
           [0.0151, 0.0156, 0.0177,  ..., 0.0210, 0.0208, 0.0206],
           ...,
           [0.0177, 0.0185, 0.0205,  ..., 0.0224, 0.0216, 0.0203],
           [0.0102, 0.0104, 0.0123,  ..., 0.0130, 0.0122, 0.0112],
           [0.0120, 0.0121, 0.0138,  ..., 0.0125, 0.0122, 0.0113]],

          ...,

          [[0.0176, 0.0180, 0.0197,  ..., 0.0239, 0.0237, 0.0229],
           [0.0072, 0.0075, 0.0094,  ..., 0.0142, 0.0137, 0.0123],
           [0.0181, 0.0190, 0.0211,  ..., 0.0287, 0.0279, 0.0259],
           ...,
           [0.0225, 0.0232, 0.0250,  ..., 0.0361, 0.0347, 0.0327],
           [0.0151, 0.0157, 0.0177,  ..., 0.0242, 0.0229, 0.0208],
           [0.0109, 0.0115, 0.0134,  ..., 0.0163, 0.0154, 0.0135]],

          [[0.0254, 0.0250, 0.0269,  ..., 0.0349, 0.0350, 0.0340],
           [0.0161, 0.0151, 0.0169,  ..., 0.0269, 0.0271, 0.0258],
           [0.0122, 0.0120, 0.0142,  ..., 0.0276, 0.0276, 0.0254],
           ...,
           [0.0180, 0.0185, 0.0203,  ..., 0.0205, 0.0195, 0.0181],
           [0.0218, 0.0221, 0.0240,  ..., 0.0207, 0.0200, 0.0186],
           [0.0081, 0.0085, 0.0103,  ..., 0.0081, 0.0072, 0.0056]],

          [[0.0184, 0.0180, 0.0198,  ..., 0.0296, 0.0295, 0.0280],
           [0.0170, 0.0164, 0.0182,  ..., 0.0315, 0.0317, 0.0302],
           [0.0139, 0.0138, 0.0159,  ..., 0.0300, 0.0304, 0.0282],
           ...,
           [0.0154, 0.0156, 0.0179,  ..., 0.0205, 0.0193, 0.0179],
           [0.0181, 0.0181, 0.0205,  ..., 0.0245, 0.0234, 0.0217],
           [0.0114, 0.0115, 0.0137,  ..., 0.0175, 0.0164, 0.0146]]]]],
       device='cuda:0')
==========
IN _TEST_STEP
==========
ERODING BRAIN MASK
MEDIAN FILTERING
SAVING OUTPUT - ORIGINAL, FINAL, MASK ETC
SAVING IMAGES!
Testing:  15%|â–ˆâ–Œ        | 3/20 [00:11<01:00,  3.53s/it]==========
IN DDPM ON TEST STEP
==========
THE WEIRD CONDITION BIT CALLED "features" in DDPM_2D
IN SPARK ENCODER FORWARDDD
x in shape torch.Size([50, 1, 96, 96])
out features torch.Size([50, 512])
i'm i DDPM2d forward block (whch is basically the encoder)
Context vector c shape: torch.Size([50, 512])
shape features:  torch.Size([50, 512])
additng features to latern space
latent space: []
iAM IN THE FORWARD METHOD OF THE WEIRD GUASSIAN IN cond_DDPM.py. I WILL BE CALLING p_losses
i am in p_losses in guassian which seems to be crucial to everything
conditioning vector shape:  torch.Size([50, 512])
in plosses i am getting a noisy image x
x shape:  torch.Size([50, 1, 96, 96])
getting model out
Initial input shape: torch.Size([50, 1, 96, 96])

inputblocks
Before block 0, shape: torch.Size([50, 1, 96, 96])
After block 0, shape: torch.Size([50, 128, 96, 96])
-
Before block 1, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 1, shape: torch.Size([50, 128, 96, 96])
-
Before block 2, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 2, shape: torch.Size([50, 128, 96, 96])
-
Before block 3, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 3, shape: torch.Size([50, 128, 96, 96])
-
Before block 4, shape: torch.Size([50, 128, 96, 96])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 256])
After block 4, shape: torch.Size([50, 128, 48, 48])
-
Before block 5, shape: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 48, 48])
-
Before block 8, shape: torch.Size([50, 256, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 8, shape: torch.Size([50, 256, 24, 24])
-
Before block 9, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 9, shape: torch.Size([50, 256, 24, 24])
-
Before block 10, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 10, shape: torch.Size([50, 256, 24, 24])
-
Before block 11, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 11, shape: torch.Size([50, 256, 24, 24])
-

Before middle block, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
in unet attention block!
x shape torch.Size([50, 256, 24, 24])
out dims torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])


After middle block, shape: torch.Size([50, 256, 24, 24])
-



outputblocks
Before block 0, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 0, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 0, shape: torch.Size([50, 256, 24, 24])
-
Before block 1, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 1, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 1, shape: torch.Size([50, 256, 24, 24])
-
Before block 2, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 2, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 2, shape: torch.Size([50, 256, 24, 24])
-
Before block 3, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 3, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 3, shape: torch.Size([50, 256, 48, 48])
-
Before block 4, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 4, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 4, shape: torch.Size([50, 256, 48, 48])
-
Before block 5, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 5, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 6, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 7, shape: torch.Size([50, 384, 48, 48])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 96, 96])
-
Before block 8, shape: torch.Size([50, 256, 96, 96])
After concatenation in upsampling block 8, shape: torch.Size([50, 384, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 8, shape: torch.Size([50, 128, 96, 96])
-
Before block 9, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 9, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 9, shape: torch.Size([50, 128, 96, 96])
-
Before block 10, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 10, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 10, shape: torch.Size([50, 128, 96, 96])
-
Before block 11, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 11, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 11, shape: torch.Size([50, 128, 96, 96])
-

Before Final layer shape: torch.Size([50, 128, 96, 96])
Final output shape: torch.Size([50, 1, 96, 96])
model out shape:  torch.Size([50, 1, 96, 96])
iAM IN THE FORWARD METHOD OF THE WEIRD GUASSIAN IN cond_DDPM.py. I WILL BE CALLING p_losses
i am in p_losses in guassian which seems to be crucial to everything
conditioning vector shape:  torch.Size([50, 512])
in plosses i am getting a noisy image x
x shape:  torch.Size([50, 1, 96, 96])
getting model out
Initial input shape: torch.Size([50, 1, 96, 96])

inputblocks
Before block 0, shape: torch.Size([50, 1, 96, 96])
After block 0, shape: torch.Size([50, 128, 96, 96])
-
Before block 1, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 1, shape: torch.Size([50, 128, 96, 96])
-
Before block 2, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 2, shape: torch.Size([50, 128, 96, 96])
-
Before block 3, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 3, shape: torch.Size([50, 128, 96, 96])
-
Before block 4, shape: torch.Size([50, 128, 96, 96])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 256])
After block 4, shape: torch.Size([50, 128, 48, 48])
-
Before block 5, shape: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 48, 48])
-
Before block 8, shape: torch.Size([50, 256, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 8, shape: torch.Size([50, 256, 24, 24])
-
Before block 9, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 9, shape: torch.Size([50, 256, 24, 24])
-
Before block 10, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 10, shape: torch.Size([50, 256, 24, 24])
-
Before block 11, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 11, shape: torch.Size([50, 256, 24, 24])
-

Before middle block, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
in unet attention block!
x shape torch.Size([50, 256, 24, 24])
out dims torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])


After middle block, shape: torch.Size([50, 256, 24, 24])
-



outputblocks
Before block 0, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 0, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 0, shape: torch.Size([50, 256, 24, 24])
-
Before block 1, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 1, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 1, shape: torch.Size([50, 256, 24, 24])
-
Before block 2, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 2, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 2, shape: torch.Size([50, 256, 24, 24])
-
Before block 3, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 3, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 3, shape: torch.Size([50, 256, 48, 48])
-
Before block 4, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 4, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 4, shape: torch.Size([50, 256, 48, 48])
-
Before block 5, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 5, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 6, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 7, shape: torch.Size([50, 384, 48, 48])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 96, 96])
-
Before block 8, shape: torch.Size([50, 256, 96, 96])
After concatenation in upsampling block 8, shape: torch.Size([50, 384, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 8, shape: torch.Size([50, 128, 96, 96])
-
Before block 9, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 9, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 9, shape: torch.Size([50, 128, 96, 96])
-
Before block 10, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 10, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 10, shape: torch.Size([50, 128, 96, 96])
-
Before block 11, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 11, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 11, shape: torch.Size([50, 128, 96, 96])
-

Before Final layer shape: torch.Size([50, 128, 96, 96])
Final output shape: torch.Size([50, 1, 96, 96])
model out shape:  torch.Size([50, 1, 96, 96])
iAM IN THE FORWARD METHOD OF THE WEIRD GUASSIAN IN cond_DDPM.py. I WILL BE CALLING p_losses
i am in p_losses in guassian which seems to be crucial to everything
conditioning vector shape:  torch.Size([50, 512])
in plosses i am getting a noisy image x
x shape:  torch.Size([50, 1, 96, 96])
getting model out
Initial input shape: torch.Size([50, 1, 96, 96])

inputblocks
Before block 0, shape: torch.Size([50, 1, 96, 96])
After block 0, shape: torch.Size([50, 128, 96, 96])
-
Before block 1, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 1, shape: torch.Size([50, 128, 96, 96])
-
Before block 2, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 2, shape: torch.Size([50, 128, 96, 96])
-
Before block 3, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 3, shape: torch.Size([50, 128, 96, 96])
-
Before block 4, shape: torch.Size([50, 128, 96, 96])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 256])
After block 4, shape: torch.Size([50, 128, 48, 48])
-
Before block 5, shape: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 48, 48])
-
Before block 8, shape: torch.Size([50, 256, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 8, shape: torch.Size([50, 256, 24, 24])
-
Before block 9, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 9, shape: torch.Size([50, 256, 24, 24])
-
Before block 10, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 10, shape: torch.Size([50, 256, 24, 24])
-
Before block 11, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 11, shape: torch.Size([50, 256, 24, 24])
-

Before middle block, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
in unet attention block!
x shape torch.Size([50, 256, 24, 24])
out dims torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])


After middle block, shape: torch.Size([50, 256, 24, 24])
-



outputblocks
Before block 0, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 0, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 0, shape: torch.Size([50, 256, 24, 24])
-
Before block 1, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 1, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 1, shape: torch.Size([50, 256, 24, 24])
-
Before block 2, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 2, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 2, shape: torch.Size([50, 256, 24, 24])
-
Before block 3, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 3, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 3, shape: torch.Size([50, 256, 48, 48])
-
Before block 4, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 4, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 4, shape: torch.Size([50, 256, 48, 48])
-
Before block 5, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 5, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 6, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 7, shape: torch.Size([50, 384, 48, 48])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 96, 96])
-
Before block 8, shape: torch.Size([50, 256, 96, 96])
After concatenation in upsampling block 8, shape: torch.Size([50, 384, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 8, shape: torch.Size([50, 128, 96, 96])
-
Before block 9, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 9, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 9, shape: torch.Size([50, 128, 96, 96])
-
Before block 10, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 10, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 10, shape: torch.Size([50, 128, 96, 96])
-
Before block 11, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 11, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 11, shape: torch.Size([50, 128, 96, 96])
-

Before Final layer shape: torch.Size([50, 128, 96, 96])
Final output shape: torch.Size([50, 1, 96, 96])
model out shape:  torch.Size([50, 1, 96, 96])
reconstruction shape torch.Size([50, 1, 96, 96])
reconstruction tensor([[[[0.0211, 0.0173, 0.0203,  ..., 0.0234, 0.0273, 0.0210],
          [0.0359, 0.0214, 0.0160,  ..., 0.0155, 0.0221, 0.0176],
          [0.0260, 0.0160, 0.0186,  ..., 0.0200, 0.0139, 0.0133],
          ...,
          [0.0200, 0.0093, 0.0190,  ..., 0.0203, 0.0140, 0.0124],
          [0.0288, 0.0216, 0.0140,  ..., 0.0166, 0.0216, 0.0150],
          [0.0189, 0.0225, 0.0165,  ..., 0.0167, 0.0199, 0.0120]]],


        [[[0.0233, 0.0196, 0.0223,  ..., 0.0251, 0.0286, 0.0223],
          [0.0367, 0.0218, 0.0171,  ..., 0.0163, 0.0228, 0.0183],
          [0.0273, 0.0171, 0.0204,  ..., 0.0217, 0.0150, 0.0143],
          ...,
          [0.0219, 0.0111, 0.0211,  ..., 0.0218, 0.0155, 0.0136],
          [0.0299, 0.0225, 0.0155,  ..., 0.0181, 0.0230, 0.0164],
          [0.0192, 0.0229, 0.0175,  ..., 0.0182, 0.0216, 0.0137]]],


        [[[0.0269, 0.0235, 0.0264,  ..., 0.0285, 0.0317, 0.0259],
          [0.0391, 0.0243, 0.0212,  ..., 0.0202, 0.0261, 0.0215],
          [0.0308, 0.0208, 0.0252,  ..., 0.0254, 0.0193, 0.0181],
          ...,
          [0.0258, 0.0161, 0.0264,  ..., 0.0276, 0.0212, 0.0185],
          [0.0334, 0.0269, 0.0203,  ..., 0.0232, 0.0278, 0.0208],
          [0.0231, 0.0268, 0.0213,  ..., 0.0228, 0.0262, 0.0186]]],


        ...,


        [[[0.0245, 0.0208, 0.0226,  ..., 0.0282, 0.0310, 0.0275],
          [0.0313, 0.0166, 0.0149,  ..., 0.0194, 0.0228, 0.0190],
          [0.0269, 0.0169, 0.0220,  ..., 0.0259, 0.0195, 0.0171],
          ...,
          [0.0269, 0.0182, 0.0313,  ..., 0.0273, 0.0209, 0.0179],
          [0.0361, 0.0298, 0.0261,  ..., 0.0203, 0.0256, 0.0190],
          [0.0269, 0.0285, 0.0213,  ..., 0.0199, 0.0251, 0.0171]]],


        [[[0.0238, 0.0199, 0.0220,  ..., 0.0278, 0.0305, 0.0267],
          [0.0310, 0.0164, 0.0142,  ..., 0.0186, 0.0223, 0.0185],
          [0.0267, 0.0165, 0.0211,  ..., 0.0250, 0.0188, 0.0166],
          ...,
          [0.0268, 0.0176, 0.0304,  ..., 0.0265, 0.0205, 0.0177],
          [0.0365, 0.0301, 0.0263,  ..., 0.0198, 0.0261, 0.0190],
          [0.0267, 0.0282, 0.0210,  ..., 0.0195, 0.0251, 0.0163]]],


        [[[0.0230, 0.0194, 0.0211,  ..., 0.0270, 0.0308, 0.0252],
          [0.0310, 0.0171, 0.0139,  ..., 0.0185, 0.0238, 0.0186],
          [0.0262, 0.0163, 0.0201,  ..., 0.0239, 0.0186, 0.0160],
          ...,
          [0.0278, 0.0186, 0.0312,  ..., 0.0271, 0.0225, 0.0185],
          [0.0395, 0.0346, 0.0306,  ..., 0.0221, 0.0314, 0.0219],
          [0.0280, 0.0308, 0.0230,  ..., 0.0210, 0.0285, 0.0173]]]],
       device='cuda:0')
FINAL VOLUME (DDPM) shape torch.Size([96, 96, 50])
FINAL VOLUME tensor([[[0.0211, 0.0233, 0.0269,  ..., 0.0245, 0.0238, 0.0230],
         [0.0173, 0.0196, 0.0235,  ..., 0.0208, 0.0199, 0.0194],
         [0.0203, 0.0223, 0.0264,  ..., 0.0226, 0.0220, 0.0211],
         ...,
         [0.0234, 0.0251, 0.0285,  ..., 0.0282, 0.0278, 0.0270],
         [0.0273, 0.0286, 0.0317,  ..., 0.0310, 0.0305, 0.0308],
         [0.0210, 0.0223, 0.0259,  ..., 0.0275, 0.0267, 0.0252]],

        [[0.0359, 0.0367, 0.0391,  ..., 0.0313, 0.0310, 0.0310],
         [0.0214, 0.0218, 0.0243,  ..., 0.0166, 0.0164, 0.0171],
         [0.0160, 0.0171, 0.0212,  ..., 0.0149, 0.0142, 0.0139],
         ...,
         [0.0155, 0.0163, 0.0202,  ..., 0.0194, 0.0186, 0.0185],
         [0.0221, 0.0228, 0.0261,  ..., 0.0228, 0.0223, 0.0238],
         [0.0176, 0.0183, 0.0215,  ..., 0.0190, 0.0185, 0.0186]],

        [[0.0260, 0.0273, 0.0308,  ..., 0.0269, 0.0267, 0.0262],
         [0.0160, 0.0171, 0.0208,  ..., 0.0169, 0.0165, 0.0163],
         [0.0186, 0.0204, 0.0252,  ..., 0.0220, 0.0211, 0.0201],
         ...,
         [0.0200, 0.0217, 0.0254,  ..., 0.0259, 0.0250, 0.0239],
         [0.0139, 0.0150, 0.0193,  ..., 0.0195, 0.0188, 0.0186],
         [0.0133, 0.0143, 0.0181,  ..., 0.0171, 0.0166, 0.0160]],

        ...,

        [[0.0200, 0.0219, 0.0258,  ..., 0.0269, 0.0268, 0.0278],
         [0.0093, 0.0111, 0.0161,  ..., 0.0182, 0.0176, 0.0186],
         [0.0190, 0.0211, 0.0264,  ..., 0.0313, 0.0304, 0.0312],
         ...,
         [0.0203, 0.0218, 0.0276,  ..., 0.0273, 0.0265, 0.0271],
         [0.0140, 0.0155, 0.0212,  ..., 0.0209, 0.0205, 0.0225],
         [0.0124, 0.0136, 0.0185,  ..., 0.0179, 0.0177, 0.0185]],

        [[0.0288, 0.0299, 0.0334,  ..., 0.0361, 0.0365, 0.0395],
         [0.0216, 0.0225, 0.0269,  ..., 0.0298, 0.0301, 0.0346],
         [0.0140, 0.0155, 0.0203,  ..., 0.0261, 0.0263, 0.0306],
         ...,
         [0.0166, 0.0181, 0.0232,  ..., 0.0203, 0.0198, 0.0221],
         [0.0216, 0.0230, 0.0278,  ..., 0.0256, 0.0261, 0.0314],
         [0.0150, 0.0164, 0.0208,  ..., 0.0190, 0.0190, 0.0219]],

        [[0.0189, 0.0192, 0.0231,  ..., 0.0269, 0.0267, 0.0280],
         [0.0225, 0.0229, 0.0268,  ..., 0.0285, 0.0282, 0.0308],
         [0.0165, 0.0175, 0.0213,  ..., 0.0213, 0.0210, 0.0230],
         ...,
         [0.0167, 0.0182, 0.0228,  ..., 0.0199, 0.0195, 0.0210],
         [0.0199, 0.0216, 0.0262,  ..., 0.0251, 0.0251, 0.0285],
         [0.0120, 0.0137, 0.0186,  ..., 0.0171, 0.0163, 0.0173]]],
       device='cuda:0')
unsqueeze final volume shape (DDPM2d) torch.Size([1, 1, 96, 96, 50])
unsqueeze final volume (DDPM 2D) tensor([[[[[0.0211, 0.0233, 0.0269,  ..., 0.0245, 0.0238, 0.0230],
           [0.0173, 0.0196, 0.0235,  ..., 0.0208, 0.0199, 0.0194],
           [0.0203, 0.0223, 0.0264,  ..., 0.0226, 0.0220, 0.0211],
           ...,
           [0.0234, 0.0251, 0.0285,  ..., 0.0282, 0.0278, 0.0270],
           [0.0273, 0.0286, 0.0317,  ..., 0.0310, 0.0305, 0.0308],
           [0.0210, 0.0223, 0.0259,  ..., 0.0275, 0.0267, 0.0252]],

          [[0.0359, 0.0367, 0.0391,  ..., 0.0313, 0.0310, 0.0310],
           [0.0214, 0.0218, 0.0243,  ..., 0.0166, 0.0164, 0.0171],
           [0.0160, 0.0171, 0.0212,  ..., 0.0149, 0.0142, 0.0139],
           ...,
           [0.0155, 0.0163, 0.0202,  ..., 0.0194, 0.0186, 0.0185],
           [0.0221, 0.0228, 0.0261,  ..., 0.0228, 0.0223, 0.0238],
           [0.0176, 0.0183, 0.0215,  ..., 0.0190, 0.0185, 0.0186]],

          [[0.0260, 0.0273, 0.0308,  ..., 0.0269, 0.0267, 0.0262],
           [0.0160, 0.0171, 0.0208,  ..., 0.0169, 0.0165, 0.0163],
           [0.0186, 0.0204, 0.0252,  ..., 0.0220, 0.0211, 0.0201],
           ...,
           [0.0200, 0.0217, 0.0254,  ..., 0.0259, 0.0250, 0.0239],
           [0.0139, 0.0150, 0.0193,  ..., 0.0195, 0.0188, 0.0186],
           [0.0133, 0.0143, 0.0181,  ..., 0.0171, 0.0166, 0.0160]],

          ...,

          [[0.0200, 0.0219, 0.0258,  ..., 0.0269, 0.0268, 0.0278],
           [0.0093, 0.0111, 0.0161,  ..., 0.0182, 0.0176, 0.0186],
           [0.0190, 0.0211, 0.0264,  ..., 0.0313, 0.0304, 0.0312],
           ...,
           [0.0203, 0.0218, 0.0276,  ..., 0.0273, 0.0265, 0.0271],
           [0.0140, 0.0155, 0.0212,  ..., 0.0209, 0.0205, 0.0225],
           [0.0124, 0.0136, 0.0185,  ..., 0.0179, 0.0177, 0.0185]],

          [[0.0288, 0.0299, 0.0334,  ..., 0.0361, 0.0365, 0.0395],
           [0.0216, 0.0225, 0.0269,  ..., 0.0298, 0.0301, 0.0346],
           [0.0140, 0.0155, 0.0203,  ..., 0.0261, 0.0263, 0.0306],
           ...,
           [0.0166, 0.0181, 0.0232,  ..., 0.0203, 0.0198, 0.0221],
           [0.0216, 0.0230, 0.0278,  ..., 0.0256, 0.0261, 0.0314],
           [0.0150, 0.0164, 0.0208,  ..., 0.0190, 0.0190, 0.0219]],

          [[0.0189, 0.0192, 0.0231,  ..., 0.0269, 0.0267, 0.0280],
           [0.0225, 0.0229, 0.0268,  ..., 0.0285, 0.0282, 0.0308],
           [0.0165, 0.0175, 0.0213,  ..., 0.0213, 0.0210, 0.0230],
           ...,
           [0.0167, 0.0182, 0.0228,  ..., 0.0199, 0.0195, 0.0210],
           [0.0199, 0.0216, 0.0262,  ..., 0.0251, 0.0251, 0.0285],
           [0.0120, 0.0137, 0.0186,  ..., 0.0171, 0.0163, 0.0173]]]]],
       device='cuda:0')
==========
IN _TEST_STEP
==========
ERODING BRAIN MASK
MEDIAN FILTERING
SAVING OUTPUT - ORIGINAL, FINAL, MASK ETC
SAVING IMAGES!
Testing:  20%|â–ˆâ–ˆ        | 4/20 [00:14<00:54,  3.41s/it]==========
IN DDPM ON TEST STEP
==========
THE WEIRD CONDITION BIT CALLED "features" in DDPM_2D
IN SPARK ENCODER FORWARDDD
x in shape torch.Size([50, 1, 96, 96])
out features torch.Size([50, 512])
i'm i DDPM2d forward block (whch is basically the encoder)
Context vector c shape: torch.Size([50, 512])
shape features:  torch.Size([50, 512])
additng features to latern space
latent space: []
iAM IN THE FORWARD METHOD OF THE WEIRD GUASSIAN IN cond_DDPM.py. I WILL BE CALLING p_losses
i am in p_losses in guassian which seems to be crucial to everything
conditioning vector shape:  torch.Size([50, 512])
in plosses i am getting a noisy image x
x shape:  torch.Size([50, 1, 96, 96])
getting model out
Initial input shape: torch.Size([50, 1, 96, 96])

inputblocks
Before block 0, shape: torch.Size([50, 1, 96, 96])
After block 0, shape: torch.Size([50, 128, 96, 96])
-
Before block 1, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 1, shape: torch.Size([50, 128, 96, 96])
-
Before block 2, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 2, shape: torch.Size([50, 128, 96, 96])
-
Before block 3, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 3, shape: torch.Size([50, 128, 96, 96])
-
Before block 4, shape: torch.Size([50, 128, 96, 96])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 256])
After block 4, shape: torch.Size([50, 128, 48, 48])
-
Before block 5, shape: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 48, 48])
-
Before block 8, shape: torch.Size([50, 256, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 8, shape: torch.Size([50, 256, 24, 24])
-
Before block 9, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 9, shape: torch.Size([50, 256, 24, 24])
-
Before block 10, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 10, shape: torch.Size([50, 256, 24, 24])
-
Before block 11, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 11, shape: torch.Size([50, 256, 24, 24])
-

Before middle block, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
in unet attention block!
x shape torch.Size([50, 256, 24, 24])
out dims torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])


After middle block, shape: torch.Size([50, 256, 24, 24])
-



outputblocks
Before block 0, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 0, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 0, shape: torch.Size([50, 256, 24, 24])
-
Before block 1, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 1, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 1, shape: torch.Size([50, 256, 24, 24])
-
Before block 2, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 2, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 2, shape: torch.Size([50, 256, 24, 24])
-
Before block 3, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 3, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 3, shape: torch.Size([50, 256, 48, 48])
-
Before block 4, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 4, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 4, shape: torch.Size([50, 256, 48, 48])
-
Before block 5, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 5, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 6, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 7, shape: torch.Size([50, 384, 48, 48])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 96, 96])
-
Before block 8, shape: torch.Size([50, 256, 96, 96])
After concatenation in upsampling block 8, shape: torch.Size([50, 384, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 8, shape: torch.Size([50, 128, 96, 96])
-
Before block 9, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 9, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 9, shape: torch.Size([50, 128, 96, 96])
-
Before block 10, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 10, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 10, shape: torch.Size([50, 128, 96, 96])
-
Before block 11, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 11, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 11, shape: torch.Size([50, 128, 96, 96])
-

Before Final layer shape: torch.Size([50, 128, 96, 96])
Final output shape: torch.Size([50, 1, 96, 96])
model out shape:  torch.Size([50, 1, 96, 96])
iAM IN THE FORWARD METHOD OF THE WEIRD GUASSIAN IN cond_DDPM.py. I WILL BE CALLING p_losses
i am in p_losses in guassian which seems to be crucial to everything
conditioning vector shape:  torch.Size([50, 512])
in plosses i am getting a noisy image x
x shape:  torch.Size([50, 1, 96, 96])
getting model out
Initial input shape: torch.Size([50, 1, 96, 96])

inputblocks
Before block 0, shape: torch.Size([50, 1, 96, 96])
After block 0, shape: torch.Size([50, 128, 96, 96])
-
Before block 1, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 1, shape: torch.Size([50, 128, 96, 96])
-
Before block 2, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 2, shape: torch.Size([50, 128, 96, 96])
-
Before block 3, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 3, shape: torch.Size([50, 128, 96, 96])
-
Before block 4, shape: torch.Size([50, 128, 96, 96])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 256])
After block 4, shape: torch.Size([50, 128, 48, 48])
-
Before block 5, shape: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 48, 48])
-
Before block 8, shape: torch.Size([50, 256, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 8, shape: torch.Size([50, 256, 24, 24])
-
Before block 9, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 9, shape: torch.Size([50, 256, 24, 24])
-
Before block 10, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 10, shape: torch.Size([50, 256, 24, 24])
-
Before block 11, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 11, shape: torch.Size([50, 256, 24, 24])
-

Before middle block, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
in unet attention block!
x shape torch.Size([50, 256, 24, 24])
out dims torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])


After middle block, shape: torch.Size([50, 256, 24, 24])
-



outputblocks
Before block 0, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 0, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 0, shape: torch.Size([50, 256, 24, 24])
-
Before block 1, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 1, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 1, shape: torch.Size([50, 256, 24, 24])
-
Before block 2, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 2, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 2, shape: torch.Size([50, 256, 24, 24])
-
Before block 3, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 3, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 3, shape: torch.Size([50, 256, 48, 48])
-
Before block 4, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 4, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 4, shape: torch.Size([50, 256, 48, 48])
-
Before block 5, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 5, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 6, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 7, shape: torch.Size([50, 384, 48, 48])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 96, 96])
-
Before block 8, shape: torch.Size([50, 256, 96, 96])
After concatenation in upsampling block 8, shape: torch.Size([50, 384, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 8, shape: torch.Size([50, 128, 96, 96])
-
Before block 9, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 9, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 9, shape: torch.Size([50, 128, 96, 96])
-
Before block 10, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 10, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 10, shape: torch.Size([50, 128, 96, 96])
-
Before block 11, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 11, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 11, shape: torch.Size([50, 128, 96, 96])
-

Before Final layer shape: torch.Size([50, 128, 96, 96])
Final output shape: torch.Size([50, 1, 96, 96])
model out shape:  torch.Size([50, 1, 96, 96])
iAM IN THE FORWARD METHOD OF THE WEIRD GUASSIAN IN cond_DDPM.py. I WILL BE CALLING p_losses
i am in p_losses in guassian which seems to be crucial to everything
conditioning vector shape:  torch.Size([50, 512])
in plosses i am getting a noisy image x
x shape:  torch.Size([50, 1, 96, 96])
getting model out
Initial input shape: torch.Size([50, 1, 96, 96])

inputblocks
Before block 0, shape: torch.Size([50, 1, 96, 96])
After block 0, shape: torch.Size([50, 128, 96, 96])
-
Before block 1, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 1, shape: torch.Size([50, 128, 96, 96])
-
Before block 2, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 2, shape: torch.Size([50, 128, 96, 96])
-
Before block 3, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 3, shape: torch.Size([50, 128, 96, 96])
-
Before block 4, shape: torch.Size([50, 128, 96, 96])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 256])
After block 4, shape: torch.Size([50, 128, 48, 48])
-
Before block 5, shape: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 48, 48])
-
Before block 8, shape: torch.Size([50, 256, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 8, shape: torch.Size([50, 256, 24, 24])
-
Before block 9, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 9, shape: torch.Size([50, 256, 24, 24])
-
Before block 10, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 10, shape: torch.Size([50, 256, 24, 24])
-
Before block 11, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 11, shape: torch.Size([50, 256, 24, 24])
-

Before middle block, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
in unet attention block!
x shape torch.Size([50, 256, 24, 24])
out dims torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])


After middle block, shape: torch.Size([50, 256, 24, 24])
-



outputblocks
Before block 0, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 0, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 0, shape: torch.Size([50, 256, 24, 24])
-
Before block 1, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 1, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 1, shape: torch.Size([50, 256, 24, 24])
-
Before block 2, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 2, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 2, shape: torch.Size([50, 256, 24, 24])
-
Before block 3, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 3, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 3, shape: torch.Size([50, 256, 48, 48])
-
Before block 4, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 4, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 4, shape: torch.Size([50, 256, 48, 48])
-
Before block 5, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 5, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 6, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 7, shape: torch.Size([50, 384, 48, 48])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 96, 96])
-
Before block 8, shape: torch.Size([50, 256, 96, 96])
After concatenation in upsampling block 8, shape: torch.Size([50, 384, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 8, shape: torch.Size([50, 128, 96, 96])
-
Before block 9, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 9, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 9, shape: torch.Size([50, 128, 96, 96])
-
Before block 10, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 10, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 10, shape: torch.Size([50, 128, 96, 96])
-
Before block 11, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 11, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 11, shape: torch.Size([50, 128, 96, 96])
-

Before Final layer shape: torch.Size([50, 128, 96, 96])
Final output shape: torch.Size([50, 1, 96, 96])
model out shape:  torch.Size([50, 1, 96, 96])
reconstruction shape torch.Size([50, 1, 96, 96])
reconstruction tensor([[[[0.0326, 0.0106, 0.0160,  ..., 0.0168, 0.0232, 0.0151],
          [0.0185, 0.0023, 0.0091,  ..., 0.0085, 0.0183, 0.0161],
          [0.0125, 0.0043, 0.0208,  ..., 0.0144, 0.0119, 0.0121],
          ...,
          [0.0143, 0.0062, 0.0194,  ..., 0.0208, 0.0126, 0.0092],
          [0.0251, 0.0156, 0.0151,  ..., 0.0194, 0.0269, 0.0129],
          [0.0184, 0.0139, 0.0160,  ..., 0.0093, 0.0117, 0.0029]]],


        [[[0.0311, 0.0091, 0.0155,  ..., 0.0154, 0.0212, 0.0132],
          [0.0168, 0.0008, 0.0082,  ..., 0.0070, 0.0171, 0.0146],
          [0.0117, 0.0037, 0.0204,  ..., 0.0129, 0.0107, 0.0110],
          ...,
          [0.0129, 0.0047, 0.0186,  ..., 0.0199, 0.0118, 0.0085],
          [0.0228, 0.0133, 0.0141,  ..., 0.0181, 0.0251, 0.0115],
          [0.0167, 0.0116, 0.0148,  ..., 0.0078, 0.0098, 0.0015]]],


        [[[0.0311, 0.0093, 0.0158,  ..., 0.0142, 0.0195, 0.0123],
          [0.0168, 0.0008, 0.0083,  ..., 0.0053, 0.0153, 0.0136],
          [0.0128, 0.0040, 0.0193,  ..., 0.0112, 0.0094, 0.0104],
          ...,
          [0.0156, 0.0089, 0.0244,  ..., 0.0198, 0.0132, 0.0098],
          [0.0244, 0.0186, 0.0224,  ..., 0.0166, 0.0230, 0.0099],
          [0.0179, 0.0158, 0.0221,  ..., 0.0083, 0.0105, 0.0033]]],


        ...,


        [[[0.0370, 0.0155, 0.0197,  ..., 0.0176, 0.0229, 0.0203],
          [0.0170, 0.0013, 0.0084,  ..., 0.0066, 0.0131, 0.0146],
          [0.0145, 0.0062, 0.0201,  ..., 0.0151, 0.0106, 0.0126],
          ...,
          [0.0212, 0.0146, 0.0273,  ..., 0.0264, 0.0186, 0.0138],
          [0.0334, 0.0283, 0.0265,  ..., 0.0223, 0.0271, 0.0142],
          [0.0269, 0.0284, 0.0306,  ..., 0.0146, 0.0184, 0.0100]]],


        [[[0.0375, 0.0161, 0.0207,  ..., 0.0182, 0.0239, 0.0209],
          [0.0173, 0.0016, 0.0090,  ..., 0.0074, 0.0143, 0.0155],
          [0.0151, 0.0069, 0.0208,  ..., 0.0159, 0.0115, 0.0133],
          ...,
          [0.0211, 0.0138, 0.0257,  ..., 0.0255, 0.0177, 0.0132],
          [0.0335, 0.0278, 0.0251,  ..., 0.0216, 0.0266, 0.0138],
          [0.0267, 0.0273, 0.0291,  ..., 0.0138, 0.0173, 0.0089]]],


        [[[0.0359, 0.0146, 0.0199,  ..., 0.0167, 0.0222, 0.0185],
          [0.0159, 0.0007, 0.0084,  ..., 0.0063, 0.0135, 0.0140],
          [0.0140, 0.0062, 0.0202,  ..., 0.0142, 0.0106, 0.0121],
          ...,
          [0.0165, 0.0085, 0.0196,  ..., 0.0229, 0.0150, 0.0107],
          [0.0279, 0.0200, 0.0177,  ..., 0.0194, 0.0239, 0.0111],
          [0.0211, 0.0194, 0.0204,  ..., 0.0111, 0.0141, 0.0061]]]],
       device='cuda:0')
FINAL VOLUME (DDPM) shape torch.Size([96, 96, 50])
FINAL VOLUME tensor([[[0.0326, 0.0311, 0.0311,  ..., 0.0370, 0.0375, 0.0359],
         [0.0106, 0.0091, 0.0093,  ..., 0.0155, 0.0161, 0.0146],
         [0.0160, 0.0155, 0.0158,  ..., 0.0197, 0.0207, 0.0199],
         ...,
         [0.0168, 0.0154, 0.0142,  ..., 0.0176, 0.0182, 0.0167],
         [0.0232, 0.0212, 0.0195,  ..., 0.0229, 0.0239, 0.0222],
         [0.0151, 0.0132, 0.0123,  ..., 0.0203, 0.0209, 0.0185]],

        [[0.0185, 0.0168, 0.0168,  ..., 0.0170, 0.0173, 0.0159],
         [0.0023, 0.0008, 0.0008,  ..., 0.0013, 0.0016, 0.0007],
         [0.0091, 0.0082, 0.0083,  ..., 0.0084, 0.0090, 0.0084],
         ...,
         [0.0085, 0.0070, 0.0053,  ..., 0.0066, 0.0074, 0.0063],
         [0.0183, 0.0171, 0.0153,  ..., 0.0131, 0.0143, 0.0135],
         [0.0161, 0.0146, 0.0136,  ..., 0.0146, 0.0155, 0.0140]],

        [[0.0125, 0.0117, 0.0128,  ..., 0.0145, 0.0151, 0.0140],
         [0.0043, 0.0037, 0.0040,  ..., 0.0062, 0.0069, 0.0062],
         [0.0208, 0.0204, 0.0193,  ..., 0.0201, 0.0208, 0.0202],
         ...,
         [0.0144, 0.0129, 0.0112,  ..., 0.0151, 0.0159, 0.0142],
         [0.0119, 0.0107, 0.0094,  ..., 0.0106, 0.0115, 0.0106],
         [0.0121, 0.0110, 0.0104,  ..., 0.0126, 0.0133, 0.0121]],

        ...,

        [[0.0143, 0.0129, 0.0156,  ..., 0.0212, 0.0211, 0.0165],
         [0.0062, 0.0047, 0.0089,  ..., 0.0146, 0.0138, 0.0085],
         [0.0194, 0.0186, 0.0244,  ..., 0.0273, 0.0257, 0.0196],
         ...,
         [0.0208, 0.0199, 0.0198,  ..., 0.0264, 0.0255, 0.0229],
         [0.0126, 0.0118, 0.0132,  ..., 0.0186, 0.0177, 0.0150],
         [0.0092, 0.0085, 0.0098,  ..., 0.0138, 0.0132, 0.0107]],

        [[0.0251, 0.0228, 0.0244,  ..., 0.0334, 0.0335, 0.0279],
         [0.0156, 0.0133, 0.0186,  ..., 0.0283, 0.0278, 0.0200],
         [0.0151, 0.0141, 0.0224,  ..., 0.0265, 0.0251, 0.0177],
         ...,
         [0.0194, 0.0181, 0.0166,  ..., 0.0223, 0.0216, 0.0194],
         [0.0269, 0.0251, 0.0230,  ..., 0.0271, 0.0266, 0.0239],
         [0.0129, 0.0115, 0.0099,  ..., 0.0142, 0.0138, 0.0111]],

        [[0.0184, 0.0167, 0.0179,  ..., 0.0269, 0.0267, 0.0211],
         [0.0139, 0.0116, 0.0158,  ..., 0.0284, 0.0273, 0.0194],
         [0.0160, 0.0148, 0.0221,  ..., 0.0306, 0.0291, 0.0204],
         ...,
         [0.0093, 0.0078, 0.0083,  ..., 0.0146, 0.0138, 0.0111],
         [0.0117, 0.0098, 0.0105,  ..., 0.0184, 0.0173, 0.0141],
         [0.0029, 0.0015, 0.0033,  ..., 0.0100, 0.0089, 0.0061]]],
       device='cuda:0')
unsqueeze final volume shape (DDPM2d) torch.Size([1, 1, 96, 96, 50])
unsqueeze final volume (DDPM 2D) tensor([[[[[0.0326, 0.0311, 0.0311,  ..., 0.0370, 0.0375, 0.0359],
           [0.0106, 0.0091, 0.0093,  ..., 0.0155, 0.0161, 0.0146],
           [0.0160, 0.0155, 0.0158,  ..., 0.0197, 0.0207, 0.0199],
           ...,
           [0.0168, 0.0154, 0.0142,  ..., 0.0176, 0.0182, 0.0167],
           [0.0232, 0.0212, 0.0195,  ..., 0.0229, 0.0239, 0.0222],
           [0.0151, 0.0132, 0.0123,  ..., 0.0203, 0.0209, 0.0185]],

          [[0.0185, 0.0168, 0.0168,  ..., 0.0170, 0.0173, 0.0159],
           [0.0023, 0.0008, 0.0008,  ..., 0.0013, 0.0016, 0.0007],
           [0.0091, 0.0082, 0.0083,  ..., 0.0084, 0.0090, 0.0084],
           ...,
           [0.0085, 0.0070, 0.0053,  ..., 0.0066, 0.0074, 0.0063],
           [0.0183, 0.0171, 0.0153,  ..., 0.0131, 0.0143, 0.0135],
           [0.0161, 0.0146, 0.0136,  ..., 0.0146, 0.0155, 0.0140]],

          [[0.0125, 0.0117, 0.0128,  ..., 0.0145, 0.0151, 0.0140],
           [0.0043, 0.0037, 0.0040,  ..., 0.0062, 0.0069, 0.0062],
           [0.0208, 0.0204, 0.0193,  ..., 0.0201, 0.0208, 0.0202],
           ...,
           [0.0144, 0.0129, 0.0112,  ..., 0.0151, 0.0159, 0.0142],
           [0.0119, 0.0107, 0.0094,  ..., 0.0106, 0.0115, 0.0106],
           [0.0121, 0.0110, 0.0104,  ..., 0.0126, 0.0133, 0.0121]],

          ...,

          [[0.0143, 0.0129, 0.0156,  ..., 0.0212, 0.0211, 0.0165],
           [0.0062, 0.0047, 0.0089,  ..., 0.0146, 0.0138, 0.0085],
           [0.0194, 0.0186, 0.0244,  ..., 0.0273, 0.0257, 0.0196],
           ...,
           [0.0208, 0.0199, 0.0198,  ..., 0.0264, 0.0255, 0.0229],
           [0.0126, 0.0118, 0.0132,  ..., 0.0186, 0.0177, 0.0150],
           [0.0092, 0.0085, 0.0098,  ..., 0.0138, 0.0132, 0.0107]],

          [[0.0251, 0.0228, 0.0244,  ..., 0.0334, 0.0335, 0.0279],
           [0.0156, 0.0133, 0.0186,  ..., 0.0283, 0.0278, 0.0200],
           [0.0151, 0.0141, 0.0224,  ..., 0.0265, 0.0251, 0.0177],
           ...,
           [0.0194, 0.0181, 0.0166,  ..., 0.0223, 0.0216, 0.0194],
           [0.0269, 0.0251, 0.0230,  ..., 0.0271, 0.0266, 0.0239],
           [0.0129, 0.0115, 0.0099,  ..., 0.0142, 0.0138, 0.0111]],

          [[0.0184, 0.0167, 0.0179,  ..., 0.0269, 0.0267, 0.0211],
           [0.0139, 0.0116, 0.0158,  ..., 0.0284, 0.0273, 0.0194],
           [0.0160, 0.0148, 0.0221,  ..., 0.0306, 0.0291, 0.0204],
           ...,
           [0.0093, 0.0078, 0.0083,  ..., 0.0146, 0.0138, 0.0111],
           [0.0117, 0.0098, 0.0105,  ..., 0.0184, 0.0173, 0.0141],
           [0.0029, 0.0015, 0.0033,  ..., 0.0100, 0.0089, 0.0061]]]]],
       device='cuda:0')
==========
IN _TEST_STEP
==========
ERODING BRAIN MASK
MEDIAN FILTERING
SAVING OUTPUT - ORIGINAL, FINAL, MASK ETC
SAVING IMAGES!
Testing:  25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:17<00:49,  3.29s/it]==========
IN DDPM ON TEST STEP
==========
THE WEIRD CONDITION BIT CALLED "features" in DDPM_2D
IN SPARK ENCODER FORWARDDD
x in shape torch.Size([50, 1, 96, 96])
out features torch.Size([50, 512])
i'm i DDPM2d forward block (whch is basically the encoder)
Context vector c shape: torch.Size([50, 512])
shape features:  torch.Size([50, 512])
additng features to latern space
latent space: []
iAM IN THE FORWARD METHOD OF THE WEIRD GUASSIAN IN cond_DDPM.py. I WILL BE CALLING p_losses
i am in p_losses in guassian which seems to be crucial to everything
conditioning vector shape:  torch.Size([50, 512])
in plosses i am getting a noisy image x
x shape:  torch.Size([50, 1, 96, 96])
getting model out
Initial input shape: torch.Size([50, 1, 96, 96])

inputblocks
Before block 0, shape: torch.Size([50, 1, 96, 96])
After block 0, shape: torch.Size([50, 128, 96, 96])
-
Before block 1, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 1, shape: torch.Size([50, 128, 96, 96])
-
Before block 2, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 2, shape: torch.Size([50, 128, 96, 96])
-
Before block 3, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 3, shape: torch.Size([50, 128, 96, 96])
-
Before block 4, shape: torch.Size([50, 128, 96, 96])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 256])
After block 4, shape: torch.Size([50, 128, 48, 48])
-
Before block 5, shape: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 48, 48])
-
Before block 8, shape: torch.Size([50, 256, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 8, shape: torch.Size([50, 256, 24, 24])
-
Before block 9, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 9, shape: torch.Size([50, 256, 24, 24])
-
Before block 10, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 10, shape: torch.Size([50, 256, 24, 24])
-
Before block 11, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 11, shape: torch.Size([50, 256, 24, 24])
-

Before middle block, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
in unet attention block!
x shape torch.Size([50, 256, 24, 24])
out dims torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])


After middle block, shape: torch.Size([50, 256, 24, 24])
-



outputblocks
Before block 0, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 0, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 0, shape: torch.Size([50, 256, 24, 24])
-
Before block 1, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 1, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 1, shape: torch.Size([50, 256, 24, 24])
-
Before block 2, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 2, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 2, shape: torch.Size([50, 256, 24, 24])
-
Before block 3, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 3, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 3, shape: torch.Size([50, 256, 48, 48])
-
Before block 4, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 4, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 4, shape: torch.Size([50, 256, 48, 48])
-
Before block 5, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 5, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 6, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 7, shape: torch.Size([50, 384, 48, 48])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 96, 96])
-
Before block 8, shape: torch.Size([50, 256, 96, 96])
After concatenation in upsampling block 8, shape: torch.Size([50, 384, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 8, shape: torch.Size([50, 128, 96, 96])
-
Before block 9, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 9, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 9, shape: torch.Size([50, 128, 96, 96])
-
Before block 10, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 10, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 10, shape: torch.Size([50, 128, 96, 96])
-
Before block 11, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 11, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 11, shape: torch.Size([50, 128, 96, 96])
-

Before Final layer shape: torch.Size([50, 128, 96, 96])
Final output shape: torch.Size([50, 1, 96, 96])
model out shape:  torch.Size([50, 1, 96, 96])
iAM IN THE FORWARD METHOD OF THE WEIRD GUASSIAN IN cond_DDPM.py. I WILL BE CALLING p_losses
i am in p_losses in guassian which seems to be crucial to everything
conditioning vector shape:  torch.Size([50, 512])
in plosses i am getting a noisy image x
x shape:  torch.Size([50, 1, 96, 96])
getting model out
Initial input shape: torch.Size([50, 1, 96, 96])

inputblocks
Before block 0, shape: torch.Size([50, 1, 96, 96])
After block 0, shape: torch.Size([50, 128, 96, 96])
-
Before block 1, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 1, shape: torch.Size([50, 128, 96, 96])
-
Before block 2, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 2, shape: torch.Size([50, 128, 96, 96])
-
Before block 3, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 3, shape: torch.Size([50, 128, 96, 96])
-
Before block 4, shape: torch.Size([50, 128, 96, 96])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 256])
After block 4, shape: torch.Size([50, 128, 48, 48])
-
Before block 5, shape: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 48, 48])
-
Before block 8, shape: torch.Size([50, 256, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 8, shape: torch.Size([50, 256, 24, 24])
-
Before block 9, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 9, shape: torch.Size([50, 256, 24, 24])
-
Before block 10, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 10, shape: torch.Size([50, 256, 24, 24])
-
Before block 11, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 11, shape: torch.Size([50, 256, 24, 24])
-

Before middle block, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
in unet attention block!
x shape torch.Size([50, 256, 24, 24])
out dims torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])


After middle block, shape: torch.Size([50, 256, 24, 24])
-



outputblocks
Before block 0, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 0, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 0, shape: torch.Size([50, 256, 24, 24])
-
Before block 1, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 1, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 1, shape: torch.Size([50, 256, 24, 24])
-
Before block 2, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 2, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 2, shape: torch.Size([50, 256, 24, 24])
-
Before block 3, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 3, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 3, shape: torch.Size([50, 256, 48, 48])
-
Before block 4, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 4, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 4, shape: torch.Size([50, 256, 48, 48])
-
Before block 5, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 5, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 6, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 7, shape: torch.Size([50, 384, 48, 48])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 96, 96])
-
Before block 8, shape: torch.Size([50, 256, 96, 96])
After concatenation in upsampling block 8, shape: torch.Size([50, 384, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 8, shape: torch.Size([50, 128, 96, 96])
-
Before block 9, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 9, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 9, shape: torch.Size([50, 128, 96, 96])
-
Before block 10, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 10, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 10, shape: torch.Size([50, 128, 96, 96])
-
Before block 11, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 11, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 11, shape: torch.Size([50, 128, 96, 96])
-

Before Final layer shape: torch.Size([50, 128, 96, 96])
Final output shape: torch.Size([50, 1, 96, 96])
model out shape:  torch.Size([50, 1, 96, 96])
iAM IN THE FORWARD METHOD OF THE WEIRD GUASSIAN IN cond_DDPM.py. I WILL BE CALLING p_losses
i am in p_losses in guassian which seems to be crucial to everything
conditioning vector shape:  torch.Size([50, 512])
in plosses i am getting a noisy image x
x shape:  torch.Size([50, 1, 96, 96])
getting model out
Initial input shape: torch.Size([50, 1, 96, 96])

inputblocks
Before block 0, shape: torch.Size([50, 1, 96, 96])
After block 0, shape: torch.Size([50, 128, 96, 96])
-
Before block 1, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 1, shape: torch.Size([50, 128, 96, 96])
-
Before block 2, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 2, shape: torch.Size([50, 128, 96, 96])
-
Before block 3, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 3, shape: torch.Size([50, 128, 96, 96])
-
Before block 4, shape: torch.Size([50, 128, 96, 96])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 256])
After block 4, shape: torch.Size([50, 128, 48, 48])
-
Before block 5, shape: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 48, 48])
-
Before block 8, shape: torch.Size([50, 256, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 8, shape: torch.Size([50, 256, 24, 24])
-
Before block 9, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 9, shape: torch.Size([50, 256, 24, 24])
-
Before block 10, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 10, shape: torch.Size([50, 256, 24, 24])
-
Before block 11, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 11, shape: torch.Size([50, 256, 24, 24])
-

Before middle block, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
in unet attention block!
x shape torch.Size([50, 256, 24, 24])
out dims torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])


After middle block, shape: torch.Size([50, 256, 24, 24])
-



outputblocks
Before block 0, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 0, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 0, shape: torch.Size([50, 256, 24, 24])
-
Before block 1, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 1, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 1, shape: torch.Size([50, 256, 24, 24])
-
Before block 2, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 2, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 2, shape: torch.Size([50, 256, 24, 24])
-
Before block 3, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 3, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 3, shape: torch.Size([50, 256, 48, 48])
-
Before block 4, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 4, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 4, shape: torch.Size([50, 256, 48, 48])
-
Before block 5, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 5, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 6, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 7, shape: torch.Size([50, 384, 48, 48])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 96, 96])
-
Before block 8, shape: torch.Size([50, 256, 96, 96])
After concatenation in upsampling block 8, shape: torch.Size([50, 384, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 8, shape: torch.Size([50, 128, 96, 96])
-
Before block 9, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 9, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 9, shape: torch.Size([50, 128, 96, 96])
-
Before block 10, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 10, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 10, shape: torch.Size([50, 128, 96, 96])
-
Before block 11, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 11, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 11, shape: torch.Size([50, 128, 96, 96])
-

Before Final layer shape: torch.Size([50, 128, 96, 96])
Final output shape: torch.Size([50, 1, 96, 96])
model out shape:  torch.Size([50, 1, 96, 96])
reconstruction shape torch.Size([50, 1, 96, 96])
reconstruction tensor([[[[0.0165, 0.0015, 0.0106,  ..., 0.0111, 0.0151, 0.0082],
          [0.0148, 0.0002, 0.0059,  ..., 0.0057, 0.0101, 0.0062],
          [0.0105, 0.0008, 0.0134,  ..., 0.0105, 0.0037, 0.0055],
          ...,
          [0.0126, 0.0013, 0.0124,  ..., 0.0138, 0.0100, 0.0090],
          [0.0185, 0.0110, 0.0107,  ..., 0.0085, 0.0152, 0.0071],
          [0.0098, 0.0085, 0.0114,  ..., 0.0065, 0.0106, 0.0049]]],


        [[[0.0179, 0.0024, 0.0121,  ..., 0.0125, 0.0160, 0.0091],
          [0.0158, 0.0000, 0.0065,  ..., 0.0062, 0.0103, 0.0064],
          [0.0123, 0.0021, 0.0151,  ..., 0.0114, 0.0049, 0.0064],
          ...,
          [0.0141, 0.0024, 0.0133,  ..., 0.0142, 0.0105, 0.0095],
          [0.0190, 0.0111, 0.0116,  ..., 0.0094, 0.0156, 0.0077],
          [0.0103, 0.0085, 0.0123,  ..., 0.0076, 0.0110, 0.0054]]],


        [[[0.0215, 0.0066, 0.0146,  ..., 0.0158, 0.0196, 0.0125],
          [0.0188, 0.0031, 0.0090,  ..., 0.0091, 0.0136, 0.0095],
          [0.0150, 0.0046, 0.0173,  ..., 0.0146, 0.0081, 0.0098],
          ...,
          [0.0194, 0.0087, 0.0200,  ..., 0.0178, 0.0158, 0.0144],
          [0.0247, 0.0182, 0.0183,  ..., 0.0131, 0.0215, 0.0131],
          [0.0157, 0.0156, 0.0191,  ..., 0.0117, 0.0169, 0.0103]]],


        ...,


        [[[0.0214, 0.0065, 0.0116,  ..., 0.0165, 0.0202, 0.0149],
          [0.0164, 0.0007, 0.0043,  ..., 0.0094, 0.0141, 0.0100],
          [0.0128, 0.0021, 0.0115,  ..., 0.0145, 0.0095, 0.0099],
          ...,
          [0.0160, 0.0052, 0.0179,  ..., 0.0306, 0.0341, 0.0276],
          [0.0216, 0.0135, 0.0145,  ..., 0.0313, 0.0445, 0.0290],
          [0.0132, 0.0137, 0.0172,  ..., 0.0253, 0.0345, 0.0237]]],


        [[[0.0210, 0.0064, 0.0119,  ..., 0.0163, 0.0205, 0.0144],
          [0.0163, 0.0011, 0.0046,  ..., 0.0094, 0.0149, 0.0103],
          [0.0125, 0.0024, 0.0116,  ..., 0.0144, 0.0096, 0.0097],
          ...,
          [0.0153, 0.0042, 0.0161,  ..., 0.0304, 0.0346, 0.0272],
          [0.0212, 0.0132, 0.0136,  ..., 0.0320, 0.0458, 0.0292],
          [0.0121, 0.0128, 0.0161,  ..., 0.0251, 0.0346, 0.0231]]],


        [[[0.0208, 0.0068, 0.0121,  ..., 0.0157, 0.0204, 0.0136],
          [0.0163, 0.0016, 0.0050,  ..., 0.0091, 0.0152, 0.0102],
          [0.0121, 0.0028, 0.0116,  ..., 0.0136, 0.0091, 0.0090],
          ...,
          [0.0140, 0.0025, 0.0136,  ..., 0.0273, 0.0317, 0.0247],
          [0.0199, 0.0111, 0.0113,  ..., 0.0294, 0.0435, 0.0270],
          [0.0104, 0.0107, 0.0136,  ..., 0.0225, 0.0323, 0.0212]]]],
       device='cuda:0')
FINAL VOLUME (DDPM) shape torch.Size([96, 96, 50])
FINAL VOLUME tensor([[[0.0165, 0.0179, 0.0215,  ..., 0.0214, 0.0210, 0.0208],
         [0.0015, 0.0024, 0.0066,  ..., 0.0065, 0.0064, 0.0068],
         [0.0106, 0.0121, 0.0146,  ..., 0.0116, 0.0119, 0.0121],
         ...,
         [0.0111, 0.0125, 0.0158,  ..., 0.0165, 0.0163, 0.0157],
         [0.0151, 0.0160, 0.0196,  ..., 0.0202, 0.0205, 0.0204],
         [0.0082, 0.0091, 0.0125,  ..., 0.0149, 0.0144, 0.0136]],

        [[0.0148, 0.0158, 0.0188,  ..., 0.0164, 0.0163, 0.0163],
         [0.0002, 0.0000, 0.0031,  ..., 0.0007, 0.0011, 0.0016],
         [0.0059, 0.0065, 0.0090,  ..., 0.0043, 0.0046, 0.0050],
         ...,
         [0.0057, 0.0062, 0.0091,  ..., 0.0094, 0.0094, 0.0091],
         [0.0101, 0.0103, 0.0136,  ..., 0.0141, 0.0149, 0.0152],
         [0.0062, 0.0064, 0.0095,  ..., 0.0100, 0.0103, 0.0102]],

        [[0.0105, 0.0123, 0.0150,  ..., 0.0128, 0.0125, 0.0121],
         [0.0008, 0.0021, 0.0046,  ..., 0.0021, 0.0024, 0.0028],
         [0.0134, 0.0151, 0.0173,  ..., 0.0115, 0.0116, 0.0116],
         ...,
         [0.0105, 0.0114, 0.0146,  ..., 0.0145, 0.0144, 0.0136],
         [0.0037, 0.0049, 0.0081,  ..., 0.0095, 0.0096, 0.0091],
         [0.0055, 0.0064, 0.0098,  ..., 0.0099, 0.0097, 0.0090]],

        ...,

        [[0.0126, 0.0141, 0.0194,  ..., 0.0160, 0.0153, 0.0140],
         [0.0013, 0.0024, 0.0087,  ..., 0.0052, 0.0042, 0.0025],
         [0.0124, 0.0133, 0.0200,  ..., 0.0179, 0.0161, 0.0136],
         ...,
         [0.0138, 0.0142, 0.0178,  ..., 0.0306, 0.0304, 0.0273],
         [0.0100, 0.0105, 0.0158,  ..., 0.0341, 0.0346, 0.0317],
         [0.0090, 0.0095, 0.0144,  ..., 0.0276, 0.0272, 0.0247]],

        [[0.0185, 0.0190, 0.0247,  ..., 0.0216, 0.0212, 0.0199],
         [0.0110, 0.0111, 0.0182,  ..., 0.0135, 0.0132, 0.0111],
         [0.0107, 0.0116, 0.0183,  ..., 0.0145, 0.0136, 0.0113],
         ...,
         [0.0085, 0.0094, 0.0131,  ..., 0.0313, 0.0320, 0.0294],
         [0.0152, 0.0156, 0.0215,  ..., 0.0445, 0.0458, 0.0435],
         [0.0071, 0.0077, 0.0131,  ..., 0.0290, 0.0292, 0.0270]],

        [[0.0098, 0.0103, 0.0157,  ..., 0.0132, 0.0121, 0.0104],
         [0.0085, 0.0085, 0.0156,  ..., 0.0137, 0.0128, 0.0107],
         [0.0114, 0.0123, 0.0191,  ..., 0.0172, 0.0161, 0.0136],
         ...,
         [0.0065, 0.0076, 0.0117,  ..., 0.0253, 0.0251, 0.0225],
         [0.0106, 0.0110, 0.0169,  ..., 0.0345, 0.0346, 0.0323],
         [0.0049, 0.0054, 0.0103,  ..., 0.0237, 0.0231, 0.0212]]],
       device='cuda:0')
unsqueeze final volume shape (DDPM2d) torch.Size([1, 1, 96, 96, 50])
unsqueeze final volume (DDPM 2D) tensor([[[[[0.0165, 0.0179, 0.0215,  ..., 0.0214, 0.0210, 0.0208],
           [0.0015, 0.0024, 0.0066,  ..., 0.0065, 0.0064, 0.0068],
           [0.0106, 0.0121, 0.0146,  ..., 0.0116, 0.0119, 0.0121],
           ...,
           [0.0111, 0.0125, 0.0158,  ..., 0.0165, 0.0163, 0.0157],
           [0.0151, 0.0160, 0.0196,  ..., 0.0202, 0.0205, 0.0204],
           [0.0082, 0.0091, 0.0125,  ..., 0.0149, 0.0144, 0.0136]],

          [[0.0148, 0.0158, 0.0188,  ..., 0.0164, 0.0163, 0.0163],
           [0.0002, 0.0000, 0.0031,  ..., 0.0007, 0.0011, 0.0016],
           [0.0059, 0.0065, 0.0090,  ..., 0.0043, 0.0046, 0.0050],
           ...,
           [0.0057, 0.0062, 0.0091,  ..., 0.0094, 0.0094, 0.0091],
           [0.0101, 0.0103, 0.0136,  ..., 0.0141, 0.0149, 0.0152],
           [0.0062, 0.0064, 0.0095,  ..., 0.0100, 0.0103, 0.0102]],

          [[0.0105, 0.0123, 0.0150,  ..., 0.0128, 0.0125, 0.0121],
           [0.0008, 0.0021, 0.0046,  ..., 0.0021, 0.0024, 0.0028],
           [0.0134, 0.0151, 0.0173,  ..., 0.0115, 0.0116, 0.0116],
           ...,
           [0.0105, 0.0114, 0.0146,  ..., 0.0145, 0.0144, 0.0136],
           [0.0037, 0.0049, 0.0081,  ..., 0.0095, 0.0096, 0.0091],
           [0.0055, 0.0064, 0.0098,  ..., 0.0099, 0.0097, 0.0090]],

          ...,

          [[0.0126, 0.0141, 0.0194,  ..., 0.0160, 0.0153, 0.0140],
           [0.0013, 0.0024, 0.0087,  ..., 0.0052, 0.0042, 0.0025],
           [0.0124, 0.0133, 0.0200,  ..., 0.0179, 0.0161, 0.0136],
           ...,
           [0.0138, 0.0142, 0.0178,  ..., 0.0306, 0.0304, 0.0273],
           [0.0100, 0.0105, 0.0158,  ..., 0.0341, 0.0346, 0.0317],
           [0.0090, 0.0095, 0.0144,  ..., 0.0276, 0.0272, 0.0247]],

          [[0.0185, 0.0190, 0.0247,  ..., 0.0216, 0.0212, 0.0199],
           [0.0110, 0.0111, 0.0182,  ..., 0.0135, 0.0132, 0.0111],
           [0.0107, 0.0116, 0.0183,  ..., 0.0145, 0.0136, 0.0113],
           ...,
           [0.0085, 0.0094, 0.0131,  ..., 0.0313, 0.0320, 0.0294],
           [0.0152, 0.0156, 0.0215,  ..., 0.0445, 0.0458, 0.0435],
           [0.0071, 0.0077, 0.0131,  ..., 0.0290, 0.0292, 0.0270]],

          [[0.0098, 0.0103, 0.0157,  ..., 0.0132, 0.0121, 0.0104],
           [0.0085, 0.0085, 0.0156,  ..., 0.0137, 0.0128, 0.0107],
           [0.0114, 0.0123, 0.0191,  ..., 0.0172, 0.0161, 0.0136],
           ...,
           [0.0065, 0.0076, 0.0117,  ..., 0.0253, 0.0251, 0.0225],
           [0.0106, 0.0110, 0.0169,  ..., 0.0345, 0.0346, 0.0323],
           [0.0049, 0.0054, 0.0103,  ..., 0.0237, 0.0231, 0.0212]]]]],
       device='cuda:0')
==========
IN _TEST_STEP
==========
ERODING BRAIN MASK
MEDIAN FILTERING
SAVING OUTPUT - ORIGINAL, FINAL, MASK ETC
SAVING IMAGES!
Testing:  30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:20<00:45,  3.23s/it]==========
IN DDPM ON TEST STEP
==========
THE WEIRD CONDITION BIT CALLED "features" in DDPM_2D
IN SPARK ENCODER FORWARDDD
x in shape torch.Size([50, 1, 96, 96])
out features torch.Size([50, 512])
i'm i DDPM2d forward block (whch is basically the encoder)
Context vector c shape: torch.Size([50, 512])
shape features:  torch.Size([50, 512])
additng features to latern space
latent space: []
iAM IN THE FORWARD METHOD OF THE WEIRD GUASSIAN IN cond_DDPM.py. I WILL BE CALLING p_losses
i am in p_losses in guassian which seems to be crucial to everything
conditioning vector shape:  torch.Size([50, 512])
in plosses i am getting a noisy image x
x shape:  torch.Size([50, 1, 96, 96])
getting model out
Initial input shape: torch.Size([50, 1, 96, 96])

inputblocks
Before block 0, shape: torch.Size([50, 1, 96, 96])
After block 0, shape: torch.Size([50, 128, 96, 96])
-
Before block 1, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 1, shape: torch.Size([50, 128, 96, 96])
-
Before block 2, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 2, shape: torch.Size([50, 128, 96, 96])
-
Before block 3, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 3, shape: torch.Size([50, 128, 96, 96])
-
Before block 4, shape: torch.Size([50, 128, 96, 96])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 256])
After block 4, shape: torch.Size([50, 128, 48, 48])
-
Before block 5, shape: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 48, 48])
-
Before block 8, shape: torch.Size([50, 256, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 8, shape: torch.Size([50, 256, 24, 24])
-
Before block 9, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 9, shape: torch.Size([50, 256, 24, 24])
-
Before block 10, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 10, shape: torch.Size([50, 256, 24, 24])
-
Before block 11, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 11, shape: torch.Size([50, 256, 24, 24])
-

Before middle block, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
in unet attention block!
x shape torch.Size([50, 256, 24, 24])
out dims torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])


After middle block, shape: torch.Size([50, 256, 24, 24])
-



outputblocks
Before block 0, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 0, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 0, shape: torch.Size([50, 256, 24, 24])
-
Before block 1, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 1, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 1, shape: torch.Size([50, 256, 24, 24])
-
Before block 2, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 2, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 2, shape: torch.Size([50, 256, 24, 24])
-
Before block 3, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 3, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 3, shape: torch.Size([50, 256, 48, 48])
-
Before block 4, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 4, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 4, shape: torch.Size([50, 256, 48, 48])
-
Before block 5, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 5, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 6, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 7, shape: torch.Size([50, 384, 48, 48])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 96, 96])
-
Before block 8, shape: torch.Size([50, 256, 96, 96])
After concatenation in upsampling block 8, shape: torch.Size([50, 384, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 8, shape: torch.Size([50, 128, 96, 96])
-
Before block 9, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 9, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 9, shape: torch.Size([50, 128, 96, 96])
-
Before block 10, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 10, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 10, shape: torch.Size([50, 128, 96, 96])
-
Before block 11, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 11, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 11, shape: torch.Size([50, 128, 96, 96])
-

Before Final layer shape: torch.Size([50, 128, 96, 96])
Final output shape: torch.Size([50, 1, 96, 96])
model out shape:  torch.Size([50, 1, 96, 96])
iAM IN THE FORWARD METHOD OF THE WEIRD GUASSIAN IN cond_DDPM.py. I WILL BE CALLING p_losses
i am in p_losses in guassian which seems to be crucial to everything
conditioning vector shape:  torch.Size([50, 512])
in plosses i am getting a noisy image x
x shape:  torch.Size([50, 1, 96, 96])
getting model out
Initial input shape: torch.Size([50, 1, 96, 96])

inputblocks
Before block 0, shape: torch.Size([50, 1, 96, 96])
After block 0, shape: torch.Size([50, 128, 96, 96])
-
Before block 1, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 1, shape: torch.Size([50, 128, 96, 96])
-
Before block 2, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 2, shape: torch.Size([50, 128, 96, 96])
-
Before block 3, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 3, shape: torch.Size([50, 128, 96, 96])
-
Before block 4, shape: torch.Size([50, 128, 96, 96])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 256])
After block 4, shape: torch.Size([50, 128, 48, 48])
-
Before block 5, shape: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 48, 48])
-
Before block 8, shape: torch.Size([50, 256, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 8, shape: torch.Size([50, 256, 24, 24])
-
Before block 9, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 9, shape: torch.Size([50, 256, 24, 24])
-
Before block 10, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 10, shape: torch.Size([50, 256, 24, 24])
-
Before block 11, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 11, shape: torch.Size([50, 256, 24, 24])
-

Before middle block, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
in unet attention block!
x shape torch.Size([50, 256, 24, 24])
out dims torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])


After middle block, shape: torch.Size([50, 256, 24, 24])
-



outputblocks
Before block 0, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 0, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 0, shape: torch.Size([50, 256, 24, 24])
-
Before block 1, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 1, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 1, shape: torch.Size([50, 256, 24, 24])
-
Before block 2, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 2, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 2, shape: torch.Size([50, 256, 24, 24])
-
Before block 3, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 3, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 3, shape: torch.Size([50, 256, 48, 48])
-
Before block 4, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 4, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 4, shape: torch.Size([50, 256, 48, 48])
-
Before block 5, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 5, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 6, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 7, shape: torch.Size([50, 384, 48, 48])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 96, 96])
-
Before block 8, shape: torch.Size([50, 256, 96, 96])
After concatenation in upsampling block 8, shape: torch.Size([50, 384, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 8, shape: torch.Size([50, 128, 96, 96])
-
Before block 9, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 9, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 9, shape: torch.Size([50, 128, 96, 96])
-
Before block 10, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 10, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 10, shape: torch.Size([50, 128, 96, 96])
-
Before block 11, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 11, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 11, shape: torch.Size([50, 128, 96, 96])
-

Before Final layer shape: torch.Size([50, 128, 96, 96])
Final output shape: torch.Size([50, 1, 96, 96])
model out shape:  torch.Size([50, 1, 96, 96])
iAM IN THE FORWARD METHOD OF THE WEIRD GUASSIAN IN cond_DDPM.py. I WILL BE CALLING p_losses
i am in p_losses in guassian which seems to be crucial to everything
conditioning vector shape:  torch.Size([50, 512])
in plosses i am getting a noisy image x
x shape:  torch.Size([50, 1, 96, 96])
getting model out
Initial input shape: torch.Size([50, 1, 96, 96])

inputblocks
Before block 0, shape: torch.Size([50, 1, 96, 96])
After block 0, shape: torch.Size([50, 128, 96, 96])
-
Before block 1, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 1, shape: torch.Size([50, 128, 96, 96])
-
Before block 2, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 2, shape: torch.Size([50, 128, 96, 96])
-
Before block 3, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 3, shape: torch.Size([50, 128, 96, 96])
-
Before block 4, shape: torch.Size([50, 128, 96, 96])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 256])
After block 4, shape: torch.Size([50, 128, 48, 48])
-
Before block 5, shape: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 48, 48])
-
Before block 8, shape: torch.Size([50, 256, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 8, shape: torch.Size([50, 256, 24, 24])
-
Before block 9, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 9, shape: torch.Size([50, 256, 24, 24])
-
Before block 10, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 10, shape: torch.Size([50, 256, 24, 24])
-
Before block 11, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 11, shape: torch.Size([50, 256, 24, 24])
-

Before middle block, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
in unet attention block!
x shape torch.Size([50, 256, 24, 24])
out dims torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])


After middle block, shape: torch.Size([50, 256, 24, 24])
-



outputblocks
Before block 0, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 0, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 0, shape: torch.Size([50, 256, 24, 24])
-
Before block 1, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 1, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 1, shape: torch.Size([50, 256, 24, 24])
-
Before block 2, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 2, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 2, shape: torch.Size([50, 256, 24, 24])
-
Before block 3, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 3, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 3, shape: torch.Size([50, 256, 48, 48])
-
Before block 4, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 4, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 4, shape: torch.Size([50, 256, 48, 48])
-
Before block 5, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 5, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 6, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 7, shape: torch.Size([50, 384, 48, 48])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 96, 96])
-
Before block 8, shape: torch.Size([50, 256, 96, 96])
After concatenation in upsampling block 8, shape: torch.Size([50, 384, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 8, shape: torch.Size([50, 128, 96, 96])
-
Before block 9, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 9, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 9, shape: torch.Size([50, 128, 96, 96])
-
Before block 10, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 10, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 10, shape: torch.Size([50, 128, 96, 96])
-
Before block 11, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 11, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 11, shape: torch.Size([50, 128, 96, 96])
-

Before Final layer shape: torch.Size([50, 128, 96, 96])
Final output shape: torch.Size([50, 1, 96, 96])
model out shape:  torch.Size([50, 1, 96, 96])
reconstruction shape torch.Size([50, 1, 96, 96])
reconstruction tensor([[[[ 0.0194,  0.0104,  0.0107,  ...,  0.0120,  0.0119,  0.0098],
          [ 0.0173,  0.0065,  0.0055,  ...,  0.0057,  0.0103,  0.0056],
          [ 0.0087, -0.0002,  0.0142,  ...,  0.0126,  0.0016,  0.0039],
          ...,
          [ 0.0141,  0.0031,  0.0188,  ...,  0.0180,  0.0085,  0.0060],
          [ 0.0136,  0.0102,  0.0094,  ...,  0.0094,  0.0109,  0.0030],
          [ 0.0129,  0.0099,  0.0104,  ...,  0.0078,  0.0055,  0.0033]]],


        [[[ 0.0202,  0.0119,  0.0117,  ...,  0.0128,  0.0127,  0.0107],
          [ 0.0181,  0.0076,  0.0063,  ...,  0.0061,  0.0111,  0.0062],
          [ 0.0093,  0.0007,  0.0151,  ...,  0.0136,  0.0024,  0.0043],
          ...,
          [ 0.0148,  0.0039,  0.0196,  ...,  0.0188,  0.0096,  0.0069],
          [ 0.0142,  0.0109,  0.0101,  ...,  0.0102,  0.0118,  0.0040],
          [ 0.0133,  0.0107,  0.0112,  ...,  0.0090,  0.0066,  0.0042]]],


        [[[ 0.0213,  0.0131,  0.0133,  ...,  0.0144,  0.0141,  0.0123],
          [ 0.0189,  0.0081,  0.0073,  ...,  0.0073,  0.0116,  0.0069],
          [ 0.0101,  0.0015,  0.0161,  ...,  0.0148,  0.0033,  0.0054],
          ...,
          [ 0.0158,  0.0052,  0.0210,  ...,  0.0200,  0.0107,  0.0081],
          [ 0.0146,  0.0114,  0.0111,  ...,  0.0115,  0.0130,  0.0053],
          [ 0.0135,  0.0109,  0.0120,  ...,  0.0104,  0.0077,  0.0050]]],


        ...,


        [[[ 0.0225,  0.0147,  0.0138,  ...,  0.0124,  0.0112,  0.0122],
          [ 0.0157,  0.0048,  0.0063,  ...,  0.0055,  0.0063,  0.0026],
          [ 0.0105,  0.0030,  0.0175,  ...,  0.0123,  0.0039,  0.0059],
          ...,
          [ 0.0152,  0.0052,  0.0194,  ...,  0.0246,  0.0150,  0.0116],
          [ 0.0155,  0.0103,  0.0107,  ...,  0.0136,  0.0123,  0.0061],
          [ 0.0178,  0.0126,  0.0122,  ...,  0.0157,  0.0116,  0.0134]]],


        [[[ 0.0222,  0.0141,  0.0134,  ...,  0.0125,  0.0111,  0.0122],
          [ 0.0157,  0.0050,  0.0063,  ...,  0.0057,  0.0068,  0.0028],
          [ 0.0107,  0.0031,  0.0171,  ...,  0.0127,  0.0046,  0.0059],
          ...,
          [ 0.0150,  0.0054,  0.0195,  ...,  0.0241,  0.0147,  0.0115],
          [ 0.0162,  0.0113,  0.0114,  ...,  0.0144,  0.0132,  0.0063],
          [ 0.0179,  0.0133,  0.0125,  ...,  0.0156,  0.0118,  0.0129]]],


        [[[ 0.0227,  0.0147,  0.0143,  ...,  0.0131,  0.0117,  0.0124],
          [ 0.0161,  0.0058,  0.0073,  ...,  0.0063,  0.0073,  0.0029],
          [ 0.0109,  0.0041,  0.0181,  ...,  0.0136,  0.0050,  0.0060],
          ...,
          [ 0.0158,  0.0060,  0.0205,  ...,  0.0240,  0.0145,  0.0110],
          [ 0.0165,  0.0120,  0.0122,  ...,  0.0133,  0.0123,  0.0055],
          [ 0.0170,  0.0129,  0.0125,  ...,  0.0138,  0.0102,  0.0108]]]],
       device='cuda:0')
FINAL VOLUME (DDPM) shape torch.Size([96, 96, 50])
FINAL VOLUME tensor([[[ 0.0194,  0.0202,  0.0213,  ...,  0.0225,  0.0222,  0.0227],
         [ 0.0104,  0.0119,  0.0131,  ...,  0.0147,  0.0141,  0.0147],
         [ 0.0107,  0.0117,  0.0133,  ...,  0.0138,  0.0134,  0.0143],
         ...,
         [ 0.0120,  0.0128,  0.0144,  ...,  0.0124,  0.0125,  0.0131],
         [ 0.0119,  0.0127,  0.0141,  ...,  0.0112,  0.0111,  0.0117],
         [ 0.0098,  0.0107,  0.0123,  ...,  0.0122,  0.0122,  0.0124]],

        [[ 0.0173,  0.0181,  0.0189,  ...,  0.0157,  0.0157,  0.0161],
         [ 0.0065,  0.0076,  0.0081,  ...,  0.0048,  0.0050,  0.0058],
         [ 0.0055,  0.0063,  0.0073,  ...,  0.0063,  0.0063,  0.0073],
         ...,
         [ 0.0057,  0.0061,  0.0073,  ...,  0.0055,  0.0057,  0.0063],
         [ 0.0103,  0.0111,  0.0116,  ...,  0.0063,  0.0068,  0.0073],
         [ 0.0056,  0.0062,  0.0069,  ...,  0.0026,  0.0028,  0.0029]],

        [[ 0.0087,  0.0093,  0.0101,  ...,  0.0105,  0.0107,  0.0109],
         [-0.0002,  0.0007,  0.0015,  ...,  0.0030,  0.0031,  0.0041],
         [ 0.0142,  0.0151,  0.0161,  ...,  0.0175,  0.0171,  0.0181],
         ...,
         [ 0.0126,  0.0136,  0.0148,  ...,  0.0123,  0.0127,  0.0136],
         [ 0.0016,  0.0024,  0.0033,  ...,  0.0039,  0.0046,  0.0050],
         [ 0.0039,  0.0043,  0.0054,  ...,  0.0059,  0.0059,  0.0060]],

        ...,

        [[ 0.0141,  0.0148,  0.0158,  ...,  0.0152,  0.0150,  0.0158],
         [ 0.0031,  0.0039,  0.0052,  ...,  0.0052,  0.0054,  0.0060],
         [ 0.0188,  0.0196,  0.0210,  ...,  0.0194,  0.0195,  0.0205],
         ...,
         [ 0.0180,  0.0188,  0.0200,  ...,  0.0246,  0.0241,  0.0240],
         [ 0.0085,  0.0096,  0.0107,  ...,  0.0150,  0.0147,  0.0145],
         [ 0.0060,  0.0069,  0.0081,  ...,  0.0116,  0.0115,  0.0110]],

        [[ 0.0136,  0.0142,  0.0146,  ...,  0.0155,  0.0162,  0.0165],
         [ 0.0102,  0.0109,  0.0114,  ...,  0.0103,  0.0113,  0.0120],
         [ 0.0094,  0.0101,  0.0111,  ...,  0.0107,  0.0114,  0.0122],
         ...,
         [ 0.0094,  0.0102,  0.0115,  ...,  0.0136,  0.0144,  0.0133],
         [ 0.0109,  0.0118,  0.0130,  ...,  0.0123,  0.0132,  0.0123],
         [ 0.0030,  0.0040,  0.0053,  ...,  0.0061,  0.0063,  0.0055]],

        [[ 0.0129,  0.0133,  0.0135,  ...,  0.0178,  0.0179,  0.0170],
         [ 0.0099,  0.0107,  0.0109,  ...,  0.0126,  0.0133,  0.0129],
         [ 0.0104,  0.0112,  0.0120,  ...,  0.0122,  0.0125,  0.0125],
         ...,
         [ 0.0078,  0.0090,  0.0104,  ...,  0.0157,  0.0156,  0.0138],
         [ 0.0055,  0.0066,  0.0077,  ...,  0.0116,  0.0118,  0.0102],
         [ 0.0033,  0.0042,  0.0050,  ...,  0.0134,  0.0129,  0.0108]]],
       device='cuda:0')
unsqueeze final volume shape (DDPM2d) torch.Size([1, 1, 96, 96, 50])
unsqueeze final volume (DDPM 2D) tensor([[[[[ 0.0194,  0.0202,  0.0213,  ...,  0.0225,  0.0222,  0.0227],
           [ 0.0104,  0.0119,  0.0131,  ...,  0.0147,  0.0141,  0.0147],
           [ 0.0107,  0.0117,  0.0133,  ...,  0.0138,  0.0134,  0.0143],
           ...,
           [ 0.0120,  0.0128,  0.0144,  ...,  0.0124,  0.0125,  0.0131],
           [ 0.0119,  0.0127,  0.0141,  ...,  0.0112,  0.0111,  0.0117],
           [ 0.0098,  0.0107,  0.0123,  ...,  0.0122,  0.0122,  0.0124]],

          [[ 0.0173,  0.0181,  0.0189,  ...,  0.0157,  0.0157,  0.0161],
           [ 0.0065,  0.0076,  0.0081,  ...,  0.0048,  0.0050,  0.0058],
           [ 0.0055,  0.0063,  0.0073,  ...,  0.0063,  0.0063,  0.0073],
           ...,
           [ 0.0057,  0.0061,  0.0073,  ...,  0.0055,  0.0057,  0.0063],
           [ 0.0103,  0.0111,  0.0116,  ...,  0.0063,  0.0068,  0.0073],
           [ 0.0056,  0.0062,  0.0069,  ...,  0.0026,  0.0028,  0.0029]],

          [[ 0.0087,  0.0093,  0.0101,  ...,  0.0105,  0.0107,  0.0109],
           [-0.0002,  0.0007,  0.0015,  ...,  0.0030,  0.0031,  0.0041],
           [ 0.0142,  0.0151,  0.0161,  ...,  0.0175,  0.0171,  0.0181],
           ...,
           [ 0.0126,  0.0136,  0.0148,  ...,  0.0123,  0.0127,  0.0136],
           [ 0.0016,  0.0024,  0.0033,  ...,  0.0039,  0.0046,  0.0050],
           [ 0.0039,  0.0043,  0.0054,  ...,  0.0059,  0.0059,  0.0060]],

          ...,

          [[ 0.0141,  0.0148,  0.0158,  ...,  0.0152,  0.0150,  0.0158],
           [ 0.0031,  0.0039,  0.0052,  ...,  0.0052,  0.0054,  0.0060],
           [ 0.0188,  0.0196,  0.0210,  ...,  0.0194,  0.0195,  0.0205],
           ...,
           [ 0.0180,  0.0188,  0.0200,  ...,  0.0246,  0.0241,  0.0240],
           [ 0.0085,  0.0096,  0.0107,  ...,  0.0150,  0.0147,  0.0145],
           [ 0.0060,  0.0069,  0.0081,  ...,  0.0116,  0.0115,  0.0110]],

          [[ 0.0136,  0.0142,  0.0146,  ...,  0.0155,  0.0162,  0.0165],
           [ 0.0102,  0.0109,  0.0114,  ...,  0.0103,  0.0113,  0.0120],
           [ 0.0094,  0.0101,  0.0111,  ...,  0.0107,  0.0114,  0.0122],
           ...,
           [ 0.0094,  0.0102,  0.0115,  ...,  0.0136,  0.0144,  0.0133],
           [ 0.0109,  0.0118,  0.0130,  ...,  0.0123,  0.0132,  0.0123],
           [ 0.0030,  0.0040,  0.0053,  ...,  0.0061,  0.0063,  0.0055]],

          [[ 0.0129,  0.0133,  0.0135,  ...,  0.0178,  0.0179,  0.0170],
           [ 0.0099,  0.0107,  0.0109,  ...,  0.0126,  0.0133,  0.0129],
           [ 0.0104,  0.0112,  0.0120,  ...,  0.0122,  0.0125,  0.0125],
           ...,
           [ 0.0078,  0.0090,  0.0104,  ...,  0.0157,  0.0156,  0.0138],
           [ 0.0055,  0.0066,  0.0077,  ...,  0.0116,  0.0118,  0.0102],
           [ 0.0033,  0.0042,  0.0050,  ...,  0.0134,  0.0129,  0.0108]]]]],
       device='cuda:0')
==========
IN _TEST_STEP
==========
ERODING BRAIN MASK
MEDIAN FILTERING
SAVING OUTPUT - ORIGINAL, FINAL, MASK ETC
SAVING IMAGES!
Testing:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:23<00:41,  3.17s/it]==========
IN DDPM ON TEST STEP
==========
THE WEIRD CONDITION BIT CALLED "features" in DDPM_2D
IN SPARK ENCODER FORWARDDD
x in shape torch.Size([50, 1, 96, 96])
out features torch.Size([50, 512])
i'm i DDPM2d forward block (whch is basically the encoder)
Context vector c shape: torch.Size([50, 512])
shape features:  torch.Size([50, 512])
additng features to latern space
latent space: []
iAM IN THE FORWARD METHOD OF THE WEIRD GUASSIAN IN cond_DDPM.py. I WILL BE CALLING p_losses
i am in p_losses in guassian which seems to be crucial to everything
conditioning vector shape:  torch.Size([50, 512])
in plosses i am getting a noisy image x
x shape:  torch.Size([50, 1, 96, 96])
getting model out
Initial input shape: torch.Size([50, 1, 96, 96])

inputblocks
Before block 0, shape: torch.Size([50, 1, 96, 96])
After block 0, shape: torch.Size([50, 128, 96, 96])
-
Before block 1, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 1, shape: torch.Size([50, 128, 96, 96])
-
Before block 2, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 2, shape: torch.Size([50, 128, 96, 96])
-
Before block 3, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 3, shape: torch.Size([50, 128, 96, 96])
-
Before block 4, shape: torch.Size([50, 128, 96, 96])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 256])
After block 4, shape: torch.Size([50, 128, 48, 48])
-
Before block 5, shape: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 48, 48])
-
Before block 8, shape: torch.Size([50, 256, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 8, shape: torch.Size([50, 256, 24, 24])
-
Before block 9, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 9, shape: torch.Size([50, 256, 24, 24])
-
Before block 10, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 10, shape: torch.Size([50, 256, 24, 24])
-
Before block 11, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 11, shape: torch.Size([50, 256, 24, 24])
-

Before middle block, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
in unet attention block!
x shape torch.Size([50, 256, 24, 24])
out dims torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])


After middle block, shape: torch.Size([50, 256, 24, 24])
-



outputblocks
Before block 0, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 0, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 0, shape: torch.Size([50, 256, 24, 24])
-
Before block 1, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 1, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 1, shape: torch.Size([50, 256, 24, 24])
-
Before block 2, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 2, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 2, shape: torch.Size([50, 256, 24, 24])
-
Before block 3, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 3, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 3, shape: torch.Size([50, 256, 48, 48])
-
Before block 4, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 4, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 4, shape: torch.Size([50, 256, 48, 48])
-
Before block 5, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 5, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 6, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 7, shape: torch.Size([50, 384, 48, 48])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 96, 96])
-
Before block 8, shape: torch.Size([50, 256, 96, 96])
After concatenation in upsampling block 8, shape: torch.Size([50, 384, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 8, shape: torch.Size([50, 128, 96, 96])
-
Before block 9, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 9, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 9, shape: torch.Size([50, 128, 96, 96])
-
Before block 10, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 10, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 10, shape: torch.Size([50, 128, 96, 96])
-
Before block 11, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 11, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 11, shape: torch.Size([50, 128, 96, 96])
-

Before Final layer shape: torch.Size([50, 128, 96, 96])
Final output shape: torch.Size([50, 1, 96, 96])
model out shape:  torch.Size([50, 1, 96, 96])
iAM IN THE FORWARD METHOD OF THE WEIRD GUASSIAN IN cond_DDPM.py. I WILL BE CALLING p_losses
i am in p_losses in guassian which seems to be crucial to everything
conditioning vector shape:  torch.Size([50, 512])
in plosses i am getting a noisy image x
x shape:  torch.Size([50, 1, 96, 96])
getting model out
Initial input shape: torch.Size([50, 1, 96, 96])

inputblocks
Before block 0, shape: torch.Size([50, 1, 96, 96])
After block 0, shape: torch.Size([50, 128, 96, 96])
-
Before block 1, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 1, shape: torch.Size([50, 128, 96, 96])
-
Before block 2, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 2, shape: torch.Size([50, 128, 96, 96])
-
Before block 3, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 3, shape: torch.Size([50, 128, 96, 96])
-
Before block 4, shape: torch.Size([50, 128, 96, 96])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 256])
After block 4, shape: torch.Size([50, 128, 48, 48])
-
Before block 5, shape: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 48, 48])
-
Before block 8, shape: torch.Size([50, 256, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 8, shape: torch.Size([50, 256, 24, 24])
-
Before block 9, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 9, shape: torch.Size([50, 256, 24, 24])
-
Before block 10, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 10, shape: torch.Size([50, 256, 24, 24])
-
Before block 11, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 11, shape: torch.Size([50, 256, 24, 24])
-

Before middle block, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
in unet attention block!
x shape torch.Size([50, 256, 24, 24])
out dims torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])


After middle block, shape: torch.Size([50, 256, 24, 24])
-



outputblocks
Before block 0, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 0, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 0, shape: torch.Size([50, 256, 24, 24])
-
Before block 1, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 1, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 1, shape: torch.Size([50, 256, 24, 24])
-
Before block 2, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 2, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 2, shape: torch.Size([50, 256, 24, 24])
-
Before block 3, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 3, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 3, shape: torch.Size([50, 256, 48, 48])
-
Before block 4, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 4, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 4, shape: torch.Size([50, 256, 48, 48])
-
Before block 5, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 5, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 6, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 7, shape: torch.Size([50, 384, 48, 48])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 96, 96])
-
Before block 8, shape: torch.Size([50, 256, 96, 96])
After concatenation in upsampling block 8, shape: torch.Size([50, 384, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 8, shape: torch.Size([50, 128, 96, 96])
-
Before block 9, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 9, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 9, shape: torch.Size([50, 128, 96, 96])
-
Before block 10, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 10, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 10, shape: torch.Size([50, 128, 96, 96])
-
Before block 11, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 11, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 11, shape: torch.Size([50, 128, 96, 96])
-

Before Final layer shape: torch.Size([50, 128, 96, 96])
Final output shape: torch.Size([50, 1, 96, 96])
model out shape:  torch.Size([50, 1, 96, 96])
iAM IN THE FORWARD METHOD OF THE WEIRD GUASSIAN IN cond_DDPM.py. I WILL BE CALLING p_losses
i am in p_losses in guassian which seems to be crucial to everything
conditioning vector shape:  torch.Size([50, 512])
in plosses i am getting a noisy image x
x shape:  torch.Size([50, 1, 96, 96])
getting model out
Initial input shape: torch.Size([50, 1, 96, 96])

inputblocks
Before block 0, shape: torch.Size([50, 1, 96, 96])
After block 0, shape: torch.Size([50, 128, 96, 96])
-
Before block 1, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 1, shape: torch.Size([50, 128, 96, 96])
-
Before block 2, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 2, shape: torch.Size([50, 128, 96, 96])
-
Before block 3, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 3, shape: torch.Size([50, 128, 96, 96])
-
Before block 4, shape: torch.Size([50, 128, 96, 96])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 256])
After block 4, shape: torch.Size([50, 128, 48, 48])
-
Before block 5, shape: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 48, 48])
-
Before block 8, shape: torch.Size([50, 256, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 8, shape: torch.Size([50, 256, 24, 24])
-
Before block 9, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 9, shape: torch.Size([50, 256, 24, 24])
-
Before block 10, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 10, shape: torch.Size([50, 256, 24, 24])
-
Before block 11, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 11, shape: torch.Size([50, 256, 24, 24])
-

Before middle block, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
in unet attention block!
x shape torch.Size([50, 256, 24, 24])
out dims torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])


After middle block, shape: torch.Size([50, 256, 24, 24])
-



outputblocks
Before block 0, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 0, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 0, shape: torch.Size([50, 256, 24, 24])
-
Before block 1, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 1, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 1, shape: torch.Size([50, 256, 24, 24])
-
Before block 2, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 2, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 2, shape: torch.Size([50, 256, 24, 24])
-
Before block 3, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 3, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 3, shape: torch.Size([50, 256, 48, 48])
-
Before block 4, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 4, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 4, shape: torch.Size([50, 256, 48, 48])
-
Before block 5, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 5, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 6, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 7, shape: torch.Size([50, 384, 48, 48])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 96, 96])
-
Before block 8, shape: torch.Size([50, 256, 96, 96])
After concatenation in upsampling block 8, shape: torch.Size([50, 384, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 8, shape: torch.Size([50, 128, 96, 96])
-
Before block 9, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 9, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 9, shape: torch.Size([50, 128, 96, 96])
-
Before block 10, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 10, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 10, shape: torch.Size([50, 128, 96, 96])
-
Before block 11, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 11, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 11, shape: torch.Size([50, 128, 96, 96])
-

Before Final layer shape: torch.Size([50, 128, 96, 96])
Final output shape: torch.Size([50, 1, 96, 96])
model out shape:  torch.Size([50, 1, 96, 96])
reconstruction shape torch.Size([50, 1, 96, 96])
reconstruction tensor([[[[0.0282, 0.0192, 0.0182,  ..., 0.0193, 0.0221, 0.0196],
          [0.0200, 0.0119, 0.0128,  ..., 0.0183, 0.0217, 0.0155],
          [0.0177, 0.0109, 0.0211,  ..., 0.0200, 0.0085, 0.0088],
          ...,
          [0.0208, 0.0111, 0.0208,  ..., 0.0229, 0.0161, 0.0156],
          [0.0269, 0.0194, 0.0168,  ..., 0.0184, 0.0228, 0.0164],
          [0.0181, 0.0168, 0.0165,  ..., 0.0173, 0.0196, 0.0155]]],


        [[[0.0286, 0.0194, 0.0186,  ..., 0.0199, 0.0227, 0.0204],
          [0.0202, 0.0119, 0.0129,  ..., 0.0187, 0.0225, 0.0163],
          [0.0179, 0.0113, 0.0218,  ..., 0.0203, 0.0090, 0.0095],
          ...,
          [0.0213, 0.0116, 0.0213,  ..., 0.0234, 0.0168, 0.0164],
          [0.0270, 0.0196, 0.0171,  ..., 0.0188, 0.0238, 0.0176],
          [0.0182, 0.0170, 0.0169,  ..., 0.0180, 0.0208, 0.0164]]],


        [[[0.0298, 0.0205, 0.0190,  ..., 0.0207, 0.0241, 0.0213],
          [0.0217, 0.0132, 0.0135,  ..., 0.0202, 0.0248, 0.0184],
          [0.0185, 0.0124, 0.0226,  ..., 0.0215, 0.0101, 0.0105],
          ...,
          [0.0219, 0.0125, 0.0220,  ..., 0.0243, 0.0183, 0.0177],
          [0.0283, 0.0211, 0.0181,  ..., 0.0200, 0.0260, 0.0193],
          [0.0192, 0.0181, 0.0177,  ..., 0.0189, 0.0227, 0.0177]]],


        ...,


        [[[0.0325, 0.0225, 0.0202,  ..., 0.0198, 0.0194, 0.0203],
          [0.0190, 0.0084, 0.0112,  ..., 0.0161, 0.0142, 0.0102],
          [0.0181, 0.0092, 0.0212,  ..., 0.0232, 0.0118, 0.0107],
          ...,
          [0.0208, 0.0092, 0.0213,  ..., 0.0239, 0.0142, 0.0136],
          [0.0271, 0.0144, 0.0146,  ..., 0.0140, 0.0165, 0.0130],
          [0.0237, 0.0202, 0.0185,  ..., 0.0165, 0.0191, 0.0183]]],


        [[[0.0321, 0.0224, 0.0203,  ..., 0.0196, 0.0197, 0.0194],
          [0.0190, 0.0090, 0.0114,  ..., 0.0163, 0.0151, 0.0103],
          [0.0178, 0.0090, 0.0206,  ..., 0.0229, 0.0116, 0.0103],
          ...,
          [0.0205, 0.0089, 0.0202,  ..., 0.0227, 0.0138, 0.0130],
          [0.0272, 0.0151, 0.0144,  ..., 0.0138, 0.0173, 0.0130],
          [0.0228, 0.0197, 0.0178,  ..., 0.0157, 0.0191, 0.0174]]],


        [[[0.0310, 0.0219, 0.0197,  ..., 0.0183, 0.0190, 0.0173],
          [0.0185, 0.0092, 0.0110,  ..., 0.0157, 0.0156, 0.0098],
          [0.0168, 0.0085, 0.0194,  ..., 0.0216, 0.0109, 0.0092],
          ...,
          [0.0194, 0.0082, 0.0190,  ..., 0.0215, 0.0132, 0.0120],
          [0.0264, 0.0155, 0.0142,  ..., 0.0134, 0.0181, 0.0126],
          [0.0203, 0.0181, 0.0160,  ..., 0.0142, 0.0185, 0.0157]]]],
       device='cuda:0')
FINAL VOLUME (DDPM) shape torch.Size([96, 96, 50])
FINAL VOLUME tensor([[[0.0282, 0.0286, 0.0298,  ..., 0.0325, 0.0321, 0.0310],
         [0.0192, 0.0194, 0.0205,  ..., 0.0225, 0.0224, 0.0219],
         [0.0182, 0.0186, 0.0190,  ..., 0.0202, 0.0203, 0.0197],
         ...,
         [0.0193, 0.0199, 0.0207,  ..., 0.0198, 0.0196, 0.0183],
         [0.0221, 0.0227, 0.0241,  ..., 0.0194, 0.0197, 0.0190],
         [0.0196, 0.0204, 0.0213,  ..., 0.0203, 0.0194, 0.0173]],

        [[0.0200, 0.0202, 0.0217,  ..., 0.0190, 0.0190, 0.0185],
         [0.0119, 0.0119, 0.0132,  ..., 0.0084, 0.0090, 0.0092],
         [0.0128, 0.0129, 0.0135,  ..., 0.0112, 0.0114, 0.0110],
         ...,
         [0.0183, 0.0187, 0.0202,  ..., 0.0161, 0.0163, 0.0157],
         [0.0217, 0.0225, 0.0248,  ..., 0.0142, 0.0151, 0.0156],
         [0.0155, 0.0163, 0.0184,  ..., 0.0102, 0.0103, 0.0098]],

        [[0.0177, 0.0179, 0.0185,  ..., 0.0181, 0.0178, 0.0168],
         [0.0109, 0.0113, 0.0124,  ..., 0.0092, 0.0090, 0.0085],
         [0.0211, 0.0218, 0.0226,  ..., 0.0212, 0.0206, 0.0194],
         ...,
         [0.0200, 0.0203, 0.0215,  ..., 0.0232, 0.0229, 0.0216],
         [0.0085, 0.0090, 0.0101,  ..., 0.0118, 0.0116, 0.0109],
         [0.0088, 0.0095, 0.0105,  ..., 0.0107, 0.0103, 0.0092]],

        ...,

        [[0.0208, 0.0213, 0.0219,  ..., 0.0208, 0.0205, 0.0194],
         [0.0111, 0.0116, 0.0125,  ..., 0.0092, 0.0089, 0.0082],
         [0.0208, 0.0213, 0.0220,  ..., 0.0213, 0.0202, 0.0190],
         ...,
         [0.0229, 0.0234, 0.0243,  ..., 0.0239, 0.0227, 0.0215],
         [0.0161, 0.0168, 0.0183,  ..., 0.0142, 0.0138, 0.0132],
         [0.0156, 0.0164, 0.0177,  ..., 0.0136, 0.0130, 0.0120]],

        [[0.0269, 0.0270, 0.0283,  ..., 0.0271, 0.0272, 0.0264],
         [0.0194, 0.0196, 0.0211,  ..., 0.0144, 0.0151, 0.0155],
         [0.0168, 0.0171, 0.0181,  ..., 0.0146, 0.0144, 0.0142],
         ...,
         [0.0184, 0.0188, 0.0200,  ..., 0.0140, 0.0138, 0.0134],
         [0.0228, 0.0238, 0.0260,  ..., 0.0165, 0.0173, 0.0181],
         [0.0164, 0.0176, 0.0193,  ..., 0.0130, 0.0130, 0.0126]],

        [[0.0181, 0.0182, 0.0192,  ..., 0.0237, 0.0228, 0.0203],
         [0.0168, 0.0170, 0.0181,  ..., 0.0202, 0.0197, 0.0181],
         [0.0165, 0.0169, 0.0177,  ..., 0.0185, 0.0178, 0.0160],
         ...,
         [0.0173, 0.0180, 0.0189,  ..., 0.0165, 0.0157, 0.0142],
         [0.0196, 0.0208, 0.0227,  ..., 0.0191, 0.0191, 0.0185],
         [0.0155, 0.0164, 0.0177,  ..., 0.0183, 0.0174, 0.0157]]],
       device='cuda:0')
unsqueeze final volume shape (DDPM2d) torch.Size([1, 1, 96, 96, 50])
unsqueeze final volume (DDPM 2D) tensor([[[[[0.0282, 0.0286, 0.0298,  ..., 0.0325, 0.0321, 0.0310],
           [0.0192, 0.0194, 0.0205,  ..., 0.0225, 0.0224, 0.0219],
           [0.0182, 0.0186, 0.0190,  ..., 0.0202, 0.0203, 0.0197],
           ...,
           [0.0193, 0.0199, 0.0207,  ..., 0.0198, 0.0196, 0.0183],
           [0.0221, 0.0227, 0.0241,  ..., 0.0194, 0.0197, 0.0190],
           [0.0196, 0.0204, 0.0213,  ..., 0.0203, 0.0194, 0.0173]],

          [[0.0200, 0.0202, 0.0217,  ..., 0.0190, 0.0190, 0.0185],
           [0.0119, 0.0119, 0.0132,  ..., 0.0084, 0.0090, 0.0092],
           [0.0128, 0.0129, 0.0135,  ..., 0.0112, 0.0114, 0.0110],
           ...,
           [0.0183, 0.0187, 0.0202,  ..., 0.0161, 0.0163, 0.0157],
           [0.0217, 0.0225, 0.0248,  ..., 0.0142, 0.0151, 0.0156],
           [0.0155, 0.0163, 0.0184,  ..., 0.0102, 0.0103, 0.0098]],

          [[0.0177, 0.0179, 0.0185,  ..., 0.0181, 0.0178, 0.0168],
           [0.0109, 0.0113, 0.0124,  ..., 0.0092, 0.0090, 0.0085],
           [0.0211, 0.0218, 0.0226,  ..., 0.0212, 0.0206, 0.0194],
           ...,
           [0.0200, 0.0203, 0.0215,  ..., 0.0232, 0.0229, 0.0216],
           [0.0085, 0.0090, 0.0101,  ..., 0.0118, 0.0116, 0.0109],
           [0.0088, 0.0095, 0.0105,  ..., 0.0107, 0.0103, 0.0092]],

          ...,

          [[0.0208, 0.0213, 0.0219,  ..., 0.0208, 0.0205, 0.0194],
           [0.0111, 0.0116, 0.0125,  ..., 0.0092, 0.0089, 0.0082],
           [0.0208, 0.0213, 0.0220,  ..., 0.0213, 0.0202, 0.0190],
           ...,
           [0.0229, 0.0234, 0.0243,  ..., 0.0239, 0.0227, 0.0215],
           [0.0161, 0.0168, 0.0183,  ..., 0.0142, 0.0138, 0.0132],
           [0.0156, 0.0164, 0.0177,  ..., 0.0136, 0.0130, 0.0120]],

          [[0.0269, 0.0270, 0.0283,  ..., 0.0271, 0.0272, 0.0264],
           [0.0194, 0.0196, 0.0211,  ..., 0.0144, 0.0151, 0.0155],
           [0.0168, 0.0171, 0.0181,  ..., 0.0146, 0.0144, 0.0142],
           ...,
           [0.0184, 0.0188, 0.0200,  ..., 0.0140, 0.0138, 0.0134],
           [0.0228, 0.0238, 0.0260,  ..., 0.0165, 0.0173, 0.0181],
           [0.0164, 0.0176, 0.0193,  ..., 0.0130, 0.0130, 0.0126]],

          [[0.0181, 0.0182, 0.0192,  ..., 0.0237, 0.0228, 0.0203],
           [0.0168, 0.0170, 0.0181,  ..., 0.0202, 0.0197, 0.0181],
           [0.0165, 0.0169, 0.0177,  ..., 0.0185, 0.0178, 0.0160],
           ...,
           [0.0173, 0.0180, 0.0189,  ..., 0.0165, 0.0157, 0.0142],
           [0.0196, 0.0208, 0.0227,  ..., 0.0191, 0.0191, 0.0185],
           [0.0155, 0.0164, 0.0177,  ..., 0.0183, 0.0174, 0.0157]]]]],
       device='cuda:0')
==========
IN _TEST_STEP
==========
ERODING BRAIN MASK
MEDIAN FILTERING
SAVING OUTPUT - ORIGINAL, FINAL, MASK ETC
SAVING IMAGES!
Testing:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:26<00:37,  3.16s/it]==========
IN DDPM ON TEST STEP
==========
THE WEIRD CONDITION BIT CALLED "features" in DDPM_2D
IN SPARK ENCODER FORWARDDD
x in shape torch.Size([50, 1, 96, 96])
out features torch.Size([50, 512])
i'm i DDPM2d forward block (whch is basically the encoder)
Context vector c shape: torch.Size([50, 512])
shape features:  torch.Size([50, 512])
additng features to latern space
latent space: []
iAM IN THE FORWARD METHOD OF THE WEIRD GUASSIAN IN cond_DDPM.py. I WILL BE CALLING p_losses
i am in p_losses in guassian which seems to be crucial to everything
conditioning vector shape:  torch.Size([50, 512])
in plosses i am getting a noisy image x
x shape:  torch.Size([50, 1, 96, 96])
getting model out
Initial input shape: torch.Size([50, 1, 96, 96])

inputblocks
Before block 0, shape: torch.Size([50, 1, 96, 96])
After block 0, shape: torch.Size([50, 128, 96, 96])
-
Before block 1, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 1, shape: torch.Size([50, 128, 96, 96])
-
Before block 2, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 2, shape: torch.Size([50, 128, 96, 96])
-
Before block 3, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 3, shape: torch.Size([50, 128, 96, 96])
-
Before block 4, shape: torch.Size([50, 128, 96, 96])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 256])
After block 4, shape: torch.Size([50, 128, 48, 48])
-
Before block 5, shape: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 48, 48])
-
Before block 8, shape: torch.Size([50, 256, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 8, shape: torch.Size([50, 256, 24, 24])
-
Before block 9, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 9, shape: torch.Size([50, 256, 24, 24])
-
Before block 10, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 10, shape: torch.Size([50, 256, 24, 24])
-
Before block 11, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 11, shape: torch.Size([50, 256, 24, 24])
-

Before middle block, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
in unet attention block!
x shape torch.Size([50, 256, 24, 24])
out dims torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])


After middle block, shape: torch.Size([50, 256, 24, 24])
-



outputblocks
Before block 0, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 0, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 0, shape: torch.Size([50, 256, 24, 24])
-
Before block 1, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 1, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 1, shape: torch.Size([50, 256, 24, 24])
-
Before block 2, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 2, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 2, shape: torch.Size([50, 256, 24, 24])
-
Before block 3, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 3, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 3, shape: torch.Size([50, 256, 48, 48])
-
Before block 4, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 4, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 4, shape: torch.Size([50, 256, 48, 48])
-
Before block 5, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 5, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 6, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 7, shape: torch.Size([50, 384, 48, 48])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 96, 96])
-
Before block 8, shape: torch.Size([50, 256, 96, 96])
After concatenation in upsampling block 8, shape: torch.Size([50, 384, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 8, shape: torch.Size([50, 128, 96, 96])
-
Before block 9, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 9, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 9, shape: torch.Size([50, 128, 96, 96])
-
Before block 10, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 10, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 10, shape: torch.Size([50, 128, 96, 96])
-
Before block 11, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 11, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 11, shape: torch.Size([50, 128, 96, 96])
-

Before Final layer shape: torch.Size([50, 128, 96, 96])
Final output shape: torch.Size([50, 1, 96, 96])
model out shape:  torch.Size([50, 1, 96, 96])
iAM IN THE FORWARD METHOD OF THE WEIRD GUASSIAN IN cond_DDPM.py. I WILL BE CALLING p_losses
i am in p_losses in guassian which seems to be crucial to everything
conditioning vector shape:  torch.Size([50, 512])
in plosses i am getting a noisy image x
x shape:  torch.Size([50, 1, 96, 96])
getting model out
Initial input shape: torch.Size([50, 1, 96, 96])

inputblocks
Before block 0, shape: torch.Size([50, 1, 96, 96])
After block 0, shape: torch.Size([50, 128, 96, 96])
-
Before block 1, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 1, shape: torch.Size([50, 128, 96, 96])
-
Before block 2, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 2, shape: torch.Size([50, 128, 96, 96])
-
Before block 3, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 3, shape: torch.Size([50, 128, 96, 96])
-
Before block 4, shape: torch.Size([50, 128, 96, 96])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 256])
After block 4, shape: torch.Size([50, 128, 48, 48])
-
Before block 5, shape: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 48, 48])
-
Before block 8, shape: torch.Size([50, 256, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 8, shape: torch.Size([50, 256, 24, 24])
-
Before block 9, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 9, shape: torch.Size([50, 256, 24, 24])
-
Before block 10, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 10, shape: torch.Size([50, 256, 24, 24])
-
Before block 11, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 11, shape: torch.Size([50, 256, 24, 24])
-

Before middle block, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
in unet attention block!
x shape torch.Size([50, 256, 24, 24])
out dims torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])


After middle block, shape: torch.Size([50, 256, 24, 24])
-



outputblocks
Before block 0, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 0, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 0, shape: torch.Size([50, 256, 24, 24])
-
Before block 1, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 1, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 1, shape: torch.Size([50, 256, 24, 24])
-
Before block 2, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 2, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 2, shape: torch.Size([50, 256, 24, 24])
-
Before block 3, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 3, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 3, shape: torch.Size([50, 256, 48, 48])
-
Before block 4, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 4, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 4, shape: torch.Size([50, 256, 48, 48])
-
Before block 5, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 5, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 6, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 7, shape: torch.Size([50, 384, 48, 48])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 96, 96])
-
Before block 8, shape: torch.Size([50, 256, 96, 96])
After concatenation in upsampling block 8, shape: torch.Size([50, 384, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 8, shape: torch.Size([50, 128, 96, 96])
-
Before block 9, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 9, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 9, shape: torch.Size([50, 128, 96, 96])
-
Before block 10, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 10, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 10, shape: torch.Size([50, 128, 96, 96])
-
Before block 11, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 11, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 11, shape: torch.Size([50, 128, 96, 96])
-

Before Final layer shape: torch.Size([50, 128, 96, 96])
Final output shape: torch.Size([50, 1, 96, 96])
model out shape:  torch.Size([50, 1, 96, 96])
iAM IN THE FORWARD METHOD OF THE WEIRD GUASSIAN IN cond_DDPM.py. I WILL BE CALLING p_losses
i am in p_losses in guassian which seems to be crucial to everything
conditioning vector shape:  torch.Size([50, 512])
in plosses i am getting a noisy image x
x shape:  torch.Size([50, 1, 96, 96])
getting model out
Initial input shape: torch.Size([50, 1, 96, 96])

inputblocks
Before block 0, shape: torch.Size([50, 1, 96, 96])
After block 0, shape: torch.Size([50, 128, 96, 96])
-
Before block 1, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 1, shape: torch.Size([50, 128, 96, 96])
-
Before block 2, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 2, shape: torch.Size([50, 128, 96, 96])
-
Before block 3, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 3, shape: torch.Size([50, 128, 96, 96])
-
Before block 4, shape: torch.Size([50, 128, 96, 96])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 256])
After block 4, shape: torch.Size([50, 128, 48, 48])
-
Before block 5, shape: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 48, 48])
-
Before block 8, shape: torch.Size([50, 256, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 8, shape: torch.Size([50, 256, 24, 24])
-
Before block 9, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 9, shape: torch.Size([50, 256, 24, 24])
-
Before block 10, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 10, shape: torch.Size([50, 256, 24, 24])
-
Before block 11, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 11, shape: torch.Size([50, 256, 24, 24])
-

Before middle block, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
in unet attention block!
x shape torch.Size([50, 256, 24, 24])
out dims torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])


After middle block, shape: torch.Size([50, 256, 24, 24])
-



outputblocks
Before block 0, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 0, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 0, shape: torch.Size([50, 256, 24, 24])
-
Before block 1, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 1, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 1, shape: torch.Size([50, 256, 24, 24])
-
Before block 2, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 2, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 2, shape: torch.Size([50, 256, 24, 24])
-
Before block 3, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 3, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 3, shape: torch.Size([50, 256, 48, 48])
-
Before block 4, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 4, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 4, shape: torch.Size([50, 256, 48, 48])
-
Before block 5, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 5, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 6, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 7, shape: torch.Size([50, 384, 48, 48])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 96, 96])
-
Before block 8, shape: torch.Size([50, 256, 96, 96])
After concatenation in upsampling block 8, shape: torch.Size([50, 384, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 8, shape: torch.Size([50, 128, 96, 96])
-
Before block 9, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 9, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 9, shape: torch.Size([50, 128, 96, 96])
-
Before block 10, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 10, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 10, shape: torch.Size([50, 128, 96, 96])
-
Before block 11, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 11, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 11, shape: torch.Size([50, 128, 96, 96])
-

Before Final layer shape: torch.Size([50, 128, 96, 96])
Final output shape: torch.Size([50, 1, 96, 96])
model out shape:  torch.Size([50, 1, 96, 96])
reconstruction shape torch.Size([50, 1, 96, 96])
reconstruction tensor([[[[0.0149, 0.0185, 0.0195,  ..., 0.0217, 0.0253, 0.0208],
          [0.0257, 0.0205, 0.0168,  ..., 0.0113, 0.0173, 0.0155],
          [0.0206, 0.0138, 0.0212,  ..., 0.0188, 0.0114, 0.0107],
          ...,
          [0.0188, 0.0113, 0.0216,  ..., 0.0210, 0.0152, 0.0160],
          [0.0286, 0.0201, 0.0137,  ..., 0.0174, 0.0259, 0.0176],
          [0.0153, 0.0141, 0.0151,  ..., 0.0160, 0.0188, 0.0121]]],


        [[[0.0169, 0.0212, 0.0221,  ..., 0.0238, 0.0274, 0.0225],
          [0.0278, 0.0225, 0.0190,  ..., 0.0138, 0.0194, 0.0172],
          [0.0225, 0.0157, 0.0234,  ..., 0.0211, 0.0133, 0.0122],
          ...,
          [0.0207, 0.0134, 0.0233,  ..., 0.0229, 0.0176, 0.0182],
          [0.0308, 0.0228, 0.0157,  ..., 0.0195, 0.0288, 0.0204],
          [0.0167, 0.0168, 0.0171,  ..., 0.0181, 0.0216, 0.0142]]],


        [[[0.0188, 0.0237, 0.0240,  ..., 0.0260, 0.0302, 0.0246],
          [0.0301, 0.0250, 0.0212,  ..., 0.0165, 0.0221, 0.0193],
          [0.0248, 0.0182, 0.0260,  ..., 0.0234, 0.0158, 0.0140],
          ...,
          [0.0236, 0.0165, 0.0260,  ..., 0.0256, 0.0203, 0.0205],
          [0.0336, 0.0259, 0.0181,  ..., 0.0221, 0.0314, 0.0224],
          [0.0192, 0.0198, 0.0195,  ..., 0.0207, 0.0246, 0.0163]]],


        ...,


        [[[0.0123, 0.0172, 0.0164,  ..., 0.0208, 0.0236, 0.0203],
          [0.0236, 0.0185, 0.0152,  ..., 0.0117, 0.0150, 0.0116],
          [0.0221, 0.0146, 0.0223,  ..., 0.0232, 0.0142, 0.0091],
          ...,
          [0.0190, 0.0130, 0.0237,  ..., 0.0238, 0.0155, 0.0133],
          [0.0272, 0.0171, 0.0138,  ..., 0.0175, 0.0208, 0.0118],
          [0.0181, 0.0141, 0.0131,  ..., 0.0165, 0.0194, 0.0139]]],


        [[[0.0112, 0.0164, 0.0159,  ..., 0.0200, 0.0226, 0.0191],
          [0.0228, 0.0184, 0.0151,  ..., 0.0111, 0.0146, 0.0109],
          [0.0214, 0.0143, 0.0217,  ..., 0.0225, 0.0138, 0.0086],
          ...,
          [0.0183, 0.0125, 0.0226,  ..., 0.0228, 0.0147, 0.0125],
          [0.0265, 0.0168, 0.0130,  ..., 0.0168, 0.0202, 0.0109],
          [0.0166, 0.0129, 0.0121,  ..., 0.0155, 0.0181, 0.0124]]],


        [[[0.0110, 0.0168, 0.0159,  ..., 0.0203, 0.0237, 0.0188],
          [0.0240, 0.0205, 0.0164,  ..., 0.0116, 0.0160, 0.0111],
          [0.0221, 0.0157, 0.0222,  ..., 0.0223, 0.0140, 0.0081],
          ...,
          [0.0186, 0.0127, 0.0221,  ..., 0.0222, 0.0148, 0.0122],
          [0.0270, 0.0176, 0.0130,  ..., 0.0177, 0.0221, 0.0115],
          [0.0158, 0.0129, 0.0117,  ..., 0.0154, 0.0186, 0.0114]]]],
       device='cuda:0')
FINAL VOLUME (DDPM) shape torch.Size([96, 96, 50])
FINAL VOLUME tensor([[[0.0149, 0.0169, 0.0188,  ..., 0.0123, 0.0112, 0.0110],
         [0.0185, 0.0212, 0.0237,  ..., 0.0172, 0.0164, 0.0168],
         [0.0195, 0.0221, 0.0240,  ..., 0.0164, 0.0159, 0.0159],
         ...,
         [0.0217, 0.0238, 0.0260,  ..., 0.0208, 0.0200, 0.0203],
         [0.0253, 0.0274, 0.0302,  ..., 0.0236, 0.0226, 0.0237],
         [0.0208, 0.0225, 0.0246,  ..., 0.0203, 0.0191, 0.0188]],

        [[0.0257, 0.0278, 0.0301,  ..., 0.0236, 0.0228, 0.0240],
         [0.0205, 0.0225, 0.0250,  ..., 0.0185, 0.0184, 0.0205],
         [0.0168, 0.0190, 0.0212,  ..., 0.0152, 0.0151, 0.0164],
         ...,
         [0.0113, 0.0138, 0.0165,  ..., 0.0117, 0.0111, 0.0116],
         [0.0173, 0.0194, 0.0221,  ..., 0.0150, 0.0146, 0.0160],
         [0.0155, 0.0172, 0.0193,  ..., 0.0116, 0.0109, 0.0111]],

        [[0.0206, 0.0225, 0.0248,  ..., 0.0221, 0.0214, 0.0221],
         [0.0138, 0.0157, 0.0182,  ..., 0.0146, 0.0143, 0.0157],
         [0.0212, 0.0234, 0.0260,  ..., 0.0223, 0.0217, 0.0222],
         ...,
         [0.0188, 0.0211, 0.0234,  ..., 0.0232, 0.0225, 0.0223],
         [0.0114, 0.0133, 0.0158,  ..., 0.0142, 0.0138, 0.0140],
         [0.0107, 0.0122, 0.0140,  ..., 0.0091, 0.0086, 0.0081]],

        ...,

        [[0.0188, 0.0207, 0.0236,  ..., 0.0190, 0.0183, 0.0186],
         [0.0113, 0.0134, 0.0165,  ..., 0.0130, 0.0125, 0.0127],
         [0.0216, 0.0233, 0.0260,  ..., 0.0237, 0.0226, 0.0221],
         ...,
         [0.0210, 0.0229, 0.0256,  ..., 0.0238, 0.0228, 0.0222],
         [0.0152, 0.0176, 0.0203,  ..., 0.0155, 0.0147, 0.0148],
         [0.0160, 0.0182, 0.0205,  ..., 0.0133, 0.0125, 0.0122]],

        [[0.0286, 0.0308, 0.0336,  ..., 0.0272, 0.0265, 0.0270],
         [0.0201, 0.0228, 0.0259,  ..., 0.0171, 0.0168, 0.0176],
         [0.0137, 0.0157, 0.0181,  ..., 0.0138, 0.0130, 0.0130],
         ...,
         [0.0174, 0.0195, 0.0221,  ..., 0.0175, 0.0168, 0.0177],
         [0.0259, 0.0288, 0.0314,  ..., 0.0208, 0.0202, 0.0221],
         [0.0176, 0.0204, 0.0224,  ..., 0.0118, 0.0109, 0.0115]],

        [[0.0153, 0.0167, 0.0192,  ..., 0.0181, 0.0166, 0.0158],
         [0.0141, 0.0168, 0.0198,  ..., 0.0141, 0.0129, 0.0129],
         [0.0151, 0.0171, 0.0195,  ..., 0.0131, 0.0121, 0.0117],
         ...,
         [0.0160, 0.0181, 0.0207,  ..., 0.0165, 0.0155, 0.0154],
         [0.0188, 0.0216, 0.0246,  ..., 0.0194, 0.0181, 0.0186],
         [0.0121, 0.0142, 0.0163,  ..., 0.0139, 0.0124, 0.0114]]],
       device='cuda:0')
unsqueeze final volume shape (DDPM2d) torch.Size([1, 1, 96, 96, 50])
unsqueeze final volume (DDPM 2D) tensor([[[[[0.0149, 0.0169, 0.0188,  ..., 0.0123, 0.0112, 0.0110],
           [0.0185, 0.0212, 0.0237,  ..., 0.0172, 0.0164, 0.0168],
           [0.0195, 0.0221, 0.0240,  ..., 0.0164, 0.0159, 0.0159],
           ...,
           [0.0217, 0.0238, 0.0260,  ..., 0.0208, 0.0200, 0.0203],
           [0.0253, 0.0274, 0.0302,  ..., 0.0236, 0.0226, 0.0237],
           [0.0208, 0.0225, 0.0246,  ..., 0.0203, 0.0191, 0.0188]],

          [[0.0257, 0.0278, 0.0301,  ..., 0.0236, 0.0228, 0.0240],
           [0.0205, 0.0225, 0.0250,  ..., 0.0185, 0.0184, 0.0205],
           [0.0168, 0.0190, 0.0212,  ..., 0.0152, 0.0151, 0.0164],
           ...,
           [0.0113, 0.0138, 0.0165,  ..., 0.0117, 0.0111, 0.0116],
           [0.0173, 0.0194, 0.0221,  ..., 0.0150, 0.0146, 0.0160],
           [0.0155, 0.0172, 0.0193,  ..., 0.0116, 0.0109, 0.0111]],

          [[0.0206, 0.0225, 0.0248,  ..., 0.0221, 0.0214, 0.0221],
           [0.0138, 0.0157, 0.0182,  ..., 0.0146, 0.0143, 0.0157],
           [0.0212, 0.0234, 0.0260,  ..., 0.0223, 0.0217, 0.0222],
           ...,
           [0.0188, 0.0211, 0.0234,  ..., 0.0232, 0.0225, 0.0223],
           [0.0114, 0.0133, 0.0158,  ..., 0.0142, 0.0138, 0.0140],
           [0.0107, 0.0122, 0.0140,  ..., 0.0091, 0.0086, 0.0081]],

          ...,

          [[0.0188, 0.0207, 0.0236,  ..., 0.0190, 0.0183, 0.0186],
           [0.0113, 0.0134, 0.0165,  ..., 0.0130, 0.0125, 0.0127],
           [0.0216, 0.0233, 0.0260,  ..., 0.0237, 0.0226, 0.0221],
           ...,
           [0.0210, 0.0229, 0.0256,  ..., 0.0238, 0.0228, 0.0222],
           [0.0152, 0.0176, 0.0203,  ..., 0.0155, 0.0147, 0.0148],
           [0.0160, 0.0182, 0.0205,  ..., 0.0133, 0.0125, 0.0122]],

          [[0.0286, 0.0308, 0.0336,  ..., 0.0272, 0.0265, 0.0270],
           [0.0201, 0.0228, 0.0259,  ..., 0.0171, 0.0168, 0.0176],
           [0.0137, 0.0157, 0.0181,  ..., 0.0138, 0.0130, 0.0130],
           ...,
           [0.0174, 0.0195, 0.0221,  ..., 0.0175, 0.0168, 0.0177],
           [0.0259, 0.0288, 0.0314,  ..., 0.0208, 0.0202, 0.0221],
           [0.0176, 0.0204, 0.0224,  ..., 0.0118, 0.0109, 0.0115]],

          [[0.0153, 0.0167, 0.0192,  ..., 0.0181, 0.0166, 0.0158],
           [0.0141, 0.0168, 0.0198,  ..., 0.0141, 0.0129, 0.0129],
           [0.0151, 0.0171, 0.0195,  ..., 0.0131, 0.0121, 0.0117],
           ...,
           [0.0160, 0.0181, 0.0207,  ..., 0.0165, 0.0155, 0.0154],
           [0.0188, 0.0216, 0.0246,  ..., 0.0194, 0.0181, 0.0186],
           [0.0121, 0.0142, 0.0163,  ..., 0.0139, 0.0124, 0.0114]]]]],
       device='cuda:0')
==========
IN _TEST_STEP
==========
ERODING BRAIN MASK
MEDIAN FILTERING
SAVING OUTPUT - ORIGINAL, FINAL, MASK ETC
SAVING IMAGES!
Testing:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [00:29<00:34,  3.17s/it]==========
IN DDPM ON TEST STEP
==========
THE WEIRD CONDITION BIT CALLED "features" in DDPM_2D
IN SPARK ENCODER FORWARDDD
x in shape torch.Size([50, 1, 96, 96])
out features torch.Size([50, 512])
i'm i DDPM2d forward block (whch is basically the encoder)
Context vector c shape: torch.Size([50, 512])
shape features:  torch.Size([50, 512])
additng features to latern space
latent space: []
iAM IN THE FORWARD METHOD OF THE WEIRD GUASSIAN IN cond_DDPM.py. I WILL BE CALLING p_losses
i am in p_losses in guassian which seems to be crucial to everything
conditioning vector shape:  torch.Size([50, 512])
in plosses i am getting a noisy image x
x shape:  torch.Size([50, 1, 96, 96])
getting model out
Initial input shape: torch.Size([50, 1, 96, 96])

inputblocks
Before block 0, shape: torch.Size([50, 1, 96, 96])
After block 0, shape: torch.Size([50, 128, 96, 96])
-
Before block 1, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 1, shape: torch.Size([50, 128, 96, 96])
-
Before block 2, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 2, shape: torch.Size([50, 128, 96, 96])
-
Before block 3, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 3, shape: torch.Size([50, 128, 96, 96])
-
Before block 4, shape: torch.Size([50, 128, 96, 96])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 256])
After block 4, shape: torch.Size([50, 128, 48, 48])
-
Before block 5, shape: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 48, 48])
-
Before block 8, shape: torch.Size([50, 256, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 8, shape: torch.Size([50, 256, 24, 24])
-
Before block 9, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 9, shape: torch.Size([50, 256, 24, 24])
-
Before block 10, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 10, shape: torch.Size([50, 256, 24, 24])
-
Before block 11, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 11, shape: torch.Size([50, 256, 24, 24])
-

Before middle block, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
in unet attention block!
x shape torch.Size([50, 256, 24, 24])
out dims torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])


After middle block, shape: torch.Size([50, 256, 24, 24])
-



outputblocks
Before block 0, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 0, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 0, shape: torch.Size([50, 256, 24, 24])
-
Before block 1, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 1, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 1, shape: torch.Size([50, 256, 24, 24])
-
Before block 2, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 2, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 2, shape: torch.Size([50, 256, 24, 24])
-
Before block 3, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 3, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 3, shape: torch.Size([50, 256, 48, 48])
-
Before block 4, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 4, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 4, shape: torch.Size([50, 256, 48, 48])
-
Before block 5, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 5, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 6, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 7, shape: torch.Size([50, 384, 48, 48])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 96, 96])
-
Before block 8, shape: torch.Size([50, 256, 96, 96])
After concatenation in upsampling block 8, shape: torch.Size([50, 384, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 8, shape: torch.Size([50, 128, 96, 96])
-
Before block 9, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 9, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 9, shape: torch.Size([50, 128, 96, 96])
-
Before block 10, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 10, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 10, shape: torch.Size([50, 128, 96, 96])
-
Before block 11, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 11, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 11, shape: torch.Size([50, 128, 96, 96])
-

Before Final layer shape: torch.Size([50, 128, 96, 96])
Final output shape: torch.Size([50, 1, 96, 96])
model out shape:  torch.Size([50, 1, 96, 96])
iAM IN THE FORWARD METHOD OF THE WEIRD GUASSIAN IN cond_DDPM.py. I WILL BE CALLING p_losses
i am in p_losses in guassian which seems to be crucial to everything
conditioning vector shape:  torch.Size([50, 512])
in plosses i am getting a noisy image x
x shape:  torch.Size([50, 1, 96, 96])
getting model out
Initial input shape: torch.Size([50, 1, 96, 96])

inputblocks
Before block 0, shape: torch.Size([50, 1, 96, 96])
After block 0, shape: torch.Size([50, 128, 96, 96])
-
Before block 1, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 1, shape: torch.Size([50, 128, 96, 96])
-
Before block 2, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 2, shape: torch.Size([50, 128, 96, 96])
-
Before block 3, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 3, shape: torch.Size([50, 128, 96, 96])
-
Before block 4, shape: torch.Size([50, 128, 96, 96])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 256])
After block 4, shape: torch.Size([50, 128, 48, 48])
-
Before block 5, shape: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 48, 48])
-
Before block 8, shape: torch.Size([50, 256, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 8, shape: torch.Size([50, 256, 24, 24])
-
Before block 9, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 9, shape: torch.Size([50, 256, 24, 24])
-
Before block 10, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 10, shape: torch.Size([50, 256, 24, 24])
-
Before block 11, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 11, shape: torch.Size([50, 256, 24, 24])
-

Before middle block, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
in unet attention block!
x shape torch.Size([50, 256, 24, 24])
out dims torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])


After middle block, shape: torch.Size([50, 256, 24, 24])
-



outputblocks
Before block 0, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 0, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 0, shape: torch.Size([50, 256, 24, 24])
-
Before block 1, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 1, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 1, shape: torch.Size([50, 256, 24, 24])
-
Before block 2, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 2, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 2, shape: torch.Size([50, 256, 24, 24])
-
Before block 3, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 3, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 3, shape: torch.Size([50, 256, 48, 48])
-
Before block 4, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 4, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 4, shape: torch.Size([50, 256, 48, 48])
-
Before block 5, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 5, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 6, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 7, shape: torch.Size([50, 384, 48, 48])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 96, 96])
-
Before block 8, shape: torch.Size([50, 256, 96, 96])
After concatenation in upsampling block 8, shape: torch.Size([50, 384, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 8, shape: torch.Size([50, 128, 96, 96])
-
Before block 9, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 9, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 9, shape: torch.Size([50, 128, 96, 96])
-
Before block 10, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 10, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 10, shape: torch.Size([50, 128, 96, 96])
-
Before block 11, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 11, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 11, shape: torch.Size([50, 128, 96, 96])
-

Before Final layer shape: torch.Size([50, 128, 96, 96])
Final output shape: torch.Size([50, 1, 96, 96])
model out shape:  torch.Size([50, 1, 96, 96])
iAM IN THE FORWARD METHOD OF THE WEIRD GUASSIAN IN cond_DDPM.py. I WILL BE CALLING p_losses
i am in p_losses in guassian which seems to be crucial to everything
conditioning vector shape:  torch.Size([50, 512])
in plosses i am getting a noisy image x
x shape:  torch.Size([50, 1, 96, 96])
getting model out
Initial input shape: torch.Size([50, 1, 96, 96])

inputblocks
Before block 0, shape: torch.Size([50, 1, 96, 96])
After block 0, shape: torch.Size([50, 128, 96, 96])
-
Before block 1, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 1, shape: torch.Size([50, 128, 96, 96])
-
Before block 2, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 2, shape: torch.Size([50, 128, 96, 96])
-
Before block 3, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 3, shape: torch.Size([50, 128, 96, 96])
-
Before block 4, shape: torch.Size([50, 128, 96, 96])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 256])
After block 4, shape: torch.Size([50, 128, 48, 48])
-
Before block 5, shape: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 48, 48])
-
Before block 8, shape: torch.Size([50, 256, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 8, shape: torch.Size([50, 256, 24, 24])
-
Before block 9, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 9, shape: torch.Size([50, 256, 24, 24])
-
Before block 10, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 10, shape: torch.Size([50, 256, 24, 24])
-
Before block 11, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 11, shape: torch.Size([50, 256, 24, 24])
-

Before middle block, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
in unet attention block!
x shape torch.Size([50, 256, 24, 24])
out dims torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])


After middle block, shape: torch.Size([50, 256, 24, 24])
-



outputblocks
Before block 0, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 0, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 0, shape: torch.Size([50, 256, 24, 24])
-
Before block 1, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 1, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 1, shape: torch.Size([50, 256, 24, 24])
-
Before block 2, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 2, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 2, shape: torch.Size([50, 256, 24, 24])
-
Before block 3, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 3, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 3, shape: torch.Size([50, 256, 48, 48])
-
Before block 4, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 4, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 4, shape: torch.Size([50, 256, 48, 48])
-
Before block 5, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 5, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 6, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 7, shape: torch.Size([50, 384, 48, 48])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 96, 96])
-
Before block 8, shape: torch.Size([50, 256, 96, 96])
After concatenation in upsampling block 8, shape: torch.Size([50, 384, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 8, shape: torch.Size([50, 128, 96, 96])
-
Before block 9, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 9, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 9, shape: torch.Size([50, 128, 96, 96])
-
Before block 10, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 10, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 10, shape: torch.Size([50, 128, 96, 96])
-
Before block 11, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 11, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 11, shape: torch.Size([50, 128, 96, 96])
-

Before Final layer shape: torch.Size([50, 128, 96, 96])
Final output shape: torch.Size([50, 1, 96, 96])
model out shape:  torch.Size([50, 1, 96, 96])
reconstruction shape torch.Size([50, 1, 96, 96])
reconstruction tensor([[[[0.0314, 0.0319, 0.0298,  ..., 0.0271, 0.0332, 0.0267],
          [0.0341, 0.0301, 0.0264,  ..., 0.0197, 0.0272, 0.0231],
          [0.0305, 0.0238, 0.0310,  ..., 0.0257, 0.0194, 0.0171],
          ...,
          [0.0262, 0.0178, 0.0269,  ..., 0.0376, 0.0296, 0.0242],
          [0.0318, 0.0251, 0.0206,  ..., 0.0271, 0.0346, 0.0225],
          [0.0133, 0.0141, 0.0157,  ..., 0.0330, 0.0365, 0.0216]]],


        [[[0.0303, 0.0301, 0.0291,  ..., 0.0267, 0.0323, 0.0260],
          [0.0327, 0.0283, 0.0256,  ..., 0.0192, 0.0260, 0.0220],
          [0.0295, 0.0229, 0.0312,  ..., 0.0258, 0.0190, 0.0166],
          ...,
          [0.0254, 0.0168, 0.0263,  ..., 0.0378, 0.0295, 0.0240],
          [0.0306, 0.0235, 0.0200,  ..., 0.0264, 0.0333, 0.0219],
          [0.0129, 0.0130, 0.0154,  ..., 0.0308, 0.0339, 0.0196]]],


        [[[0.0292, 0.0278, 0.0278,  ..., 0.0264, 0.0314, 0.0256],
          [0.0309, 0.0251, 0.0237,  ..., 0.0184, 0.0244, 0.0207],
          [0.0284, 0.0211, 0.0301,  ..., 0.0260, 0.0184, 0.0160],
          ...,
          [0.0250, 0.0157, 0.0261,  ..., 0.0375, 0.0286, 0.0234],
          [0.0295, 0.0213, 0.0194,  ..., 0.0251, 0.0317, 0.0208],
          [0.0129, 0.0121, 0.0156,  ..., 0.0288, 0.0316, 0.0185]]],


        ...,


        [[[0.0343, 0.0328, 0.0297,  ..., 0.0264, 0.0308, 0.0284],
          [0.0303, 0.0236, 0.0229,  ..., 0.0182, 0.0208, 0.0185],
          [0.0284, 0.0197, 0.0291,  ..., 0.0286, 0.0200, 0.0166],
          ...,
          [0.0242, 0.0157, 0.0264,  ..., 0.0380, 0.0264, 0.0200],
          [0.0299, 0.0194, 0.0161,  ..., 0.0201, 0.0196, 0.0116],
          [0.0157, 0.0122, 0.0120,  ..., 0.0294, 0.0296, 0.0198]]],


        [[[0.0327, 0.0316, 0.0286,  ..., 0.0260, 0.0305, 0.0278],
          [0.0290, 0.0228, 0.0215,  ..., 0.0177, 0.0206, 0.0181],
          [0.0274, 0.0186, 0.0270,  ..., 0.0279, 0.0195, 0.0160],
          ...,
          [0.0238, 0.0153, 0.0256,  ..., 0.0374, 0.0254, 0.0189],
          [0.0298, 0.0199, 0.0164,  ..., 0.0200, 0.0196, 0.0107],
          [0.0144, 0.0116, 0.0116,  ..., 0.0283, 0.0285, 0.0175]]],


        [[[0.0328, 0.0316, 0.0286,  ..., 0.0264, 0.0311, 0.0281],
          [0.0290, 0.0231, 0.0215,  ..., 0.0179, 0.0212, 0.0186],
          [0.0275, 0.0186, 0.0264,  ..., 0.0278, 0.0194, 0.0160],
          ...,
          [0.0240, 0.0153, 0.0251,  ..., 0.0368, 0.0249, 0.0186],
          [0.0301, 0.0208, 0.0171,  ..., 0.0203, 0.0202, 0.0113],
          [0.0137, 0.0113, 0.0115,  ..., 0.0283, 0.0286, 0.0169]]]],
       device='cuda:0')
FINAL VOLUME (DDPM) shape torch.Size([96, 96, 50])
FINAL VOLUME tensor([[[0.0314, 0.0303, 0.0292,  ..., 0.0343, 0.0327, 0.0328],
         [0.0319, 0.0301, 0.0278,  ..., 0.0328, 0.0316, 0.0316],
         [0.0298, 0.0291, 0.0278,  ..., 0.0297, 0.0286, 0.0286],
         ...,
         [0.0271, 0.0267, 0.0264,  ..., 0.0264, 0.0260, 0.0264],
         [0.0332, 0.0323, 0.0314,  ..., 0.0308, 0.0305, 0.0311],
         [0.0267, 0.0260, 0.0256,  ..., 0.0284, 0.0278, 0.0281]],

        [[0.0341, 0.0327, 0.0309,  ..., 0.0303, 0.0290, 0.0290],
         [0.0301, 0.0283, 0.0251,  ..., 0.0236, 0.0228, 0.0231],
         [0.0264, 0.0256, 0.0237,  ..., 0.0229, 0.0215, 0.0215],
         ...,
         [0.0197, 0.0192, 0.0184,  ..., 0.0182, 0.0177, 0.0179],
         [0.0272, 0.0260, 0.0244,  ..., 0.0208, 0.0206, 0.0212],
         [0.0231, 0.0220, 0.0207,  ..., 0.0185, 0.0181, 0.0186]],

        [[0.0305, 0.0295, 0.0284,  ..., 0.0284, 0.0274, 0.0275],
         [0.0238, 0.0229, 0.0211,  ..., 0.0197, 0.0186, 0.0186],
         [0.0310, 0.0312, 0.0301,  ..., 0.0291, 0.0270, 0.0264],
         ...,
         [0.0257, 0.0258, 0.0260,  ..., 0.0286, 0.0279, 0.0278],
         [0.0194, 0.0190, 0.0184,  ..., 0.0200, 0.0195, 0.0194],
         [0.0171, 0.0166, 0.0160,  ..., 0.0166, 0.0160, 0.0160]],

        ...,

        [[0.0262, 0.0254, 0.0250,  ..., 0.0242, 0.0238, 0.0240],
         [0.0178, 0.0168, 0.0157,  ..., 0.0157, 0.0153, 0.0153],
         [0.0269, 0.0263, 0.0261,  ..., 0.0264, 0.0256, 0.0251],
         ...,
         [0.0376, 0.0378, 0.0375,  ..., 0.0380, 0.0374, 0.0368],
         [0.0296, 0.0295, 0.0286,  ..., 0.0264, 0.0254, 0.0249],
         [0.0242, 0.0240, 0.0234,  ..., 0.0200, 0.0189, 0.0186]],

        [[0.0318, 0.0306, 0.0295,  ..., 0.0299, 0.0298, 0.0301],
         [0.0251, 0.0235, 0.0213,  ..., 0.0194, 0.0199, 0.0208],
         [0.0206, 0.0200, 0.0194,  ..., 0.0161, 0.0164, 0.0171],
         ...,
         [0.0271, 0.0264, 0.0251,  ..., 0.0201, 0.0200, 0.0203],
         [0.0346, 0.0333, 0.0317,  ..., 0.0196, 0.0196, 0.0202],
         [0.0225, 0.0219, 0.0208,  ..., 0.0116, 0.0107, 0.0113]],

        [[0.0133, 0.0129, 0.0129,  ..., 0.0157, 0.0144, 0.0137],
         [0.0141, 0.0130, 0.0121,  ..., 0.0122, 0.0116, 0.0113],
         [0.0157, 0.0154, 0.0156,  ..., 0.0120, 0.0116, 0.0115],
         ...,
         [0.0330, 0.0308, 0.0288,  ..., 0.0294, 0.0283, 0.0283],
         [0.0365, 0.0339, 0.0316,  ..., 0.0296, 0.0285, 0.0286],
         [0.0216, 0.0196, 0.0185,  ..., 0.0198, 0.0175, 0.0169]]],
       device='cuda:0')
unsqueeze final volume shape (DDPM2d) torch.Size([1, 1, 96, 96, 50])
unsqueeze final volume (DDPM 2D) tensor([[[[[0.0314, 0.0303, 0.0292,  ..., 0.0343, 0.0327, 0.0328],
           [0.0319, 0.0301, 0.0278,  ..., 0.0328, 0.0316, 0.0316],
           [0.0298, 0.0291, 0.0278,  ..., 0.0297, 0.0286, 0.0286],
           ...,
           [0.0271, 0.0267, 0.0264,  ..., 0.0264, 0.0260, 0.0264],
           [0.0332, 0.0323, 0.0314,  ..., 0.0308, 0.0305, 0.0311],
           [0.0267, 0.0260, 0.0256,  ..., 0.0284, 0.0278, 0.0281]],

          [[0.0341, 0.0327, 0.0309,  ..., 0.0303, 0.0290, 0.0290],
           [0.0301, 0.0283, 0.0251,  ..., 0.0236, 0.0228, 0.0231],
           [0.0264, 0.0256, 0.0237,  ..., 0.0229, 0.0215, 0.0215],
           ...,
           [0.0197, 0.0192, 0.0184,  ..., 0.0182, 0.0177, 0.0179],
           [0.0272, 0.0260, 0.0244,  ..., 0.0208, 0.0206, 0.0212],
           [0.0231, 0.0220, 0.0207,  ..., 0.0185, 0.0181, 0.0186]],

          [[0.0305, 0.0295, 0.0284,  ..., 0.0284, 0.0274, 0.0275],
           [0.0238, 0.0229, 0.0211,  ..., 0.0197, 0.0186, 0.0186],
           [0.0310, 0.0312, 0.0301,  ..., 0.0291, 0.0270, 0.0264],
           ...,
           [0.0257, 0.0258, 0.0260,  ..., 0.0286, 0.0279, 0.0278],
           [0.0194, 0.0190, 0.0184,  ..., 0.0200, 0.0195, 0.0194],
           [0.0171, 0.0166, 0.0160,  ..., 0.0166, 0.0160, 0.0160]],

          ...,

          [[0.0262, 0.0254, 0.0250,  ..., 0.0242, 0.0238, 0.0240],
           [0.0178, 0.0168, 0.0157,  ..., 0.0157, 0.0153, 0.0153],
           [0.0269, 0.0263, 0.0261,  ..., 0.0264, 0.0256, 0.0251],
           ...,
           [0.0376, 0.0378, 0.0375,  ..., 0.0380, 0.0374, 0.0368],
           [0.0296, 0.0295, 0.0286,  ..., 0.0264, 0.0254, 0.0249],
           [0.0242, 0.0240, 0.0234,  ..., 0.0200, 0.0189, 0.0186]],

          [[0.0318, 0.0306, 0.0295,  ..., 0.0299, 0.0298, 0.0301],
           [0.0251, 0.0235, 0.0213,  ..., 0.0194, 0.0199, 0.0208],
           [0.0206, 0.0200, 0.0194,  ..., 0.0161, 0.0164, 0.0171],
           ...,
           [0.0271, 0.0264, 0.0251,  ..., 0.0201, 0.0200, 0.0203],
           [0.0346, 0.0333, 0.0317,  ..., 0.0196, 0.0196, 0.0202],
           [0.0225, 0.0219, 0.0208,  ..., 0.0116, 0.0107, 0.0113]],

          [[0.0133, 0.0129, 0.0129,  ..., 0.0157, 0.0144, 0.0137],
           [0.0141, 0.0130, 0.0121,  ..., 0.0122, 0.0116, 0.0113],
           [0.0157, 0.0154, 0.0156,  ..., 0.0120, 0.0116, 0.0115],
           ...,
           [0.0330, 0.0308, 0.0288,  ..., 0.0294, 0.0283, 0.0283],
           [0.0365, 0.0339, 0.0316,  ..., 0.0296, 0.0285, 0.0286],
           [0.0216, 0.0196, 0.0185,  ..., 0.0198, 0.0175, 0.0169]]]]],
       device='cuda:0')
==========
IN _TEST_STEP
==========
ERODING BRAIN MASK
MEDIAN FILTERING
SAVING OUTPUT - ORIGINAL, FINAL, MASK ETC
SAVING IMAGES!
Testing:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [00:32<00:31,  3.13s/it]==========
IN DDPM ON TEST STEP
==========
THE WEIRD CONDITION BIT CALLED "features" in DDPM_2D
IN SPARK ENCODER FORWARDDD
x in shape torch.Size([50, 1, 96, 96])
out features torch.Size([50, 512])
i'm i DDPM2d forward block (whch is basically the encoder)
Context vector c shape: torch.Size([50, 512])
shape features:  torch.Size([50, 512])
additng features to latern space
latent space: []
iAM IN THE FORWARD METHOD OF THE WEIRD GUASSIAN IN cond_DDPM.py. I WILL BE CALLING p_losses
i am in p_losses in guassian which seems to be crucial to everything
conditioning vector shape:  torch.Size([50, 512])
in plosses i am getting a noisy image x
x shape:  torch.Size([50, 1, 96, 96])
getting model out
Initial input shape: torch.Size([50, 1, 96, 96])

inputblocks
Before block 0, shape: torch.Size([50, 1, 96, 96])
After block 0, shape: torch.Size([50, 128, 96, 96])
-
Before block 1, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 1, shape: torch.Size([50, 128, 96, 96])
-
Before block 2, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 2, shape: torch.Size([50, 128, 96, 96])
-
Before block 3, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 3, shape: torch.Size([50, 128, 96, 96])
-
Before block 4, shape: torch.Size([50, 128, 96, 96])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 256])
After block 4, shape: torch.Size([50, 128, 48, 48])
-
Before block 5, shape: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 48, 48])
-
Before block 8, shape: torch.Size([50, 256, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 8, shape: torch.Size([50, 256, 24, 24])
-
Before block 9, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 9, shape: torch.Size([50, 256, 24, 24])
-
Before block 10, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 10, shape: torch.Size([50, 256, 24, 24])
-
Before block 11, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 11, shape: torch.Size([50, 256, 24, 24])
-

Before middle block, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
in unet attention block!
x shape torch.Size([50, 256, 24, 24])
out dims torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])


After middle block, shape: torch.Size([50, 256, 24, 24])
-



outputblocks
Before block 0, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 0, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 0, shape: torch.Size([50, 256, 24, 24])
-
Before block 1, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 1, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 1, shape: torch.Size([50, 256, 24, 24])
-
Before block 2, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 2, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 2, shape: torch.Size([50, 256, 24, 24])
-
Before block 3, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 3, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 3, shape: torch.Size([50, 256, 48, 48])
-
Before block 4, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 4, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 4, shape: torch.Size([50, 256, 48, 48])
-
Before block 5, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 5, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 6, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 7, shape: torch.Size([50, 384, 48, 48])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 96, 96])
-
Before block 8, shape: torch.Size([50, 256, 96, 96])
After concatenation in upsampling block 8, shape: torch.Size([50, 384, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 8, shape: torch.Size([50, 128, 96, 96])
-
Before block 9, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 9, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 9, shape: torch.Size([50, 128, 96, 96])
-
Before block 10, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 10, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 10, shape: torch.Size([50, 128, 96, 96])
-
Before block 11, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 11, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 11, shape: torch.Size([50, 128, 96, 96])
-

Before Final layer shape: torch.Size([50, 128, 96, 96])
Final output shape: torch.Size([50, 1, 96, 96])
model out shape:  torch.Size([50, 1, 96, 96])
iAM IN THE FORWARD METHOD OF THE WEIRD GUASSIAN IN cond_DDPM.py. I WILL BE CALLING p_losses
i am in p_losses in guassian which seems to be crucial to everything
conditioning vector shape:  torch.Size([50, 512])
in plosses i am getting a noisy image x
x shape:  torch.Size([50, 1, 96, 96])
getting model out
Initial input shape: torch.Size([50, 1, 96, 96])

inputblocks
Before block 0, shape: torch.Size([50, 1, 96, 96])
After block 0, shape: torch.Size([50, 128, 96, 96])
-
Before block 1, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 1, shape: torch.Size([50, 128, 96, 96])
-
Before block 2, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 2, shape: torch.Size([50, 128, 96, 96])
-
Before block 3, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 3, shape: torch.Size([50, 128, 96, 96])
-
Before block 4, shape: torch.Size([50, 128, 96, 96])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 256])
After block 4, shape: torch.Size([50, 128, 48, 48])
-
Before block 5, shape: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 48, 48])
-
Before block 8, shape: torch.Size([50, 256, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 8, shape: torch.Size([50, 256, 24, 24])
-
Before block 9, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 9, shape: torch.Size([50, 256, 24, 24])
-
Before block 10, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 10, shape: torch.Size([50, 256, 24, 24])
-
Before block 11, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 11, shape: torch.Size([50, 256, 24, 24])
-

Before middle block, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
in unet attention block!
x shape torch.Size([50, 256, 24, 24])
out dims torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])


After middle block, shape: torch.Size([50, 256, 24, 24])
-



outputblocks
Before block 0, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 0, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 0, shape: torch.Size([50, 256, 24, 24])
-
Before block 1, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 1, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 1, shape: torch.Size([50, 256, 24, 24])
-
Before block 2, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 2, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 2, shape: torch.Size([50, 256, 24, 24])
-
Before block 3, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 3, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 3, shape: torch.Size([50, 256, 48, 48])
-
Before block 4, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 4, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 4, shape: torch.Size([50, 256, 48, 48])
-
Before block 5, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 5, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 6, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 7, shape: torch.Size([50, 384, 48, 48])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 96, 96])
-
Before block 8, shape: torch.Size([50, 256, 96, 96])
After concatenation in upsampling block 8, shape: torch.Size([50, 384, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 8, shape: torch.Size([50, 128, 96, 96])
-
Before block 9, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 9, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 9, shape: torch.Size([50, 128, 96, 96])
-
Before block 10, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 10, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 10, shape: torch.Size([50, 128, 96, 96])
-
Before block 11, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 11, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 11, shape: torch.Size([50, 128, 96, 96])
-

Before Final layer shape: torch.Size([50, 128, 96, 96])
Final output shape: torch.Size([50, 1, 96, 96])
model out shape:  torch.Size([50, 1, 96, 96])
iAM IN THE FORWARD METHOD OF THE WEIRD GUASSIAN IN cond_DDPM.py. I WILL BE CALLING p_losses
i am in p_losses in guassian which seems to be crucial to everything
conditioning vector shape:  torch.Size([50, 512])
in plosses i am getting a noisy image x
x shape:  torch.Size([50, 1, 96, 96])
getting model out
Initial input shape: torch.Size([50, 1, 96, 96])

inputblocks
Before block 0, shape: torch.Size([50, 1, 96, 96])
After block 0, shape: torch.Size([50, 128, 96, 96])
-
Before block 1, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 1, shape: torch.Size([50, 128, 96, 96])
-
Before block 2, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 2, shape: torch.Size([50, 128, 96, 96])
-
Before block 3, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 3, shape: torch.Size([50, 128, 96, 96])
-
Before block 4, shape: torch.Size([50, 128, 96, 96])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 256])
After block 4, shape: torch.Size([50, 128, 48, 48])
-
Before block 5, shape: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 48, 48])
-
Before block 8, shape: torch.Size([50, 256, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 8, shape: torch.Size([50, 256, 24, 24])
-
Before block 9, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 9, shape: torch.Size([50, 256, 24, 24])
-
Before block 10, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 10, shape: torch.Size([50, 256, 24, 24])
-
Before block 11, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 11, shape: torch.Size([50, 256, 24, 24])
-

Before middle block, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
in unet attention block!
x shape torch.Size([50, 256, 24, 24])
out dims torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])


After middle block, shape: torch.Size([50, 256, 24, 24])
-



outputblocks
Before block 0, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 0, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 0, shape: torch.Size([50, 256, 24, 24])
-
Before block 1, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 1, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 1, shape: torch.Size([50, 256, 24, 24])
-
Before block 2, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 2, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 2, shape: torch.Size([50, 256, 24, 24])
-
Before block 3, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 3, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 3, shape: torch.Size([50, 256, 48, 48])
-
Before block 4, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 4, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 4, shape: torch.Size([50, 256, 48, 48])
-
Before block 5, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 5, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 6, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 7, shape: torch.Size([50, 384, 48, 48])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 96, 96])
-
Before block 8, shape: torch.Size([50, 256, 96, 96])
After concatenation in upsampling block 8, shape: torch.Size([50, 384, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 8, shape: torch.Size([50, 128, 96, 96])
-
Before block 9, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 9, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 9, shape: torch.Size([50, 128, 96, 96])
-
Before block 10, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 10, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 10, shape: torch.Size([50, 128, 96, 96])
-
Before block 11, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 11, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 11, shape: torch.Size([50, 128, 96, 96])
-

Before Final layer shape: torch.Size([50, 128, 96, 96])
Final output shape: torch.Size([50, 1, 96, 96])
model out shape:  torch.Size([50, 1, 96, 96])
reconstruction shape torch.Size([50, 1, 96, 96])
reconstruction tensor([[[[0.0182, 0.0159, 0.0181,  ..., 0.0186, 0.0205, 0.0231],
          [0.0259, 0.0153, 0.0144,  ..., 0.0126, 0.0160, 0.0161],
          [0.0174, 0.0086, 0.0199,  ..., 0.0201, 0.0061, 0.0101],
          ...,
          [0.0185, 0.0074, 0.0186,  ..., 0.0216, 0.0132, 0.0142],
          [0.0190, 0.0100, 0.0107,  ..., 0.0162, 0.0186, 0.0168],
          [0.0106, 0.0097, 0.0141,  ..., 0.0156, 0.0177, 0.0158]]],


        [[[0.0194, 0.0173, 0.0194,  ..., 0.0203, 0.0221, 0.0245],
          [0.0273, 0.0164, 0.0157,  ..., 0.0140, 0.0170, 0.0169],
          [0.0187, 0.0101, 0.0214,  ..., 0.0219, 0.0073, 0.0110],
          ...,
          [0.0195, 0.0086, 0.0197,  ..., 0.0232, 0.0146, 0.0155],
          [0.0205, 0.0113, 0.0118,  ..., 0.0176, 0.0201, 0.0182],
          [0.0116, 0.0110, 0.0151,  ..., 0.0172, 0.0192, 0.0170]]],


        [[[0.0201, 0.0183, 0.0204,  ..., 0.0216, 0.0233, 0.0256],
          [0.0285, 0.0177, 0.0173,  ..., 0.0155, 0.0182, 0.0179],
          [0.0197, 0.0114, 0.0226,  ..., 0.0232, 0.0085, 0.0117],
          ...,
          [0.0209, 0.0102, 0.0208,  ..., 0.0243, 0.0160, 0.0165],
          [0.0218, 0.0128, 0.0131,  ..., 0.0189, 0.0215, 0.0195],
          [0.0128, 0.0122, 0.0163,  ..., 0.0184, 0.0203, 0.0179]]],


        ...,


        [[[0.0210, 0.0179, 0.0196,  ..., 0.0196, 0.0188, 0.0235],
          [0.0243, 0.0112, 0.0132,  ..., 0.0116, 0.0110, 0.0122],
          [0.0187, 0.0085, 0.0201,  ..., 0.0236, 0.0109, 0.0125],
          ...,
          [0.0183, 0.0068, 0.0179,  ..., 0.0234, 0.0133, 0.0138],
          [0.0205, 0.0091, 0.0098,  ..., 0.0153, 0.0142, 0.0151],
          [0.0156, 0.0138, 0.0161,  ..., 0.0181, 0.0180, 0.0187]]],


        [[[0.0219, 0.0194, 0.0206,  ..., 0.0205, 0.0200, 0.0243],
          [0.0255, 0.0127, 0.0142,  ..., 0.0125, 0.0120, 0.0133],
          [0.0196, 0.0095, 0.0209,  ..., 0.0243, 0.0115, 0.0128],
          ...,
          [0.0190, 0.0076, 0.0184,  ..., 0.0239, 0.0139, 0.0145],
          [0.0213, 0.0101, 0.0106,  ..., 0.0160, 0.0153, 0.0158],
          [0.0156, 0.0145, 0.0166,  ..., 0.0185, 0.0187, 0.0190]]],


        [[[0.0216, 0.0193, 0.0203,  ..., 0.0195, 0.0201, 0.0234],
          [0.0258, 0.0134, 0.0143,  ..., 0.0120, 0.0129, 0.0133],
          [0.0192, 0.0092, 0.0201,  ..., 0.0228, 0.0107, 0.0119],
          ...,
          [0.0187, 0.0068, 0.0172,  ..., 0.0229, 0.0132, 0.0137],
          [0.0216, 0.0107, 0.0101,  ..., 0.0155, 0.0156, 0.0157],
          [0.0143, 0.0138, 0.0159,  ..., 0.0176, 0.0180, 0.0176]]]],
       device='cuda:0')
FINAL VOLUME (DDPM) shape torch.Size([96, 96, 50])
FINAL VOLUME tensor([[[0.0182, 0.0194, 0.0201,  ..., 0.0210, 0.0219, 0.0216],
         [0.0159, 0.0173, 0.0183,  ..., 0.0179, 0.0194, 0.0193],
         [0.0181, 0.0194, 0.0204,  ..., 0.0196, 0.0206, 0.0203],
         ...,
         [0.0186, 0.0203, 0.0216,  ..., 0.0196, 0.0205, 0.0195],
         [0.0205, 0.0221, 0.0233,  ..., 0.0188, 0.0200, 0.0201],
         [0.0231, 0.0245, 0.0256,  ..., 0.0235, 0.0243, 0.0234]],

        [[0.0259, 0.0273, 0.0285,  ..., 0.0243, 0.0255, 0.0258],
         [0.0153, 0.0164, 0.0177,  ..., 0.0112, 0.0127, 0.0134],
         [0.0144, 0.0157, 0.0173,  ..., 0.0132, 0.0142, 0.0143],
         ...,
         [0.0126, 0.0140, 0.0155,  ..., 0.0116, 0.0125, 0.0120],
         [0.0160, 0.0170, 0.0182,  ..., 0.0110, 0.0120, 0.0129],
         [0.0161, 0.0169, 0.0179,  ..., 0.0122, 0.0133, 0.0133]],

        [[0.0174, 0.0187, 0.0197,  ..., 0.0187, 0.0196, 0.0192],
         [0.0086, 0.0101, 0.0114,  ..., 0.0085, 0.0095, 0.0092],
         [0.0199, 0.0214, 0.0226,  ..., 0.0201, 0.0209, 0.0201],
         ...,
         [0.0201, 0.0219, 0.0232,  ..., 0.0236, 0.0243, 0.0228],
         [0.0061, 0.0073, 0.0085,  ..., 0.0109, 0.0115, 0.0107],
         [0.0101, 0.0110, 0.0117,  ..., 0.0125, 0.0128, 0.0119]],

        ...,

        [[0.0185, 0.0195, 0.0209,  ..., 0.0183, 0.0190, 0.0187],
         [0.0074, 0.0086, 0.0102,  ..., 0.0068, 0.0076, 0.0068],
         [0.0186, 0.0197, 0.0208,  ..., 0.0179, 0.0184, 0.0172],
         ...,
         [0.0216, 0.0232, 0.0243,  ..., 0.0234, 0.0239, 0.0229],
         [0.0132, 0.0146, 0.0160,  ..., 0.0133, 0.0139, 0.0132],
         [0.0142, 0.0155, 0.0165,  ..., 0.0138, 0.0145, 0.0137]],

        [[0.0190, 0.0205, 0.0218,  ..., 0.0205, 0.0213, 0.0216],
         [0.0100, 0.0113, 0.0128,  ..., 0.0091, 0.0101, 0.0107],
         [0.0107, 0.0118, 0.0131,  ..., 0.0098, 0.0106, 0.0101],
         ...,
         [0.0162, 0.0176, 0.0189,  ..., 0.0153, 0.0160, 0.0155],
         [0.0186, 0.0201, 0.0215,  ..., 0.0142, 0.0153, 0.0156],
         [0.0168, 0.0182, 0.0195,  ..., 0.0151, 0.0158, 0.0157]],

        [[0.0106, 0.0116, 0.0128,  ..., 0.0156, 0.0156, 0.0143],
         [0.0097, 0.0110, 0.0122,  ..., 0.0138, 0.0145, 0.0138],
         [0.0141, 0.0151, 0.0163,  ..., 0.0161, 0.0166, 0.0159],
         ...,
         [0.0156, 0.0172, 0.0184,  ..., 0.0181, 0.0185, 0.0176],
         [0.0177, 0.0192, 0.0203,  ..., 0.0180, 0.0187, 0.0180],
         [0.0158, 0.0170, 0.0179,  ..., 0.0187, 0.0190, 0.0176]]],
       device='cuda:0')
unsqueeze final volume shape (DDPM2d) torch.Size([1, 1, 96, 96, 50])
unsqueeze final volume (DDPM 2D) tensor([[[[[0.0182, 0.0194, 0.0201,  ..., 0.0210, 0.0219, 0.0216],
           [0.0159, 0.0173, 0.0183,  ..., 0.0179, 0.0194, 0.0193],
           [0.0181, 0.0194, 0.0204,  ..., 0.0196, 0.0206, 0.0203],
           ...,
           [0.0186, 0.0203, 0.0216,  ..., 0.0196, 0.0205, 0.0195],
           [0.0205, 0.0221, 0.0233,  ..., 0.0188, 0.0200, 0.0201],
           [0.0231, 0.0245, 0.0256,  ..., 0.0235, 0.0243, 0.0234]],

          [[0.0259, 0.0273, 0.0285,  ..., 0.0243, 0.0255, 0.0258],
           [0.0153, 0.0164, 0.0177,  ..., 0.0112, 0.0127, 0.0134],
           [0.0144, 0.0157, 0.0173,  ..., 0.0132, 0.0142, 0.0143],
           ...,
           [0.0126, 0.0140, 0.0155,  ..., 0.0116, 0.0125, 0.0120],
           [0.0160, 0.0170, 0.0182,  ..., 0.0110, 0.0120, 0.0129],
           [0.0161, 0.0169, 0.0179,  ..., 0.0122, 0.0133, 0.0133]],

          [[0.0174, 0.0187, 0.0197,  ..., 0.0187, 0.0196, 0.0192],
           [0.0086, 0.0101, 0.0114,  ..., 0.0085, 0.0095, 0.0092],
           [0.0199, 0.0214, 0.0226,  ..., 0.0201, 0.0209, 0.0201],
           ...,
           [0.0201, 0.0219, 0.0232,  ..., 0.0236, 0.0243, 0.0228],
           [0.0061, 0.0073, 0.0085,  ..., 0.0109, 0.0115, 0.0107],
           [0.0101, 0.0110, 0.0117,  ..., 0.0125, 0.0128, 0.0119]],

          ...,

          [[0.0185, 0.0195, 0.0209,  ..., 0.0183, 0.0190, 0.0187],
           [0.0074, 0.0086, 0.0102,  ..., 0.0068, 0.0076, 0.0068],
           [0.0186, 0.0197, 0.0208,  ..., 0.0179, 0.0184, 0.0172],
           ...,
           [0.0216, 0.0232, 0.0243,  ..., 0.0234, 0.0239, 0.0229],
           [0.0132, 0.0146, 0.0160,  ..., 0.0133, 0.0139, 0.0132],
           [0.0142, 0.0155, 0.0165,  ..., 0.0138, 0.0145, 0.0137]],

          [[0.0190, 0.0205, 0.0218,  ..., 0.0205, 0.0213, 0.0216],
           [0.0100, 0.0113, 0.0128,  ..., 0.0091, 0.0101, 0.0107],
           [0.0107, 0.0118, 0.0131,  ..., 0.0098, 0.0106, 0.0101],
           ...,
           [0.0162, 0.0176, 0.0189,  ..., 0.0153, 0.0160, 0.0155],
           [0.0186, 0.0201, 0.0215,  ..., 0.0142, 0.0153, 0.0156],
           [0.0168, 0.0182, 0.0195,  ..., 0.0151, 0.0158, 0.0157]],

          [[0.0106, 0.0116, 0.0128,  ..., 0.0156, 0.0156, 0.0143],
           [0.0097, 0.0110, 0.0122,  ..., 0.0138, 0.0145, 0.0138],
           [0.0141, 0.0151, 0.0163,  ..., 0.0161, 0.0166, 0.0159],
           ...,
           [0.0156, 0.0172, 0.0184,  ..., 0.0181, 0.0185, 0.0176],
           [0.0177, 0.0192, 0.0203,  ..., 0.0180, 0.0187, 0.0180],
           [0.0158, 0.0170, 0.0179,  ..., 0.0187, 0.0190, 0.0176]]]]],
       device='cuda:0')
==========
IN _TEST_STEP
==========
ERODING BRAIN MASK
MEDIAN FILTERING
SAVING OUTPUT - ORIGINAL, FINAL, MASK ETC
SAVING IMAGES!
Testing:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [00:36<00:28,  3.16s/it]==========
IN DDPM ON TEST STEP
==========
THE WEIRD CONDITION BIT CALLED "features" in DDPM_2D
IN SPARK ENCODER FORWARDDD
x in shape torch.Size([50, 1, 96, 96])
out features torch.Size([50, 512])
i'm i DDPM2d forward block (whch is basically the encoder)
Context vector c shape: torch.Size([50, 512])
shape features:  torch.Size([50, 512])
additng features to latern space
latent space: []
iAM IN THE FORWARD METHOD OF THE WEIRD GUASSIAN IN cond_DDPM.py. I WILL BE CALLING p_losses
i am in p_losses in guassian which seems to be crucial to everything
conditioning vector shape:  torch.Size([50, 512])
in plosses i am getting a noisy image x
x shape:  torch.Size([50, 1, 96, 96])
getting model out
Initial input shape: torch.Size([50, 1, 96, 96])

inputblocks
Before block 0, shape: torch.Size([50, 1, 96, 96])
After block 0, shape: torch.Size([50, 128, 96, 96])
-
Before block 1, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 1, shape: torch.Size([50, 128, 96, 96])
-
Before block 2, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 2, shape: torch.Size([50, 128, 96, 96])
-
Before block 3, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 3, shape: torch.Size([50, 128, 96, 96])
-
Before block 4, shape: torch.Size([50, 128, 96, 96])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 256])
After block 4, shape: torch.Size([50, 128, 48, 48])
-
Before block 5, shape: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 48, 48])
-
Before block 8, shape: torch.Size([50, 256, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 8, shape: torch.Size([50, 256, 24, 24])
-
Before block 9, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 9, shape: torch.Size([50, 256, 24, 24])
-
Before block 10, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 10, shape: torch.Size([50, 256, 24, 24])
-
Before block 11, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 11, shape: torch.Size([50, 256, 24, 24])
-

Before middle block, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
in unet attention block!
x shape torch.Size([50, 256, 24, 24])
out dims torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])


After middle block, shape: torch.Size([50, 256, 24, 24])
-



outputblocks
Before block 0, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 0, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 0, shape: torch.Size([50, 256, 24, 24])
-
Before block 1, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 1, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 1, shape: torch.Size([50, 256, 24, 24])
-
Before block 2, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 2, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 2, shape: torch.Size([50, 256, 24, 24])
-
Before block 3, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 3, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 3, shape: torch.Size([50, 256, 48, 48])
-
Before block 4, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 4, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 4, shape: torch.Size([50, 256, 48, 48])
-
Before block 5, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 5, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 6, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 7, shape: torch.Size([50, 384, 48, 48])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 96, 96])
-
Before block 8, shape: torch.Size([50, 256, 96, 96])
After concatenation in upsampling block 8, shape: torch.Size([50, 384, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 8, shape: torch.Size([50, 128, 96, 96])
-
Before block 9, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 9, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 9, shape: torch.Size([50, 128, 96, 96])
-
Before block 10, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 10, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 10, shape: torch.Size([50, 128, 96, 96])
-
Before block 11, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 11, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 11, shape: torch.Size([50, 128, 96, 96])
-

Before Final layer shape: torch.Size([50, 128, 96, 96])
Final output shape: torch.Size([50, 1, 96, 96])
model out shape:  torch.Size([50, 1, 96, 96])
iAM IN THE FORWARD METHOD OF THE WEIRD GUASSIAN IN cond_DDPM.py. I WILL BE CALLING p_losses
i am in p_losses in guassian which seems to be crucial to everything
conditioning vector shape:  torch.Size([50, 512])
in plosses i am getting a noisy image x
x shape:  torch.Size([50, 1, 96, 96])
getting model out
Initial input shape: torch.Size([50, 1, 96, 96])

inputblocks
Before block 0, shape: torch.Size([50, 1, 96, 96])
After block 0, shape: torch.Size([50, 128, 96, 96])
-
Before block 1, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 1, shape: torch.Size([50, 128, 96, 96])
-
Before block 2, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 2, shape: torch.Size([50, 128, 96, 96])
-
Before block 3, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 3, shape: torch.Size([50, 128, 96, 96])
-
Before block 4, shape: torch.Size([50, 128, 96, 96])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 256])
After block 4, shape: torch.Size([50, 128, 48, 48])
-
Before block 5, shape: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 48, 48])
-
Before block 8, shape: torch.Size([50, 256, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 8, shape: torch.Size([50, 256, 24, 24])
-
Before block 9, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 9, shape: torch.Size([50, 256, 24, 24])
-
Before block 10, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 10, shape: torch.Size([50, 256, 24, 24])
-
Before block 11, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 11, shape: torch.Size([50, 256, 24, 24])
-

Before middle block, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
in unet attention block!
x shape torch.Size([50, 256, 24, 24])
out dims torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])


After middle block, shape: torch.Size([50, 256, 24, 24])
-



outputblocks
Before block 0, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 0, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 0, shape: torch.Size([50, 256, 24, 24])
-
Before block 1, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 1, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 1, shape: torch.Size([50, 256, 24, 24])
-
Before block 2, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 2, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 2, shape: torch.Size([50, 256, 24, 24])
-
Before block 3, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 3, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 3, shape: torch.Size([50, 256, 48, 48])
-
Before block 4, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 4, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 4, shape: torch.Size([50, 256, 48, 48])
-
Before block 5, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 5, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 6, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 7, shape: torch.Size([50, 384, 48, 48])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 96, 96])
-
Before block 8, shape: torch.Size([50, 256, 96, 96])
After concatenation in upsampling block 8, shape: torch.Size([50, 384, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 8, shape: torch.Size([50, 128, 96, 96])
-
Before block 9, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 9, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 9, shape: torch.Size([50, 128, 96, 96])
-
Before block 10, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 10, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 10, shape: torch.Size([50, 128, 96, 96])
-
Before block 11, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 11, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 11, shape: torch.Size([50, 128, 96, 96])
-

Before Final layer shape: torch.Size([50, 128, 96, 96])
Final output shape: torch.Size([50, 1, 96, 96])
model out shape:  torch.Size([50, 1, 96, 96])
iAM IN THE FORWARD METHOD OF THE WEIRD GUASSIAN IN cond_DDPM.py. I WILL BE CALLING p_losses
i am in p_losses in guassian which seems to be crucial to everything
conditioning vector shape:  torch.Size([50, 512])
in plosses i am getting a noisy image x
x shape:  torch.Size([50, 1, 96, 96])
getting model out
Initial input shape: torch.Size([50, 1, 96, 96])

inputblocks
Before block 0, shape: torch.Size([50, 1, 96, 96])
After block 0, shape: torch.Size([50, 128, 96, 96])
-
Before block 1, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 1, shape: torch.Size([50, 128, 96, 96])
-
Before block 2, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 2, shape: torch.Size([50, 128, 96, 96])
-
Before block 3, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 3, shape: torch.Size([50, 128, 96, 96])
-
Before block 4, shape: torch.Size([50, 128, 96, 96])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 256])
After block 4, shape: torch.Size([50, 128, 48, 48])
-
Before block 5, shape: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 48, 48])
-
Before block 8, shape: torch.Size([50, 256, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 8, shape: torch.Size([50, 256, 24, 24])
-
Before block 9, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 9, shape: torch.Size([50, 256, 24, 24])
-
Before block 10, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 10, shape: torch.Size([50, 256, 24, 24])
-
Before block 11, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 11, shape: torch.Size([50, 256, 24, 24])
-

Before middle block, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
in unet attention block!
x shape torch.Size([50, 256, 24, 24])
out dims torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])


After middle block, shape: torch.Size([50, 256, 24, 24])
-



outputblocks
Before block 0, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 0, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 0, shape: torch.Size([50, 256, 24, 24])
-
Before block 1, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 1, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 1, shape: torch.Size([50, 256, 24, 24])
-
Before block 2, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 2, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 2, shape: torch.Size([50, 256, 24, 24])
-
Before block 3, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 3, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 3, shape: torch.Size([50, 256, 48, 48])
-
Before block 4, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 4, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 4, shape: torch.Size([50, 256, 48, 48])
-
Before block 5, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 5, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 6, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 7, shape: torch.Size([50, 384, 48, 48])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 96, 96])
-
Before block 8, shape: torch.Size([50, 256, 96, 96])
After concatenation in upsampling block 8, shape: torch.Size([50, 384, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 8, shape: torch.Size([50, 128, 96, 96])
-
Before block 9, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 9, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 9, shape: torch.Size([50, 128, 96, 96])
-
Before block 10, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 10, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 10, shape: torch.Size([50, 128, 96, 96])
-
Before block 11, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 11, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 11, shape: torch.Size([50, 128, 96, 96])
-

Before Final layer shape: torch.Size([50, 128, 96, 96])
Final output shape: torch.Size([50, 1, 96, 96])
model out shape:  torch.Size([50, 1, 96, 96])
reconstruction shape torch.Size([50, 1, 96, 96])
reconstruction tensor([[[[0.0413, 0.0427, 0.0403,  ..., 0.0403, 0.0500, 0.0446],
          [0.0469, 0.0356, 0.0315,  ..., 0.0339, 0.0395, 0.0315],
          [0.0364, 0.0291, 0.0345,  ..., 0.0367, 0.0321, 0.0304],
          ...,
          [0.0421, 0.0292, 0.0374,  ..., 0.0382, 0.0352, 0.0300],
          [0.0472, 0.0400, 0.0329,  ..., 0.0343, 0.0496, 0.0380],
          [0.0250, 0.0331, 0.0326,  ..., 0.0326, 0.0448, 0.0236]]],


        [[[0.0407, 0.0426, 0.0396,  ..., 0.0396, 0.0496, 0.0433],
          [0.0470, 0.0361, 0.0315,  ..., 0.0337, 0.0396, 0.0309],
          [0.0361, 0.0293, 0.0347,  ..., 0.0369, 0.0326, 0.0300],
          ...,
          [0.0419, 0.0295, 0.0377,  ..., 0.0384, 0.0356, 0.0297],
          [0.0473, 0.0409, 0.0334,  ..., 0.0345, 0.0501, 0.0381],
          [0.0242, 0.0333, 0.0326,  ..., 0.0325, 0.0452, 0.0232]]],


        [[[0.0407, 0.0427, 0.0391,  ..., 0.0393, 0.0499, 0.0426],
          [0.0478, 0.0372, 0.0319,  ..., 0.0339, 0.0409, 0.0315],
          [0.0358, 0.0296, 0.0345,  ..., 0.0367, 0.0328, 0.0300],
          ...,
          [0.0417, 0.0298, 0.0379,  ..., 0.0383, 0.0361, 0.0299],
          [0.0477, 0.0418, 0.0339,  ..., 0.0349, 0.0516, 0.0386],
          [0.0240, 0.0338, 0.0326,  ..., 0.0325, 0.0457, 0.0230]]],


        ...,


        [[[0.0430, 0.0417, 0.0391,  ..., 0.0394, 0.0484, 0.0462],
          [0.0426, 0.0259, 0.0257,  ..., 0.0302, 0.0332, 0.0286],
          [0.0347, 0.0243, 0.0339,  ..., 0.0373, 0.0287, 0.0264],
          ...,
          [0.0404, 0.0251, 0.0360,  ..., 0.0361, 0.0286, 0.0247],
          [0.0457, 0.0330, 0.0289,  ..., 0.0291, 0.0391, 0.0317],
          [0.0288, 0.0328, 0.0314,  ..., 0.0317, 0.0410, 0.0251]]],


        [[[0.0417, 0.0407, 0.0382,  ..., 0.0386, 0.0481, 0.0452],
          [0.0414, 0.0255, 0.0248,  ..., 0.0290, 0.0330, 0.0282],
          [0.0338, 0.0231, 0.0321,  ..., 0.0353, 0.0275, 0.0253],
          ...,
          [0.0396, 0.0241, 0.0344,  ..., 0.0345, 0.0275, 0.0237],
          [0.0452, 0.0330, 0.0280,  ..., 0.0278, 0.0388, 0.0310],
          [0.0273, 0.0318, 0.0304,  ..., 0.0304, 0.0398, 0.0234]]],


        [[[0.0412, 0.0410, 0.0380,  ..., 0.0382, 0.0487, 0.0447],
          [0.0417, 0.0272, 0.0252,  ..., 0.0290, 0.0350, 0.0288],
          [0.0336, 0.0235, 0.0312,  ..., 0.0343, 0.0274, 0.0250],
          ...,
          [0.0396, 0.0245, 0.0340,  ..., 0.0338, 0.0277, 0.0233],
          [0.0460, 0.0351, 0.0287,  ..., 0.0285, 0.0409, 0.0316],
          [0.0264, 0.0317, 0.0297,  ..., 0.0298, 0.0401, 0.0228]]]],
       device='cuda:0')
FINAL VOLUME (DDPM) shape torch.Size([96, 96, 50])
FINAL VOLUME tensor([[[0.0413, 0.0407, 0.0407,  ..., 0.0430, 0.0417, 0.0412],
         [0.0427, 0.0426, 0.0427,  ..., 0.0417, 0.0407, 0.0410],
         [0.0403, 0.0396, 0.0391,  ..., 0.0391, 0.0382, 0.0380],
         ...,
         [0.0403, 0.0396, 0.0393,  ..., 0.0394, 0.0386, 0.0382],
         [0.0500, 0.0496, 0.0499,  ..., 0.0484, 0.0481, 0.0487],
         [0.0446, 0.0433, 0.0426,  ..., 0.0462, 0.0452, 0.0447]],

        [[0.0469, 0.0470, 0.0478,  ..., 0.0426, 0.0414, 0.0417],
         [0.0356, 0.0361, 0.0372,  ..., 0.0259, 0.0255, 0.0272],
         [0.0315, 0.0315, 0.0319,  ..., 0.0257, 0.0248, 0.0252],
         ...,
         [0.0339, 0.0337, 0.0339,  ..., 0.0302, 0.0290, 0.0290],
         [0.0395, 0.0396, 0.0409,  ..., 0.0332, 0.0330, 0.0350],
         [0.0315, 0.0309, 0.0315,  ..., 0.0286, 0.0282, 0.0288]],

        [[0.0364, 0.0361, 0.0358,  ..., 0.0347, 0.0338, 0.0336],
         [0.0291, 0.0293, 0.0296,  ..., 0.0243, 0.0231, 0.0235],
         [0.0345, 0.0347, 0.0345,  ..., 0.0339, 0.0321, 0.0312],
         ...,
         [0.0367, 0.0369, 0.0367,  ..., 0.0373, 0.0353, 0.0343],
         [0.0321, 0.0326, 0.0328,  ..., 0.0287, 0.0275, 0.0274],
         [0.0304, 0.0300, 0.0300,  ..., 0.0264, 0.0253, 0.0250]],

        ...,

        [[0.0421, 0.0419, 0.0417,  ..., 0.0404, 0.0396, 0.0396],
         [0.0292, 0.0295, 0.0298,  ..., 0.0251, 0.0241, 0.0245],
         [0.0374, 0.0377, 0.0379,  ..., 0.0360, 0.0344, 0.0340],
         ...,
         [0.0382, 0.0384, 0.0383,  ..., 0.0361, 0.0345, 0.0338],
         [0.0352, 0.0356, 0.0361,  ..., 0.0286, 0.0275, 0.0277],
         [0.0300, 0.0297, 0.0299,  ..., 0.0247, 0.0237, 0.0233]],

        [[0.0472, 0.0473, 0.0477,  ..., 0.0457, 0.0452, 0.0460],
         [0.0400, 0.0409, 0.0418,  ..., 0.0330, 0.0330, 0.0351],
         [0.0329, 0.0334, 0.0339,  ..., 0.0289, 0.0280, 0.0287],
         ...,
         [0.0343, 0.0345, 0.0349,  ..., 0.0291, 0.0278, 0.0285],
         [0.0496, 0.0501, 0.0516,  ..., 0.0391, 0.0388, 0.0409],
         [0.0380, 0.0381, 0.0386,  ..., 0.0317, 0.0310, 0.0316]],

        [[0.0250, 0.0242, 0.0240,  ..., 0.0288, 0.0273, 0.0264],
         [0.0331, 0.0333, 0.0338,  ..., 0.0328, 0.0318, 0.0317],
         [0.0326, 0.0326, 0.0326,  ..., 0.0314, 0.0304, 0.0297],
         ...,
         [0.0326, 0.0325, 0.0325,  ..., 0.0317, 0.0304, 0.0298],
         [0.0448, 0.0452, 0.0457,  ..., 0.0410, 0.0398, 0.0401],
         [0.0236, 0.0232, 0.0230,  ..., 0.0251, 0.0234, 0.0228]]],
       device='cuda:0')
unsqueeze final volume shape (DDPM2d) torch.Size([1, 1, 96, 96, 50])
unsqueeze final volume (DDPM 2D) tensor([[[[[0.0413, 0.0407, 0.0407,  ..., 0.0430, 0.0417, 0.0412],
           [0.0427, 0.0426, 0.0427,  ..., 0.0417, 0.0407, 0.0410],
           [0.0403, 0.0396, 0.0391,  ..., 0.0391, 0.0382, 0.0380],
           ...,
           [0.0403, 0.0396, 0.0393,  ..., 0.0394, 0.0386, 0.0382],
           [0.0500, 0.0496, 0.0499,  ..., 0.0484, 0.0481, 0.0487],
           [0.0446, 0.0433, 0.0426,  ..., 0.0462, 0.0452, 0.0447]],

          [[0.0469, 0.0470, 0.0478,  ..., 0.0426, 0.0414, 0.0417],
           [0.0356, 0.0361, 0.0372,  ..., 0.0259, 0.0255, 0.0272],
           [0.0315, 0.0315, 0.0319,  ..., 0.0257, 0.0248, 0.0252],
           ...,
           [0.0339, 0.0337, 0.0339,  ..., 0.0302, 0.0290, 0.0290],
           [0.0395, 0.0396, 0.0409,  ..., 0.0332, 0.0330, 0.0350],
           [0.0315, 0.0309, 0.0315,  ..., 0.0286, 0.0282, 0.0288]],

          [[0.0364, 0.0361, 0.0358,  ..., 0.0347, 0.0338, 0.0336],
           [0.0291, 0.0293, 0.0296,  ..., 0.0243, 0.0231, 0.0235],
           [0.0345, 0.0347, 0.0345,  ..., 0.0339, 0.0321, 0.0312],
           ...,
           [0.0367, 0.0369, 0.0367,  ..., 0.0373, 0.0353, 0.0343],
           [0.0321, 0.0326, 0.0328,  ..., 0.0287, 0.0275, 0.0274],
           [0.0304, 0.0300, 0.0300,  ..., 0.0264, 0.0253, 0.0250]],

          ...,

          [[0.0421, 0.0419, 0.0417,  ..., 0.0404, 0.0396, 0.0396],
           [0.0292, 0.0295, 0.0298,  ..., 0.0251, 0.0241, 0.0245],
           [0.0374, 0.0377, 0.0379,  ..., 0.0360, 0.0344, 0.0340],
           ...,
           [0.0382, 0.0384, 0.0383,  ..., 0.0361, 0.0345, 0.0338],
           [0.0352, 0.0356, 0.0361,  ..., 0.0286, 0.0275, 0.0277],
           [0.0300, 0.0297, 0.0299,  ..., 0.0247, 0.0237, 0.0233]],

          [[0.0472, 0.0473, 0.0477,  ..., 0.0457, 0.0452, 0.0460],
           [0.0400, 0.0409, 0.0418,  ..., 0.0330, 0.0330, 0.0351],
           [0.0329, 0.0334, 0.0339,  ..., 0.0289, 0.0280, 0.0287],
           ...,
           [0.0343, 0.0345, 0.0349,  ..., 0.0291, 0.0278, 0.0285],
           [0.0496, 0.0501, 0.0516,  ..., 0.0391, 0.0388, 0.0409],
           [0.0380, 0.0381, 0.0386,  ..., 0.0317, 0.0310, 0.0316]],

          [[0.0250, 0.0242, 0.0240,  ..., 0.0288, 0.0273, 0.0264],
           [0.0331, 0.0333, 0.0338,  ..., 0.0328, 0.0318, 0.0317],
           [0.0326, 0.0326, 0.0326,  ..., 0.0314, 0.0304, 0.0297],
           ...,
           [0.0326, 0.0325, 0.0325,  ..., 0.0317, 0.0304, 0.0298],
           [0.0448, 0.0452, 0.0457,  ..., 0.0410, 0.0398, 0.0401],
           [0.0236, 0.0232, 0.0230,  ..., 0.0251, 0.0234, 0.0228]]]]],
       device='cuda:0')
==========
IN _TEST_STEP
==========
ERODING BRAIN MASK
MEDIAN FILTERING
SAVING OUTPUT - ORIGINAL, FINAL, MASK ETC
SAVING IMAGES!
Testing:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [00:39<00:25,  3.16s/it]==========
IN DDPM ON TEST STEP
==========
THE WEIRD CONDITION BIT CALLED "features" in DDPM_2D
IN SPARK ENCODER FORWARDDD
x in shape torch.Size([50, 1, 96, 96])
out features torch.Size([50, 512])
i'm i DDPM2d forward block (whch is basically the encoder)
Context vector c shape: torch.Size([50, 512])
shape features:  torch.Size([50, 512])
additng features to latern space
latent space: []
iAM IN THE FORWARD METHOD OF THE WEIRD GUASSIAN IN cond_DDPM.py. I WILL BE CALLING p_losses
i am in p_losses in guassian which seems to be crucial to everything
conditioning vector shape:  torch.Size([50, 512])
in plosses i am getting a noisy image x
x shape:  torch.Size([50, 1, 96, 96])
getting model out
Initial input shape: torch.Size([50, 1, 96, 96])

inputblocks
Before block 0, shape: torch.Size([50, 1, 96, 96])
After block 0, shape: torch.Size([50, 128, 96, 96])
-
Before block 1, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 1, shape: torch.Size([50, 128, 96, 96])
-
Before block 2, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 2, shape: torch.Size([50, 128, 96, 96])
-
Before block 3, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 3, shape: torch.Size([50, 128, 96, 96])
-
Before block 4, shape: torch.Size([50, 128, 96, 96])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 256])
After block 4, shape: torch.Size([50, 128, 48, 48])
-
Before block 5, shape: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 48, 48])
-
Before block 8, shape: torch.Size([50, 256, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 8, shape: torch.Size([50, 256, 24, 24])
-
Before block 9, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 9, shape: torch.Size([50, 256, 24, 24])
-
Before block 10, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 10, shape: torch.Size([50, 256, 24, 24])
-
Before block 11, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 11, shape: torch.Size([50, 256, 24, 24])
-

Before middle block, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
in unet attention block!
x shape torch.Size([50, 256, 24, 24])
out dims torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])


After middle block, shape: torch.Size([50, 256, 24, 24])
-



outputblocks
Before block 0, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 0, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 0, shape: torch.Size([50, 256, 24, 24])
-
Before block 1, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 1, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 1, shape: torch.Size([50, 256, 24, 24])
-
Before block 2, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 2, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 2, shape: torch.Size([50, 256, 24, 24])
-
Before block 3, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 3, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 3, shape: torch.Size([50, 256, 48, 48])
-
Before block 4, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 4, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 4, shape: torch.Size([50, 256, 48, 48])
-
Before block 5, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 5, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 6, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 7, shape: torch.Size([50, 384, 48, 48])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 96, 96])
-
Before block 8, shape: torch.Size([50, 256, 96, 96])
After concatenation in upsampling block 8, shape: torch.Size([50, 384, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 8, shape: torch.Size([50, 128, 96, 96])
-
Before block 9, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 9, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 9, shape: torch.Size([50, 128, 96, 96])
-
Before block 10, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 10, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 10, shape: torch.Size([50, 128, 96, 96])
-
Before block 11, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 11, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 11, shape: torch.Size([50, 128, 96, 96])
-

Before Final layer shape: torch.Size([50, 128, 96, 96])
Final output shape: torch.Size([50, 1, 96, 96])
model out shape:  torch.Size([50, 1, 96, 96])
iAM IN THE FORWARD METHOD OF THE WEIRD GUASSIAN IN cond_DDPM.py. I WILL BE CALLING p_losses
i am in p_losses in guassian which seems to be crucial to everything
conditioning vector shape:  torch.Size([50, 512])
in plosses i am getting a noisy image x
x shape:  torch.Size([50, 1, 96, 96])
getting model out
Initial input shape: torch.Size([50, 1, 96, 96])

inputblocks
Before block 0, shape: torch.Size([50, 1, 96, 96])
After block 0, shape: torch.Size([50, 128, 96, 96])
-
Before block 1, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 1, shape: torch.Size([50, 128, 96, 96])
-
Before block 2, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 2, shape: torch.Size([50, 128, 96, 96])
-
Before block 3, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 3, shape: torch.Size([50, 128, 96, 96])
-
Before block 4, shape: torch.Size([50, 128, 96, 96])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 256])
After block 4, shape: torch.Size([50, 128, 48, 48])
-
Before block 5, shape: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 48, 48])
-
Before block 8, shape: torch.Size([50, 256, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 8, shape: torch.Size([50, 256, 24, 24])
-
Before block 9, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 9, shape: torch.Size([50, 256, 24, 24])
-
Before block 10, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 10, shape: torch.Size([50, 256, 24, 24])
-
Before block 11, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 11, shape: torch.Size([50, 256, 24, 24])
-

Before middle block, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
in unet attention block!
x shape torch.Size([50, 256, 24, 24])
out dims torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])


After middle block, shape: torch.Size([50, 256, 24, 24])
-



outputblocks
Before block 0, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 0, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 0, shape: torch.Size([50, 256, 24, 24])
-
Before block 1, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 1, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 1, shape: torch.Size([50, 256, 24, 24])
-
Before block 2, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 2, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 2, shape: torch.Size([50, 256, 24, 24])
-
Before block 3, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 3, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 3, shape: torch.Size([50, 256, 48, 48])
-
Before block 4, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 4, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 4, shape: torch.Size([50, 256, 48, 48])
-
Before block 5, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 5, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 6, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 7, shape: torch.Size([50, 384, 48, 48])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 96, 96])
-
Before block 8, shape: torch.Size([50, 256, 96, 96])
After concatenation in upsampling block 8, shape: torch.Size([50, 384, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 8, shape: torch.Size([50, 128, 96, 96])
-
Before block 9, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 9, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 9, shape: torch.Size([50, 128, 96, 96])
-
Before block 10, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 10, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 10, shape: torch.Size([50, 128, 96, 96])
-
Before block 11, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 11, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 11, shape: torch.Size([50, 128, 96, 96])
-

Before Final layer shape: torch.Size([50, 128, 96, 96])
Final output shape: torch.Size([50, 1, 96, 96])
model out shape:  torch.Size([50, 1, 96, 96])
iAM IN THE FORWARD METHOD OF THE WEIRD GUASSIAN IN cond_DDPM.py. I WILL BE CALLING p_losses
i am in p_losses in guassian which seems to be crucial to everything
conditioning vector shape:  torch.Size([50, 512])
in plosses i am getting a noisy image x
x shape:  torch.Size([50, 1, 96, 96])
getting model out
Initial input shape: torch.Size([50, 1, 96, 96])

inputblocks
Before block 0, shape: torch.Size([50, 1, 96, 96])
After block 0, shape: torch.Size([50, 128, 96, 96])
-
Before block 1, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 1, shape: torch.Size([50, 128, 96, 96])
-
Before block 2, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 2, shape: torch.Size([50, 128, 96, 96])
-
Before block 3, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 3, shape: torch.Size([50, 128, 96, 96])
-
Before block 4, shape: torch.Size([50, 128, 96, 96])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 256])
After block 4, shape: torch.Size([50, 128, 48, 48])
-
Before block 5, shape: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 48, 48])
-
Before block 8, shape: torch.Size([50, 256, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 8, shape: torch.Size([50, 256, 24, 24])
-
Before block 9, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 9, shape: torch.Size([50, 256, 24, 24])
-
Before block 10, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 10, shape: torch.Size([50, 256, 24, 24])
-
Before block 11, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 11, shape: torch.Size([50, 256, 24, 24])
-

Before middle block, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
in unet attention block!
x shape torch.Size([50, 256, 24, 24])
out dims torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])


After middle block, shape: torch.Size([50, 256, 24, 24])
-



outputblocks
Before block 0, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 0, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 0, shape: torch.Size([50, 256, 24, 24])
-
Before block 1, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 1, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 1, shape: torch.Size([50, 256, 24, 24])
-
Before block 2, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 2, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 2, shape: torch.Size([50, 256, 24, 24])
-
Before block 3, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 3, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 3, shape: torch.Size([50, 256, 48, 48])
-
Before block 4, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 4, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 4, shape: torch.Size([50, 256, 48, 48])
-
Before block 5, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 5, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 6, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 7, shape: torch.Size([50, 384, 48, 48])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 96, 96])
-
Before block 8, shape: torch.Size([50, 256, 96, 96])
After concatenation in upsampling block 8, shape: torch.Size([50, 384, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 8, shape: torch.Size([50, 128, 96, 96])
-
Before block 9, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 9, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 9, shape: torch.Size([50, 128, 96, 96])
-
Before block 10, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 10, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 10, shape: torch.Size([50, 128, 96, 96])
-
Before block 11, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 11, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 11, shape: torch.Size([50, 128, 96, 96])
-

Before Final layer shape: torch.Size([50, 128, 96, 96])
Final output shape: torch.Size([50, 1, 96, 96])
model out shape:  torch.Size([50, 1, 96, 96])
reconstruction shape torch.Size([50, 1, 96, 96])
reconstruction tensor([[[[ 0.0068,  0.0052,  0.0100,  ...,  0.0099,  0.0132,  0.0111],
          [ 0.0140,  0.0042,  0.0021,  ...,  0.0023,  0.0112,  0.0082],
          [ 0.0070, -0.0003,  0.0091,  ...,  0.0068,  0.0028,  0.0042],
          ...,
          [ 0.0065, -0.0018,  0.0110,  ...,  0.0131,  0.0059,  0.0055],
          [ 0.0069,  0.0032,  0.0041,  ...,  0.0069,  0.0135,  0.0048],
          [ 0.0057,  0.0011,  0.0049,  ...,  0.0044,  0.0060,  0.0020]]],


        [[[ 0.0069,  0.0047,  0.0107,  ...,  0.0101,  0.0127,  0.0111],
          [ 0.0134,  0.0028,  0.0020,  ...,  0.0021,  0.0103,  0.0076],
          [ 0.0072, -0.0005,  0.0096,  ...,  0.0064,  0.0024,  0.0041],
          ...,
          [ 0.0064, -0.0023,  0.0115,  ...,  0.0136,  0.0059,  0.0055],
          [ 0.0060,  0.0020,  0.0041,  ...,  0.0068,  0.0130,  0.0043],
          [ 0.0050,  0.0000,  0.0047,  ...,  0.0041,  0.0048,  0.0010]]],


        [[[ 0.0073,  0.0052,  0.0108,  ...,  0.0101,  0.0130,  0.0113],
          [ 0.0136,  0.0028,  0.0021,  ...,  0.0018,  0.0106,  0.0078],
          [ 0.0073, -0.0007,  0.0097,  ...,  0.0067,  0.0026,  0.0046],
          ...,
          [ 0.0065, -0.0020,  0.0115,  ...,  0.0137,  0.0059,  0.0057],
          [ 0.0063,  0.0023,  0.0040,  ...,  0.0068,  0.0132,  0.0045],
          [ 0.0055,  0.0002,  0.0049,  ...,  0.0044,  0.0052,  0.0013]]],


        ...,


        [[[ 0.0104,  0.0065,  0.0106,  ...,  0.0094,  0.0113,  0.0131],
          [ 0.0156,  0.0034,  0.0018,  ...,  0.0020,  0.0085,  0.0063],
          [ 0.0100,  0.0005,  0.0078,  ...,  0.0060,  0.0034,  0.0063],
          ...,
          [ 0.0099,  0.0024,  0.0129,  ...,  0.0117,  0.0050,  0.0046],
          [ 0.0096,  0.0061,  0.0078,  ...,  0.0065,  0.0103,  0.0039],
          [ 0.0114,  0.0059,  0.0099,  ...,  0.0063,  0.0073,  0.0046]]],


        [[[ 0.0104,  0.0069,  0.0110,  ...,  0.0098,  0.0119,  0.0135],
          [ 0.0159,  0.0039,  0.0023,  ...,  0.0024,  0.0092,  0.0069],
          [ 0.0101,  0.0010,  0.0081,  ...,  0.0065,  0.0041,  0.0068],
          ...,
          [ 0.0103,  0.0028,  0.0132,  ...,  0.0125,  0.0058,  0.0052],
          [ 0.0099,  0.0065,  0.0081,  ...,  0.0071,  0.0110,  0.0042],
          [ 0.0114,  0.0063,  0.0102,  ...,  0.0068,  0.0081,  0.0052]]],


        [[[ 0.0100,  0.0070,  0.0111,  ...,  0.0102,  0.0122,  0.0135],
          [ 0.0159,  0.0049,  0.0031,  ...,  0.0033,  0.0098,  0.0071],
          [ 0.0103,  0.0018,  0.0088,  ...,  0.0072,  0.0048,  0.0070],
          ...,
          [ 0.0104,  0.0029,  0.0133,  ...,  0.0133,  0.0063,  0.0052],
          [ 0.0103,  0.0070,  0.0084,  ...,  0.0076,  0.0115,  0.0041],
          [ 0.0110,  0.0063,  0.0100,  ...,  0.0068,  0.0080,  0.0043]]]],
       device='cuda:0')
FINAL VOLUME (DDPM) shape torch.Size([96, 96, 50])
FINAL VOLUME tensor([[[ 0.0068,  0.0069,  0.0073,  ...,  0.0104,  0.0104,  0.0100],
         [ 0.0052,  0.0047,  0.0052,  ...,  0.0065,  0.0069,  0.0070],
         [ 0.0100,  0.0107,  0.0108,  ...,  0.0106,  0.0110,  0.0111],
         ...,
         [ 0.0099,  0.0101,  0.0101,  ...,  0.0094,  0.0098,  0.0102],
         [ 0.0132,  0.0127,  0.0130,  ...,  0.0113,  0.0119,  0.0122],
         [ 0.0111,  0.0111,  0.0113,  ...,  0.0131,  0.0135,  0.0135]],

        [[ 0.0140,  0.0134,  0.0136,  ...,  0.0156,  0.0159,  0.0159],
         [ 0.0042,  0.0028,  0.0028,  ...,  0.0034,  0.0039,  0.0049],
         [ 0.0021,  0.0020,  0.0021,  ...,  0.0018,  0.0023,  0.0031],
         ...,
         [ 0.0023,  0.0021,  0.0018,  ...,  0.0020,  0.0024,  0.0033],
         [ 0.0112,  0.0103,  0.0106,  ...,  0.0085,  0.0092,  0.0098],
         [ 0.0082,  0.0076,  0.0078,  ...,  0.0063,  0.0069,  0.0071]],

        [[ 0.0070,  0.0072,  0.0073,  ...,  0.0100,  0.0101,  0.0103],
         [-0.0003, -0.0005, -0.0007,  ...,  0.0005,  0.0010,  0.0018],
         [ 0.0091,  0.0096,  0.0097,  ...,  0.0078,  0.0081,  0.0088],
         ...,
         [ 0.0068,  0.0064,  0.0067,  ...,  0.0060,  0.0065,  0.0072],
         [ 0.0028,  0.0024,  0.0026,  ...,  0.0034,  0.0041,  0.0048],
         [ 0.0042,  0.0041,  0.0046,  ...,  0.0063,  0.0068,  0.0070]],

        ...,

        [[ 0.0065,  0.0064,  0.0065,  ...,  0.0099,  0.0103,  0.0104],
         [-0.0018, -0.0023, -0.0020,  ...,  0.0024,  0.0028,  0.0029],
         [ 0.0110,  0.0115,  0.0115,  ...,  0.0129,  0.0132,  0.0133],
         ...,
         [ 0.0131,  0.0136,  0.0137,  ...,  0.0117,  0.0125,  0.0133],
         [ 0.0059,  0.0059,  0.0059,  ...,  0.0050,  0.0058,  0.0063],
         [ 0.0055,  0.0055,  0.0057,  ...,  0.0046,  0.0052,  0.0052]],

        [[ 0.0069,  0.0060,  0.0063,  ...,  0.0096,  0.0099,  0.0103],
         [ 0.0032,  0.0020,  0.0023,  ...,  0.0061,  0.0065,  0.0070],
         [ 0.0041,  0.0041,  0.0040,  ...,  0.0078,  0.0081,  0.0084],
         ...,
         [ 0.0069,  0.0068,  0.0068,  ...,  0.0065,  0.0071,  0.0076],
         [ 0.0135,  0.0130,  0.0132,  ...,  0.0103,  0.0110,  0.0115],
         [ 0.0048,  0.0043,  0.0045,  ...,  0.0039,  0.0042,  0.0041]],

        [[ 0.0057,  0.0050,  0.0055,  ...,  0.0114,  0.0114,  0.0110],
         [ 0.0011,  0.0000,  0.0002,  ...,  0.0059,  0.0063,  0.0063],
         [ 0.0049,  0.0047,  0.0049,  ...,  0.0099,  0.0102,  0.0100],
         ...,
         [ 0.0044,  0.0041,  0.0044,  ...,  0.0063,  0.0068,  0.0068],
         [ 0.0060,  0.0048,  0.0052,  ...,  0.0073,  0.0081,  0.0080],
         [ 0.0020,  0.0010,  0.0013,  ...,  0.0046,  0.0052,  0.0043]]],
       device='cuda:0')
unsqueeze final volume shape (DDPM2d) torch.Size([1, 1, 96, 96, 50])
unsqueeze final volume (DDPM 2D) tensor([[[[[ 0.0068,  0.0069,  0.0073,  ...,  0.0104,  0.0104,  0.0100],
           [ 0.0052,  0.0047,  0.0052,  ...,  0.0065,  0.0069,  0.0070],
           [ 0.0100,  0.0107,  0.0108,  ...,  0.0106,  0.0110,  0.0111],
           ...,
           [ 0.0099,  0.0101,  0.0101,  ...,  0.0094,  0.0098,  0.0102],
           [ 0.0132,  0.0127,  0.0130,  ...,  0.0113,  0.0119,  0.0122],
           [ 0.0111,  0.0111,  0.0113,  ...,  0.0131,  0.0135,  0.0135]],

          [[ 0.0140,  0.0134,  0.0136,  ...,  0.0156,  0.0159,  0.0159],
           [ 0.0042,  0.0028,  0.0028,  ...,  0.0034,  0.0039,  0.0049],
           [ 0.0021,  0.0020,  0.0021,  ...,  0.0018,  0.0023,  0.0031],
           ...,
           [ 0.0023,  0.0021,  0.0018,  ...,  0.0020,  0.0024,  0.0033],
           [ 0.0112,  0.0103,  0.0106,  ...,  0.0085,  0.0092,  0.0098],
           [ 0.0082,  0.0076,  0.0078,  ...,  0.0063,  0.0069,  0.0071]],

          [[ 0.0070,  0.0072,  0.0073,  ...,  0.0100,  0.0101,  0.0103],
           [-0.0003, -0.0005, -0.0007,  ...,  0.0005,  0.0010,  0.0018],
           [ 0.0091,  0.0096,  0.0097,  ...,  0.0078,  0.0081,  0.0088],
           ...,
           [ 0.0068,  0.0064,  0.0067,  ...,  0.0060,  0.0065,  0.0072],
           [ 0.0028,  0.0024,  0.0026,  ...,  0.0034,  0.0041,  0.0048],
           [ 0.0042,  0.0041,  0.0046,  ...,  0.0063,  0.0068,  0.0070]],

          ...,

          [[ 0.0065,  0.0064,  0.0065,  ...,  0.0099,  0.0103,  0.0104],
           [-0.0018, -0.0023, -0.0020,  ...,  0.0024,  0.0028,  0.0029],
           [ 0.0110,  0.0115,  0.0115,  ...,  0.0129,  0.0132,  0.0133],
           ...,
           [ 0.0131,  0.0136,  0.0137,  ...,  0.0117,  0.0125,  0.0133],
           [ 0.0059,  0.0059,  0.0059,  ...,  0.0050,  0.0058,  0.0063],
           [ 0.0055,  0.0055,  0.0057,  ...,  0.0046,  0.0052,  0.0052]],

          [[ 0.0069,  0.0060,  0.0063,  ...,  0.0096,  0.0099,  0.0103],
           [ 0.0032,  0.0020,  0.0023,  ...,  0.0061,  0.0065,  0.0070],
           [ 0.0041,  0.0041,  0.0040,  ...,  0.0078,  0.0081,  0.0084],
           ...,
           [ 0.0069,  0.0068,  0.0068,  ...,  0.0065,  0.0071,  0.0076],
           [ 0.0135,  0.0130,  0.0132,  ...,  0.0103,  0.0110,  0.0115],
           [ 0.0048,  0.0043,  0.0045,  ...,  0.0039,  0.0042,  0.0041]],

          [[ 0.0057,  0.0050,  0.0055,  ...,  0.0114,  0.0114,  0.0110],
           [ 0.0011,  0.0000,  0.0002,  ...,  0.0059,  0.0063,  0.0063],
           [ 0.0049,  0.0047,  0.0049,  ...,  0.0099,  0.0102,  0.0100],
           ...,
           [ 0.0044,  0.0041,  0.0044,  ...,  0.0063,  0.0068,  0.0068],
           [ 0.0060,  0.0048,  0.0052,  ...,  0.0073,  0.0081,  0.0080],
           [ 0.0020,  0.0010,  0.0013,  ...,  0.0046,  0.0052,  0.0043]]]]],
       device='cuda:0')
==========
IN _TEST_STEP
==========
ERODING BRAIN MASK
MEDIAN FILTERING
SAVING OUTPUT - ORIGINAL, FINAL, MASK ETC
SAVING IMAGES!
Testing:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [00:42<00:22,  3.17s/it]==========
IN DDPM ON TEST STEP
==========
THE WEIRD CONDITION BIT CALLED "features" in DDPM_2D
IN SPARK ENCODER FORWARDDD
x in shape torch.Size([50, 1, 96, 96])
out features torch.Size([50, 512])
i'm i DDPM2d forward block (whch is basically the encoder)
Context vector c shape: torch.Size([50, 512])
shape features:  torch.Size([50, 512])
additng features to latern space
latent space: []
iAM IN THE FORWARD METHOD OF THE WEIRD GUASSIAN IN cond_DDPM.py. I WILL BE CALLING p_losses
i am in p_losses in guassian which seems to be crucial to everything
conditioning vector shape:  torch.Size([50, 512])
in plosses i am getting a noisy image x
x shape:  torch.Size([50, 1, 96, 96])
getting model out
Initial input shape: torch.Size([50, 1, 96, 96])

inputblocks
Before block 0, shape: torch.Size([50, 1, 96, 96])
After block 0, shape: torch.Size([50, 128, 96, 96])
-
Before block 1, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 1, shape: torch.Size([50, 128, 96, 96])
-
Before block 2, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 2, shape: torch.Size([50, 128, 96, 96])
-
Before block 3, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 3, shape: torch.Size([50, 128, 96, 96])
-
Before block 4, shape: torch.Size([50, 128, 96, 96])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 256])
After block 4, shape: torch.Size([50, 128, 48, 48])
-
Before block 5, shape: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 48, 48])
-
Before block 8, shape: torch.Size([50, 256, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 8, shape: torch.Size([50, 256, 24, 24])
-
Before block 9, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 9, shape: torch.Size([50, 256, 24, 24])
-
Before block 10, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 10, shape: torch.Size([50, 256, 24, 24])
-
Before block 11, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 11, shape: torch.Size([50, 256, 24, 24])
-

Before middle block, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
in unet attention block!
x shape torch.Size([50, 256, 24, 24])
out dims torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])


After middle block, shape: torch.Size([50, 256, 24, 24])
-



outputblocks
Before block 0, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 0, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 0, shape: torch.Size([50, 256, 24, 24])
-
Before block 1, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 1, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 1, shape: torch.Size([50, 256, 24, 24])
-
Before block 2, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 2, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 2, shape: torch.Size([50, 256, 24, 24])
-
Before block 3, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 3, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 3, shape: torch.Size([50, 256, 48, 48])
-
Before block 4, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 4, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 4, shape: torch.Size([50, 256, 48, 48])
-
Before block 5, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 5, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 6, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 7, shape: torch.Size([50, 384, 48, 48])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 96, 96])
-
Before block 8, shape: torch.Size([50, 256, 96, 96])
After concatenation in upsampling block 8, shape: torch.Size([50, 384, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 8, shape: torch.Size([50, 128, 96, 96])
-
Before block 9, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 9, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 9, shape: torch.Size([50, 128, 96, 96])
-
Before block 10, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 10, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 10, shape: torch.Size([50, 128, 96, 96])
-
Before block 11, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 11, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 11, shape: torch.Size([50, 128, 96, 96])
-

Before Final layer shape: torch.Size([50, 128, 96, 96])
Final output shape: torch.Size([50, 1, 96, 96])
model out shape:  torch.Size([50, 1, 96, 96])
iAM IN THE FORWARD METHOD OF THE WEIRD GUASSIAN IN cond_DDPM.py. I WILL BE CALLING p_losses
i am in p_losses in guassian which seems to be crucial to everything
conditioning vector shape:  torch.Size([50, 512])
in plosses i am getting a noisy image x
x shape:  torch.Size([50, 1, 96, 96])
getting model out
Initial input shape: torch.Size([50, 1, 96, 96])

inputblocks
Before block 0, shape: torch.Size([50, 1, 96, 96])
After block 0, shape: torch.Size([50, 128, 96, 96])
-
Before block 1, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 1, shape: torch.Size([50, 128, 96, 96])
-
Before block 2, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 2, shape: torch.Size([50, 128, 96, 96])
-
Before block 3, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 3, shape: torch.Size([50, 128, 96, 96])
-
Before block 4, shape: torch.Size([50, 128, 96, 96])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 256])
After block 4, shape: torch.Size([50, 128, 48, 48])
-
Before block 5, shape: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 48, 48])
-
Before block 8, shape: torch.Size([50, 256, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 8, shape: torch.Size([50, 256, 24, 24])
-
Before block 9, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 9, shape: torch.Size([50, 256, 24, 24])
-
Before block 10, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 10, shape: torch.Size([50, 256, 24, 24])
-
Before block 11, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 11, shape: torch.Size([50, 256, 24, 24])
-

Before middle block, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
in unet attention block!
x shape torch.Size([50, 256, 24, 24])
out dims torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])


After middle block, shape: torch.Size([50, 256, 24, 24])
-



outputblocks
Before block 0, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 0, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 0, shape: torch.Size([50, 256, 24, 24])
-
Before block 1, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 1, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 1, shape: torch.Size([50, 256, 24, 24])
-
Before block 2, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 2, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 2, shape: torch.Size([50, 256, 24, 24])
-
Before block 3, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 3, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 3, shape: torch.Size([50, 256, 48, 48])
-
Before block 4, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 4, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 4, shape: torch.Size([50, 256, 48, 48])
-
Before block 5, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 5, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 6, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 7, shape: torch.Size([50, 384, 48, 48])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 96, 96])
-
Before block 8, shape: torch.Size([50, 256, 96, 96])
After concatenation in upsampling block 8, shape: torch.Size([50, 384, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 8, shape: torch.Size([50, 128, 96, 96])
-
Before block 9, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 9, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 9, shape: torch.Size([50, 128, 96, 96])
-
Before block 10, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 10, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 10, shape: torch.Size([50, 128, 96, 96])
-
Before block 11, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 11, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 11, shape: torch.Size([50, 128, 96, 96])
-

Before Final layer shape: torch.Size([50, 128, 96, 96])
Final output shape: torch.Size([50, 1, 96, 96])
model out shape:  torch.Size([50, 1, 96, 96])
iAM IN THE FORWARD METHOD OF THE WEIRD GUASSIAN IN cond_DDPM.py. I WILL BE CALLING p_losses
i am in p_losses in guassian which seems to be crucial to everything
conditioning vector shape:  torch.Size([50, 512])
in plosses i am getting a noisy image x
x shape:  torch.Size([50, 1, 96, 96])
getting model out
Initial input shape: torch.Size([50, 1, 96, 96])

inputblocks
Before block 0, shape: torch.Size([50, 1, 96, 96])
After block 0, shape: torch.Size([50, 128, 96, 96])
-
Before block 1, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 1, shape: torch.Size([50, 128, 96, 96])
-
Before block 2, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 2, shape: torch.Size([50, 128, 96, 96])
-
Before block 3, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 3, shape: torch.Size([50, 128, 96, 96])
-
Before block 4, shape: torch.Size([50, 128, 96, 96])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 256])
After block 4, shape: torch.Size([50, 128, 48, 48])
-
Before block 5, shape: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 48, 48])
-
Before block 8, shape: torch.Size([50, 256, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 8, shape: torch.Size([50, 256, 24, 24])
-
Before block 9, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 9, shape: torch.Size([50, 256, 24, 24])
-
Before block 10, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 10, shape: torch.Size([50, 256, 24, 24])
-
Before block 11, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 11, shape: torch.Size([50, 256, 24, 24])
-

Before middle block, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
in unet attention block!
x shape torch.Size([50, 256, 24, 24])
out dims torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])


After middle block, shape: torch.Size([50, 256, 24, 24])
-



outputblocks
Before block 0, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 0, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 0, shape: torch.Size([50, 256, 24, 24])
-
Before block 1, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 1, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 1, shape: torch.Size([50, 256, 24, 24])
-
Before block 2, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 2, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 2, shape: torch.Size([50, 256, 24, 24])
-
Before block 3, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 3, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 3, shape: torch.Size([50, 256, 48, 48])
-
Before block 4, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 4, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 4, shape: torch.Size([50, 256, 48, 48])
-
Before block 5, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 5, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 6, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 7, shape: torch.Size([50, 384, 48, 48])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 96, 96])
-
Before block 8, shape: torch.Size([50, 256, 96, 96])
After concatenation in upsampling block 8, shape: torch.Size([50, 384, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 8, shape: torch.Size([50, 128, 96, 96])
-
Before block 9, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 9, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 9, shape: torch.Size([50, 128, 96, 96])
-
Before block 10, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 10, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 10, shape: torch.Size([50, 128, 96, 96])
-
Before block 11, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 11, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 11, shape: torch.Size([50, 128, 96, 96])
-

Before Final layer shape: torch.Size([50, 128, 96, 96])
Final output shape: torch.Size([50, 1, 96, 96])
model out shape:  torch.Size([50, 1, 96, 96])
reconstruction shape torch.Size([50, 1, 96, 96])
reconstruction tensor([[[[0.0410, 0.0317, 0.0348,  ..., 0.0306, 0.0343, 0.0256],
          [0.0307, 0.0247, 0.0242,  ..., 0.0219, 0.0273, 0.0205],
          [0.0208, 0.0190, 0.0321,  ..., 0.0282, 0.0237, 0.0227],
          ...,
          [0.0276, 0.0247, 0.0306,  ..., 0.0284, 0.0234, 0.0227],
          [0.0371, 0.0396, 0.0267,  ..., 0.0244, 0.0307, 0.0237],
          [0.0204, 0.0292, 0.0291,  ..., 0.0223, 0.0291, 0.0166]]],


        [[[0.0408, 0.0326, 0.0356,  ..., 0.0312, 0.0349, 0.0263],
          [0.0308, 0.0251, 0.0244,  ..., 0.0223, 0.0274, 0.0208],
          [0.0213, 0.0195, 0.0326,  ..., 0.0287, 0.0241, 0.0234],
          ...,
          [0.0285, 0.0261, 0.0316,  ..., 0.0291, 0.0243, 0.0238],
          [0.0382, 0.0413, 0.0273,  ..., 0.0248, 0.0316, 0.0247],
          [0.0207, 0.0304, 0.0295,  ..., 0.0229, 0.0301, 0.0173]]],


        [[[0.0411, 0.0334, 0.0366,  ..., 0.0317, 0.0353, 0.0266],
          [0.0314, 0.0264, 0.0256,  ..., 0.0234, 0.0280, 0.0211],
          [0.0218, 0.0205, 0.0335,  ..., 0.0296, 0.0250, 0.0239],
          ...,
          [0.0295, 0.0276, 0.0329,  ..., 0.0301, 0.0253, 0.0243],
          [0.0390, 0.0425, 0.0284,  ..., 0.0256, 0.0325, 0.0253],
          [0.0212, 0.0313, 0.0303,  ..., 0.0238, 0.0310, 0.0176]]],


        ...,


        [[[0.0454, 0.0326, 0.0338,  ..., 0.0324, 0.0347, 0.0320],
          [0.0281, 0.0177, 0.0190,  ..., 0.0218, 0.0234, 0.0216],
          [0.0229, 0.0174, 0.0299,  ..., 0.0301, 0.0227, 0.0244],
          ...,
          [0.0269, 0.0222, 0.0309,  ..., 0.0304, 0.0211, 0.0191],
          [0.0347, 0.0308, 0.0242,  ..., 0.0225, 0.0238, 0.0191],
          [0.0273, 0.0308, 0.0321,  ..., 0.0256, 0.0291, 0.0178]]],


        [[[0.0443, 0.0312, 0.0333,  ..., 0.0315, 0.0340, 0.0309],
          [0.0264, 0.0154, 0.0177,  ..., 0.0198, 0.0216, 0.0205],
          [0.0217, 0.0157, 0.0294,  ..., 0.0287, 0.0210, 0.0234],
          ...,
          [0.0255, 0.0192, 0.0291,  ..., 0.0291, 0.0189, 0.0180],
          [0.0321, 0.0271, 0.0215,  ..., 0.0208, 0.0214, 0.0173],
          [0.0240, 0.0275, 0.0299,  ..., 0.0250, 0.0275, 0.0157]]],


        [[[0.0448, 0.0322, 0.0341,  ..., 0.0323, 0.0354, 0.0312],
          [0.0274, 0.0168, 0.0186,  ..., 0.0203, 0.0231, 0.0213],
          [0.0223, 0.0168, 0.0303,  ..., 0.0286, 0.0217, 0.0237],
          ...,
          [0.0261, 0.0194, 0.0288,  ..., 0.0293, 0.0191, 0.0182],
          [0.0326, 0.0279, 0.0220,  ..., 0.0217, 0.0229, 0.0179],
          [0.0225, 0.0273, 0.0301,  ..., 0.0253, 0.0282, 0.0152]]]],
       device='cuda:0')
FINAL VOLUME (DDPM) shape torch.Size([96, 96, 50])
FINAL VOLUME tensor([[[0.0410, 0.0408, 0.0411,  ..., 0.0454, 0.0443, 0.0448],
         [0.0317, 0.0326, 0.0334,  ..., 0.0326, 0.0312, 0.0322],
         [0.0348, 0.0356, 0.0366,  ..., 0.0338, 0.0333, 0.0341],
         ...,
         [0.0306, 0.0312, 0.0317,  ..., 0.0324, 0.0315, 0.0323],
         [0.0343, 0.0349, 0.0353,  ..., 0.0347, 0.0340, 0.0354],
         [0.0256, 0.0263, 0.0266,  ..., 0.0320, 0.0309, 0.0312]],

        [[0.0307, 0.0308, 0.0314,  ..., 0.0281, 0.0264, 0.0274],
         [0.0247, 0.0251, 0.0264,  ..., 0.0177, 0.0154, 0.0168],
         [0.0242, 0.0244, 0.0256,  ..., 0.0190, 0.0177, 0.0186],
         ...,
         [0.0219, 0.0223, 0.0234,  ..., 0.0218, 0.0198, 0.0203],
         [0.0273, 0.0274, 0.0280,  ..., 0.0234, 0.0216, 0.0231],
         [0.0205, 0.0208, 0.0211,  ..., 0.0216, 0.0205, 0.0213]],

        [[0.0208, 0.0213, 0.0218,  ..., 0.0229, 0.0217, 0.0223],
         [0.0190, 0.0195, 0.0205,  ..., 0.0174, 0.0157, 0.0168],
         [0.0321, 0.0326, 0.0335,  ..., 0.0299, 0.0294, 0.0303],
         ...,
         [0.0282, 0.0287, 0.0296,  ..., 0.0301, 0.0287, 0.0286],
         [0.0237, 0.0241, 0.0250,  ..., 0.0227, 0.0210, 0.0217],
         [0.0227, 0.0234, 0.0239,  ..., 0.0244, 0.0234, 0.0237]],

        ...,

        [[0.0276, 0.0285, 0.0295,  ..., 0.0269, 0.0255, 0.0261],
         [0.0247, 0.0261, 0.0276,  ..., 0.0222, 0.0192, 0.0194],
         [0.0306, 0.0316, 0.0329,  ..., 0.0309, 0.0291, 0.0288],
         ...,
         [0.0284, 0.0291, 0.0301,  ..., 0.0304, 0.0291, 0.0293],
         [0.0234, 0.0243, 0.0253,  ..., 0.0211, 0.0189, 0.0191],
         [0.0227, 0.0238, 0.0243,  ..., 0.0191, 0.0180, 0.0182]],

        [[0.0371, 0.0382, 0.0390,  ..., 0.0347, 0.0321, 0.0326],
         [0.0396, 0.0413, 0.0425,  ..., 0.0308, 0.0271, 0.0279],
         [0.0267, 0.0273, 0.0284,  ..., 0.0242, 0.0215, 0.0220],
         ...,
         [0.0244, 0.0248, 0.0256,  ..., 0.0225, 0.0208, 0.0217],
         [0.0307, 0.0316, 0.0325,  ..., 0.0238, 0.0214, 0.0229],
         [0.0237, 0.0247, 0.0253,  ..., 0.0191, 0.0173, 0.0179]],

        [[0.0204, 0.0207, 0.0212,  ..., 0.0273, 0.0240, 0.0225],
         [0.0292, 0.0304, 0.0313,  ..., 0.0308, 0.0275, 0.0273],
         [0.0291, 0.0295, 0.0303,  ..., 0.0321, 0.0299, 0.0301],
         ...,
         [0.0223, 0.0229, 0.0238,  ..., 0.0256, 0.0250, 0.0253],
         [0.0291, 0.0301, 0.0310,  ..., 0.0291, 0.0275, 0.0282],
         [0.0166, 0.0173, 0.0176,  ..., 0.0178, 0.0157, 0.0152]]],
       device='cuda:0')
unsqueeze final volume shape (DDPM2d) torch.Size([1, 1, 96, 96, 50])
unsqueeze final volume (DDPM 2D) tensor([[[[[0.0410, 0.0408, 0.0411,  ..., 0.0454, 0.0443, 0.0448],
           [0.0317, 0.0326, 0.0334,  ..., 0.0326, 0.0312, 0.0322],
           [0.0348, 0.0356, 0.0366,  ..., 0.0338, 0.0333, 0.0341],
           ...,
           [0.0306, 0.0312, 0.0317,  ..., 0.0324, 0.0315, 0.0323],
           [0.0343, 0.0349, 0.0353,  ..., 0.0347, 0.0340, 0.0354],
           [0.0256, 0.0263, 0.0266,  ..., 0.0320, 0.0309, 0.0312]],

          [[0.0307, 0.0308, 0.0314,  ..., 0.0281, 0.0264, 0.0274],
           [0.0247, 0.0251, 0.0264,  ..., 0.0177, 0.0154, 0.0168],
           [0.0242, 0.0244, 0.0256,  ..., 0.0190, 0.0177, 0.0186],
           ...,
           [0.0219, 0.0223, 0.0234,  ..., 0.0218, 0.0198, 0.0203],
           [0.0273, 0.0274, 0.0280,  ..., 0.0234, 0.0216, 0.0231],
           [0.0205, 0.0208, 0.0211,  ..., 0.0216, 0.0205, 0.0213]],

          [[0.0208, 0.0213, 0.0218,  ..., 0.0229, 0.0217, 0.0223],
           [0.0190, 0.0195, 0.0205,  ..., 0.0174, 0.0157, 0.0168],
           [0.0321, 0.0326, 0.0335,  ..., 0.0299, 0.0294, 0.0303],
           ...,
           [0.0282, 0.0287, 0.0296,  ..., 0.0301, 0.0287, 0.0286],
           [0.0237, 0.0241, 0.0250,  ..., 0.0227, 0.0210, 0.0217],
           [0.0227, 0.0234, 0.0239,  ..., 0.0244, 0.0234, 0.0237]],

          ...,

          [[0.0276, 0.0285, 0.0295,  ..., 0.0269, 0.0255, 0.0261],
           [0.0247, 0.0261, 0.0276,  ..., 0.0222, 0.0192, 0.0194],
           [0.0306, 0.0316, 0.0329,  ..., 0.0309, 0.0291, 0.0288],
           ...,
           [0.0284, 0.0291, 0.0301,  ..., 0.0304, 0.0291, 0.0293],
           [0.0234, 0.0243, 0.0253,  ..., 0.0211, 0.0189, 0.0191],
           [0.0227, 0.0238, 0.0243,  ..., 0.0191, 0.0180, 0.0182]],

          [[0.0371, 0.0382, 0.0390,  ..., 0.0347, 0.0321, 0.0326],
           [0.0396, 0.0413, 0.0425,  ..., 0.0308, 0.0271, 0.0279],
           [0.0267, 0.0273, 0.0284,  ..., 0.0242, 0.0215, 0.0220],
           ...,
           [0.0244, 0.0248, 0.0256,  ..., 0.0225, 0.0208, 0.0217],
           [0.0307, 0.0316, 0.0325,  ..., 0.0238, 0.0214, 0.0229],
           [0.0237, 0.0247, 0.0253,  ..., 0.0191, 0.0173, 0.0179]],

          [[0.0204, 0.0207, 0.0212,  ..., 0.0273, 0.0240, 0.0225],
           [0.0292, 0.0304, 0.0313,  ..., 0.0308, 0.0275, 0.0273],
           [0.0291, 0.0295, 0.0303,  ..., 0.0321, 0.0299, 0.0301],
           ...,
           [0.0223, 0.0229, 0.0238,  ..., 0.0256, 0.0250, 0.0253],
           [0.0291, 0.0301, 0.0310,  ..., 0.0291, 0.0275, 0.0282],
           [0.0166, 0.0173, 0.0176,  ..., 0.0178, 0.0157, 0.0152]]]]],
       device='cuda:0')
==========
IN _TEST_STEP
==========
ERODING BRAIN MASK
MEDIAN FILTERING
SAVING OUTPUT - ORIGINAL, FINAL, MASK ETC
SAVING IMAGES!
Testing:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [00:45<00:18,  3.16s/it]==========
IN DDPM ON TEST STEP
==========
THE WEIRD CONDITION BIT CALLED "features" in DDPM_2D
IN SPARK ENCODER FORWARDDD
x in shape torch.Size([50, 1, 96, 96])
out features torch.Size([50, 512])
i'm i DDPM2d forward block (whch is basically the encoder)
Context vector c shape: torch.Size([50, 512])
shape features:  torch.Size([50, 512])
additng features to latern space
latent space: []
iAM IN THE FORWARD METHOD OF THE WEIRD GUASSIAN IN cond_DDPM.py. I WILL BE CALLING p_losses
i am in p_losses in guassian which seems to be crucial to everything
conditioning vector shape:  torch.Size([50, 512])
in plosses i am getting a noisy image x
x shape:  torch.Size([50, 1, 96, 96])
getting model out
Initial input shape: torch.Size([50, 1, 96, 96])

inputblocks
Before block 0, shape: torch.Size([50, 1, 96, 96])
After block 0, shape: torch.Size([50, 128, 96, 96])
-
Before block 1, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 1, shape: torch.Size([50, 128, 96, 96])
-
Before block 2, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 2, shape: torch.Size([50, 128, 96, 96])
-
Before block 3, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 3, shape: torch.Size([50, 128, 96, 96])
-
Before block 4, shape: torch.Size([50, 128, 96, 96])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 256])
After block 4, shape: torch.Size([50, 128, 48, 48])
-
Before block 5, shape: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 48, 48])
-
Before block 8, shape: torch.Size([50, 256, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 8, shape: torch.Size([50, 256, 24, 24])
-
Before block 9, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 9, shape: torch.Size([50, 256, 24, 24])
-
Before block 10, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 10, shape: torch.Size([50, 256, 24, 24])
-
Before block 11, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 11, shape: torch.Size([50, 256, 24, 24])
-

Before middle block, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
in unet attention block!
x shape torch.Size([50, 256, 24, 24])
out dims torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])


After middle block, shape: torch.Size([50, 256, 24, 24])
-



outputblocks
Before block 0, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 0, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 0, shape: torch.Size([50, 256, 24, 24])
-
Before block 1, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 1, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 1, shape: torch.Size([50, 256, 24, 24])
-
Before block 2, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 2, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 2, shape: torch.Size([50, 256, 24, 24])
-
Before block 3, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 3, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 3, shape: torch.Size([50, 256, 48, 48])
-
Before block 4, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 4, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 4, shape: torch.Size([50, 256, 48, 48])
-
Before block 5, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 5, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 6, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 7, shape: torch.Size([50, 384, 48, 48])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 96, 96])
-
Before block 8, shape: torch.Size([50, 256, 96, 96])
After concatenation in upsampling block 8, shape: torch.Size([50, 384, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 8, shape: torch.Size([50, 128, 96, 96])
-
Before block 9, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 9, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 9, shape: torch.Size([50, 128, 96, 96])
-
Before block 10, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 10, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 10, shape: torch.Size([50, 128, 96, 96])
-
Before block 11, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 11, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 11, shape: torch.Size([50, 128, 96, 96])
-

Before Final layer shape: torch.Size([50, 128, 96, 96])
Final output shape: torch.Size([50, 1, 96, 96])
model out shape:  torch.Size([50, 1, 96, 96])
iAM IN THE FORWARD METHOD OF THE WEIRD GUASSIAN IN cond_DDPM.py. I WILL BE CALLING p_losses
i am in p_losses in guassian which seems to be crucial to everything
conditioning vector shape:  torch.Size([50, 512])
in plosses i am getting a noisy image x
x shape:  torch.Size([50, 1, 96, 96])
getting model out
Initial input shape: torch.Size([50, 1, 96, 96])

inputblocks
Before block 0, shape: torch.Size([50, 1, 96, 96])
After block 0, shape: torch.Size([50, 128, 96, 96])
-
Before block 1, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 1, shape: torch.Size([50, 128, 96, 96])
-
Before block 2, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 2, shape: torch.Size([50, 128, 96, 96])
-
Before block 3, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 3, shape: torch.Size([50, 128, 96, 96])
-
Before block 4, shape: torch.Size([50, 128, 96, 96])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 256])
After block 4, shape: torch.Size([50, 128, 48, 48])
-
Before block 5, shape: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 48, 48])
-
Before block 8, shape: torch.Size([50, 256, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 8, shape: torch.Size([50, 256, 24, 24])
-
Before block 9, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 9, shape: torch.Size([50, 256, 24, 24])
-
Before block 10, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 10, shape: torch.Size([50, 256, 24, 24])
-
Before block 11, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 11, shape: torch.Size([50, 256, 24, 24])
-

Before middle block, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
in unet attention block!
x shape torch.Size([50, 256, 24, 24])
out dims torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])


After middle block, shape: torch.Size([50, 256, 24, 24])
-



outputblocks
Before block 0, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 0, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 0, shape: torch.Size([50, 256, 24, 24])
-
Before block 1, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 1, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 1, shape: torch.Size([50, 256, 24, 24])
-
Before block 2, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 2, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 2, shape: torch.Size([50, 256, 24, 24])
-
Before block 3, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 3, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 3, shape: torch.Size([50, 256, 48, 48])
-
Before block 4, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 4, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 4, shape: torch.Size([50, 256, 48, 48])
-
Before block 5, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 5, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 6, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 7, shape: torch.Size([50, 384, 48, 48])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 96, 96])
-
Before block 8, shape: torch.Size([50, 256, 96, 96])
After concatenation in upsampling block 8, shape: torch.Size([50, 384, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 8, shape: torch.Size([50, 128, 96, 96])
-
Before block 9, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 9, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 9, shape: torch.Size([50, 128, 96, 96])
-
Before block 10, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 10, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 10, shape: torch.Size([50, 128, 96, 96])
-
Before block 11, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 11, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 11, shape: torch.Size([50, 128, 96, 96])
-

Before Final layer shape: torch.Size([50, 128, 96, 96])
Final output shape: torch.Size([50, 1, 96, 96])
model out shape:  torch.Size([50, 1, 96, 96])
iAM IN THE FORWARD METHOD OF THE WEIRD GUASSIAN IN cond_DDPM.py. I WILL BE CALLING p_losses
i am in p_losses in guassian which seems to be crucial to everything
conditioning vector shape:  torch.Size([50, 512])
in plosses i am getting a noisy image x
x shape:  torch.Size([50, 1, 96, 96])
getting model out
Initial input shape: torch.Size([50, 1, 96, 96])

inputblocks
Before block 0, shape: torch.Size([50, 1, 96, 96])
After block 0, shape: torch.Size([50, 128, 96, 96])
-
Before block 1, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 1, shape: torch.Size([50, 128, 96, 96])
-
Before block 2, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 2, shape: torch.Size([50, 128, 96, 96])
-
Before block 3, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 3, shape: torch.Size([50, 128, 96, 96])
-
Before block 4, shape: torch.Size([50, 128, 96, 96])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 256])
After block 4, shape: torch.Size([50, 128, 48, 48])
-
Before block 5, shape: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 48, 48])
-
Before block 8, shape: torch.Size([50, 256, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 8, shape: torch.Size([50, 256, 24, 24])
-
Before block 9, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 9, shape: torch.Size([50, 256, 24, 24])
-
Before block 10, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 10, shape: torch.Size([50, 256, 24, 24])
-
Before block 11, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 11, shape: torch.Size([50, 256, 24, 24])
-

Before middle block, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
in unet attention block!
x shape torch.Size([50, 256, 24, 24])
out dims torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])


After middle block, shape: torch.Size([50, 256, 24, 24])
-



outputblocks
Before block 0, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 0, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 0, shape: torch.Size([50, 256, 24, 24])
-
Before block 1, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 1, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 1, shape: torch.Size([50, 256, 24, 24])
-
Before block 2, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 2, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 2, shape: torch.Size([50, 256, 24, 24])
-
Before block 3, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 3, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 3, shape: torch.Size([50, 256, 48, 48])
-
Before block 4, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 4, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 4, shape: torch.Size([50, 256, 48, 48])
-
Before block 5, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 5, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 6, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 7, shape: torch.Size([50, 384, 48, 48])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 96, 96])
-
Before block 8, shape: torch.Size([50, 256, 96, 96])
After concatenation in upsampling block 8, shape: torch.Size([50, 384, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 8, shape: torch.Size([50, 128, 96, 96])
-
Before block 9, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 9, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 9, shape: torch.Size([50, 128, 96, 96])
-
Before block 10, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 10, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 10, shape: torch.Size([50, 128, 96, 96])
-
Before block 11, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 11, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 11, shape: torch.Size([50, 128, 96, 96])
-

Before Final layer shape: torch.Size([50, 128, 96, 96])
Final output shape: torch.Size([50, 1, 96, 96])
model out shape:  torch.Size([50, 1, 96, 96])
reconstruction shape torch.Size([50, 1, 96, 96])
reconstruction tensor([[[[0.0172, 0.0023, 0.0107,  ..., 0.0111, 0.0158, 0.0183],
          [0.0249, 0.0077, 0.0062,  ..., 0.0077, 0.0195, 0.0173],
          [0.0201, 0.0045, 0.0116,  ..., 0.0106, 0.0076, 0.0091],
          ...,
          [0.0122, 0.0021, 0.0129,  ..., 0.0146, 0.0094, 0.0068],
          [0.0164, 0.0068, 0.0051,  ..., 0.0071, 0.0139, 0.0081],
          [0.0081, 0.0041, 0.0073,  ..., 0.0115, 0.0151, 0.0068]]],


        [[[0.0198, 0.0049, 0.0126,  ..., 0.0130, 0.0182, 0.0212],
          [0.0266, 0.0090, 0.0069,  ..., 0.0090, 0.0209, 0.0191],
          [0.0215, 0.0057, 0.0129,  ..., 0.0120, 0.0090, 0.0107],
          ...,
          [0.0142, 0.0037, 0.0147,  ..., 0.0160, 0.0114, 0.0090],
          [0.0186, 0.0087, 0.0065,  ..., 0.0085, 0.0164, 0.0108],
          [0.0103, 0.0068, 0.0092,  ..., 0.0134, 0.0181, 0.0094]]],


        [[[0.0225, 0.0087, 0.0164,  ..., 0.0160, 0.0215, 0.0247],
          [0.0287, 0.0118, 0.0105,  ..., 0.0121, 0.0242, 0.0221],
          [0.0245, 0.0093, 0.0164,  ..., 0.0155, 0.0125, 0.0139],
          ...,
          [0.0174, 0.0073, 0.0190,  ..., 0.0199, 0.0160, 0.0131],
          [0.0217, 0.0119, 0.0101,  ..., 0.0131, 0.0213, 0.0151],
          [0.0138, 0.0104, 0.0129,  ..., 0.0176, 0.0229, 0.0136]]],


        ...,


        [[[0.0191, 0.0063, 0.0151,  ..., 0.0137, 0.0182, 0.0232],
          [0.0217, 0.0044, 0.0060,  ..., 0.0072, 0.0164, 0.0168],
          [0.0204, 0.0033, 0.0113,  ..., 0.0119, 0.0090, 0.0113],
          ...,
          [0.0157, 0.0026, 0.0134,  ..., 0.0166, 0.0106, 0.0100],
          [0.0199, 0.0065, 0.0059,  ..., 0.0084, 0.0134, 0.0098],
          [0.0131, 0.0090, 0.0116,  ..., 0.0138, 0.0169, 0.0094]]],


        [[[0.0178, 0.0055, 0.0143,  ..., 0.0129, 0.0181, 0.0219],
          [0.0215, 0.0050, 0.0060,  ..., 0.0068, 0.0176, 0.0169],
          [0.0199, 0.0033, 0.0106,  ..., 0.0108, 0.0090, 0.0107],
          ...,
          [0.0144, 0.0018, 0.0114,  ..., 0.0154, 0.0099, 0.0087],
          [0.0191, 0.0066, 0.0053,  ..., 0.0080, 0.0134, 0.0090],
          [0.0111, 0.0076, 0.0100,  ..., 0.0125, 0.0156, 0.0068]]],


        [[[0.0159, 0.0037, 0.0129,  ..., 0.0118, 0.0172, 0.0197],
          [0.0209, 0.0055, 0.0057,  ..., 0.0067, 0.0183, 0.0166],
          [0.0189, 0.0030, 0.0095,  ..., 0.0090, 0.0084, 0.0095],
          ...,
          [0.0126, 0.0003, 0.0089,  ..., 0.0136, 0.0086, 0.0070],
          [0.0177, 0.0062, 0.0044,  ..., 0.0070, 0.0126, 0.0072],
          [0.0086, 0.0048, 0.0077,  ..., 0.0103, 0.0130, 0.0039]]]],
       device='cuda:0')
FINAL VOLUME (DDPM) shape torch.Size([96, 96, 50])
FINAL VOLUME tensor([[[0.0172, 0.0198, 0.0225,  ..., 0.0191, 0.0178, 0.0159],
         [0.0023, 0.0049, 0.0087,  ..., 0.0063, 0.0055, 0.0037],
         [0.0107, 0.0126, 0.0164,  ..., 0.0151, 0.0143, 0.0129],
         ...,
         [0.0111, 0.0130, 0.0160,  ..., 0.0137, 0.0129, 0.0118],
         [0.0158, 0.0182, 0.0215,  ..., 0.0182, 0.0181, 0.0172],
         [0.0183, 0.0212, 0.0247,  ..., 0.0232, 0.0219, 0.0197]],

        [[0.0249, 0.0266, 0.0287,  ..., 0.0217, 0.0215, 0.0209],
         [0.0077, 0.0090, 0.0118,  ..., 0.0044, 0.0050, 0.0055],
         [0.0062, 0.0069, 0.0105,  ..., 0.0060, 0.0060, 0.0057],
         ...,
         [0.0077, 0.0090, 0.0121,  ..., 0.0072, 0.0068, 0.0067],
         [0.0195, 0.0209, 0.0242,  ..., 0.0164, 0.0176, 0.0183],
         [0.0173, 0.0191, 0.0221,  ..., 0.0168, 0.0169, 0.0166]],

        [[0.0201, 0.0215, 0.0245,  ..., 0.0204, 0.0199, 0.0189],
         [0.0045, 0.0057, 0.0093,  ..., 0.0033, 0.0033, 0.0030],
         [0.0116, 0.0129, 0.0164,  ..., 0.0113, 0.0106, 0.0095],
         ...,
         [0.0106, 0.0120, 0.0155,  ..., 0.0119, 0.0108, 0.0090],
         [0.0076, 0.0090, 0.0125,  ..., 0.0090, 0.0090, 0.0084],
         [0.0091, 0.0107, 0.0139,  ..., 0.0113, 0.0107, 0.0095]],

        ...,

        [[0.0122, 0.0142, 0.0174,  ..., 0.0157, 0.0144, 0.0126],
         [0.0021, 0.0037, 0.0073,  ..., 0.0026, 0.0018, 0.0003],
         [0.0129, 0.0147, 0.0190,  ..., 0.0134, 0.0114, 0.0089],
         ...,
         [0.0146, 0.0160, 0.0199,  ..., 0.0166, 0.0154, 0.0136],
         [0.0094, 0.0114, 0.0160,  ..., 0.0106, 0.0099, 0.0086],
         [0.0068, 0.0090, 0.0131,  ..., 0.0100, 0.0087, 0.0070]],

        [[0.0164, 0.0186, 0.0217,  ..., 0.0199, 0.0191, 0.0177],
         [0.0068, 0.0087, 0.0119,  ..., 0.0065, 0.0066, 0.0062],
         [0.0051, 0.0065, 0.0101,  ..., 0.0059, 0.0053, 0.0044],
         ...,
         [0.0071, 0.0085, 0.0131,  ..., 0.0084, 0.0080, 0.0070],
         [0.0139, 0.0164, 0.0213,  ..., 0.0134, 0.0134, 0.0126],
         [0.0081, 0.0108, 0.0151,  ..., 0.0098, 0.0090, 0.0072]],

        [[0.0081, 0.0103, 0.0138,  ..., 0.0131, 0.0111, 0.0086],
         [0.0041, 0.0068, 0.0104,  ..., 0.0090, 0.0076, 0.0048],
         [0.0073, 0.0092, 0.0129,  ..., 0.0116, 0.0100, 0.0077],
         ...,
         [0.0115, 0.0134, 0.0176,  ..., 0.0138, 0.0125, 0.0103],
         [0.0151, 0.0181, 0.0229,  ..., 0.0169, 0.0156, 0.0130],
         [0.0068, 0.0094, 0.0136,  ..., 0.0094, 0.0068, 0.0039]]],
       device='cuda:0')
unsqueeze final volume shape (DDPM2d) torch.Size([1, 1, 96, 96, 50])
unsqueeze final volume (DDPM 2D) tensor([[[[[0.0172, 0.0198, 0.0225,  ..., 0.0191, 0.0178, 0.0159],
           [0.0023, 0.0049, 0.0087,  ..., 0.0063, 0.0055, 0.0037],
           [0.0107, 0.0126, 0.0164,  ..., 0.0151, 0.0143, 0.0129],
           ...,
           [0.0111, 0.0130, 0.0160,  ..., 0.0137, 0.0129, 0.0118],
           [0.0158, 0.0182, 0.0215,  ..., 0.0182, 0.0181, 0.0172],
           [0.0183, 0.0212, 0.0247,  ..., 0.0232, 0.0219, 0.0197]],

          [[0.0249, 0.0266, 0.0287,  ..., 0.0217, 0.0215, 0.0209],
           [0.0077, 0.0090, 0.0118,  ..., 0.0044, 0.0050, 0.0055],
           [0.0062, 0.0069, 0.0105,  ..., 0.0060, 0.0060, 0.0057],
           ...,
           [0.0077, 0.0090, 0.0121,  ..., 0.0072, 0.0068, 0.0067],
           [0.0195, 0.0209, 0.0242,  ..., 0.0164, 0.0176, 0.0183],
           [0.0173, 0.0191, 0.0221,  ..., 0.0168, 0.0169, 0.0166]],

          [[0.0201, 0.0215, 0.0245,  ..., 0.0204, 0.0199, 0.0189],
           [0.0045, 0.0057, 0.0093,  ..., 0.0033, 0.0033, 0.0030],
           [0.0116, 0.0129, 0.0164,  ..., 0.0113, 0.0106, 0.0095],
           ...,
           [0.0106, 0.0120, 0.0155,  ..., 0.0119, 0.0108, 0.0090],
           [0.0076, 0.0090, 0.0125,  ..., 0.0090, 0.0090, 0.0084],
           [0.0091, 0.0107, 0.0139,  ..., 0.0113, 0.0107, 0.0095]],

          ...,

          [[0.0122, 0.0142, 0.0174,  ..., 0.0157, 0.0144, 0.0126],
           [0.0021, 0.0037, 0.0073,  ..., 0.0026, 0.0018, 0.0003],
           [0.0129, 0.0147, 0.0190,  ..., 0.0134, 0.0114, 0.0089],
           ...,
           [0.0146, 0.0160, 0.0199,  ..., 0.0166, 0.0154, 0.0136],
           [0.0094, 0.0114, 0.0160,  ..., 0.0106, 0.0099, 0.0086],
           [0.0068, 0.0090, 0.0131,  ..., 0.0100, 0.0087, 0.0070]],

          [[0.0164, 0.0186, 0.0217,  ..., 0.0199, 0.0191, 0.0177],
           [0.0068, 0.0087, 0.0119,  ..., 0.0065, 0.0066, 0.0062],
           [0.0051, 0.0065, 0.0101,  ..., 0.0059, 0.0053, 0.0044],
           ...,
           [0.0071, 0.0085, 0.0131,  ..., 0.0084, 0.0080, 0.0070],
           [0.0139, 0.0164, 0.0213,  ..., 0.0134, 0.0134, 0.0126],
           [0.0081, 0.0108, 0.0151,  ..., 0.0098, 0.0090, 0.0072]],

          [[0.0081, 0.0103, 0.0138,  ..., 0.0131, 0.0111, 0.0086],
           [0.0041, 0.0068, 0.0104,  ..., 0.0090, 0.0076, 0.0048],
           [0.0073, 0.0092, 0.0129,  ..., 0.0116, 0.0100, 0.0077],
           ...,
           [0.0115, 0.0134, 0.0176,  ..., 0.0138, 0.0125, 0.0103],
           [0.0151, 0.0181, 0.0229,  ..., 0.0169, 0.0156, 0.0130],
           [0.0068, 0.0094, 0.0136,  ..., 0.0094, 0.0068, 0.0039]]]]],
       device='cuda:0')
==========
IN _TEST_STEP
==========
ERODING BRAIN MASK
MEDIAN FILTERING
SAVING OUTPUT - ORIGINAL, FINAL, MASK ETC
SAVING IMAGES!
Testing:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [00:48<00:15,  3.12s/it]==========
IN DDPM ON TEST STEP
==========
THE WEIRD CONDITION BIT CALLED "features" in DDPM_2D
IN SPARK ENCODER FORWARDDD
x in shape torch.Size([50, 1, 96, 96])
out features torch.Size([50, 512])
i'm i DDPM2d forward block (whch is basically the encoder)
Context vector c shape: torch.Size([50, 512])
shape features:  torch.Size([50, 512])
additng features to latern space
latent space: []
iAM IN THE FORWARD METHOD OF THE WEIRD GUASSIAN IN cond_DDPM.py. I WILL BE CALLING p_losses
i am in p_losses in guassian which seems to be crucial to everything
conditioning vector shape:  torch.Size([50, 512])
in plosses i am getting a noisy image x
x shape:  torch.Size([50, 1, 96, 96])
getting model out
Initial input shape: torch.Size([50, 1, 96, 96])

inputblocks
Before block 0, shape: torch.Size([50, 1, 96, 96])
After block 0, shape: torch.Size([50, 128, 96, 96])
-
Before block 1, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 1, shape: torch.Size([50, 128, 96, 96])
-
Before block 2, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 2, shape: torch.Size([50, 128, 96, 96])
-
Before block 3, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 3, shape: torch.Size([50, 128, 96, 96])
-
Before block 4, shape: torch.Size([50, 128, 96, 96])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 256])
After block 4, shape: torch.Size([50, 128, 48, 48])
-
Before block 5, shape: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 48, 48])
-
Before block 8, shape: torch.Size([50, 256, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 8, shape: torch.Size([50, 256, 24, 24])
-
Before block 9, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 9, shape: torch.Size([50, 256, 24, 24])
-
Before block 10, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 10, shape: torch.Size([50, 256, 24, 24])
-
Before block 11, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 11, shape: torch.Size([50, 256, 24, 24])
-

Before middle block, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
in unet attention block!
x shape torch.Size([50, 256, 24, 24])
out dims torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])


After middle block, shape: torch.Size([50, 256, 24, 24])
-



outputblocks
Before block 0, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 0, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 0, shape: torch.Size([50, 256, 24, 24])
-
Before block 1, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 1, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 1, shape: torch.Size([50, 256, 24, 24])
-
Before block 2, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 2, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 2, shape: torch.Size([50, 256, 24, 24])
-
Before block 3, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 3, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 3, shape: torch.Size([50, 256, 48, 48])
-
Before block 4, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 4, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 4, shape: torch.Size([50, 256, 48, 48])
-
Before block 5, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 5, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 6, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 7, shape: torch.Size([50, 384, 48, 48])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 96, 96])
-
Before block 8, shape: torch.Size([50, 256, 96, 96])
After concatenation in upsampling block 8, shape: torch.Size([50, 384, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 8, shape: torch.Size([50, 128, 96, 96])
-
Before block 9, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 9, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 9, shape: torch.Size([50, 128, 96, 96])
-
Before block 10, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 10, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 10, shape: torch.Size([50, 128, 96, 96])
-
Before block 11, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 11, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 11, shape: torch.Size([50, 128, 96, 96])
-

Before Final layer shape: torch.Size([50, 128, 96, 96])
Final output shape: torch.Size([50, 1, 96, 96])
model out shape:  torch.Size([50, 1, 96, 96])
iAM IN THE FORWARD METHOD OF THE WEIRD GUASSIAN IN cond_DDPM.py. I WILL BE CALLING p_losses
i am in p_losses in guassian which seems to be crucial to everything
conditioning vector shape:  torch.Size([50, 512])
in plosses i am getting a noisy image x
x shape:  torch.Size([50, 1, 96, 96])
getting model out
Initial input shape: torch.Size([50, 1, 96, 96])

inputblocks
Before block 0, shape: torch.Size([50, 1, 96, 96])
After block 0, shape: torch.Size([50, 128, 96, 96])
-
Before block 1, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 1, shape: torch.Size([50, 128, 96, 96])
-
Before block 2, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 2, shape: torch.Size([50, 128, 96, 96])
-
Before block 3, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 3, shape: torch.Size([50, 128, 96, 96])
-
Before block 4, shape: torch.Size([50, 128, 96, 96])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 256])
After block 4, shape: torch.Size([50, 128, 48, 48])
-
Before block 5, shape: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 48, 48])
-
Before block 8, shape: torch.Size([50, 256, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 8, shape: torch.Size([50, 256, 24, 24])
-
Before block 9, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 9, shape: torch.Size([50, 256, 24, 24])
-
Before block 10, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 10, shape: torch.Size([50, 256, 24, 24])
-
Before block 11, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 11, shape: torch.Size([50, 256, 24, 24])
-

Before middle block, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
in unet attention block!
x shape torch.Size([50, 256, 24, 24])
out dims torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])


After middle block, shape: torch.Size([50, 256, 24, 24])
-



outputblocks
Before block 0, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 0, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 0, shape: torch.Size([50, 256, 24, 24])
-
Before block 1, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 1, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 1, shape: torch.Size([50, 256, 24, 24])
-
Before block 2, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 2, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 2, shape: torch.Size([50, 256, 24, 24])
-
Before block 3, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 3, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 3, shape: torch.Size([50, 256, 48, 48])
-
Before block 4, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 4, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 4, shape: torch.Size([50, 256, 48, 48])
-
Before block 5, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 5, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 6, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 7, shape: torch.Size([50, 384, 48, 48])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 96, 96])
-
Before block 8, shape: torch.Size([50, 256, 96, 96])
After concatenation in upsampling block 8, shape: torch.Size([50, 384, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 8, shape: torch.Size([50, 128, 96, 96])
-
Before block 9, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 9, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 9, shape: torch.Size([50, 128, 96, 96])
-
Before block 10, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 10, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 10, shape: torch.Size([50, 128, 96, 96])
-
Before block 11, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 11, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 11, shape: torch.Size([50, 128, 96, 96])
-

Before Final layer shape: torch.Size([50, 128, 96, 96])
Final output shape: torch.Size([50, 1, 96, 96])
model out shape:  torch.Size([50, 1, 96, 96])
iAM IN THE FORWARD METHOD OF THE WEIRD GUASSIAN IN cond_DDPM.py. I WILL BE CALLING p_losses
i am in p_losses in guassian which seems to be crucial to everything
conditioning vector shape:  torch.Size([50, 512])
in plosses i am getting a noisy image x
x shape:  torch.Size([50, 1, 96, 96])
getting model out
Initial input shape: torch.Size([50, 1, 96, 96])

inputblocks
Before block 0, shape: torch.Size([50, 1, 96, 96])
After block 0, shape: torch.Size([50, 128, 96, 96])
-
Before block 1, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 1, shape: torch.Size([50, 128, 96, 96])
-
Before block 2, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 2, shape: torch.Size([50, 128, 96, 96])
-
Before block 3, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 3, shape: torch.Size([50, 128, 96, 96])
-
Before block 4, shape: torch.Size([50, 128, 96, 96])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 256])
After block 4, shape: torch.Size([50, 128, 48, 48])
-
Before block 5, shape: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 48, 48])
-
Before block 8, shape: torch.Size([50, 256, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 8, shape: torch.Size([50, 256, 24, 24])
-
Before block 9, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 9, shape: torch.Size([50, 256, 24, 24])
-
Before block 10, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 10, shape: torch.Size([50, 256, 24, 24])
-
Before block 11, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 11, shape: torch.Size([50, 256, 24, 24])
-

Before middle block, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
in unet attention block!
x shape torch.Size([50, 256, 24, 24])
out dims torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])


After middle block, shape: torch.Size([50, 256, 24, 24])
-



outputblocks
Before block 0, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 0, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 0, shape: torch.Size([50, 256, 24, 24])
-
Before block 1, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 1, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 1, shape: torch.Size([50, 256, 24, 24])
-
Before block 2, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 2, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 2, shape: torch.Size([50, 256, 24, 24])
-
Before block 3, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 3, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 3, shape: torch.Size([50, 256, 48, 48])
-
Before block 4, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 4, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 4, shape: torch.Size([50, 256, 48, 48])
-
Before block 5, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 5, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 6, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 7, shape: torch.Size([50, 384, 48, 48])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 96, 96])
-
Before block 8, shape: torch.Size([50, 256, 96, 96])
After concatenation in upsampling block 8, shape: torch.Size([50, 384, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 8, shape: torch.Size([50, 128, 96, 96])
-
Before block 9, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 9, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 9, shape: torch.Size([50, 128, 96, 96])
-
Before block 10, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 10, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 10, shape: torch.Size([50, 128, 96, 96])
-
Before block 11, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 11, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 11, shape: torch.Size([50, 128, 96, 96])
-

Before Final layer shape: torch.Size([50, 128, 96, 96])
Final output shape: torch.Size([50, 1, 96, 96])
model out shape:  torch.Size([50, 1, 96, 96])
reconstruction shape torch.Size([50, 1, 96, 96])
reconstruction tensor([[[[0.0286, 0.0187, 0.0231,  ..., 0.0244, 0.0258, 0.0163],
          [0.0334, 0.0190, 0.0180,  ..., 0.0153, 0.0199, 0.0152],
          [0.0223, 0.0133, 0.0247,  ..., 0.0220, 0.0161, 0.0152],
          ...,
          [0.0243, 0.0132, 0.0229,  ..., 0.0224, 0.0198, 0.0166],
          [0.0319, 0.0213, 0.0178,  ..., 0.0202, 0.0327, 0.0225],
          [0.0236, 0.0225, 0.0193,  ..., 0.0184, 0.0278, 0.0146]]],


        [[[0.0292, 0.0194, 0.0239,  ..., 0.0251, 0.0265, 0.0171],
          [0.0338, 0.0195, 0.0186,  ..., 0.0161, 0.0202, 0.0155],
          [0.0229, 0.0142, 0.0260,  ..., 0.0232, 0.0171, 0.0160],
          ...,
          [0.0251, 0.0140, 0.0241,  ..., 0.0234, 0.0205, 0.0173],
          [0.0324, 0.0216, 0.0185,  ..., 0.0209, 0.0330, 0.0232],
          [0.0243, 0.0234, 0.0202,  ..., 0.0194, 0.0286, 0.0153]]],


        [[[0.0305, 0.0207, 0.0253,  ..., 0.0265, 0.0273, 0.0181],
          [0.0341, 0.0199, 0.0197,  ..., 0.0171, 0.0207, 0.0160],
          [0.0242, 0.0152, 0.0274,  ..., 0.0245, 0.0181, 0.0171],
          ...,
          [0.0263, 0.0151, 0.0253,  ..., 0.0251, 0.0215, 0.0184],
          [0.0326, 0.0216, 0.0194,  ..., 0.0218, 0.0332, 0.0237],
          [0.0253, 0.0236, 0.0212,  ..., 0.0207, 0.0294, 0.0163]]],


        ...,


        [[[0.0321, 0.0177, 0.0219,  ..., 0.0258, 0.0264, 0.0218],
          [0.0310, 0.0121, 0.0125,  ..., 0.0142, 0.0142, 0.0125],
          [0.0268, 0.0151, 0.0256,  ..., 0.0245, 0.0161, 0.0162],
          ...,
          [0.0253, 0.0129, 0.0269,  ..., 0.0254, 0.0171, 0.0173],
          [0.0336, 0.0187, 0.0195,  ..., 0.0177, 0.0226, 0.0199],
          [0.0332, 0.0297, 0.0269,  ..., 0.0229, 0.0274, 0.0221]]],


        [[[0.0308, 0.0166, 0.0212,  ..., 0.0253, 0.0260, 0.0205],
          [0.0302, 0.0116, 0.0118,  ..., 0.0135, 0.0140, 0.0120],
          [0.0261, 0.0145, 0.0248,  ..., 0.0233, 0.0155, 0.0154],
          ...,
          [0.0243, 0.0109, 0.0246,  ..., 0.0239, 0.0160, 0.0162],
          [0.0326, 0.0173, 0.0179,  ..., 0.0169, 0.0226, 0.0192],
          [0.0316, 0.0282, 0.0256,  ..., 0.0219, 0.0266, 0.0203]]],


        [[[0.0301, 0.0162, 0.0208,  ..., 0.0250, 0.0258, 0.0200],
          [0.0299, 0.0112, 0.0111,  ..., 0.0131, 0.0140, 0.0121],
          [0.0260, 0.0142, 0.0241,  ..., 0.0224, 0.0147, 0.0151],
          ...,
          [0.0242, 0.0103, 0.0238,  ..., 0.0230, 0.0155, 0.0158],
          [0.0324, 0.0172, 0.0176,  ..., 0.0164, 0.0225, 0.0189],
          [0.0307, 0.0278, 0.0253,  ..., 0.0212, 0.0261, 0.0194]]]],
       device='cuda:0')
FINAL VOLUME (DDPM) shape torch.Size([96, 96, 50])
FINAL VOLUME tensor([[[0.0286, 0.0292, 0.0305,  ..., 0.0321, 0.0308, 0.0301],
         [0.0187, 0.0194, 0.0207,  ..., 0.0177, 0.0166, 0.0162],
         [0.0231, 0.0239, 0.0253,  ..., 0.0219, 0.0212, 0.0208],
         ...,
         [0.0244, 0.0251, 0.0265,  ..., 0.0258, 0.0253, 0.0250],
         [0.0258, 0.0265, 0.0273,  ..., 0.0264, 0.0260, 0.0258],
         [0.0163, 0.0171, 0.0181,  ..., 0.0218, 0.0205, 0.0200]],

        [[0.0334, 0.0338, 0.0341,  ..., 0.0310, 0.0302, 0.0299],
         [0.0190, 0.0195, 0.0199,  ..., 0.0121, 0.0116, 0.0112],
         [0.0180, 0.0186, 0.0197,  ..., 0.0125, 0.0118, 0.0111],
         ...,
         [0.0153, 0.0161, 0.0171,  ..., 0.0142, 0.0135, 0.0131],
         [0.0199, 0.0202, 0.0207,  ..., 0.0142, 0.0140, 0.0140],
         [0.0152, 0.0155, 0.0160,  ..., 0.0125, 0.0120, 0.0121]],

        [[0.0223, 0.0229, 0.0242,  ..., 0.0268, 0.0261, 0.0260],
         [0.0133, 0.0142, 0.0152,  ..., 0.0151, 0.0145, 0.0142],
         [0.0247, 0.0260, 0.0274,  ..., 0.0256, 0.0248, 0.0241],
         ...,
         [0.0220, 0.0232, 0.0245,  ..., 0.0245, 0.0233, 0.0224],
         [0.0161, 0.0171, 0.0181,  ..., 0.0161, 0.0155, 0.0147],
         [0.0152, 0.0160, 0.0171,  ..., 0.0162, 0.0154, 0.0151]],

        ...,

        [[0.0243, 0.0251, 0.0263,  ..., 0.0253, 0.0243, 0.0242],
         [0.0132, 0.0140, 0.0151,  ..., 0.0129, 0.0109, 0.0103],
         [0.0229, 0.0241, 0.0253,  ..., 0.0269, 0.0246, 0.0238],
         ...,
         [0.0224, 0.0234, 0.0251,  ..., 0.0254, 0.0239, 0.0230],
         [0.0198, 0.0205, 0.0215,  ..., 0.0171, 0.0160, 0.0155],
         [0.0166, 0.0173, 0.0184,  ..., 0.0173, 0.0162, 0.0158]],

        [[0.0319, 0.0324, 0.0326,  ..., 0.0336, 0.0326, 0.0324],
         [0.0213, 0.0216, 0.0216,  ..., 0.0187, 0.0173, 0.0172],
         [0.0178, 0.0185, 0.0194,  ..., 0.0195, 0.0179, 0.0176],
         ...,
         [0.0202, 0.0209, 0.0218,  ..., 0.0177, 0.0169, 0.0164],
         [0.0327, 0.0330, 0.0332,  ..., 0.0226, 0.0226, 0.0225],
         [0.0225, 0.0232, 0.0237,  ..., 0.0199, 0.0192, 0.0189]],

        [[0.0236, 0.0243, 0.0253,  ..., 0.0332, 0.0316, 0.0307],
         [0.0225, 0.0234, 0.0236,  ..., 0.0297, 0.0282, 0.0278],
         [0.0193, 0.0202, 0.0212,  ..., 0.0269, 0.0256, 0.0253],
         ...,
         [0.0184, 0.0194, 0.0207,  ..., 0.0229, 0.0219, 0.0212],
         [0.0278, 0.0286, 0.0294,  ..., 0.0274, 0.0266, 0.0261],
         [0.0146, 0.0153, 0.0163,  ..., 0.0221, 0.0203, 0.0194]]],
       device='cuda:0')
unsqueeze final volume shape (DDPM2d) torch.Size([1, 1, 96, 96, 50])
unsqueeze final volume (DDPM 2D) tensor([[[[[0.0286, 0.0292, 0.0305,  ..., 0.0321, 0.0308, 0.0301],
           [0.0187, 0.0194, 0.0207,  ..., 0.0177, 0.0166, 0.0162],
           [0.0231, 0.0239, 0.0253,  ..., 0.0219, 0.0212, 0.0208],
           ...,
           [0.0244, 0.0251, 0.0265,  ..., 0.0258, 0.0253, 0.0250],
           [0.0258, 0.0265, 0.0273,  ..., 0.0264, 0.0260, 0.0258],
           [0.0163, 0.0171, 0.0181,  ..., 0.0218, 0.0205, 0.0200]],

          [[0.0334, 0.0338, 0.0341,  ..., 0.0310, 0.0302, 0.0299],
           [0.0190, 0.0195, 0.0199,  ..., 0.0121, 0.0116, 0.0112],
           [0.0180, 0.0186, 0.0197,  ..., 0.0125, 0.0118, 0.0111],
           ...,
           [0.0153, 0.0161, 0.0171,  ..., 0.0142, 0.0135, 0.0131],
           [0.0199, 0.0202, 0.0207,  ..., 0.0142, 0.0140, 0.0140],
           [0.0152, 0.0155, 0.0160,  ..., 0.0125, 0.0120, 0.0121]],

          [[0.0223, 0.0229, 0.0242,  ..., 0.0268, 0.0261, 0.0260],
           [0.0133, 0.0142, 0.0152,  ..., 0.0151, 0.0145, 0.0142],
           [0.0247, 0.0260, 0.0274,  ..., 0.0256, 0.0248, 0.0241],
           ...,
           [0.0220, 0.0232, 0.0245,  ..., 0.0245, 0.0233, 0.0224],
           [0.0161, 0.0171, 0.0181,  ..., 0.0161, 0.0155, 0.0147],
           [0.0152, 0.0160, 0.0171,  ..., 0.0162, 0.0154, 0.0151]],

          ...,

          [[0.0243, 0.0251, 0.0263,  ..., 0.0253, 0.0243, 0.0242],
           [0.0132, 0.0140, 0.0151,  ..., 0.0129, 0.0109, 0.0103],
           [0.0229, 0.0241, 0.0253,  ..., 0.0269, 0.0246, 0.0238],
           ...,
           [0.0224, 0.0234, 0.0251,  ..., 0.0254, 0.0239, 0.0230],
           [0.0198, 0.0205, 0.0215,  ..., 0.0171, 0.0160, 0.0155],
           [0.0166, 0.0173, 0.0184,  ..., 0.0173, 0.0162, 0.0158]],

          [[0.0319, 0.0324, 0.0326,  ..., 0.0336, 0.0326, 0.0324],
           [0.0213, 0.0216, 0.0216,  ..., 0.0187, 0.0173, 0.0172],
           [0.0178, 0.0185, 0.0194,  ..., 0.0195, 0.0179, 0.0176],
           ...,
           [0.0202, 0.0209, 0.0218,  ..., 0.0177, 0.0169, 0.0164],
           [0.0327, 0.0330, 0.0332,  ..., 0.0226, 0.0226, 0.0225],
           [0.0225, 0.0232, 0.0237,  ..., 0.0199, 0.0192, 0.0189]],

          [[0.0236, 0.0243, 0.0253,  ..., 0.0332, 0.0316, 0.0307],
           [0.0225, 0.0234, 0.0236,  ..., 0.0297, 0.0282, 0.0278],
           [0.0193, 0.0202, 0.0212,  ..., 0.0269, 0.0256, 0.0253],
           ...,
           [0.0184, 0.0194, 0.0207,  ..., 0.0229, 0.0219, 0.0212],
           [0.0278, 0.0286, 0.0294,  ..., 0.0274, 0.0266, 0.0261],
           [0.0146, 0.0153, 0.0163,  ..., 0.0221, 0.0203, 0.0194]]]]],
       device='cuda:0')
==========
IN _TEST_STEP
==========
ERODING BRAIN MASK
MEDIAN FILTERING
SAVING OUTPUT - ORIGINAL, FINAL, MASK ETC
SAVING IMAGES!
Testing:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [00:51<00:12,  3.15s/it]==========
IN DDPM ON TEST STEP
==========
THE WEIRD CONDITION BIT CALLED "features" in DDPM_2D
IN SPARK ENCODER FORWARDDD
x in shape torch.Size([50, 1, 96, 96])
out features torch.Size([50, 512])
i'm i DDPM2d forward block (whch is basically the encoder)
Context vector c shape: torch.Size([50, 512])
shape features:  torch.Size([50, 512])
additng features to latern space
latent space: []
iAM IN THE FORWARD METHOD OF THE WEIRD GUASSIAN IN cond_DDPM.py. I WILL BE CALLING p_losses
i am in p_losses in guassian which seems to be crucial to everything
conditioning vector shape:  torch.Size([50, 512])
in plosses i am getting a noisy image x
x shape:  torch.Size([50, 1, 96, 96])
getting model out
Initial input shape: torch.Size([50, 1, 96, 96])

inputblocks
Before block 0, shape: torch.Size([50, 1, 96, 96])
After block 0, shape: torch.Size([50, 128, 96, 96])
-
Before block 1, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 1, shape: torch.Size([50, 128, 96, 96])
-
Before block 2, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 2, shape: torch.Size([50, 128, 96, 96])
-
Before block 3, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 3, shape: torch.Size([50, 128, 96, 96])
-
Before block 4, shape: torch.Size([50, 128, 96, 96])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 256])
After block 4, shape: torch.Size([50, 128, 48, 48])
-
Before block 5, shape: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 48, 48])
-
Before block 8, shape: torch.Size([50, 256, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 8, shape: torch.Size([50, 256, 24, 24])
-
Before block 9, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 9, shape: torch.Size([50, 256, 24, 24])
-
Before block 10, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 10, shape: torch.Size([50, 256, 24, 24])
-
Before block 11, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 11, shape: torch.Size([50, 256, 24, 24])
-

Before middle block, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
in unet attention block!
x shape torch.Size([50, 256, 24, 24])
out dims torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])


After middle block, shape: torch.Size([50, 256, 24, 24])
-



outputblocks
Before block 0, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 0, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 0, shape: torch.Size([50, 256, 24, 24])
-
Before block 1, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 1, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 1, shape: torch.Size([50, 256, 24, 24])
-
Before block 2, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 2, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 2, shape: torch.Size([50, 256, 24, 24])
-
Before block 3, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 3, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 3, shape: torch.Size([50, 256, 48, 48])
-
Before block 4, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 4, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 4, shape: torch.Size([50, 256, 48, 48])
-
Before block 5, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 5, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 6, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 7, shape: torch.Size([50, 384, 48, 48])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 96, 96])
-
Before block 8, shape: torch.Size([50, 256, 96, 96])
After concatenation in upsampling block 8, shape: torch.Size([50, 384, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 8, shape: torch.Size([50, 128, 96, 96])
-
Before block 9, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 9, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 9, shape: torch.Size([50, 128, 96, 96])
-
Before block 10, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 10, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 10, shape: torch.Size([50, 128, 96, 96])
-
Before block 11, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 11, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 11, shape: torch.Size([50, 128, 96, 96])
-

Before Final layer shape: torch.Size([50, 128, 96, 96])
Final output shape: torch.Size([50, 1, 96, 96])
model out shape:  torch.Size([50, 1, 96, 96])
iAM IN THE FORWARD METHOD OF THE WEIRD GUASSIAN IN cond_DDPM.py. I WILL BE CALLING p_losses
i am in p_losses in guassian which seems to be crucial to everything
conditioning vector shape:  torch.Size([50, 512])
in plosses i am getting a noisy image x
x shape:  torch.Size([50, 1, 96, 96])
getting model out
Initial input shape: torch.Size([50, 1, 96, 96])

inputblocks
Before block 0, shape: torch.Size([50, 1, 96, 96])
After block 0, shape: torch.Size([50, 128, 96, 96])
-
Before block 1, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 1, shape: torch.Size([50, 128, 96, 96])
-
Before block 2, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 2, shape: torch.Size([50, 128, 96, 96])
-
Before block 3, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 3, shape: torch.Size([50, 128, 96, 96])
-
Before block 4, shape: torch.Size([50, 128, 96, 96])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 256])
After block 4, shape: torch.Size([50, 128, 48, 48])
-
Before block 5, shape: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 48, 48])
-
Before block 8, shape: torch.Size([50, 256, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 8, shape: torch.Size([50, 256, 24, 24])
-
Before block 9, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 9, shape: torch.Size([50, 256, 24, 24])
-
Before block 10, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 10, shape: torch.Size([50, 256, 24, 24])
-
Before block 11, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 11, shape: torch.Size([50, 256, 24, 24])
-

Before middle block, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
in unet attention block!
x shape torch.Size([50, 256, 24, 24])
out dims torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])


After middle block, shape: torch.Size([50, 256, 24, 24])
-



outputblocks
Before block 0, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 0, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 0, shape: torch.Size([50, 256, 24, 24])
-
Before block 1, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 1, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 1, shape: torch.Size([50, 256, 24, 24])
-
Before block 2, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 2, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 2, shape: torch.Size([50, 256, 24, 24])
-
Before block 3, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 3, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 3, shape: torch.Size([50, 256, 48, 48])
-
Before block 4, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 4, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 4, shape: torch.Size([50, 256, 48, 48])
-
Before block 5, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 5, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 6, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 7, shape: torch.Size([50, 384, 48, 48])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 96, 96])
-
Before block 8, shape: torch.Size([50, 256, 96, 96])
After concatenation in upsampling block 8, shape: torch.Size([50, 384, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 8, shape: torch.Size([50, 128, 96, 96])
-
Before block 9, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 9, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 9, shape: torch.Size([50, 128, 96, 96])
-
Before block 10, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 10, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 10, shape: torch.Size([50, 128, 96, 96])
-
Before block 11, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 11, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 11, shape: torch.Size([50, 128, 96, 96])
-

Before Final layer shape: torch.Size([50, 128, 96, 96])
Final output shape: torch.Size([50, 1, 96, 96])
model out shape:  torch.Size([50, 1, 96, 96])
iAM IN THE FORWARD METHOD OF THE WEIRD GUASSIAN IN cond_DDPM.py. I WILL BE CALLING p_losses
i am in p_losses in guassian which seems to be crucial to everything
conditioning vector shape:  torch.Size([50, 512])
in plosses i am getting a noisy image x
x shape:  torch.Size([50, 1, 96, 96])
getting model out
Initial input shape: torch.Size([50, 1, 96, 96])

inputblocks
Before block 0, shape: torch.Size([50, 1, 96, 96])
After block 0, shape: torch.Size([50, 128, 96, 96])
-
Before block 1, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 1, shape: torch.Size([50, 128, 96, 96])
-
Before block 2, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 2, shape: torch.Size([50, 128, 96, 96])
-
Before block 3, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 3, shape: torch.Size([50, 128, 96, 96])
-
Before block 4, shape: torch.Size([50, 128, 96, 96])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 256])
After block 4, shape: torch.Size([50, 128, 48, 48])
-
Before block 5, shape: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 48, 48])
-
Before block 8, shape: torch.Size([50, 256, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 8, shape: torch.Size([50, 256, 24, 24])
-
Before block 9, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 9, shape: torch.Size([50, 256, 24, 24])
-
Before block 10, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 10, shape: torch.Size([50, 256, 24, 24])
-
Before block 11, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 11, shape: torch.Size([50, 256, 24, 24])
-

Before middle block, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
in unet attention block!
x shape torch.Size([50, 256, 24, 24])
out dims torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])


After middle block, shape: torch.Size([50, 256, 24, 24])
-



outputblocks
Before block 0, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 0, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 0, shape: torch.Size([50, 256, 24, 24])
-
Before block 1, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 1, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 1, shape: torch.Size([50, 256, 24, 24])
-
Before block 2, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 2, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 2, shape: torch.Size([50, 256, 24, 24])
-
Before block 3, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 3, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 3, shape: torch.Size([50, 256, 48, 48])
-
Before block 4, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 4, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 4, shape: torch.Size([50, 256, 48, 48])
-
Before block 5, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 5, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 6, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 7, shape: torch.Size([50, 384, 48, 48])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 96, 96])
-
Before block 8, shape: torch.Size([50, 256, 96, 96])
After concatenation in upsampling block 8, shape: torch.Size([50, 384, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 8, shape: torch.Size([50, 128, 96, 96])
-
Before block 9, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 9, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 9, shape: torch.Size([50, 128, 96, 96])
-
Before block 10, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 10, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 10, shape: torch.Size([50, 128, 96, 96])
-
Before block 11, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 11, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 11, shape: torch.Size([50, 128, 96, 96])
-

Before Final layer shape: torch.Size([50, 128, 96, 96])
Final output shape: torch.Size([50, 1, 96, 96])
model out shape:  torch.Size([50, 1, 96, 96])
reconstruction shape torch.Size([50, 1, 96, 96])
reconstruction tensor([[[[ 0.0160,  0.0078,  0.0119,  ...,  0.0094,  0.0122,  0.0046],
          [ 0.0108,  0.0024,  0.0036,  ...,  0.0029,  0.0107,  0.0046],
          [ 0.0060, -0.0013,  0.0118,  ...,  0.0073,  0.0042,  0.0039],
          ...,
          [ 0.0081, -0.0018,  0.0104,  ...,  0.0122,  0.0067,  0.0018],
          [ 0.0103,  0.0055,  0.0042,  ...,  0.0059,  0.0135,  0.0045],
          [ 0.0057,  0.0038,  0.0062,  ...,  0.0029,  0.0084,  0.0012]]],


        [[[ 0.0166,  0.0082,  0.0120,  ...,  0.0097,  0.0127,  0.0046],
          [ 0.0111,  0.0023,  0.0036,  ...,  0.0029,  0.0107,  0.0047],
          [ 0.0063, -0.0013,  0.0120,  ...,  0.0074,  0.0043,  0.0041],
          ...,
          [ 0.0082, -0.0018,  0.0103,  ...,  0.0121,  0.0070,  0.0020],
          [ 0.0105,  0.0055,  0.0041,  ...,  0.0059,  0.0142,  0.0048],
          [ 0.0058,  0.0042,  0.0064,  ...,  0.0035,  0.0091,  0.0018]]],


        [[[ 0.0193,  0.0107,  0.0146,  ...,  0.0120,  0.0145,  0.0071],
          [ 0.0129,  0.0033,  0.0055,  ...,  0.0046,  0.0116,  0.0058],
          [ 0.0082,  0.0003,  0.0144,  ...,  0.0098,  0.0061,  0.0063],
          ...,
          [ 0.0105,  0.0002,  0.0127,  ...,  0.0147,  0.0097,  0.0048],
          [ 0.0119,  0.0064,  0.0059,  ...,  0.0090,  0.0168,  0.0072],
          [ 0.0079,  0.0057,  0.0086,  ...,  0.0067,  0.0122,  0.0047]]],


        ...,


        [[[ 0.0221,  0.0120,  0.0141,  ...,  0.0102,  0.0122,  0.0083],
          [ 0.0127,  0.0026,  0.0036,  ...,  0.0011,  0.0069,  0.0031],
          [ 0.0086,  0.0008,  0.0118,  ...,  0.0068,  0.0039,  0.0054],
          ...,
          [ 0.0106,  0.0010,  0.0111,  ...,  0.0343,  0.0334,  0.0245],
          [ 0.0155,  0.0114,  0.0090,  ...,  0.0418,  0.0551,  0.0358],
          [ 0.0116,  0.0123,  0.0133,  ...,  0.0359,  0.0436,  0.0283]]],


        [[[ 0.0220,  0.0121,  0.0144,  ...,  0.0106,  0.0128,  0.0083],
          [ 0.0126,  0.0033,  0.0042,  ...,  0.0020,  0.0078,  0.0033],
          [ 0.0089,  0.0018,  0.0125,  ...,  0.0077,  0.0049,  0.0057],
          ...,
          [ 0.0107,  0.0013,  0.0115,  ...,  0.0305,  0.0294,  0.0207],
          [ 0.0155,  0.0120,  0.0093,  ...,  0.0361,  0.0492,  0.0311],
          [ 0.0107,  0.0120,  0.0130,  ...,  0.0305,  0.0387,  0.0244]]],


        [[[ 0.0214,  0.0118,  0.0142,  ...,  0.0112,  0.0131,  0.0080],
          [ 0.0121,  0.0033,  0.0044,  ...,  0.0028,  0.0084,  0.0035],
          [ 0.0085,  0.0018,  0.0129,  ...,  0.0085,  0.0054,  0.0058],
          ...,
          [ 0.0106,  0.0011,  0.0116,  ...,  0.0253,  0.0232,  0.0153],
          [ 0.0148,  0.0111,  0.0085,  ...,  0.0276,  0.0396,  0.0242],
          [ 0.0092,  0.0109,  0.0120,  ...,  0.0229,  0.0310,  0.0186]]]],
       device='cuda:0')
FINAL VOLUME (DDPM) shape torch.Size([96, 96, 50])
FINAL VOLUME tensor([[[ 0.0160,  0.0166,  0.0193,  ...,  0.0221,  0.0220,  0.0214],
         [ 0.0078,  0.0082,  0.0107,  ...,  0.0120,  0.0121,  0.0118],
         [ 0.0119,  0.0120,  0.0146,  ...,  0.0141,  0.0144,  0.0142],
         ...,
         [ 0.0094,  0.0097,  0.0120,  ...,  0.0102,  0.0106,  0.0112],
         [ 0.0122,  0.0127,  0.0145,  ...,  0.0122,  0.0128,  0.0131],
         [ 0.0046,  0.0046,  0.0071,  ...,  0.0083,  0.0083,  0.0080]],

        [[ 0.0108,  0.0111,  0.0129,  ...,  0.0127,  0.0126,  0.0121],
         [ 0.0024,  0.0023,  0.0033,  ...,  0.0026,  0.0033,  0.0033],
         [ 0.0036,  0.0036,  0.0055,  ...,  0.0036,  0.0042,  0.0044],
         ...,
         [ 0.0029,  0.0029,  0.0046,  ...,  0.0011,  0.0020,  0.0028],
         [ 0.0107,  0.0107,  0.0116,  ...,  0.0069,  0.0078,  0.0084],
         [ 0.0046,  0.0047,  0.0058,  ...,  0.0031,  0.0033,  0.0035]],

        [[ 0.0060,  0.0063,  0.0082,  ...,  0.0086,  0.0089,  0.0085],
         [-0.0013, -0.0013,  0.0003,  ...,  0.0008,  0.0018,  0.0018],
         [ 0.0118,  0.0120,  0.0144,  ...,  0.0118,  0.0125,  0.0129],
         ...,
         [ 0.0073,  0.0074,  0.0098,  ...,  0.0068,  0.0077,  0.0085],
         [ 0.0042,  0.0043,  0.0061,  ...,  0.0039,  0.0049,  0.0054],
         [ 0.0039,  0.0041,  0.0063,  ...,  0.0054,  0.0057,  0.0058]],

        ...,

        [[ 0.0081,  0.0082,  0.0105,  ...,  0.0106,  0.0107,  0.0106],
         [-0.0018, -0.0018,  0.0002,  ...,  0.0010,  0.0013,  0.0011],
         [ 0.0104,  0.0103,  0.0127,  ...,  0.0111,  0.0115,  0.0116],
         ...,
         [ 0.0122,  0.0121,  0.0147,  ...,  0.0343,  0.0305,  0.0253],
         [ 0.0067,  0.0070,  0.0097,  ...,  0.0334,  0.0294,  0.0232],
         [ 0.0018,  0.0020,  0.0048,  ...,  0.0245,  0.0207,  0.0153]],

        [[ 0.0103,  0.0105,  0.0119,  ...,  0.0155,  0.0155,  0.0148],
         [ 0.0055,  0.0055,  0.0064,  ...,  0.0114,  0.0120,  0.0111],
         [ 0.0042,  0.0041,  0.0059,  ...,  0.0090,  0.0093,  0.0085],
         ...,
         [ 0.0059,  0.0059,  0.0090,  ...,  0.0418,  0.0361,  0.0276],
         [ 0.0135,  0.0142,  0.0168,  ...,  0.0551,  0.0492,  0.0396],
         [ 0.0045,  0.0048,  0.0072,  ...,  0.0358,  0.0311,  0.0242]],

        [[ 0.0057,  0.0058,  0.0079,  ...,  0.0116,  0.0107,  0.0092],
         [ 0.0038,  0.0042,  0.0057,  ...,  0.0123,  0.0120,  0.0109],
         [ 0.0062,  0.0064,  0.0086,  ...,  0.0133,  0.0130,  0.0120],
         ...,
         [ 0.0029,  0.0035,  0.0067,  ...,  0.0359,  0.0305,  0.0229],
         [ 0.0084,  0.0091,  0.0122,  ...,  0.0436,  0.0387,  0.0310],
         [ 0.0012,  0.0018,  0.0047,  ...,  0.0283,  0.0244,  0.0186]]],
       device='cuda:0')
unsqueeze final volume shape (DDPM2d) torch.Size([1, 1, 96, 96, 50])
unsqueeze final volume (DDPM 2D) tensor([[[[[ 0.0160,  0.0166,  0.0193,  ...,  0.0221,  0.0220,  0.0214],
           [ 0.0078,  0.0082,  0.0107,  ...,  0.0120,  0.0121,  0.0118],
           [ 0.0119,  0.0120,  0.0146,  ...,  0.0141,  0.0144,  0.0142],
           ...,
           [ 0.0094,  0.0097,  0.0120,  ...,  0.0102,  0.0106,  0.0112],
           [ 0.0122,  0.0127,  0.0145,  ...,  0.0122,  0.0128,  0.0131],
           [ 0.0046,  0.0046,  0.0071,  ...,  0.0083,  0.0083,  0.0080]],

          [[ 0.0108,  0.0111,  0.0129,  ...,  0.0127,  0.0126,  0.0121],
           [ 0.0024,  0.0023,  0.0033,  ...,  0.0026,  0.0033,  0.0033],
           [ 0.0036,  0.0036,  0.0055,  ...,  0.0036,  0.0042,  0.0044],
           ...,
           [ 0.0029,  0.0029,  0.0046,  ...,  0.0011,  0.0020,  0.0028],
           [ 0.0107,  0.0107,  0.0116,  ...,  0.0069,  0.0078,  0.0084],
           [ 0.0046,  0.0047,  0.0058,  ...,  0.0031,  0.0033,  0.0035]],

          [[ 0.0060,  0.0063,  0.0082,  ...,  0.0086,  0.0089,  0.0085],
           [-0.0013, -0.0013,  0.0003,  ...,  0.0008,  0.0018,  0.0018],
           [ 0.0118,  0.0120,  0.0144,  ...,  0.0118,  0.0125,  0.0129],
           ...,
           [ 0.0073,  0.0074,  0.0098,  ...,  0.0068,  0.0077,  0.0085],
           [ 0.0042,  0.0043,  0.0061,  ...,  0.0039,  0.0049,  0.0054],
           [ 0.0039,  0.0041,  0.0063,  ...,  0.0054,  0.0057,  0.0058]],

          ...,

          [[ 0.0081,  0.0082,  0.0105,  ...,  0.0106,  0.0107,  0.0106],
           [-0.0018, -0.0018,  0.0002,  ...,  0.0010,  0.0013,  0.0011],
           [ 0.0104,  0.0103,  0.0127,  ...,  0.0111,  0.0115,  0.0116],
           ...,
           [ 0.0122,  0.0121,  0.0147,  ...,  0.0343,  0.0305,  0.0253],
           [ 0.0067,  0.0070,  0.0097,  ...,  0.0334,  0.0294,  0.0232],
           [ 0.0018,  0.0020,  0.0048,  ...,  0.0245,  0.0207,  0.0153]],

          [[ 0.0103,  0.0105,  0.0119,  ...,  0.0155,  0.0155,  0.0148],
           [ 0.0055,  0.0055,  0.0064,  ...,  0.0114,  0.0120,  0.0111],
           [ 0.0042,  0.0041,  0.0059,  ...,  0.0090,  0.0093,  0.0085],
           ...,
           [ 0.0059,  0.0059,  0.0090,  ...,  0.0418,  0.0361,  0.0276],
           [ 0.0135,  0.0142,  0.0168,  ...,  0.0551,  0.0492,  0.0396],
           [ 0.0045,  0.0048,  0.0072,  ...,  0.0358,  0.0311,  0.0242]],

          [[ 0.0057,  0.0058,  0.0079,  ...,  0.0116,  0.0107,  0.0092],
           [ 0.0038,  0.0042,  0.0057,  ...,  0.0123,  0.0120,  0.0109],
           [ 0.0062,  0.0064,  0.0086,  ...,  0.0133,  0.0130,  0.0120],
           ...,
           [ 0.0029,  0.0035,  0.0067,  ...,  0.0359,  0.0305,  0.0229],
           [ 0.0084,  0.0091,  0.0122,  ...,  0.0436,  0.0387,  0.0310],
           [ 0.0012,  0.0018,  0.0047,  ...,  0.0283,  0.0244,  0.0186]]]]],
       device='cuda:0')
==========
IN _TEST_STEP
==========
ERODING BRAIN MASK
MEDIAN FILTERING
SAVING OUTPUT - ORIGINAL, FINAL, MASK ETC
SAVING IMAGES!
Testing:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [00:54<00:09,  3.12s/it]==========
IN DDPM ON TEST STEP
==========
THE WEIRD CONDITION BIT CALLED "features" in DDPM_2D
IN SPARK ENCODER FORWARDDD
x in shape torch.Size([50, 1, 96, 96])
out features torch.Size([50, 512])
i'm i DDPM2d forward block (whch is basically the encoder)
Context vector c shape: torch.Size([50, 512])
shape features:  torch.Size([50, 512])
additng features to latern space
latent space: []
iAM IN THE FORWARD METHOD OF THE WEIRD GUASSIAN IN cond_DDPM.py. I WILL BE CALLING p_losses
i am in p_losses in guassian which seems to be crucial to everything
conditioning vector shape:  torch.Size([50, 512])
in plosses i am getting a noisy image x
x shape:  torch.Size([50, 1, 96, 96])
getting model out
Initial input shape: torch.Size([50, 1, 96, 96])

inputblocks
Before block 0, shape: torch.Size([50, 1, 96, 96])
After block 0, shape: torch.Size([50, 128, 96, 96])
-
Before block 1, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 1, shape: torch.Size([50, 128, 96, 96])
-
Before block 2, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 2, shape: torch.Size([50, 128, 96, 96])
-
Before block 3, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 3, shape: torch.Size([50, 128, 96, 96])
-
Before block 4, shape: torch.Size([50, 128, 96, 96])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 256])
After block 4, shape: torch.Size([50, 128, 48, 48])
-
Before block 5, shape: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 48, 48])
-
Before block 8, shape: torch.Size([50, 256, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 8, shape: torch.Size([50, 256, 24, 24])
-
Before block 9, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 9, shape: torch.Size([50, 256, 24, 24])
-
Before block 10, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 10, shape: torch.Size([50, 256, 24, 24])
-
Before block 11, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 11, shape: torch.Size([50, 256, 24, 24])
-

Before middle block, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
in unet attention block!
x shape torch.Size([50, 256, 24, 24])
out dims torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])


After middle block, shape: torch.Size([50, 256, 24, 24])
-



outputblocks
Before block 0, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 0, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 0, shape: torch.Size([50, 256, 24, 24])
-
Before block 1, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 1, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 1, shape: torch.Size([50, 256, 24, 24])
-
Before block 2, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 2, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 2, shape: torch.Size([50, 256, 24, 24])
-
Before block 3, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 3, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 3, shape: torch.Size([50, 256, 48, 48])
-
Before block 4, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 4, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 4, shape: torch.Size([50, 256, 48, 48])
-
Before block 5, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 5, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 6, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 7, shape: torch.Size([50, 384, 48, 48])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 96, 96])
-
Before block 8, shape: torch.Size([50, 256, 96, 96])
After concatenation in upsampling block 8, shape: torch.Size([50, 384, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 8, shape: torch.Size([50, 128, 96, 96])
-
Before block 9, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 9, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 9, shape: torch.Size([50, 128, 96, 96])
-
Before block 10, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 10, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 10, shape: torch.Size([50, 128, 96, 96])
-
Before block 11, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 11, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 11, shape: torch.Size([50, 128, 96, 96])
-

Before Final layer shape: torch.Size([50, 128, 96, 96])
Final output shape: torch.Size([50, 1, 96, 96])
model out shape:  torch.Size([50, 1, 96, 96])
iAM IN THE FORWARD METHOD OF THE WEIRD GUASSIAN IN cond_DDPM.py. I WILL BE CALLING p_losses
i am in p_losses in guassian which seems to be crucial to everything
conditioning vector shape:  torch.Size([50, 512])
in plosses i am getting a noisy image x
x shape:  torch.Size([50, 1, 96, 96])
getting model out
Initial input shape: torch.Size([50, 1, 96, 96])

inputblocks
Before block 0, shape: torch.Size([50, 1, 96, 96])
After block 0, shape: torch.Size([50, 128, 96, 96])
-
Before block 1, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 1, shape: torch.Size([50, 128, 96, 96])
-
Before block 2, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 2, shape: torch.Size([50, 128, 96, 96])
-
Before block 3, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 3, shape: torch.Size([50, 128, 96, 96])
-
Before block 4, shape: torch.Size([50, 128, 96, 96])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 256])
After block 4, shape: torch.Size([50, 128, 48, 48])
-
Before block 5, shape: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 48, 48])
-
Before block 8, shape: torch.Size([50, 256, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 8, shape: torch.Size([50, 256, 24, 24])
-
Before block 9, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 9, shape: torch.Size([50, 256, 24, 24])
-
Before block 10, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 10, shape: torch.Size([50, 256, 24, 24])
-
Before block 11, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 11, shape: torch.Size([50, 256, 24, 24])
-

Before middle block, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
in unet attention block!
x shape torch.Size([50, 256, 24, 24])
out dims torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])


After middle block, shape: torch.Size([50, 256, 24, 24])
-



outputblocks
Before block 0, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 0, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 0, shape: torch.Size([50, 256, 24, 24])
-
Before block 1, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 1, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 1, shape: torch.Size([50, 256, 24, 24])
-
Before block 2, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 2, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 2, shape: torch.Size([50, 256, 24, 24])
-
Before block 3, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 3, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 3, shape: torch.Size([50, 256, 48, 48])
-
Before block 4, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 4, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 4, shape: torch.Size([50, 256, 48, 48])
-
Before block 5, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 5, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 6, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 7, shape: torch.Size([50, 384, 48, 48])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 96, 96])
-
Before block 8, shape: torch.Size([50, 256, 96, 96])
After concatenation in upsampling block 8, shape: torch.Size([50, 384, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 8, shape: torch.Size([50, 128, 96, 96])
-
Before block 9, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 9, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 9, shape: torch.Size([50, 128, 96, 96])
-
Before block 10, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 10, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 10, shape: torch.Size([50, 128, 96, 96])
-
Before block 11, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 11, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 11, shape: torch.Size([50, 128, 96, 96])
-

Before Final layer shape: torch.Size([50, 128, 96, 96])
Final output shape: torch.Size([50, 1, 96, 96])
model out shape:  torch.Size([50, 1, 96, 96])
iAM IN THE FORWARD METHOD OF THE WEIRD GUASSIAN IN cond_DDPM.py. I WILL BE CALLING p_losses
i am in p_losses in guassian which seems to be crucial to everything
conditioning vector shape:  torch.Size([50, 512])
in plosses i am getting a noisy image x
x shape:  torch.Size([50, 1, 96, 96])
getting model out
Initial input shape: torch.Size([50, 1, 96, 96])

inputblocks
Before block 0, shape: torch.Size([50, 1, 96, 96])
After block 0, shape: torch.Size([50, 128, 96, 96])
-
Before block 1, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 1, shape: torch.Size([50, 128, 96, 96])
-
Before block 2, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 2, shape: torch.Size([50, 128, 96, 96])
-
Before block 3, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 3, shape: torch.Size([50, 128, 96, 96])
-
Before block 4, shape: torch.Size([50, 128, 96, 96])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 256])
After block 4, shape: torch.Size([50, 128, 48, 48])
-
Before block 5, shape: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 48, 48])
-
Before block 8, shape: torch.Size([50, 256, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 8, shape: torch.Size([50, 256, 24, 24])
-
Before block 9, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 9, shape: torch.Size([50, 256, 24, 24])
-
Before block 10, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 10, shape: torch.Size([50, 256, 24, 24])
-
Before block 11, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 11, shape: torch.Size([50, 256, 24, 24])
-

Before middle block, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
in unet attention block!
x shape torch.Size([50, 256, 24, 24])
out dims torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])


After middle block, shape: torch.Size([50, 256, 24, 24])
-



outputblocks
Before block 0, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 0, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 0, shape: torch.Size([50, 256, 24, 24])
-
Before block 1, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 1, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 1, shape: torch.Size([50, 256, 24, 24])
-
Before block 2, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 2, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 2, shape: torch.Size([50, 256, 24, 24])
-
Before block 3, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 3, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 3, shape: torch.Size([50, 256, 48, 48])
-
Before block 4, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 4, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 4, shape: torch.Size([50, 256, 48, 48])
-
Before block 5, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 5, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 6, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 7, shape: torch.Size([50, 384, 48, 48])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 96, 96])
-
Before block 8, shape: torch.Size([50, 256, 96, 96])
After concatenation in upsampling block 8, shape: torch.Size([50, 384, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 8, shape: torch.Size([50, 128, 96, 96])
-
Before block 9, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 9, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 9, shape: torch.Size([50, 128, 96, 96])
-
Before block 10, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 10, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 10, shape: torch.Size([50, 128, 96, 96])
-
Before block 11, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 11, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 11, shape: torch.Size([50, 128, 96, 96])
-

Before Final layer shape: torch.Size([50, 128, 96, 96])
Final output shape: torch.Size([50, 1, 96, 96])
model out shape:  torch.Size([50, 1, 96, 96])
reconstruction shape torch.Size([50, 1, 96, 96])
reconstruction tensor([[[[0.0538, 0.0485, 0.0494,  ..., 0.0526, 0.0556, 0.0493],
          [0.0518, 0.0430, 0.0444,  ..., 0.0470, 0.0470, 0.0389],
          [0.0442, 0.0396, 0.0492,  ..., 0.0526, 0.0443, 0.0391],
          ...,
          [0.0544, 0.0475, 0.0610,  ..., 0.0547, 0.0487, 0.0430],
          [0.0630, 0.0536, 0.0549,  ..., 0.0506, 0.0592, 0.0437],
          [0.0496, 0.0516, 0.0488,  ..., 0.0463, 0.0534, 0.0409]]],


        [[[0.0536, 0.0487, 0.0496,  ..., 0.0527, 0.0558, 0.0493],
          [0.0522, 0.0435, 0.0448,  ..., 0.0475, 0.0474, 0.0391],
          [0.0444, 0.0400, 0.0499,  ..., 0.0531, 0.0449, 0.0393],
          ...,
          [0.0540, 0.0474, 0.0602,  ..., 0.0553, 0.0493, 0.0431],
          [0.0628, 0.0534, 0.0539,  ..., 0.0513, 0.0596, 0.0436],
          [0.0496, 0.0518, 0.0484,  ..., 0.0466, 0.0539, 0.0412]]],


        [[[0.0543, 0.0492, 0.0499,  ..., 0.0532, 0.0561, 0.0498],
          [0.0525, 0.0436, 0.0451,  ..., 0.0479, 0.0474, 0.0391],
          [0.0448, 0.0404, 0.0505,  ..., 0.0535, 0.0452, 0.0395],
          ...,
          [0.0545, 0.0479, 0.0609,  ..., 0.0560, 0.0496, 0.0435],
          [0.0634, 0.0536, 0.0544,  ..., 0.0515, 0.0596, 0.0440],
          [0.0501, 0.0524, 0.0489,  ..., 0.0471, 0.0542, 0.0417]]],


        ...,


        [[[0.0578, 0.0509, 0.0499,  ..., 0.0533, 0.0565, 0.0527],
          [0.0533, 0.0426, 0.0457,  ..., 0.0506, 0.0500, 0.0416],
          [0.0452, 0.0402, 0.0513,  ..., 0.0556, 0.0469, 0.0398],
          ...,
          [0.0553, 0.0481, 0.0655,  ..., 0.0641, 0.0548, 0.0459],
          [0.0636, 0.0518, 0.0561,  ..., 0.0590, 0.0649, 0.0480],
          [0.0599, 0.0567, 0.0518,  ..., 0.0534, 0.0609, 0.0514]]],


        [[[0.0562, 0.0492, 0.0487,  ..., 0.0514, 0.0545, 0.0508],
          [0.0513, 0.0399, 0.0434,  ..., 0.0471, 0.0465, 0.0392],
          [0.0437, 0.0379, 0.0497,  ..., 0.0532, 0.0439, 0.0379],
          ...,
          [0.0555, 0.0469, 0.0654,  ..., 0.0621, 0.0521, 0.0438],
          [0.0636, 0.0515, 0.0563,  ..., 0.0560, 0.0619, 0.0455],
          [0.0588, 0.0566, 0.0524,  ..., 0.0513, 0.0583, 0.0489]]],


        [[[0.0557, 0.0492, 0.0481,  ..., 0.0515, 0.0557, 0.0502],
          [0.0518, 0.0406, 0.0431,  ..., 0.0479, 0.0492, 0.0404],
          [0.0431, 0.0368, 0.0477,  ..., 0.0523, 0.0439, 0.0376],
          ...,
          [0.0576, 0.0495, 0.0706,  ..., 0.0645, 0.0566, 0.0468],
          [0.0671, 0.0563, 0.0627,  ..., 0.0613, 0.0699, 0.0500],
          [0.0604, 0.0588, 0.0552,  ..., 0.0551, 0.0636, 0.0509]]]],
       device='cuda:0')
FINAL VOLUME (DDPM) shape torch.Size([96, 96, 50])
FINAL VOLUME tensor([[[0.0538, 0.0536, 0.0543,  ..., 0.0578, 0.0562, 0.0557],
         [0.0485, 0.0487, 0.0492,  ..., 0.0509, 0.0492, 0.0492],
         [0.0494, 0.0496, 0.0499,  ..., 0.0499, 0.0487, 0.0481],
         ...,
         [0.0526, 0.0527, 0.0532,  ..., 0.0533, 0.0514, 0.0515],
         [0.0556, 0.0558, 0.0561,  ..., 0.0565, 0.0545, 0.0557],
         [0.0493, 0.0493, 0.0498,  ..., 0.0527, 0.0508, 0.0502]],

        [[0.0518, 0.0522, 0.0525,  ..., 0.0533, 0.0513, 0.0518],
         [0.0430, 0.0435, 0.0436,  ..., 0.0426, 0.0399, 0.0406],
         [0.0444, 0.0448, 0.0451,  ..., 0.0457, 0.0434, 0.0431],
         ...,
         [0.0470, 0.0475, 0.0479,  ..., 0.0506, 0.0471, 0.0479],
         [0.0470, 0.0474, 0.0474,  ..., 0.0500, 0.0465, 0.0492],
         [0.0389, 0.0391, 0.0391,  ..., 0.0416, 0.0392, 0.0404]],

        [[0.0442, 0.0444, 0.0448,  ..., 0.0452, 0.0437, 0.0431],
         [0.0396, 0.0400, 0.0404,  ..., 0.0402, 0.0379, 0.0368],
         [0.0492, 0.0499, 0.0505,  ..., 0.0513, 0.0497, 0.0477],
         ...,
         [0.0526, 0.0531, 0.0535,  ..., 0.0556, 0.0532, 0.0523],
         [0.0443, 0.0449, 0.0452,  ..., 0.0469, 0.0439, 0.0439],
         [0.0391, 0.0393, 0.0395,  ..., 0.0398, 0.0379, 0.0376]],

        ...,

        [[0.0544, 0.0540, 0.0545,  ..., 0.0553, 0.0555, 0.0576],
         [0.0475, 0.0474, 0.0479,  ..., 0.0481, 0.0469, 0.0495],
         [0.0610, 0.0602, 0.0609,  ..., 0.0655, 0.0654, 0.0706],
         ...,
         [0.0547, 0.0553, 0.0560,  ..., 0.0641, 0.0621, 0.0645],
         [0.0487, 0.0493, 0.0496,  ..., 0.0548, 0.0521, 0.0566],
         [0.0430, 0.0431, 0.0435,  ..., 0.0459, 0.0438, 0.0468]],

        [[0.0630, 0.0628, 0.0634,  ..., 0.0636, 0.0636, 0.0671],
         [0.0536, 0.0534, 0.0536,  ..., 0.0518, 0.0515, 0.0563],
         [0.0549, 0.0539, 0.0544,  ..., 0.0561, 0.0563, 0.0627],
         ...,
         [0.0506, 0.0513, 0.0515,  ..., 0.0590, 0.0560, 0.0613],
         [0.0592, 0.0596, 0.0596,  ..., 0.0649, 0.0619, 0.0699],
         [0.0437, 0.0436, 0.0440,  ..., 0.0480, 0.0455, 0.0500]],

        [[0.0496, 0.0496, 0.0501,  ..., 0.0599, 0.0588, 0.0604],
         [0.0516, 0.0518, 0.0524,  ..., 0.0567, 0.0566, 0.0588],
         [0.0488, 0.0484, 0.0489,  ..., 0.0518, 0.0524, 0.0552],
         ...,
         [0.0463, 0.0466, 0.0471,  ..., 0.0534, 0.0513, 0.0551],
         [0.0534, 0.0539, 0.0542,  ..., 0.0609, 0.0583, 0.0636],
         [0.0409, 0.0412, 0.0417,  ..., 0.0514, 0.0489, 0.0509]]],
       device='cuda:0')
unsqueeze final volume shape (DDPM2d) torch.Size([1, 1, 96, 96, 50])
unsqueeze final volume (DDPM 2D) tensor([[[[[0.0538, 0.0536, 0.0543,  ..., 0.0578, 0.0562, 0.0557],
           [0.0485, 0.0487, 0.0492,  ..., 0.0509, 0.0492, 0.0492],
           [0.0494, 0.0496, 0.0499,  ..., 0.0499, 0.0487, 0.0481],
           ...,
           [0.0526, 0.0527, 0.0532,  ..., 0.0533, 0.0514, 0.0515],
           [0.0556, 0.0558, 0.0561,  ..., 0.0565, 0.0545, 0.0557],
           [0.0493, 0.0493, 0.0498,  ..., 0.0527, 0.0508, 0.0502]],

          [[0.0518, 0.0522, 0.0525,  ..., 0.0533, 0.0513, 0.0518],
           [0.0430, 0.0435, 0.0436,  ..., 0.0426, 0.0399, 0.0406],
           [0.0444, 0.0448, 0.0451,  ..., 0.0457, 0.0434, 0.0431],
           ...,
           [0.0470, 0.0475, 0.0479,  ..., 0.0506, 0.0471, 0.0479],
           [0.0470, 0.0474, 0.0474,  ..., 0.0500, 0.0465, 0.0492],
           [0.0389, 0.0391, 0.0391,  ..., 0.0416, 0.0392, 0.0404]],

          [[0.0442, 0.0444, 0.0448,  ..., 0.0452, 0.0437, 0.0431],
           [0.0396, 0.0400, 0.0404,  ..., 0.0402, 0.0379, 0.0368],
           [0.0492, 0.0499, 0.0505,  ..., 0.0513, 0.0497, 0.0477],
           ...,
           [0.0526, 0.0531, 0.0535,  ..., 0.0556, 0.0532, 0.0523],
           [0.0443, 0.0449, 0.0452,  ..., 0.0469, 0.0439, 0.0439],
           [0.0391, 0.0393, 0.0395,  ..., 0.0398, 0.0379, 0.0376]],

          ...,

          [[0.0544, 0.0540, 0.0545,  ..., 0.0553, 0.0555, 0.0576],
           [0.0475, 0.0474, 0.0479,  ..., 0.0481, 0.0469, 0.0495],
           [0.0610, 0.0602, 0.0609,  ..., 0.0655, 0.0654, 0.0706],
           ...,
           [0.0547, 0.0553, 0.0560,  ..., 0.0641, 0.0621, 0.0645],
           [0.0487, 0.0493, 0.0496,  ..., 0.0548, 0.0521, 0.0566],
           [0.0430, 0.0431, 0.0435,  ..., 0.0459, 0.0438, 0.0468]],

          [[0.0630, 0.0628, 0.0634,  ..., 0.0636, 0.0636, 0.0671],
           [0.0536, 0.0534, 0.0536,  ..., 0.0518, 0.0515, 0.0563],
           [0.0549, 0.0539, 0.0544,  ..., 0.0561, 0.0563, 0.0627],
           ...,
           [0.0506, 0.0513, 0.0515,  ..., 0.0590, 0.0560, 0.0613],
           [0.0592, 0.0596, 0.0596,  ..., 0.0649, 0.0619, 0.0699],
           [0.0437, 0.0436, 0.0440,  ..., 0.0480, 0.0455, 0.0500]],

          [[0.0496, 0.0496, 0.0501,  ..., 0.0599, 0.0588, 0.0604],
           [0.0516, 0.0518, 0.0524,  ..., 0.0567, 0.0566, 0.0588],
           [0.0488, 0.0484, 0.0489,  ..., 0.0518, 0.0524, 0.0552],
           ...,
           [0.0463, 0.0466, 0.0471,  ..., 0.0534, 0.0513, 0.0551],
           [0.0534, 0.0539, 0.0542,  ..., 0.0609, 0.0583, 0.0636],
           [0.0409, 0.0412, 0.0417,  ..., 0.0514, 0.0489, 0.0509]]]]],
       device='cuda:0')
==========
IN _TEST_STEP
==========
ERODING BRAIN MASK
MEDIAN FILTERING
SAVING OUTPUT - ORIGINAL, FINAL, MASK ETC
SAVING IMAGES!
Testing:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [00:57<00:06,  3.02s/it]==========
IN DDPM ON TEST STEP
==========
THE WEIRD CONDITION BIT CALLED "features" in DDPM_2D
IN SPARK ENCODER FORWARDDD
x in shape torch.Size([50, 1, 96, 96])
out features torch.Size([50, 512])
i'm i DDPM2d forward block (whch is basically the encoder)
Context vector c shape: torch.Size([50, 512])
shape features:  torch.Size([50, 512])
additng features to latern space
latent space: []
iAM IN THE FORWARD METHOD OF THE WEIRD GUASSIAN IN cond_DDPM.py. I WILL BE CALLING p_losses
i am in p_losses in guassian which seems to be crucial to everything
conditioning vector shape:  torch.Size([50, 512])
in plosses i am getting a noisy image x
x shape:  torch.Size([50, 1, 96, 96])
getting model out
Initial input shape: torch.Size([50, 1, 96, 96])

inputblocks
Before block 0, shape: torch.Size([50, 1, 96, 96])
After block 0, shape: torch.Size([50, 128, 96, 96])
-
Before block 1, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 1, shape: torch.Size([50, 128, 96, 96])
-
Before block 2, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 2, shape: torch.Size([50, 128, 96, 96])
-
Before block 3, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 3, shape: torch.Size([50, 128, 96, 96])
-
Before block 4, shape: torch.Size([50, 128, 96, 96])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 256])
After block 4, shape: torch.Size([50, 128, 48, 48])
-
Before block 5, shape: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 48, 48])
-
Before block 8, shape: torch.Size([50, 256, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 8, shape: torch.Size([50, 256, 24, 24])
-
Before block 9, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 9, shape: torch.Size([50, 256, 24, 24])
-
Before block 10, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 10, shape: torch.Size([50, 256, 24, 24])
-
Before block 11, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 11, shape: torch.Size([50, 256, 24, 24])
-

Before middle block, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
in unet attention block!
x shape torch.Size([50, 256, 24, 24])
out dims torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])


After middle block, shape: torch.Size([50, 256, 24, 24])
-



outputblocks
Before block 0, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 0, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 0, shape: torch.Size([50, 256, 24, 24])
-
Before block 1, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 1, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 1, shape: torch.Size([50, 256, 24, 24])
-
Before block 2, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 2, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 2, shape: torch.Size([50, 256, 24, 24])
-
Before block 3, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 3, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 3, shape: torch.Size([50, 256, 48, 48])
-
Before block 4, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 4, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 4, shape: torch.Size([50, 256, 48, 48])
-
Before block 5, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 5, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 6, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 7, shape: torch.Size([50, 384, 48, 48])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 96, 96])
-
Before block 8, shape: torch.Size([50, 256, 96, 96])
After concatenation in upsampling block 8, shape: torch.Size([50, 384, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 8, shape: torch.Size([50, 128, 96, 96])
-
Before block 9, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 9, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 9, shape: torch.Size([50, 128, 96, 96])
-
Before block 10, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 10, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 10, shape: torch.Size([50, 128, 96, 96])
-
Before block 11, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 11, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 11, shape: torch.Size([50, 128, 96, 96])
-

Before Final layer shape: torch.Size([50, 128, 96, 96])
Final output shape: torch.Size([50, 1, 96, 96])
model out shape:  torch.Size([50, 1, 96, 96])
iAM IN THE FORWARD METHOD OF THE WEIRD GUASSIAN IN cond_DDPM.py. I WILL BE CALLING p_losses
i am in p_losses in guassian which seems to be crucial to everything
conditioning vector shape:  torch.Size([50, 512])
in plosses i am getting a noisy image x
x shape:  torch.Size([50, 1, 96, 96])
getting model out
Initial input shape: torch.Size([50, 1, 96, 96])

inputblocks
Before block 0, shape: torch.Size([50, 1, 96, 96])
After block 0, shape: torch.Size([50, 128, 96, 96])
-
Before block 1, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 1, shape: torch.Size([50, 128, 96, 96])
-
Before block 2, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 2, shape: torch.Size([50, 128, 96, 96])
-
Before block 3, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 3, shape: torch.Size([50, 128, 96, 96])
-
Before block 4, shape: torch.Size([50, 128, 96, 96])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 256])
After block 4, shape: torch.Size([50, 128, 48, 48])
-
Before block 5, shape: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 48, 48])
-
Before block 8, shape: torch.Size([50, 256, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 8, shape: torch.Size([50, 256, 24, 24])
-
Before block 9, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 9, shape: torch.Size([50, 256, 24, 24])
-
Before block 10, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 10, shape: torch.Size([50, 256, 24, 24])
-
Before block 11, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 11, shape: torch.Size([50, 256, 24, 24])
-

Before middle block, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
in unet attention block!
x shape torch.Size([50, 256, 24, 24])
out dims torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])


After middle block, shape: torch.Size([50, 256, 24, 24])
-



outputblocks
Before block 0, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 0, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 0, shape: torch.Size([50, 256, 24, 24])
-
Before block 1, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 1, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 1, shape: torch.Size([50, 256, 24, 24])
-
Before block 2, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 2, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 2, shape: torch.Size([50, 256, 24, 24])
-
Before block 3, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 3, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 3, shape: torch.Size([50, 256, 48, 48])
-
Before block 4, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 4, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 4, shape: torch.Size([50, 256, 48, 48])
-
Before block 5, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 5, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 6, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 7, shape: torch.Size([50, 384, 48, 48])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 96, 96])
-
Before block 8, shape: torch.Size([50, 256, 96, 96])
After concatenation in upsampling block 8, shape: torch.Size([50, 384, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 8, shape: torch.Size([50, 128, 96, 96])
-
Before block 9, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 9, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 9, shape: torch.Size([50, 128, 96, 96])
-
Before block 10, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 10, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 10, shape: torch.Size([50, 128, 96, 96])
-
Before block 11, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 11, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 11, shape: torch.Size([50, 128, 96, 96])
-

Before Final layer shape: torch.Size([50, 128, 96, 96])
Final output shape: torch.Size([50, 1, 96, 96])
model out shape:  torch.Size([50, 1, 96, 96])
iAM IN THE FORWARD METHOD OF THE WEIRD GUASSIAN IN cond_DDPM.py. I WILL BE CALLING p_losses
i am in p_losses in guassian which seems to be crucial to everything
conditioning vector shape:  torch.Size([50, 512])
in plosses i am getting a noisy image x
x shape:  torch.Size([50, 1, 96, 96])
getting model out
Initial input shape: torch.Size([50, 1, 96, 96])

inputblocks
Before block 0, shape: torch.Size([50, 1, 96, 96])
After block 0, shape: torch.Size([50, 128, 96, 96])
-
Before block 1, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 1, shape: torch.Size([50, 128, 96, 96])
-
Before block 2, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 2, shape: torch.Size([50, 128, 96, 96])
-
Before block 3, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 3, shape: torch.Size([50, 128, 96, 96])
-
Before block 4, shape: torch.Size([50, 128, 96, 96])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 256])
After block 4, shape: torch.Size([50, 128, 48, 48])
-
Before block 5, shape: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 48, 48])
-
Before block 8, shape: torch.Size([50, 256, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 8, shape: torch.Size([50, 256, 24, 24])
-
Before block 9, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 9, shape: torch.Size([50, 256, 24, 24])
-
Before block 10, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 10, shape: torch.Size([50, 256, 24, 24])
-
Before block 11, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 11, shape: torch.Size([50, 256, 24, 24])
-

Before middle block, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
in unet attention block!
x shape torch.Size([50, 256, 24, 24])
out dims torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])


After middle block, shape: torch.Size([50, 256, 24, 24])
-



outputblocks
Before block 0, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 0, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 0, shape: torch.Size([50, 256, 24, 24])
-
Before block 1, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 1, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 1, shape: torch.Size([50, 256, 24, 24])
-
Before block 2, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 2, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 2, shape: torch.Size([50, 256, 24, 24])
-
Before block 3, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 3, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 3, shape: torch.Size([50, 256, 48, 48])
-
Before block 4, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 4, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 4, shape: torch.Size([50, 256, 48, 48])
-
Before block 5, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 5, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 6, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 7, shape: torch.Size([50, 384, 48, 48])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 96, 96])
-
Before block 8, shape: torch.Size([50, 256, 96, 96])
After concatenation in upsampling block 8, shape: torch.Size([50, 384, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 8, shape: torch.Size([50, 128, 96, 96])
-
Before block 9, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 9, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 9, shape: torch.Size([50, 128, 96, 96])
-
Before block 10, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 10, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 10, shape: torch.Size([50, 128, 96, 96])
-
Before block 11, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 11, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 11, shape: torch.Size([50, 128, 96, 96])
-

Before Final layer shape: torch.Size([50, 128, 96, 96])
Final output shape: torch.Size([50, 1, 96, 96])
model out shape:  torch.Size([50, 1, 96, 96])
reconstruction shape torch.Size([50, 1, 96, 96])
reconstruction tensor([[[[ 0.0256,  0.0037,  0.0086,  ...,  0.0101,  0.0146,  0.0069],
          [ 0.0119, -0.0016,  0.0046,  ...,  0.0041,  0.0122,  0.0066],
          [ 0.0050, -0.0024,  0.0144,  ...,  0.0070,  0.0068,  0.0088],
          ...,
          [ 0.0126, -0.0021,  0.0127,  ...,  0.0109,  0.0058,  0.0044],
          [ 0.0141,  0.0015,  0.0041,  ...,  0.0055,  0.0089,  0.0016],
          [ 0.0130,  0.0016,  0.0067,  ...,  0.0077,  0.0085,  0.0034]]],


        [[[ 0.0263,  0.0043,  0.0090,  ...,  0.0106,  0.0155,  0.0081],
          [ 0.0125, -0.0013,  0.0047,  ...,  0.0041,  0.0122,  0.0072],
          [ 0.0052, -0.0023,  0.0146,  ...,  0.0076,  0.0072,  0.0095],
          ...,
          [ 0.0132, -0.0011,  0.0134,  ...,  0.0115,  0.0063,  0.0050],
          [ 0.0151,  0.0023,  0.0044,  ...,  0.0062,  0.0100,  0.0028],
          [ 0.0140,  0.0028,  0.0072,  ...,  0.0085,  0.0097,  0.0047]]],


        [[[ 0.0272,  0.0048,  0.0090,  ...,  0.0112,  0.0161,  0.0089],
          [ 0.0131, -0.0010,  0.0047,  ...,  0.0044,  0.0123,  0.0076],
          [ 0.0057, -0.0020,  0.0151,  ...,  0.0083,  0.0074,  0.0100],
          ...,
          [ 0.0142, -0.0003,  0.0140,  ...,  0.0123,  0.0072,  0.0062],
          [ 0.0163,  0.0033,  0.0047,  ...,  0.0071,  0.0112,  0.0039],
          [ 0.0149,  0.0037,  0.0078,  ...,  0.0093,  0.0112,  0.0061]]],


        ...,


        [[[ 0.0314,  0.0089,  0.0094,  ...,  0.0143,  0.0191,  0.0120],
          [ 0.0141,  0.0007,  0.0043,  ...,  0.0080,  0.0172,  0.0116],
          [ 0.0050, -0.0021,  0.0111,  ...,  0.0091,  0.0111,  0.0146],
          ...,
          [ 0.0132,  0.0024,  0.0160,  ...,  0.0162,  0.0138,  0.0115],
          [ 0.0180,  0.0083,  0.0114,  ...,  0.0155,  0.0220,  0.0120],
          [ 0.0179,  0.0088,  0.0133,  ...,  0.0183,  0.0200,  0.0114]]],


        [[[ 0.0314,  0.0092,  0.0098,  ...,  0.0137,  0.0186,  0.0111],
          [ 0.0137,  0.0008,  0.0050,  ...,  0.0076,  0.0168,  0.0107],
          [ 0.0050, -0.0013,  0.0123,  ...,  0.0089,  0.0108,  0.0140],
          ...,
          [ 0.0123,  0.0007,  0.0132,  ...,  0.0133,  0.0106,  0.0090],
          [ 0.0171,  0.0061,  0.0083,  ...,  0.0117,  0.0177,  0.0090],
          [ 0.0168,  0.0072,  0.0107,  ...,  0.0146,  0.0166,  0.0090]]],


        [[[ 0.0305,  0.0084,  0.0101,  ...,  0.0129,  0.0178,  0.0104],
          [ 0.0131,  0.0007,  0.0055,  ...,  0.0068,  0.0159,  0.0098],
          [ 0.0052, -0.0007,  0.0129,  ...,  0.0084,  0.0103,  0.0130],
          ...,
          [ 0.0116, -0.0008,  0.0120,  ...,  0.0109,  0.0080,  0.0065],
          [ 0.0157,  0.0040,  0.0063,  ...,  0.0087,  0.0144,  0.0060],
          [ 0.0154,  0.0049,  0.0085,  ...,  0.0117,  0.0133,  0.0063]]]],
       device='cuda:0')
FINAL VOLUME (DDPM) shape torch.Size([96, 96, 50])
FINAL VOLUME tensor([[[ 0.0256,  0.0263,  0.0272,  ...,  0.0314,  0.0314,  0.0305],
         [ 0.0037,  0.0043,  0.0048,  ...,  0.0089,  0.0092,  0.0084],
         [ 0.0086,  0.0090,  0.0090,  ...,  0.0094,  0.0098,  0.0101],
         ...,
         [ 0.0101,  0.0106,  0.0112,  ...,  0.0143,  0.0137,  0.0129],
         [ 0.0146,  0.0155,  0.0161,  ...,  0.0191,  0.0186,  0.0178],
         [ 0.0069,  0.0081,  0.0089,  ...,  0.0120,  0.0111,  0.0104]],

        [[ 0.0119,  0.0125,  0.0131,  ...,  0.0141,  0.0137,  0.0131],
         [-0.0016, -0.0013, -0.0010,  ...,  0.0007,  0.0008,  0.0007],
         [ 0.0046,  0.0047,  0.0047,  ...,  0.0043,  0.0050,  0.0055],
         ...,
         [ 0.0041,  0.0041,  0.0044,  ...,  0.0080,  0.0076,  0.0068],
         [ 0.0122,  0.0122,  0.0123,  ...,  0.0172,  0.0168,  0.0159],
         [ 0.0066,  0.0072,  0.0076,  ...,  0.0116,  0.0107,  0.0098]],

        [[ 0.0050,  0.0052,  0.0057,  ...,  0.0050,  0.0050,  0.0052],
         [-0.0024, -0.0023, -0.0020,  ..., -0.0021, -0.0013, -0.0007],
         [ 0.0144,  0.0146,  0.0151,  ...,  0.0111,  0.0123,  0.0129],
         ...,
         [ 0.0070,  0.0076,  0.0083,  ...,  0.0091,  0.0089,  0.0084],
         [ 0.0068,  0.0072,  0.0074,  ...,  0.0111,  0.0108,  0.0103],
         [ 0.0088,  0.0095,  0.0100,  ...,  0.0146,  0.0140,  0.0130]],

        ...,

        [[ 0.0126,  0.0132,  0.0142,  ...,  0.0132,  0.0123,  0.0116],
         [-0.0021, -0.0011, -0.0003,  ...,  0.0024,  0.0007, -0.0008],
         [ 0.0127,  0.0134,  0.0140,  ...,  0.0160,  0.0132,  0.0120],
         ...,
         [ 0.0109,  0.0115,  0.0123,  ...,  0.0162,  0.0133,  0.0109],
         [ 0.0058,  0.0063,  0.0072,  ...,  0.0138,  0.0106,  0.0080],
         [ 0.0044,  0.0050,  0.0062,  ...,  0.0115,  0.0090,  0.0065]],

        [[ 0.0141,  0.0151,  0.0163,  ...,  0.0180,  0.0171,  0.0157],
         [ 0.0015,  0.0023,  0.0033,  ...,  0.0083,  0.0061,  0.0040],
         [ 0.0041,  0.0044,  0.0047,  ...,  0.0114,  0.0083,  0.0063],
         ...,
         [ 0.0055,  0.0062,  0.0071,  ...,  0.0155,  0.0117,  0.0087],
         [ 0.0089,  0.0100,  0.0112,  ...,  0.0220,  0.0177,  0.0144],
         [ 0.0016,  0.0028,  0.0039,  ...,  0.0120,  0.0090,  0.0060]],

        [[ 0.0130,  0.0140,  0.0149,  ...,  0.0179,  0.0168,  0.0154],
         [ 0.0016,  0.0028,  0.0037,  ...,  0.0088,  0.0072,  0.0049],
         [ 0.0067,  0.0072,  0.0078,  ...,  0.0133,  0.0107,  0.0085],
         ...,
         [ 0.0077,  0.0085,  0.0093,  ...,  0.0183,  0.0146,  0.0117],
         [ 0.0085,  0.0097,  0.0112,  ...,  0.0200,  0.0166,  0.0133],
         [ 0.0034,  0.0047,  0.0061,  ...,  0.0114,  0.0090,  0.0063]]],
       device='cuda:0')
unsqueeze final volume shape (DDPM2d) torch.Size([1, 1, 96, 96, 50])
unsqueeze final volume (DDPM 2D) tensor([[[[[ 0.0256,  0.0263,  0.0272,  ...,  0.0314,  0.0314,  0.0305],
           [ 0.0037,  0.0043,  0.0048,  ...,  0.0089,  0.0092,  0.0084],
           [ 0.0086,  0.0090,  0.0090,  ...,  0.0094,  0.0098,  0.0101],
           ...,
           [ 0.0101,  0.0106,  0.0112,  ...,  0.0143,  0.0137,  0.0129],
           [ 0.0146,  0.0155,  0.0161,  ...,  0.0191,  0.0186,  0.0178],
           [ 0.0069,  0.0081,  0.0089,  ...,  0.0120,  0.0111,  0.0104]],

          [[ 0.0119,  0.0125,  0.0131,  ...,  0.0141,  0.0137,  0.0131],
           [-0.0016, -0.0013, -0.0010,  ...,  0.0007,  0.0008,  0.0007],
           [ 0.0046,  0.0047,  0.0047,  ...,  0.0043,  0.0050,  0.0055],
           ...,
           [ 0.0041,  0.0041,  0.0044,  ...,  0.0080,  0.0076,  0.0068],
           [ 0.0122,  0.0122,  0.0123,  ...,  0.0172,  0.0168,  0.0159],
           [ 0.0066,  0.0072,  0.0076,  ...,  0.0116,  0.0107,  0.0098]],

          [[ 0.0050,  0.0052,  0.0057,  ...,  0.0050,  0.0050,  0.0052],
           [-0.0024, -0.0023, -0.0020,  ..., -0.0021, -0.0013, -0.0007],
           [ 0.0144,  0.0146,  0.0151,  ...,  0.0111,  0.0123,  0.0129],
           ...,
           [ 0.0070,  0.0076,  0.0083,  ...,  0.0091,  0.0089,  0.0084],
           [ 0.0068,  0.0072,  0.0074,  ...,  0.0111,  0.0108,  0.0103],
           [ 0.0088,  0.0095,  0.0100,  ...,  0.0146,  0.0140,  0.0130]],

          ...,

          [[ 0.0126,  0.0132,  0.0142,  ...,  0.0132,  0.0123,  0.0116],
           [-0.0021, -0.0011, -0.0003,  ...,  0.0024,  0.0007, -0.0008],
           [ 0.0127,  0.0134,  0.0140,  ...,  0.0160,  0.0132,  0.0120],
           ...,
           [ 0.0109,  0.0115,  0.0123,  ...,  0.0162,  0.0133,  0.0109],
           [ 0.0058,  0.0063,  0.0072,  ...,  0.0138,  0.0106,  0.0080],
           [ 0.0044,  0.0050,  0.0062,  ...,  0.0115,  0.0090,  0.0065]],

          [[ 0.0141,  0.0151,  0.0163,  ...,  0.0180,  0.0171,  0.0157],
           [ 0.0015,  0.0023,  0.0033,  ...,  0.0083,  0.0061,  0.0040],
           [ 0.0041,  0.0044,  0.0047,  ...,  0.0114,  0.0083,  0.0063],
           ...,
           [ 0.0055,  0.0062,  0.0071,  ...,  0.0155,  0.0117,  0.0087],
           [ 0.0089,  0.0100,  0.0112,  ...,  0.0220,  0.0177,  0.0144],
           [ 0.0016,  0.0028,  0.0039,  ...,  0.0120,  0.0090,  0.0060]],

          [[ 0.0130,  0.0140,  0.0149,  ...,  0.0179,  0.0168,  0.0154],
           [ 0.0016,  0.0028,  0.0037,  ...,  0.0088,  0.0072,  0.0049],
           [ 0.0067,  0.0072,  0.0078,  ...,  0.0133,  0.0107,  0.0085],
           ...,
           [ 0.0077,  0.0085,  0.0093,  ...,  0.0183,  0.0146,  0.0117],
           [ 0.0085,  0.0097,  0.0112,  ...,  0.0200,  0.0166,  0.0133],
           [ 0.0034,  0.0047,  0.0061,  ...,  0.0114,  0.0090,  0.0063]]]]],
       device='cuda:0')
==========
IN _TEST_STEP
==========
ERODING BRAIN MASK
MEDIAN FILTERING
SAVING OUTPUT - ORIGINAL, FINAL, MASK ETC
SAVING IMAGES!
Testing:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [01:00<00:02,  2.99s/it]==========
IN DDPM ON TEST STEP
==========
THE WEIRD CONDITION BIT CALLED "features" in DDPM_2D
IN SPARK ENCODER FORWARDDD
x in shape torch.Size([50, 1, 96, 96])
out features torch.Size([50, 512])
i'm i DDPM2d forward block (whch is basically the encoder)
Context vector c shape: torch.Size([50, 512])
shape features:  torch.Size([50, 512])
additng features to latern space
latent space: []
iAM IN THE FORWARD METHOD OF THE WEIRD GUASSIAN IN cond_DDPM.py. I WILL BE CALLING p_losses
i am in p_losses in guassian which seems to be crucial to everything
conditioning vector shape:  torch.Size([50, 512])
in plosses i am getting a noisy image x
x shape:  torch.Size([50, 1, 96, 96])
getting model out
Initial input shape: torch.Size([50, 1, 96, 96])

inputblocks
Before block 0, shape: torch.Size([50, 1, 96, 96])
After block 0, shape: torch.Size([50, 128, 96, 96])
-
Before block 1, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 1, shape: torch.Size([50, 128, 96, 96])
-
Before block 2, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 2, shape: torch.Size([50, 128, 96, 96])
-
Before block 3, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 3, shape: torch.Size([50, 128, 96, 96])
-
Before block 4, shape: torch.Size([50, 128, 96, 96])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 256])
After block 4, shape: torch.Size([50, 128, 48, 48])
-
Before block 5, shape: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 48, 48])
-
Before block 8, shape: torch.Size([50, 256, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 8, shape: torch.Size([50, 256, 24, 24])
-
Before block 9, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 9, shape: torch.Size([50, 256, 24, 24])
-
Before block 10, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 10, shape: torch.Size([50, 256, 24, 24])
-
Before block 11, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 11, shape: torch.Size([50, 256, 24, 24])
-

Before middle block, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
in unet attention block!
x shape torch.Size([50, 256, 24, 24])
out dims torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])


After middle block, shape: torch.Size([50, 256, 24, 24])
-



outputblocks
Before block 0, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 0, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 0, shape: torch.Size([50, 256, 24, 24])
-
Before block 1, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 1, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 1, shape: torch.Size([50, 256, 24, 24])
-
Before block 2, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 2, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 2, shape: torch.Size([50, 256, 24, 24])
-
Before block 3, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 3, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 3, shape: torch.Size([50, 256, 48, 48])
-
Before block 4, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 4, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 4, shape: torch.Size([50, 256, 48, 48])
-
Before block 5, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 5, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 6, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 7, shape: torch.Size([50, 384, 48, 48])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 96, 96])
-
Before block 8, shape: torch.Size([50, 256, 96, 96])
After concatenation in upsampling block 8, shape: torch.Size([50, 384, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 8, shape: torch.Size([50, 128, 96, 96])
-
Before block 9, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 9, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 9, shape: torch.Size([50, 128, 96, 96])
-
Before block 10, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 10, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 10, shape: torch.Size([50, 128, 96, 96])
-
Before block 11, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 11, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 11, shape: torch.Size([50, 128, 96, 96])
-

Before Final layer shape: torch.Size([50, 128, 96, 96])
Final output shape: torch.Size([50, 1, 96, 96])
model out shape:  torch.Size([50, 1, 96, 96])
iAM IN THE FORWARD METHOD OF THE WEIRD GUASSIAN IN cond_DDPM.py. I WILL BE CALLING p_losses
i am in p_losses in guassian which seems to be crucial to everything
conditioning vector shape:  torch.Size([50, 512])
in plosses i am getting a noisy image x
x shape:  torch.Size([50, 1, 96, 96])
getting model out
Initial input shape: torch.Size([50, 1, 96, 96])

inputblocks
Before block 0, shape: torch.Size([50, 1, 96, 96])
After block 0, shape: torch.Size([50, 128, 96, 96])
-
Before block 1, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 1, shape: torch.Size([50, 128, 96, 96])
-
Before block 2, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 2, shape: torch.Size([50, 128, 96, 96])
-
Before block 3, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 3, shape: torch.Size([50, 128, 96, 96])
-
Before block 4, shape: torch.Size([50, 128, 96, 96])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 256])
After block 4, shape: torch.Size([50, 128, 48, 48])
-
Before block 5, shape: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 48, 48])
-
Before block 8, shape: torch.Size([50, 256, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 8, shape: torch.Size([50, 256, 24, 24])
-
Before block 9, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 9, shape: torch.Size([50, 256, 24, 24])
-
Before block 10, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 10, shape: torch.Size([50, 256, 24, 24])
-
Before block 11, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 11, shape: torch.Size([50, 256, 24, 24])
-

Before middle block, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
in unet attention block!
x shape torch.Size([50, 256, 24, 24])
out dims torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])


After middle block, shape: torch.Size([50, 256, 24, 24])
-



outputblocks
Before block 0, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 0, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 0, shape: torch.Size([50, 256, 24, 24])
-
Before block 1, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 1, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 1, shape: torch.Size([50, 256, 24, 24])
-
Before block 2, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 2, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 2, shape: torch.Size([50, 256, 24, 24])
-
Before block 3, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 3, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 3, shape: torch.Size([50, 256, 48, 48])
-
Before block 4, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 4, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 4, shape: torch.Size([50, 256, 48, 48])
-
Before block 5, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 5, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 6, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 7, shape: torch.Size([50, 384, 48, 48])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 96, 96])
-
Before block 8, shape: torch.Size([50, 256, 96, 96])
After concatenation in upsampling block 8, shape: torch.Size([50, 384, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 8, shape: torch.Size([50, 128, 96, 96])
-
Before block 9, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 9, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 9, shape: torch.Size([50, 128, 96, 96])
-
Before block 10, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 10, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 10, shape: torch.Size([50, 128, 96, 96])
-
Before block 11, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 11, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 11, shape: torch.Size([50, 128, 96, 96])
-

Before Final layer shape: torch.Size([50, 128, 96, 96])
Final output shape: torch.Size([50, 1, 96, 96])
model out shape:  torch.Size([50, 1, 96, 96])
iAM IN THE FORWARD METHOD OF THE WEIRD GUASSIAN IN cond_DDPM.py. I WILL BE CALLING p_losses
i am in p_losses in guassian which seems to be crucial to everything
conditioning vector shape:  torch.Size([50, 512])
in plosses i am getting a noisy image x
x shape:  torch.Size([50, 1, 96, 96])
getting model out
Initial input shape: torch.Size([50, 1, 96, 96])

inputblocks
Before block 0, shape: torch.Size([50, 1, 96, 96])
After block 0, shape: torch.Size([50, 128, 96, 96])
-
Before block 1, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 1, shape: torch.Size([50, 128, 96, 96])
-
Before block 2, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 2, shape: torch.Size([50, 128, 96, 96])
-
Before block 3, shape: torch.Size([50, 128, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 3, shape: torch.Size([50, 128, 96, 96])
-
Before block 4, shape: torch.Size([50, 128, 96, 96])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 128, 96, 96])
out dims: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 256])
After block 4, shape: torch.Size([50, 128, 48, 48])
-
Before block 5, shape: torch.Size([50, 128, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 48, 48])
-
Before block 8, shape: torch.Size([50, 256, 48, 48])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
IN DOWNSAMPLE FORWARD STEP
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 8, shape: torch.Size([50, 256, 24, 24])
-
Before block 9, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 9, shape: torch.Size([50, 256, 24, 24])
-
Before block 10, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 10, shape: torch.Size([50, 256, 24, 24])
-
Before block 11, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 11, shape: torch.Size([50, 256, 24, 24])
-

Before middle block, shape: torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])
in unet attention block!
x shape torch.Size([50, 256, 24, 24])
out dims torch.Size([50, 256, 24, 24])
Projected embedding: torch.Size([50, 512])


After middle block, shape: torch.Size([50, 256, 24, 24])
-



outputblocks
Before block 0, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 0, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 0, shape: torch.Size([50, 256, 24, 24])
-
Before block 1, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 1, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 1, shape: torch.Size([50, 256, 24, 24])
-
Before block 2, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 2, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
After block 2, shape: torch.Size([50, 256, 24, 24])
-
Before block 3, shape: torch.Size([50, 256, 24, 24])
After concatenation in upsampling block 3, shape: torch.Size([50, 512, 24, 24])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 24, 24])
out dims: torch.Size([50, 256, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 3, shape: torch.Size([50, 256, 48, 48])
-
Before block 4, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 4, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 4, shape: torch.Size([50, 256, 48, 48])
-
Before block 5, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 5, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 5, shape: torch.Size([50, 256, 48, 48])
-
Before block 6, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 6, shape: torch.Size([50, 512, 48, 48])
Projected embedding: torch.Size([50, 512])
After block 6, shape: torch.Size([50, 256, 48, 48])
-
Before block 7, shape: torch.Size([50, 256, 48, 48])
After concatenation in upsampling block 7, shape: torch.Size([50, 384, 48, 48])
Projected embedding: torch.Size([50, 512])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
UPSAMPLING!!!!
in dims: torch.Size([50, 256, 48, 48])
out dims: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 512])
After block 7, shape: torch.Size([50, 256, 96, 96])
-
Before block 8, shape: torch.Size([50, 256, 96, 96])
After concatenation in upsampling block 8, shape: torch.Size([50, 384, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 8, shape: torch.Size([50, 128, 96, 96])
-
Before block 9, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 9, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 9, shape: torch.Size([50, 128, 96, 96])
-
Before block 10, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 10, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 10, shape: torch.Size([50, 128, 96, 96])
-
Before block 11, shape: torch.Size([50, 128, 96, 96])
After concatenation in upsampling block 11, shape: torch.Size([50, 256, 96, 96])
Projected embedding: torch.Size([50, 256])
After block 11, shape: torch.Size([50, 128, 96, 96])
-

Before Final layer shape: torch.Size([50, 128, 96, 96])
Final output shape: torch.Size([50, 1, 96, 96])
model out shape:  torch.Size([50, 1, 96, 96])
reconstruction shape torch.Size([50, 1, 96, 96])
reconstruction tensor([[[[0.0186, 0.0208, 0.0218,  ..., 0.0217, 0.0264, 0.0193],
          [0.0272, 0.0185, 0.0174,  ..., 0.0164, 0.0199, 0.0149],
          [0.0205, 0.0120, 0.0206,  ..., 0.0185, 0.0105, 0.0116],
          ...,
          [0.0190, 0.0106, 0.0198,  ..., 0.0194, 0.0131, 0.0151],
          [0.0202, 0.0186, 0.0129,  ..., 0.0148, 0.0226, 0.0098],
          [0.0080, 0.0067, 0.0101,  ..., 0.0163, 0.0184, 0.0048]]],


        [[[0.0211, 0.0230, 0.0239,  ..., 0.0230, 0.0277, 0.0207],
          [0.0289, 0.0198, 0.0196,  ..., 0.0176, 0.0212, 0.0163],
          [0.0222, 0.0136, 0.0234,  ..., 0.0202, 0.0121, 0.0131],
          ...,
          [0.0205, 0.0125, 0.0220,  ..., 0.0212, 0.0148, 0.0169],
          [0.0206, 0.0189, 0.0140,  ..., 0.0163, 0.0237, 0.0115],
          [0.0097, 0.0076, 0.0112,  ..., 0.0179, 0.0200, 0.0074]]],


        [[[0.0196, 0.0228, 0.0237,  ..., 0.0201, 0.0257, 0.0183],
          [0.0279, 0.0196, 0.0203,  ..., 0.0151, 0.0205, 0.0151],
          [0.0221, 0.0136, 0.0245,  ..., 0.0177, 0.0111, 0.0116],
          ...,
          [0.0186, 0.0106, 0.0198,  ..., 0.0187, 0.0133, 0.0143],
          [0.0172, 0.0146, 0.0107,  ..., 0.0148, 0.0216, 0.0082],
          [0.0079, 0.0035, 0.0078,  ..., 0.0171, 0.0182, 0.0059]]],


        ...,


        [[[0.0199, 0.0203, 0.0218,  ..., 0.0247, 0.0279, 0.0245],
          [0.0237, 0.0109, 0.0125,  ..., 0.0162, 0.0170, 0.0151],
          [0.0203, 0.0094, 0.0190,  ..., 0.0229, 0.0138, 0.0148],
          ...,
          [0.0195, 0.0106, 0.0216,  ..., 0.0244, 0.0158, 0.0167],
          [0.0176, 0.0110, 0.0119,  ..., 0.0172, 0.0190, 0.0092],
          [0.0119, 0.0055, 0.0116,  ..., 0.0227, 0.0191, 0.0085]]],


        [[[0.0181, 0.0191, 0.0210,  ..., 0.0234, 0.0271, 0.0226],
          [0.0227, 0.0109, 0.0119,  ..., 0.0154, 0.0170, 0.0141],
          [0.0194, 0.0086, 0.0175,  ..., 0.0212, 0.0128, 0.0133],
          ...,
          [0.0188, 0.0101, 0.0209,  ..., 0.0224, 0.0139, 0.0146],
          [0.0171, 0.0112, 0.0117,  ..., 0.0153, 0.0175, 0.0068],
          [0.0097, 0.0044, 0.0100,  ..., 0.0194, 0.0164, 0.0050]]],


        [[[0.0171, 0.0185, 0.0203,  ..., 0.0222, 0.0265, 0.0209],
          [0.0218, 0.0112, 0.0120,  ..., 0.0147, 0.0173, 0.0134],
          [0.0186, 0.0085, 0.0170,  ..., 0.0202, 0.0120, 0.0119],
          ...,
          [0.0178, 0.0092, 0.0199,  ..., 0.0209, 0.0130, 0.0131],
          [0.0164, 0.0113, 0.0111,  ..., 0.0144, 0.0176, 0.0058],
          [0.0074, 0.0026, 0.0083,  ..., 0.0171, 0.0150, 0.0029]]]],
       device='cuda:0')
FINAL VOLUME (DDPM) shape torch.Size([96, 96, 50])
FINAL VOLUME tensor([[[0.0186, 0.0211, 0.0196,  ..., 0.0199, 0.0181, 0.0171],
         [0.0208, 0.0230, 0.0228,  ..., 0.0203, 0.0191, 0.0185],
         [0.0218, 0.0239, 0.0237,  ..., 0.0218, 0.0210, 0.0203],
         ...,
         [0.0217, 0.0230, 0.0201,  ..., 0.0247, 0.0234, 0.0222],
         [0.0264, 0.0277, 0.0257,  ..., 0.0279, 0.0271, 0.0265],
         [0.0193, 0.0207, 0.0183,  ..., 0.0245, 0.0226, 0.0209]],

        [[0.0272, 0.0289, 0.0279,  ..., 0.0237, 0.0227, 0.0218],
         [0.0185, 0.0198, 0.0196,  ..., 0.0109, 0.0109, 0.0112],
         [0.0174, 0.0196, 0.0203,  ..., 0.0125, 0.0119, 0.0120],
         ...,
         [0.0164, 0.0176, 0.0151,  ..., 0.0162, 0.0154, 0.0147],
         [0.0199, 0.0212, 0.0205,  ..., 0.0170, 0.0170, 0.0173],
         [0.0149, 0.0163, 0.0151,  ..., 0.0151, 0.0141, 0.0134]],

        [[0.0205, 0.0222, 0.0221,  ..., 0.0203, 0.0194, 0.0186],
         [0.0120, 0.0136, 0.0136,  ..., 0.0094, 0.0086, 0.0085],
         [0.0206, 0.0234, 0.0245,  ..., 0.0190, 0.0175, 0.0170],
         ...,
         [0.0185, 0.0202, 0.0177,  ..., 0.0229, 0.0212, 0.0202],
         [0.0105, 0.0121, 0.0111,  ..., 0.0138, 0.0128, 0.0120],
         [0.0116, 0.0131, 0.0116,  ..., 0.0148, 0.0133, 0.0119]],

        ...,

        [[0.0190, 0.0205, 0.0186,  ..., 0.0195, 0.0188, 0.0178],
         [0.0106, 0.0125, 0.0106,  ..., 0.0106, 0.0101, 0.0092],
         [0.0198, 0.0220, 0.0198,  ..., 0.0216, 0.0209, 0.0199],
         ...,
         [0.0194, 0.0212, 0.0187,  ..., 0.0244, 0.0224, 0.0209],
         [0.0131, 0.0148, 0.0133,  ..., 0.0158, 0.0139, 0.0130],
         [0.0151, 0.0169, 0.0143,  ..., 0.0167, 0.0146, 0.0131]],

        [[0.0202, 0.0206, 0.0172,  ..., 0.0176, 0.0171, 0.0164],
         [0.0186, 0.0189, 0.0146,  ..., 0.0110, 0.0112, 0.0113],
         [0.0129, 0.0140, 0.0107,  ..., 0.0119, 0.0117, 0.0111],
         ...,
         [0.0148, 0.0163, 0.0148,  ..., 0.0172, 0.0153, 0.0144],
         [0.0226, 0.0237, 0.0216,  ..., 0.0190, 0.0175, 0.0176],
         [0.0098, 0.0115, 0.0082,  ..., 0.0092, 0.0068, 0.0058]],

        [[0.0080, 0.0097, 0.0079,  ..., 0.0119, 0.0097, 0.0074],
         [0.0067, 0.0076, 0.0035,  ..., 0.0055, 0.0044, 0.0026],
         [0.0101, 0.0112, 0.0078,  ..., 0.0116, 0.0100, 0.0083],
         ...,
         [0.0163, 0.0179, 0.0171,  ..., 0.0227, 0.0194, 0.0171],
         [0.0184, 0.0200, 0.0182,  ..., 0.0191, 0.0164, 0.0150],
         [0.0048, 0.0074, 0.0059,  ..., 0.0085, 0.0050, 0.0029]]],
       device='cuda:0')
unsqueeze final volume shape (DDPM2d) torch.Size([1, 1, 96, 96, 50])
unsqueeze final volume (DDPM 2D) tensor([[[[[0.0186, 0.0211, 0.0196,  ..., 0.0199, 0.0181, 0.0171],
           [0.0208, 0.0230, 0.0228,  ..., 0.0203, 0.0191, 0.0185],
           [0.0218, 0.0239, 0.0237,  ..., 0.0218, 0.0210, 0.0203],
           ...,
           [0.0217, 0.0230, 0.0201,  ..., 0.0247, 0.0234, 0.0222],
           [0.0264, 0.0277, 0.0257,  ..., 0.0279, 0.0271, 0.0265],
           [0.0193, 0.0207, 0.0183,  ..., 0.0245, 0.0226, 0.0209]],

          [[0.0272, 0.0289, 0.0279,  ..., 0.0237, 0.0227, 0.0218],
           [0.0185, 0.0198, 0.0196,  ..., 0.0109, 0.0109, 0.0112],
           [0.0174, 0.0196, 0.0203,  ..., 0.0125, 0.0119, 0.0120],
           ...,
           [0.0164, 0.0176, 0.0151,  ..., 0.0162, 0.0154, 0.0147],
           [0.0199, 0.0212, 0.0205,  ..., 0.0170, 0.0170, 0.0173],
           [0.0149, 0.0163, 0.0151,  ..., 0.0151, 0.0141, 0.0134]],

          [[0.0205, 0.0222, 0.0221,  ..., 0.0203, 0.0194, 0.0186],
           [0.0120, 0.0136, 0.0136,  ..., 0.0094, 0.0086, 0.0085],
           [0.0206, 0.0234, 0.0245,  ..., 0.0190, 0.0175, 0.0170],
           ...,
           [0.0185, 0.0202, 0.0177,  ..., 0.0229, 0.0212, 0.0202],
           [0.0105, 0.0121, 0.0111,  ..., 0.0138, 0.0128, 0.0120],
           [0.0116, 0.0131, 0.0116,  ..., 0.0148, 0.0133, 0.0119]],

          ...,

          [[0.0190, 0.0205, 0.0186,  ..., 0.0195, 0.0188, 0.0178],
           [0.0106, 0.0125, 0.0106,  ..., 0.0106, 0.0101, 0.0092],
           [0.0198, 0.0220, 0.0198,  ..., 0.0216, 0.0209, 0.0199],
           ...,
           [0.0194, 0.0212, 0.0187,  ..., 0.0244, 0.0224, 0.0209],
           [0.0131, 0.0148, 0.0133,  ..., 0.0158, 0.0139, 0.0130],
           [0.0151, 0.0169, 0.0143,  ..., 0.0167, 0.0146, 0.0131]],

          [[0.0202, 0.0206, 0.0172,  ..., 0.0176, 0.0171, 0.0164],
           [0.0186, 0.0189, 0.0146,  ..., 0.0110, 0.0112, 0.0113],
           [0.0129, 0.0140, 0.0107,  ..., 0.0119, 0.0117, 0.0111],
           ...,
           [0.0148, 0.0163, 0.0148,  ..., 0.0172, 0.0153, 0.0144],
           [0.0226, 0.0237, 0.0216,  ..., 0.0190, 0.0175, 0.0176],
           [0.0098, 0.0115, 0.0082,  ..., 0.0092, 0.0068, 0.0058]],

          [[0.0080, 0.0097, 0.0079,  ..., 0.0119, 0.0097, 0.0074],
           [0.0067, 0.0076, 0.0035,  ..., 0.0055, 0.0044, 0.0026],
           [0.0101, 0.0112, 0.0078,  ..., 0.0116, 0.0100, 0.0083],
           ...,
           [0.0163, 0.0179, 0.0171,  ..., 0.0227, 0.0194, 0.0171],
           [0.0184, 0.0200, 0.0182,  ..., 0.0191, 0.0164, 0.0150],
           [0.0048, 0.0074, 0.0059,  ..., 0.0085, 0.0050, 0.0029]]]]],
       device='cuda:0')
==========
IN _TEST_STEP
==========
ERODING BRAIN MASK
MEDIAN FILTERING
SAVING OUTPUT - ORIGINAL, FINAL, MASK ETC
SAVING IMAGES!
Testing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [01:03<00:00,  2.99s/it]--------------------------------------------------------------------------------
DATALOADER:0 TEST RESULTS
{}
--------------------------------------------------------------------------------
Testing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [01:03<00:00,  3.18s/it]
IN TEST END
[[36m2024-11-27 18:59:01,098[0m][[34msrc.train[0m][[32mINFO[0m] - Finalizing![0m
