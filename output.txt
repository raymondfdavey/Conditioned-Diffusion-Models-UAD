(cddpm) rd81@cs31c025338:~/projects/diffusion-uad$ python run.py experiment=cDDPM/DDPM_cond_spark_2D datamodule.cfg.mode=t1
syspath ['/home/rd81/projects/diffusion-uad', '/home/rd81/miniconda3/envs/cddpm/lib/python39.zip', '/home/rd81/miniconda3/envs/cddpm/lib/python3.9', '/home/rd81/miniconda3/envs/cddpm/lib/python3.9/lib-dynload', '/home/rd81/miniconda3/envs/cddpm/lib/python3.9/site-packages']
/home/rd81/projects/diffusion-uad
CONFIGGGG
work_dir: ${hydra:runtime.cwd}
data_dir: ${oc.env:DATA_DIR}
log_dir: ${oc.env:LOG_DIR}
name: DDPM_cond_2D_spark
debug: false
print_config: false
ignore_warnings: false
checkpoint: best
new_wandb_run: true
test_after_training: true
onlyEval: true
load_checkpoint: /home/rd81/projects/full_logs/logs/runs/DDPM_cond_2D_spark/DDPM_2D_IXI_DDPM_cond_2D_spark__2024-11-25_13-54-17
trainer:
  _target_: pytorch_lightning.Trainer
  gpus: -1
  min_epochs: 1
  max_epochs: 1200
  log_every_n_steps: 5
  precision: 16
  num_sanity_val_steps: 0
  check_val_every_n_epoch: 10
  benchmark: true
  overfit_batches: false
model:
  _target_: src.models.DDPM_2D.DDPM_2D
  cfg:
    name: DDPM_2D
    imageDim: ${datamodule.cfg.imageDim}
    rescaleFactor: ${datamodule.cfg.rescaleFactor}
    interRes: ${datamodule.cfg.interRes}
    cropMode: ${datamodule.cfg.cropMode}
    spatialDims: 2D
    resizedEvaluation: ${datamodule.cfg.resizedEvaluation}
    unet_dim: 128
    dim_mults:
    - 1
    - 2
    - 2
    learned_variance: false
    learned_sinusoidal_cond: false
    loss: l1
    lossStrategy: mean
    lr: ${datamodule.cfg.lr}
    scheduleLR: false
    patienceLR: 10
    earlyStopping: false
    patienceStopping: 50
    saveOutputImages: true
    evalSeg: true
    pad: ${datamodule.cfg.pad}
    erodeBrainmask: true
    medianFiltering: true
    threshold: auto
    mode: ${datamodule.cfg.mode}
    noise_ensemble: true
    step_ensemble:
    - 250
    - 500
    - 750
    test_timesteps: 250
    backbone: Spark_Encoder_2D
    version: resnet50
    cond_dim: 128
    OpenaiUnet: true
    spatial_transformer: false
    condition: true
    noisetype: simplex
    encoder_path: /home/rd81/projects/full_logs/logs/runs/MAE_2D/Spark_2D_IXI_MAE_2D__2024-11-25_10-25-18/checkpoints/epoch-1089_step-13079_loss-0.00_fold-1.ckpt
    pretrained_encoder: true
    save_to_disc: true
datamodule:
  _target_: src.datamodules.Datamodules_train.IXI
  cfg:
    name: IXI
    path:
      pathBase: ${data_dir}
      IXI:
        IDs:
          train:
          - ${data_dir}/Data/splits/IXI_train_fold0.csv
          - ${data_dir}/Data/splits/IXI_train_fold1.csv
          - ${data_dir}/Data/splits/IXI_train_fold2.csv
          - ${data_dir}/Data/splits/IXI_train_fold3.csv
          - ${data_dir}/Data/splits/IXI_train_fold4.csv
          val:
          - ${data_dir}/Data/splits/IXI_val_fold0.csv
          - ${data_dir}/Data/splits/IXI_val_fold1.csv
          - ${data_dir}/Data/splits/IXI_val_fold2.csv
          - ${data_dir}/Data/splits/IXI_val_fold3.csv
          - ${data_dir}/Data/splits/IXI_val_fold4.csv
          test: ${data_dir}/Data/splits/IXI_test.csv
        keep_t2: ${data_dir}/Data/splits/avail_t2.csv
      Brats21:
        IDs:
          test: ${data_dir}/Data/splits/Brats21_test.csv
          val: ${data_dir}/Data/splits/Brats21_val.csv
      MSLUB:
        IDs:
          test: ${data_dir}/Data/splits/MSLUB_test.csv
          val: ${data_dir}/Data/splits/MSLUB_val.csv
    imageDim:
    - 192
    - 192
    - 100
    rescaleFactor: 2
    interRes:
    - 8
    - 8
    - 5
    cropMode: isotropic
    spatialDims: ${model.cfg.spatialDims}
    unisotropic_sampling: true
    sample_set: false
    preLoad: true
    curvatureFlow: true
    percentile: true
    pad: true
    permute: false
    randomRotate: false
    rotateDegree: 5
    horizontalFlip: false
    randomBrightness: false
    brightnessRange: (0.75,1.25)
    randomContrast: false
    contrastRange: (0.75,1.25)
    modelpath: ${data_dir}/Data/pretrained_2D_model/
    num_workers: 4
    batch_size: 32
    lr: 0.0001
    droplast: true
    mode: t1
    resizedEvaluation: true
    testsets:
    - Datamodules_train.IXI
    aug_intensity: true
callbacks:
  model_checkpoint:
    _target_: pytorch_lightning.callbacks.model_checkpoint.ModelCheckpoint
    monitor: val/Loss_comb
    save_top_k: 1
    auto_insert_metric_name: false
    save_last: true
    mode: min
    dirpath: checkpoints/
    filename: epoch-{epoch}_step-{step}_loss-{val/Loss_comb:.2f}
logger:
  wandb:
    _target_: pytorch_lightning.loggers.wandb.WandbLogger
    project: cDDPM
    name: ${hydra:job.name}
    save_dir: ./debugging
    offline: false
    id: null
    resume: false
    log_model: false
    prefix: ''
    job_type: ''
    group: ''
    tags: []
  csv:
    _target_: pytorch_lightning.loggers.csv_logs.CSVLogger
    save_dir: ./debugging
    name: csv/
    version: ''
    prefix: ''
num_folds: 1
ckpt_path: best
seed: 3141
default_mode: true

END CONFIGGGG
/home/rd81/projects/full_logs/logs/runs/DDPM_cond_2D_spark/DDPM_2D_IXI_DDPM_cond_2D_spark__2024-11-25_13-54-17
---------------
/home/rd81/projects/full_logs/logs/runs/DDPM_cond_2D_spark/DDPM_2D_IXI_DDPM_cond_2D_spark__2024-11-25_13-54-17
best
['last_fold-1.ckpt', 'epoch-719_step-8639_loss-0.00_fold-1.ckpt']
/home/rd81/projects/full_logs/logs/runs/DDPM_cond_2D_spark/DDPM_2D_IXI_DDPM_cond_2D_spark__2024-11-25_13-54-17
gu3elgat
{'fold-1': '/home/rd81/projects/full_logs/logs/runs/DDPM_cond_2D_spark/DDPM_2D_IXI_DDPM_cond_2D_spark__2024-11-25_13-54-17/checkpoints/epoch-719_step-8639_loss-0.00_fold-1.ckpt'}
---------------
[2024-11-26 13:44:01,730][src.train][INFO] - Seed specified to 3141 by config
[2024-11-26 13:44:01,730][pytorch_lightning.utilities.seed][INFO] - Global seed set to 3141
0
1
[2024-11-26 13:44:01,731][src.train][INFO] - Training Fold 1 of 1 in the WandB group DDPM_cond_2D_spark
[2024-11-26 13:44:01,731][src.train][INFO] - Instantiating datamodule <src.datamodules.Datamodules_train.IXI>
[2024-11-26 13:44:01,970][src.train][INFO] - Instantiating model <src.models.DDPM_2D.DDPM_2D>
MAKING THE ACTUAL MODEL HERE INCLUDING LOADING THE PRETRAINED ENCODER
[2024-11-26 13:44:02,754][torch.distributed.nn.jit.instantiator][INFO] - Created a temporary directory at /tmp/tmpd9yok03g
[2024-11-26 13:44:02,754][torch.distributed.nn.jit.instantiator][INFO] - Writing /tmp/tmpd9yok03g/_remote_module_non_scriptable.py
[sparse_cnn] model kwargs={'drop_path_rate': 0.05, 'pretrained': False, 'num_classes': 512}
Loading pretrained encoder from:  /home/rd81/projects/full_logs/logs/runs/MAE_2D/Spark_2D_IXI_MAE_2D__2024-11-25_10-25-18/checkpoints/epoch-1089_step-13079_loss-0.00_fold-1.ckpt
encoder path,  /home/rd81/projects/full_logs/logs/runs/MAE_2D/Spark_2D_IXI_MAE_2D__2024-11-25_10-25-18/checkpoints/epoch-1089_step-13079_loss-0.00_fold-1.ckpt
[2024-11-26 13:44:04,257][src.train][INFO] - Instantiating callback <pytorch_lightning.callbacks.model_checkpoint.ModelCheckpoint>
[2024-11-26 13:44:04,258][src.train][INFO] - Instantiating logger <pytorch_lightning.loggers.wandb.WandbLogger>
[2024-11-26 13:44:04,260][src.train][INFO] - Instantiating logger <pytorch_lightning.loggers.csv_logs.CSVLogger>
[2024-11-26 13:44:04,261][src.train][INFO] - Restoring Trainer State of loaded checkpoint: /home/rd81/projects/full_logs/logs/runs/DDPM_cond_2D_spark/DDPM_2D_IXI_DDPM_cond_2D_spark__2024-11-25_13-54-17/checkpoints/epoch-719_step-8639_loss-0.00_fold-1.ckpt
[2024-11-26 13:44:04,261][src.train][INFO] - Instantiating trainer <pytorch_lightning.Trainer>
[2024-11-26 13:44:04,263][pytorch_lightning.utilities.distributed][INFO] - Using 16bit native Automatic Mixed Precision (AMP)
/home/rd81/miniconda3/envs/cddpm/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:45: LightningDeprecationWarning: Setting `Trainer(resume_from_checkpoint=)` is deprecated in v1.5 and will be removed in v1.7. Please pass `Trainer.fit(ckpt_path=)` directly instead.
  rank_zero_deprecation(
[2024-11-26 13:44:04,263][pytorch_lightning.utilities.distributed][INFO] - GPU available: True, used: True
[2024-11-26 13:44:04,263][pytorch_lightning.utilities.distributed][INFO] - TPU available: False, using: 0 TPU cores
[2024-11-26 13:44:04,263][pytorch_lightning.utilities.distributed][INFO] - IPU available: False, using: 0 IPUs
[2024-11-26 13:44:04,264][src.train][INFO] - Logging hyperparameters!
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: raymondfdavey. Use `wandb login --relogin` to force relogin
wandb: WARNING Path ./debugging/wandb/ wasn't writable, using system temp directory.
wandb: Tracking run with wandb version 0.18.7
wandb: Run data is saved locally in /tmp/wandb/run-20241126_134404-fowotoha
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run DDPM_2D_IXI_DDPM_cond_2D_spark_datamodule.cfg.mode-t1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/raymondfdavey/cDDPM
wandb: üöÄ View run at https://wandb.ai/raymondfdavey/cDDPM/runs/fowotoha
loading model from checkpoint
done loading model from checkpoint
[2024-11-26 13:44:05,969][src.train][INFO] - Best checkpoint path:

[2024-11-26 13:44:05,970][src.train][INFO] - Best checkpoint metric:
None
[2024-11-26 13:44:05,970][src.train][INFO] - Starting evaluation phase of fold 1!
[2024-11-26 13:44:05,971][src.train][INFO] - Instantiating datamodule <src.datamodules.Datamodules_train.IXI>
Created vol2slice with 387 volumes
Created vol2slice with 44 volumes
^CTraceback (most recent call last):
  File "/home/rd81/projects/diffusion-uad/run.py", line 60, in <module>
    main()
  File "/home/rd81/miniconda3/envs/cddpm/lib/python3.9/site-packages/hydra/main.py", line 49, in decorated_main
    _run_hydra(
  File "/home/rd81/miniconda3/envs/cddpm/lib/python3.9/site-packages/hydra/_internal/utils.py", line 367, in _run_hydra
    run_and_report(
  File "/home/rd81/miniconda3/envs/cddpm/lib/python3.9/site-packages/hydra/_internal/utils.py", line 211, in run_and_report
    return func()
  File "/home/rd81/miniconda3/envs/cddpm/lib/python3.9/site-packages/hydra/_internal/utils.py", line 368, in <lambda>
    lambda: hydra.run(
  File "/home/rd81/miniconda3/envs/cddpm/lib/python3.9/site-packages/hydra/_internal/hydra.py", line 97, in run
    ret = run_job(
  File "/home/rd81/miniconda3/envs/cddpm/lib/python3.9/site-packages/hydra/core/utils.py", line 160, in run_job
    ret.return_value = task_function(task_cfg)
  File "/home/rd81/projects/diffusion-uad/run.py", line 56, in main
    return train(config)
  File "/home/rd81/miniconda3/envs/cddpm/lib/python3.9/site-packages/hydra/main.py", line 44, in decorated_main
    return task_function(cfg_passthrough)
  File "/home/rd81/projects/diffusion-uad/src/train.py", line 190, in train
    datamodule.setup()
  File "/home/rd81/miniconda3/envs/cddpm/lib/python3.9/site-packages/pytorch_lightning/core/datamodule.py", line 474, in wrapped_fn
    fn(*args, **kwargs)
  File "/home/rd81/projects/diffusion-uad/src/datamodules/Datamodules_train.py", line 80, in setup
    self.test_eval = create_dataset.Eval(self.csv['test'],self.cfg)
  File "/home/rd81/projects/diffusion-uad/src/datamodules/create_dataset.py", line 57, in Eval
    if sub.mask_path is not None and tio.ScalarImage(sub.img_path,reader=sitk_reader).shape != tio.ScalarImage(sub.mask_path,reader=sitk_reader).shape:
  File "/home/rd81/miniconda3/envs/cddpm/lib/python3.9/site-packages/torchio/data/image.py", line 289, in shape
    channels, si, sj, sk = self.data.shape
  File "/home/rd81/miniconda3/envs/cddpm/lib/python3.9/site-packages/torchio/data/image.py", line 236, in data
    return self[DATA]
  File "/home/rd81/miniconda3/envs/cddpm/lib/python3.9/site-packages/torchio/data/image.py", line 207, in __getitem__
    self.load()
(cddpm) rd81@cs31c025338:~/projects/diffusion-uad$ python run.py experiment=cDDPM/DDPM_cond_spark_2D datamodule.cfg.mode=t1
syspath ['/home/rd81/projects/diffusion-uad', '/home/rd81/miniconda3/envs/cddpm/lib/python39.zip', '/home/rd81/miniconda3/envs/cddpm/lib/python3.9', '/home/rd81/miniconda3/envs/cddpm/lib/python3.9/lib-dynload', '/home/rd81/miniconda3/envs/cddpm/lib/python3.9/site-packages']
/home/rd81/projects/diffusion-uad
CONFIGGGG
work_dir: ${hydra:runtime.cwd}
data_dir: ${oc.env:DATA_DIR}
log_dir: ${oc.env:LOG_DIR}
name: DDPM_cond_2D_spark
debug: false
print_config: false
ignore_warnings: false
checkpoint: best
new_wandb_run: true
test_after_training: true
onlyEval: true
load_checkpoint: /home/rd81/projects/full_logs/logs/runs/DDPM_cond_2D_spark/DDPM_2D_IXI_DDPM_cond_2D_spark__2024-11-25_13-54-17
trainer:
  _target_: pytorch_lightning.Trainer
  gpus: -1
  min_epochs: 1
  max_epochs: 1200
  log_every_n_steps: 5
  precision: 16
  num_sanity_val_steps: 0
  check_val_every_n_epoch: 10
  benchmark: true
  overfit_batches: false
model:
  _target_: src.models.DDPM_2D.DDPM_2D
  cfg:
    name: DDPM_2D
    imageDim: ${datamodule.cfg.imageDim}
    rescaleFactor: ${datamodule.cfg.rescaleFactor}
    interRes: ${datamodule.cfg.interRes}
    cropMode: ${datamodule.cfg.cropMode}
    spatialDims: 2D
    resizedEvaluation: ${datamodule.cfg.resizedEvaluation}
    unet_dim: 128
    dim_mults:
    - 1
    - 2
    - 2
    learned_variance: false
    learned_sinusoidal_cond: false
    loss: l1
    lossStrategy: mean
    lr: ${datamodule.cfg.lr}
    scheduleLR: false
    patienceLR: 10
    earlyStopping: false
    patienceStopping: 50
    saveOutputImages: true
    evalSeg: true
    pad: ${datamodule.cfg.pad}
    erodeBrainmask: true
    medianFiltering: true
    threshold: auto
    mode: ${datamodule.cfg.mode}
    noise_ensemble: true
    step_ensemble:
    - 250
    - 500
    - 750
    test_timesteps: 250
    backbone: Spark_Encoder_2D
    version: resnet50
    cond_dim: 128
    OpenaiUnet: true
    spatial_transformer: false
    condition: true
    noisetype: simplex
    encoder_path: /home/rd81/projects/full_logs/logs/runs/MAE_2D/Spark_2D_IXI_MAE_2D__2024-11-25_10-25-18/checkpoints/epoch-1089_step-13079_loss-0.00_fold-1.ckpt
    pretrained_encoder: true
    save_to_disc: true
datamodule:
  _target_: src.datamodules.Datamodules_train.IXI
  cfg:
    name: IXI
    path:
      pathBase: ${data_dir}
      IXI:
        IDs:
          train:
          - ${data_dir}/Data/splits/IXI_train_fold0.csv
          - ${data_dir}/Data/splits/IXI_train_fold1.csv
          - ${data_dir}/Data/splits/IXI_train_fold2.csv
          - ${data_dir}/Data/splits/IXI_train_fold3.csv
          - ${data_dir}/Data/splits/IXI_train_fold4.csv
          val:
          - ${data_dir}/Data/splits/IXI_val_fold0.csv
          - ${data_dir}/Data/splits/IXI_val_fold1.csv
          - ${data_dir}/Data/splits/IXI_val_fold2.csv
          - ${data_dir}/Data/splits/IXI_val_fold3.csv
          - ${data_dir}/Data/splits/IXI_val_fold4.csv
          test: ${data_dir}/Data/splits/IXI_test.csv
        keep_t2: ${data_dir}/Data/splits/avail_t2.csv
      Brats21:
        IDs:
          test: ${data_dir}/Data/splits/Brats21_test.csv
          val: ${data_dir}/Data/splits/Brats21_val.csv
      MSLUB:
        IDs:
          test: ${data_dir}/Data/splits/MSLUB_test.csv
          val: ${data_dir}/Data/splits/MSLUB_val.csv
    imageDim:
    - 192
    - 192
    - 100
    rescaleFactor: 2
    interRes:
    - 8
    - 8
    - 5
    cropMode: isotropic
    spatialDims: ${model.cfg.spatialDims}
    unisotropic_sampling: true
    sample_set: false
    preLoad: true
    curvatureFlow: true
    percentile: true
    pad: true
    permute: false
    randomRotate: false
    rotateDegree: 5
    horizontalFlip: false
    randomBrightness: false
    brightnessRange: (0.75,1.25)
    randomContrast: false
    contrastRange: (0.75,1.25)
    modelpath: ${data_dir}/Data/pretrained_2D_model/
    num_workers: 4
    batch_size: 32
    lr: 0.0001
    droplast: true
    mode: t1
    resizedEvaluation: true
    testsets:
    - Datamodules_train.IXI
    aug_intensity: true
callbacks:
  model_checkpoint:
    _target_: pytorch_lightning.callbacks.model_checkpoint.ModelCheckpoint
    monitor: val/Loss_comb
    save_top_k: 1
    auto_insert_metric_name: false
    save_last: true
    mode: min
    dirpath: checkpoints/
    filename: epoch-{epoch}_step-{step}_loss-{val/Loss_comb:.2f}
logger:
  wandb:
    _target_: pytorch_lightning.loggers.wandb.WandbLogger
    project: cDDPM
    name: ${hydra:job.name}
    save_dir: ./debugging
    offline: false
    id: null
    resume: false
    log_model: false
    prefix: ''
    job_type: ''
    group: ''
    tags: []
  csv:
    _target_: pytorch_lightning.loggers.csv_logs.CSVLogger
    save_dir: ./debugging
    name: csv/
    version: ''
    prefix: ''
num_folds: 1
ckpt_path: best
seed: 3141
default_mode: true

END CONFIGGGG
/home/rd81/projects/full_logs/logs/runs/DDPM_cond_2D_spark/DDPM_2D_IXI_DDPM_cond_2D_spark__2024-11-25_13-54-17
---------------
/home/rd81/projects/full_logs/logs/runs/DDPM_cond_2D_spark/DDPM_2D_IXI_DDPM_cond_2D_spark__2024-11-25_13-54-17
best
['last_fold-1.ckpt', 'epoch-719_step-8639_loss-0.00_fold-1.ckpt']
/home/rd81/projects/full_logs/logs/runs/DDPM_cond_2D_spark/DDPM_2D_IXI_DDPM_cond_2D_spark__2024-11-25_13-54-17
gu3elgat
{'fold-1': '/home/rd81/projects/full_logs/logs/runs/DDPM_cond_2D_spark/DDPM_2D_IXI_DDPM_cond_2D_spark__2024-11-25_13-54-17/checkpoints/epoch-719_step-8639_loss-0.00_fold-1.ckpt'}
---------------
[2024-11-26 13:47:21,996][src.train][INFO] - Seed specified to 3141 by config
[2024-11-26 13:47:21,996][pytorch_lightning.utilities.seed][INFO] - Global seed set to 3141
0
1
[2024-11-26 13:47:21,996][src.train][INFO] - Training Fold 1 of 1 in the WandB group DDPM_cond_2D_spark
[2024-11-26 13:47:21,997][src.train][INFO] - Instantiating datamodule <src.datamodules.Datamodules_train.IXI>
[2024-11-26 13:47:22,235][src.train][INFO] - Instantiating model <src.models.DDPM_2D.DDPM_2D>
MAKING THE ACTUAL MODEL HERE INCLUDING LOADING THE PRETRAINED ENCODER
[2024-11-26 13:47:22,993][torch.distributed.nn.jit.instantiator][INFO] - Created a temporary directory at /tmp/tmp0fmniuae
[2024-11-26 13:47:22,995][torch.distributed.nn.jit.instantiator][INFO] - Writing /tmp/tmp0fmniuae/_remote_module_non_scriptable.py
[sparse_cnn] model kwargs={'drop_path_rate': 0.05, 'pretrained': False, 'num_classes': 512}
Loading pretrained encoder from:  /home/rd81/projects/full_logs/logs/runs/MAE_2D/Spark_2D_IXI_MAE_2D__2024-11-25_10-25-18/checkpoints/epoch-1089_step-13079_loss-0.00_fold-1.ckpt
encoder path,  /home/rd81/projects/full_logs/logs/runs/MAE_2D/Spark_2D_IXI_MAE_2D__2024-11-25_10-25-18/checkpoints/epoch-1089_step-13079_loss-0.00_fold-1.ckpt
[2024-11-26 13:47:24,474][src.train][INFO] - Instantiating callback <pytorch_lightning.callbacks.model_checkpoint.ModelCheckpoint>
[2024-11-26 13:47:24,474][src.train][INFO] - Instantiating logger <pytorch_lightning.loggers.wandb.WandbLogger>
[2024-11-26 13:47:24,477][src.train][INFO] - Instantiating logger <pytorch_lightning.loggers.csv_logs.CSVLogger>
[2024-11-26 13:47:24,477][src.train][INFO] - Restoring Trainer State of loaded checkpoint: /home/rd81/projects/full_logs/logs/runs/DDPM_cond_2D_spark/DDPM_2D_IXI_DDPM_cond_2D_spark__2024-11-25_13-54-17/checkpoints/epoch-719_step-8639_loss-0.00_fold-1.ckpt
[2024-11-26 13:47:24,478][src.train][INFO] - Instantiating trainer <pytorch_lightning.Trainer>
[2024-11-26 13:47:24,479][pytorch_lightning.utilities.distributed][INFO] - Using 16bit native Automatic Mixed Precision (AMP)
/home/rd81/miniconda3/envs/cddpm/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:45: LightningDeprecationWarning: Setting `Trainer(resume_from_checkpoint=)` is deprecated in v1.5 and will be removed in v1.7. Please pass `Trainer.fit(ckpt_path=)` directly instead.
  rank_zero_deprecation(
[2024-11-26 13:47:24,480][pytorch_lightning.utilities.distributed][INFO] - GPU available: True, used: True
[2024-11-26 13:47:24,480][pytorch_lightning.utilities.distributed][INFO] - TPU available: False, using: 0 TPU cores
[2024-11-26 13:47:24,480][pytorch_lightning.utilities.distributed][INFO] - IPU available: False, using: 0 IPUs
[2024-11-26 13:47:24,480][src.train][INFO] - Logging hyperparameters!
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: raymondfdavey. Use `wandb login --relogin` to force relogin
wandb: WARNING Path ./debugging/wandb/ wasn't writable, using system temp directory.
wandb: Tracking run with wandb version 0.18.7
wandb: Run data is saved locally in /tmp/wandb/run-20241126_134725-6l13gkaz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run DDPM_2D_IXI_DDPM_cond_2D_spark_datamodule.cfg.mode-t1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/raymondfdavey/cDDPM
wandb: üöÄ View run at https://wandb.ai/raymondfdavey/cDDPM/runs/6l13gkaz
loading model from checkpoint
done loading model from checkpoint
[2024-11-26 13:47:26,101][src.train][INFO] - Best checkpoint path:

[2024-11-26 13:47:26,101][src.train][INFO] - Best checkpoint metric:
None
[2024-11-26 13:47:26,101][src.train][INFO] - Starting evaluation phase of fold 1!
[2024-11-26 13:47:26,102][src.train][INFO] - Instantiating datamodule <src.datamodules.Datamodules_train.IXI>
Creating TRAIN dataset with 387 samples
Created vol2slice with 387 volumes
Creating TRAIN dataset with 44 samples
Created vol2slice with 44 volumes
Creating EVAL dataset with 44 samples
Creating EVAL dataset with 160 samples
[2024-11-26 13:47:45,207][src.train][INFO] - Validation of Datamodules_train.IXI!
!!!!! None
[2024-11-26 13:47:45,216][pytorch_lightning.accelerators.gpu][INFO] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Testing: 0it [00:00, ?it/s]Context vector c shape: torch.Size([50, 512])
Context vector c: tensor([[-1.2686, -0.4910,  0.4043,  ...,  4.0664, -0.1990, -0.8306],
        [-1.1338, -0.4524,  0.4175,  ...,  3.9844, -0.2859, -0.9419],
        [-1.0996, -0.6479,  0.5083,  ...,  4.0117, -0.3821, -1.1934],
        ...,
        [-1.8301, -1.5176,  0.9595,  ...,  4.3281, -0.0522, -0.3926],
        [-1.9102, -1.4307,  0.9043,  ...,  4.2734,  0.0395, -0.3608],
        [-2.0156, -1.3408,  0.7734,  ...,  4.3164,  0.0983, -0.4375]],
       device='cuda:0', dtype=torch.float16)

=== UNet Forward Pass ===
Input shape: torch.Size([50, 1, 96, 96])
Timesteps: tensor([249, 249, 249, 249, 249, 249, 249, 249, 249, 249, 249, 249, 249, 249,
        249, 249, 249, 249, 249, 249, 249, 249, 249, 249, 249, 249, 249, 249,
        249, 249, 249, 249, 249, 249, 249, 249, 249, 249, 249, 249, 249, 249,
        249, 249, 249, 249, 249, 249, 249, 249], device='cuda:0')
Conditioning shape: torch.Size([50, 512])

=== Time Embedding ===
Time embedding shape: torch.Size([50, 512])
Time embedding stats - mean: 0.0208, std: 0.7222

=== Combined Time+Label Embedding ===
Combined embedding shape: torch.Size([50, 1024])

=== Block Outputs ===

Input Block 0:
Shape: torch.Size([50, 128, 96, 96])
Stats - mean: -0.0040, std: 0.5059

=== ResBlock _forward ===
Input x shape: torch.Size([50, 128, 96, 96])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 128, 96, 96])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 256])
Projected embedding shape after expansion: torch.Size([50, 256, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 128, 1, 1])
Shift shape: torch.Size([50, 128, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 128, 96, 96])

Input Block 1:
Shape: torch.Size([50, 128, 96, 96])
Stats - mean: -0.0409, std: 0.7246

=== ResBlock _forward ===
Input x shape: torch.Size([50, 128, 96, 96])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 128, 96, 96])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 256])
Projected embedding shape after expansion: torch.Size([50, 256, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 128, 1, 1])
Shift shape: torch.Size([50, 128, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 128, 96, 96])

Input Block 2:
Shape: torch.Size([50, 128, 96, 96])
Stats - mean: -0.0341, std: 1.2256

=== ResBlock _forward ===
Input x shape: torch.Size([50, 128, 96, 96])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 128, 96, 96])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 256])
Projected embedding shape after expansion: torch.Size([50, 256, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 128, 1, 1])
Shift shape: torch.Size([50, 128, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 128, 96, 96])

Input Block 3:
Shape: torch.Size([50, 128, 96, 96])
Stats - mean: 0.0558, std: 1.6475

=== ResBlock _forward ===
Input x shape: torch.Size([50, 128, 96, 96])
Input embedding shape: torch.Size([50, 1024])

Updown processing:
After in_rest shape: torch.Size([50, 128, 96, 96])
After h_upd shape: torch.Size([50, 128, 48, 48])
After x_upd shape: torch.Size([50, 128, 48, 48])
After final conv shape: torch.Size([50, 128, 48, 48])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 256])
Projected embedding shape after expansion: torch.Size([50, 256, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 128, 1, 1])
Shift shape: torch.Size([50, 128, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 128, 48, 48])

Input Block 4:
Shape: torch.Size([50, 128, 48, 48])
Stats - mean: -0.0430, std: 1.8750

=== ResBlock _forward ===
Input x shape: torch.Size([50, 128, 48, 48])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 48, 48])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 48, 48])

Input Block 5:
Shape: torch.Size([50, 256, 48, 48])
Stats - mean: -0.0327, std: 1.9971

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 48, 48])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 48, 48])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 48, 48])

Input Block 6:
Shape: torch.Size([50, 256, 48, 48])
Stats - mean: -0.0911, std: 2.2129

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 48, 48])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 48, 48])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 48, 48])

Input Block 7:
Shape: torch.Size([50, 256, 48, 48])
Stats - mean: -0.0275, std: 2.4688

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 48, 48])
Input embedding shape: torch.Size([50, 1024])

Updown processing:
After in_rest shape: torch.Size([50, 256, 48, 48])
After h_upd shape: torch.Size([50, 256, 24, 24])
After x_upd shape: torch.Size([50, 256, 24, 24])
After final conv shape: torch.Size([50, 256, 24, 24])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 24, 24])

Input Block 8:
Shape: torch.Size([50, 256, 24, 24])
Stats - mean: -0.2585, std: 3.2812

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 24, 24])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 24, 24])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 24, 24])

Input Block 9:
Shape: torch.Size([50, 256, 24, 24])
Stats - mean: -0.7280, std: 4.6289

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 24, 24])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 24, 24])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 24, 24])

Input Block 10:
Shape: torch.Size([50, 256, 24, 24])
Stats - mean: -0.8574, std: 5.8281

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 24, 24])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 24, 24])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 24, 24])

Input Block 11:
Shape: torch.Size([50, 256, 24, 24])
Stats - mean: -0.7651, std: 7.1719

Middle Block:
Shape: torch.Size([50, 256, 24, 24])
Stats - mean: -0.7651, std: 7.1719

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 24, 24])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 24, 24])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 24, 24])

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 24, 24])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 24, 24])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 24, 24])

=== ResBlock _forward ===
Input x shape: torch.Size([50, 512, 24, 24])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 24, 24])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 24, 24])

Output Block 0:
Shape: torch.Size([50, 256, 24, 24])
Stats - mean: 0.8374, std: 6.7188

=== ResBlock _forward ===
Input x shape: torch.Size([50, 512, 24, 24])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 24, 24])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 24, 24])

Output Block 1:
Shape: torch.Size([50, 256, 24, 24])
Stats - mean: -0.0671, std: 6.2461

=== ResBlock _forward ===
Input x shape: torch.Size([50, 512, 24, 24])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 24, 24])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 24, 24])

Output Block 2:
Shape: torch.Size([50, 256, 24, 24])
Stats - mean: -0.4500, std: 5.7969

=== ResBlock _forward ===
Input x shape: torch.Size([50, 512, 24, 24])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 24, 24])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 24, 24])

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 24, 24])
Input embedding shape: torch.Size([50, 1024])

Updown processing:
After in_rest shape: torch.Size([50, 256, 24, 24])
After h_upd shape: torch.Size([50, 256, 48, 48])
After x_upd shape: torch.Size([50, 256, 48, 48])
After final conv shape: torch.Size([50, 256, 48, 48])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 48, 48])

Output Block 3:
Shape: torch.Size([50, 256, 48, 48])
Stats - mean: -0.1967, std: 5.9102

=== ResBlock _forward ===
Input x shape: torch.Size([50, 512, 48, 48])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 48, 48])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 48, 48])

Output Block 4:
Shape: torch.Size([50, 256, 48, 48])
Stats - mean: -0.0690, std: 3.9961

=== ResBlock _forward ===
Input x shape: torch.Size([50, 512, 48, 48])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 48, 48])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 48, 48])

Output Block 5:
Shape: torch.Size([50, 256, 48, 48])
Stats - mean: 0.1814, std: 2.7910

=== ResBlock _forward ===
Input x shape: torch.Size([50, 512, 48, 48])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 48, 48])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 48, 48])

Output Block 6:
Shape: torch.Size([50, 256, 48, 48])
Stats - mean: 0.0095, std: 2.4902

=== ResBlock _forward ===
Input x shape: torch.Size([50, 384, 48, 48])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 48, 48])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 48, 48])

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 48, 48])
Input embedding shape: torch.Size([50, 1024])

Updown processing:
After in_rest shape: torch.Size([50, 256, 48, 48])
After h_upd shape: torch.Size([50, 256, 96, 96])
After x_upd shape: torch.Size([50, 256, 96, 96])
After final conv shape: torch.Size([50, 256, 96, 96])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 96, 96])

Output Block 7:
Shape: torch.Size([50, 256, 96, 96])
Stats - mean: -0.7075, std: 3.4922

=== ResBlock _forward ===
Input x shape: torch.Size([50, 384, 96, 96])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 128, 96, 96])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 256])
Projected embedding shape after expansion: torch.Size([50, 256, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 128, 1, 1])
Shift shape: torch.Size([50, 128, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 128, 96, 96])

Output Block 8:
Shape: torch.Size([50, 128, 96, 96])
Stats - mean: 0.1378, std: 4.1406

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 96, 96])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 128, 96, 96])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 256])
Projected embedding shape after expansion: torch.Size([50, 256, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 128, 1, 1])
Shift shape: torch.Size([50, 128, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 128, 96, 96])

Output Block 9:
Shape: torch.Size([50, 128, 96, 96])
Stats - mean: 0.7031, std: 5.2070

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 96, 96])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 128, 96, 96])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 256])
Projected embedding shape after expansion: torch.Size([50, 256, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 128, 1, 1])
Shift shape: torch.Size([50, 128, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 128, 96, 96])

Output Block 10:
Shape: torch.Size([50, 128, 96, 96])
Stats - mean: -0.6553, std: 10.5312

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 96, 96])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 128, 96, 96])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 256])
Projected embedding shape after expansion: torch.Size([50, 256, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 128, 1, 1])
Shift shape: torch.Size([50, 128, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 128, 96, 96])

Output Block 11:
Shape: torch.Size([50, 128, 96, 96])
Stats - mean: -2.8887, std: 21.3438

=== Final Output ===
Shape: torch.Size([50, 128, 96, 96])
Stats - mean: -2.8887, std: 21.3438

=== UNet Forward Pass ===
Input shape: torch.Size([50, 1, 96, 96])
Timesteps: tensor([499, 499, 499, 499, 499, 499, 499, 499, 499, 499, 499, 499, 499, 499,
        499, 499, 499, 499, 499, 499, 499, 499, 499, 499, 499, 499, 499, 499,
        499, 499, 499, 499, 499, 499, 499, 499, 499, 499, 499, 499, 499, 499,
        499, 499, 499, 499, 499, 499, 499, 499], device='cuda:0')
Conditioning shape: torch.Size([50, 512])

=== Time Embedding ===
Time embedding shape: torch.Size([50, 512])
Time embedding stats - mean: -0.0212, std: 0.5400

=== Combined Time+Label Embedding ===
Combined embedding shape: torch.Size([50, 1024])

=== Block Outputs ===

Input Block 0:
Shape: torch.Size([50, 128, 96, 96])
Stats - mean: -0.0030, std: 0.4294

=== ResBlock _forward ===
Input x shape: torch.Size([50, 128, 96, 96])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 128, 96, 96])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 256])
Projected embedding shape after expansion: torch.Size([50, 256, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 128, 1, 1])
Shift shape: torch.Size([50, 128, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 128, 96, 96])

Input Block 1:
Shape: torch.Size([50, 128, 96, 96])
Stats - mean: -0.0242, std: 0.5693

=== ResBlock _forward ===
Input x shape: torch.Size([50, 128, 96, 96])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 128, 96, 96])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 256])
Projected embedding shape after expansion: torch.Size([50, 256, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 128, 1, 1])
Shift shape: torch.Size([50, 128, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 128, 96, 96])

Input Block 2:
Shape: torch.Size([50, 128, 96, 96])
Stats - mean: -0.0399, std: 1.1025

=== ResBlock _forward ===
Input x shape: torch.Size([50, 128, 96, 96])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 128, 96, 96])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 256])
Projected embedding shape after expansion: torch.Size([50, 256, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 128, 1, 1])
Shift shape: torch.Size([50, 128, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 128, 96, 96])

Input Block 3:
Shape: torch.Size([50, 128, 96, 96])
Stats - mean: 0.0614, std: 1.5811

=== ResBlock _forward ===
Input x shape: torch.Size([50, 128, 96, 96])
Input embedding shape: torch.Size([50, 1024])

Updown processing:
After in_rest shape: torch.Size([50, 128, 96, 96])
After h_upd shape: torch.Size([50, 128, 48, 48])
After x_upd shape: torch.Size([50, 128, 48, 48])
After final conv shape: torch.Size([50, 128, 48, 48])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 256])
Projected embedding shape after expansion: torch.Size([50, 256, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 128, 1, 1])
Shift shape: torch.Size([50, 128, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 128, 48, 48])

Input Block 4:
Shape: torch.Size([50, 128, 48, 48])
Stats - mean: -0.1213, std: 1.8779

=== ResBlock _forward ===
Input x shape: torch.Size([50, 128, 48, 48])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 48, 48])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 48, 48])

Input Block 5:
Shape: torch.Size([50, 256, 48, 48])
Stats - mean: -0.0718, std: 2.0684

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 48, 48])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 48, 48])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 48, 48])

Input Block 6:
Shape: torch.Size([50, 256, 48, 48])
Stats - mean: -0.1383, std: 2.2578

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 48, 48])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 48, 48])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 48, 48])

Input Block 7:
Shape: torch.Size([50, 256, 48, 48])
Stats - mean: -0.0860, std: 2.4648

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 48, 48])
Input embedding shape: torch.Size([50, 1024])

Updown processing:
After in_rest shape: torch.Size([50, 256, 48, 48])
After h_upd shape: torch.Size([50, 256, 24, 24])
After x_upd shape: torch.Size([50, 256, 24, 24])
After final conv shape: torch.Size([50, 256, 24, 24])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 24, 24])

Input Block 8:
Shape: torch.Size([50, 256, 24, 24])
Stats - mean: -0.2458, std: 3.2031

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 24, 24])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 24, 24])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 24, 24])

Input Block 9:
Shape: torch.Size([50, 256, 24, 24])
Stats - mean: -0.6831, std: 4.4727

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 24, 24])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 24, 24])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 24, 24])

Input Block 10:
Shape: torch.Size([50, 256, 24, 24])
Stats - mean: -0.7661, std: 5.5508

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 24, 24])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 24, 24])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 24, 24])

Input Block 11:
Shape: torch.Size([50, 256, 24, 24])
Stats - mean: -0.5264, std: 6.8008

Middle Block:
Shape: torch.Size([50, 256, 24, 24])
Stats - mean: -0.5264, std: 6.8008

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 24, 24])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 24, 24])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 24, 24])

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 24, 24])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 24, 24])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 24, 24])

=== ResBlock _forward ===
Input x shape: torch.Size([50, 512, 24, 24])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 24, 24])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 24, 24])

Output Block 0:
Shape: torch.Size([50, 256, 24, 24])
Stats - mean: 0.9370, std: 6.6914

=== ResBlock _forward ===
Input x shape: torch.Size([50, 512, 24, 24])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 24, 24])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 24, 24])

Output Block 1:
Shape: torch.Size([50, 256, 24, 24])
Stats - mean: 0.0222, std: 6.3164

=== ResBlock _forward ===
Input x shape: torch.Size([50, 512, 24, 24])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 24, 24])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 24, 24])

Output Block 2:
Shape: torch.Size([50, 256, 24, 24])
Stats - mean: -0.4741, std: 5.9531

=== ResBlock _forward ===
Input x shape: torch.Size([50, 512, 24, 24])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 24, 24])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 24, 24])

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 24, 24])
Input embedding shape: torch.Size([50, 1024])

Updown processing:
After in_rest shape: torch.Size([50, 256, 24, 24])
After h_upd shape: torch.Size([50, 256, 48, 48])
After x_upd shape: torch.Size([50, 256, 48, 48])
After final conv shape: torch.Size([50, 256, 48, 48])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 48, 48])

Output Block 3:
Shape: torch.Size([50, 256, 48, 48])
Stats - mean: -0.1200, std: 6.4648

=== ResBlock _forward ===
Input x shape: torch.Size([50, 512, 48, 48])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 48, 48])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 48, 48])

Output Block 4:
Shape: torch.Size([50, 256, 48, 48])
Stats - mean: -0.0867, std: 4.4570

=== ResBlock _forward ===
Input x shape: torch.Size([50, 512, 48, 48])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 48, 48])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 48, 48])

Output Block 5:
Shape: torch.Size([50, 256, 48, 48])
Stats - mean: 0.1862, std: 3.0410

=== ResBlock _forward ===
Input x shape: torch.Size([50, 512, 48, 48])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 48, 48])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 48, 48])

Output Block 6:
Shape: torch.Size([50, 256, 48, 48])
Stats - mean: -0.0873, std: 2.7578

=== ResBlock _forward ===
Input x shape: torch.Size([50, 384, 48, 48])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 48, 48])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 48, 48])

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 48, 48])
Input embedding shape: torch.Size([50, 1024])

Updown processing:
After in_rest shape: torch.Size([50, 256, 48, 48])
After h_upd shape: torch.Size([50, 256, 96, 96])
After x_upd shape: torch.Size([50, 256, 96, 96])
After final conv shape: torch.Size([50, 256, 96, 96])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 96, 96])

Output Block 7:
Shape: torch.Size([50, 256, 96, 96])
Stats - mean: -0.6367, std: 3.9375

=== ResBlock _forward ===
Input x shape: torch.Size([50, 384, 96, 96])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 128, 96, 96])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 256])
Projected embedding shape after expansion: torch.Size([50, 256, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 128, 1, 1])
Shift shape: torch.Size([50, 128, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 128, 96, 96])

Output Block 8:
Shape: torch.Size([50, 128, 96, 96])
Stats - mean: 0.1213, std: 4.8320

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 96, 96])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 128, 96, 96])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 256])
Projected embedding shape after expansion: torch.Size([50, 256, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 128, 1, 1])
Shift shape: torch.Size([50, 128, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 128, 96, 96])

Output Block 9:
Shape: torch.Size([50, 128, 96, 96])
Stats - mean: 0.7017, std: 5.1367

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 96, 96])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 128, 96, 96])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 256])
Projected embedding shape after expansion: torch.Size([50, 256, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 128, 1, 1])
Shift shape: torch.Size([50, 128, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 128, 96, 96])

Output Block 10:
Shape: torch.Size([50, 128, 96, 96])
Stats - mean: -0.5176, std: 9.2500

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 96, 96])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 128, 96, 96])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 256])
Projected embedding shape after expansion: torch.Size([50, 256, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 128, 1, 1])
Shift shape: torch.Size([50, 128, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 128, 96, 96])

Output Block 11:
Shape: torch.Size([50, 128, 96, 96])
Stats - mean: -2.5566, std: 18.4688

=== Final Output ===
Shape: torch.Size([50, 128, 96, 96])
Stats - mean: -2.5566, std: 18.4688

=== UNet Forward Pass ===
Input shape: torch.Size([50, 1, 96, 96])
Timesteps: tensor([749, 749, 749, 749, 749, 749, 749, 749, 749, 749, 749, 749, 749, 749,
        749, 749, 749, 749, 749, 749, 749, 749, 749, 749, 749, 749, 749, 749,
        749, 749, 749, 749, 749, 749, 749, 749, 749, 749, 749, 749, 749, 749,
        749, 749, 749, 749, 749, 749, 749, 749], device='cuda:0')
Conditioning shape: torch.Size([50, 512])

=== Time Embedding ===
Time embedding shape: torch.Size([50, 512])
Time embedding stats - mean: -0.0521, std: 0.2510

=== Combined Time+Label Embedding ===
Combined embedding shape: torch.Size([50, 1024])

=== Block Outputs ===

Input Block 0:
Shape: torch.Size([50, 128, 96, 96])
Stats - mean: -0.0046, std: 0.3977

=== ResBlock _forward ===
Input x shape: torch.Size([50, 128, 96, 96])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 128, 96, 96])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 256])
Projected embedding shape after expansion: torch.Size([50, 256, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 128, 1, 1])
Shift shape: torch.Size([50, 128, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 128, 96, 96])

Input Block 1:
Shape: torch.Size([50, 128, 96, 96])
Stats - mean: -0.0115, std: 0.5454

=== ResBlock _forward ===
Input x shape: torch.Size([50, 128, 96, 96])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 128, 96, 96])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 256])
Projected embedding shape after expansion: torch.Size([50, 256, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 128, 1, 1])
Shift shape: torch.Size([50, 128, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 128, 96, 96])

Input Block 2:
Shape: torch.Size([50, 128, 96, 96])
Stats - mean: -0.0013, std: 0.7842

=== ResBlock _forward ===
Input x shape: torch.Size([50, 128, 96, 96])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 128, 96, 96])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 256])
Projected embedding shape after expansion: torch.Size([50, 256, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 128, 1, 1])
Shift shape: torch.Size([50, 128, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 128, 96, 96])

Input Block 3:
Shape: torch.Size([50, 128, 96, 96])
Stats - mean: 0.1091, std: 1.3721

=== ResBlock _forward ===
Input x shape: torch.Size([50, 128, 96, 96])
Input embedding shape: torch.Size([50, 1024])

Updown processing:
After in_rest shape: torch.Size([50, 128, 96, 96])
After h_upd shape: torch.Size([50, 128, 48, 48])
After x_upd shape: torch.Size([50, 128, 48, 48])
After final conv shape: torch.Size([50, 128, 48, 48])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 256])
Projected embedding shape after expansion: torch.Size([50, 256, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 128, 1, 1])
Shift shape: torch.Size([50, 128, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 128, 48, 48])

Input Block 4:
Shape: torch.Size([50, 128, 48, 48])
Stats - mean: -0.0981, std: 1.7158

=== ResBlock _forward ===
Input x shape: torch.Size([50, 128, 48, 48])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 48, 48])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 48, 48])

Input Block 5:
Shape: torch.Size([50, 256, 48, 48])
Stats - mean: -0.0645, std: 1.9463

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 48, 48])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 48, 48])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 48, 48])

Input Block 6:
Shape: torch.Size([50, 256, 48, 48])
Stats - mean: -0.1533, std: 2.1367

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 48, 48])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 48, 48])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 48, 48])

Input Block 7:
Shape: torch.Size([50, 256, 48, 48])
Stats - mean: -0.1498, std: 2.3984

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 48, 48])
Input embedding shape: torch.Size([50, 1024])

Updown processing:
After in_rest shape: torch.Size([50, 256, 48, 48])
After h_upd shape: torch.Size([50, 256, 24, 24])
After x_upd shape: torch.Size([50, 256, 24, 24])
After final conv shape: torch.Size([50, 256, 24, 24])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 24, 24])

Input Block 8:
Shape: torch.Size([50, 256, 24, 24])
Stats - mean: -0.2646, std: 3.1016

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 24, 24])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 24, 24])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 24, 24])

Input Block 9:
Shape: torch.Size([50, 256, 24, 24])
Stats - mean: -0.6157, std: 4.2305

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 24, 24])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 24, 24])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 24, 24])

Input Block 10:
Shape: torch.Size([50, 256, 24, 24])
Stats - mean: -0.6440, std: 5.1953

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 24, 24])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 24, 24])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 24, 24])

Input Block 11:
Shape: torch.Size([50, 256, 24, 24])
Stats - mean: -0.2197, std: 6.4414

Middle Block:
Shape: torch.Size([50, 256, 24, 24])
Stats - mean: -0.2197, std: 6.4414

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 24, 24])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 24, 24])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 24, 24])

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 24, 24])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 24, 24])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 24, 24])

=== ResBlock _forward ===
Input x shape: torch.Size([50, 512, 24, 24])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 24, 24])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 24, 24])

Output Block 0:
Shape: torch.Size([50, 256, 24, 24])
Stats - mean: 1.0098, std: 6.9297

=== ResBlock _forward ===
Input x shape: torch.Size([50, 512, 24, 24])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 24, 24])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 24, 24])

Output Block 1:
Shape: torch.Size([50, 256, 24, 24])
Stats - mean: 0.1357, std: 6.4453

=== ResBlock _forward ===
Input x shape: torch.Size([50, 512, 24, 24])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 24, 24])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 24, 24])

Output Block 2:
Shape: torch.Size([50, 256, 24, 24])
Stats - mean: -0.4907, std: 6.0898

=== ResBlock _forward ===
Input x shape: torch.Size([50, 512, 24, 24])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 24, 24])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 24, 24])

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 24, 24])
Input embedding shape: torch.Size([50, 1024])

Updown processing:
After in_rest shape: torch.Size([50, 256, 24, 24])
After h_upd shape: torch.Size([50, 256, 48, 48])
After x_upd shape: torch.Size([50, 256, 48, 48])
After final conv shape: torch.Size([50, 256, 48, 48])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 48, 48])

Output Block 3:
Shape: torch.Size([50, 256, 48, 48])
Stats - mean: -0.2224, std: 6.7812

=== ResBlock _forward ===
Input x shape: torch.Size([50, 512, 48, 48])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 48, 48])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 48, 48])

Output Block 4:
Shape: torch.Size([50, 256, 48, 48])
Stats - mean: -0.0975, std: 4.7578

=== ResBlock _forward ===
Input x shape: torch.Size([50, 512, 48, 48])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 48, 48])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 48, 48])

Output Block 5:
Shape: torch.Size([50, 256, 48, 48])
Stats - mean: 0.2083, std: 3.1543

=== ResBlock _forward ===
Input x shape: torch.Size([50, 512, 48, 48])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 48, 48])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 48, 48])

Output Block 6:
Shape: torch.Size([50, 256, 48, 48])
Stats - mean: -0.1550, std: 2.8770

=== ResBlock _forward ===
Input x shape: torch.Size([50, 384, 48, 48])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 48, 48])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 48, 48])

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 48, 48])
Input embedding shape: torch.Size([50, 1024])

Updown processing:
After in_rest shape: torch.Size([50, 256, 48, 48])
After h_upd shape: torch.Size([50, 256, 96, 96])
After x_upd shape: torch.Size([50, 256, 96, 96])
After final conv shape: torch.Size([50, 256, 96, 96])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 96, 96])

Output Block 7:
Shape: torch.Size([50, 256, 96, 96])
Stats - mean: -0.6187, std: 4.4062

=== ResBlock _forward ===
Input x shape: torch.Size([50, 384, 96, 96])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 128, 96, 96])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 256])
Projected embedding shape after expansion: torch.Size([50, 256, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 128, 1, 1])
Shift shape: torch.Size([50, 128, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 128, 96, 96])

Output Block 8:
Shape: torch.Size([50, 128, 96, 96])
Stats - mean: 0.0845, std: 5.3906

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 96, 96])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 128, 96, 96])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 256])
Projected embedding shape after expansion: torch.Size([50, 256, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 128, 1, 1])
Shift shape: torch.Size([50, 128, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 128, 96, 96])

Output Block 9:
Shape: torch.Size([50, 128, 96, 96])
Stats - mean: 0.7114, std: 5.0195

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 96, 96])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 128, 96, 96])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 256])
Projected embedding shape after expansion: torch.Size([50, 256, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 128, 1, 1])
Shift shape: torch.Size([50, 128, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 128, 96, 96])

Output Block 10:
Shape: torch.Size([50, 128, 96, 96])
Stats - mean: -0.3208, std: 7.6445

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 96, 96])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 128, 96, 96])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 256])
Projected embedding shape after expansion: torch.Size([50, 256, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 128, 1, 1])
Shift shape: torch.Size([50, 128, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 128, 96, 96])

Output Block 11:
Shape: torch.Size([50, 128, 96, 96])
Stats - mean: -2.1621, std: 14.5469

=== Final Output ===
Shape: torch.Size([50, 128, 96, 96])
Stats - mean: -2.1621, std: 14.5469
Testing:   2%|‚ñà‚ñà‚ñà‚ñà‚ñâ                                                                                                                                                                                                                  | 1/44 [00:13<09:42, 13.54s/it]Context vector c shape: torch.Size([50, 512])
Context vector c: tensor([[-1.1133, -0.4404,  0.3950,  ...,  4.0664, -0.2786, -0.9248],
        [-1.0967, -0.4524,  0.4153,  ...,  4.0078, -0.2898, -0.8979],
        [-0.9863, -0.4167,  0.4392,  ...,  3.8457, -0.3289, -0.8989],
        ...,
        [-1.5264, -1.4873,  1.0771,  ...,  3.9922, -0.1718, -0.3279],
        [-1.6680, -1.4482,  0.9785,  ...,  4.1445, -0.1141, -0.4004],
        [-1.8838, -1.4453,  0.8911,  ...,  4.3281, -0.0221, -0.4297]],
       device='cuda:0', dtype=torch.float16)

=== UNet Forward Pass ===
Input shape: torch.Size([50, 1, 96, 96])
Timesteps: tensor([249, 249, 249, 249, 249, 249, 249, 249, 249, 249, 249, 249, 249, 249,
        249, 249, 249, 249, 249, 249, 249, 249, 249, 249, 249, 249, 249, 249,
        249, 249, 249, 249, 249, 249, 249, 249, 249, 249, 249, 249, 249, 249,
        249, 249, 249, 249, 249, 249, 249, 249], device='cuda:0')
Conditioning shape: torch.Size([50, 512])

=== Time Embedding ===
Time embedding shape: torch.Size([50, 512])
Time embedding stats - mean: 0.0208, std: 0.7222

=== Combined Time+Label Embedding ===
Combined embedding shape: torch.Size([50, 1024])

=== Block Outputs ===

Input Block 0:
Shape: torch.Size([50, 128, 96, 96])
Stats - mean: -0.0083, std: 0.4910

=== ResBlock _forward ===
Input x shape: torch.Size([50, 128, 96, 96])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 128, 96, 96])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 256])
Projected embedding shape after expansion: torch.Size([50, 256, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 128, 1, 1])
Shift shape: torch.Size([50, 128, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 128, 96, 96])

Input Block 1:
Shape: torch.Size([50, 128, 96, 96])
Stats - mean: -0.0521, std: 0.7515

=== ResBlock _forward ===
Input x shape: torch.Size([50, 128, 96, 96])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 128, 96, 96])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 256])
Projected embedding shape after expansion: torch.Size([50, 256, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 128, 1, 1])
Shift shape: torch.Size([50, 128, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 128, 96, 96])

Input Block 2:
Shape: torch.Size([50, 128, 96, 96])
Stats - mean: -0.0450, std: 1.2500

=== ResBlock _forward ===
Input x shape: torch.Size([50, 128, 96, 96])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 128, 96, 96])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 256])
Projected embedding shape after expansion: torch.Size([50, 256, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 128, 1, 1])
Shift shape: torch.Size([50, 128, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 128, 96, 96])

Input Block 3:
Shape: torch.Size([50, 128, 96, 96])
Stats - mean: 0.0528, std: 1.6309

=== ResBlock _forward ===
Input x shape: torch.Size([50, 128, 96, 96])
Input embedding shape: torch.Size([50, 1024])

Updown processing:
After in_rest shape: torch.Size([50, 128, 96, 96])
After h_upd shape: torch.Size([50, 128, 48, 48])
After x_upd shape: torch.Size([50, 128, 48, 48])
After final conv shape: torch.Size([50, 128, 48, 48])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 256])
Projected embedding shape after expansion: torch.Size([50, 256, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 128, 1, 1])
Shift shape: torch.Size([50, 128, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 128, 48, 48])

Input Block 4:
Shape: torch.Size([50, 128, 48, 48])
Stats - mean: -0.0540, std: 1.8398

=== ResBlock _forward ===
Input x shape: torch.Size([50, 128, 48, 48])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 48, 48])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 48, 48])

Input Block 5:
Shape: torch.Size([50, 256, 48, 48])
Stats - mean: -0.0247, std: 2.0098

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 48, 48])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 48, 48])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 48, 48])

Input Block 6:
Shape: torch.Size([50, 256, 48, 48])
Stats - mean: -0.0817, std: 2.2441

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 48, 48])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 48, 48])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 48, 48])

Input Block 7:
Shape: torch.Size([50, 256, 48, 48])
Stats - mean: -0.0150, std: 2.5059

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 48, 48])
Input embedding shape: torch.Size([50, 1024])

Updown processing:
After in_rest shape: torch.Size([50, 256, 48, 48])
After h_upd shape: torch.Size([50, 256, 24, 24])
After x_upd shape: torch.Size([50, 256, 24, 24])
After final conv shape: torch.Size([50, 256, 24, 24])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 24, 24])

Input Block 8:
Shape: torch.Size([50, 256, 24, 24])
Stats - mean: -0.2239, std: 3.2812

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 24, 24])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 24, 24])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 24, 24])

Input Block 9:
Shape: torch.Size([50, 256, 24, 24])
Stats - mean: -0.6929, std: 4.6445

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 24, 24])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 24, 24])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 24, 24])

Input Block 10:
Shape: torch.Size([50, 256, 24, 24])
Stats - mean: -0.8184, std: 5.7852

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 24, 24])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 24, 24])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 24, 24])

Input Block 11:
Shape: torch.Size([50, 256, 24, 24])
Stats - mean: -0.7300, std: 7.0625

Middle Block:
Shape: torch.Size([50, 256, 24, 24])
Stats - mean: -0.7300, std: 7.0625

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 24, 24])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 24, 24])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 24, 24])

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 24, 24])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 24, 24])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 24, 24])

=== ResBlock _forward ===
Input x shape: torch.Size([50, 512, 24, 24])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 24, 24])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 24, 24])

Output Block 0:
Shape: torch.Size([50, 256, 24, 24])
Stats - mean: 0.8203, std: 6.3867

=== ResBlock _forward ===
Input x shape: torch.Size([50, 512, 24, 24])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 24, 24])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 24, 24])

Output Block 1:
Shape: torch.Size([50, 256, 24, 24])
Stats - mean: -0.0565, std: 6.0547

=== ResBlock _forward ===
Input x shape: torch.Size([50, 512, 24, 24])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 24, 24])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 24, 24])

Output Block 2:
Shape: torch.Size([50, 256, 24, 24])
Stats - mean: -0.4536, std: 5.6953

=== ResBlock _forward ===
Input x shape: torch.Size([50, 512, 24, 24])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 24, 24])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 24, 24])

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 24, 24])
Input embedding shape: torch.Size([50, 1024])

Updown processing:
After in_rest shape: torch.Size([50, 256, 24, 24])
After h_upd shape: torch.Size([50, 256, 48, 48])
After x_upd shape: torch.Size([50, 256, 48, 48])
After final conv shape: torch.Size([50, 256, 48, 48])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 48, 48])

Output Block 3:
Shape: torch.Size([50, 256, 48, 48])
Stats - mean: -0.1475, std: 5.8477

=== ResBlock _forward ===
Input x shape: torch.Size([50, 512, 48, 48])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 48, 48])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 48, 48])

Output Block 4:
Shape: torch.Size([50, 256, 48, 48])
Stats - mean: -0.0786, std: 4.0000

=== ResBlock _forward ===
Input x shape: torch.Size([50, 512, 48, 48])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 48, 48])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 48, 48])

Output Block 5:
Shape: torch.Size([50, 256, 48, 48])
Stats - mean: 0.1709, std: 2.8066

=== ResBlock _forward ===
Input x shape: torch.Size([50, 512, 48, 48])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 48, 48])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 48, 48])

Output Block 6:
Shape: torch.Size([50, 256, 48, 48])
Stats - mean: -0.0029, std: 2.5195

=== ResBlock _forward ===
Input x shape: torch.Size([50, 384, 48, 48])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 48, 48])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 48, 48])

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 48, 48])
Input embedding shape: torch.Size([50, 1024])

Updown processing:
After in_rest shape: torch.Size([50, 256, 48, 48])
After h_upd shape: torch.Size([50, 256, 96, 96])
After x_upd shape: torch.Size([50, 256, 96, 96])
After final conv shape: torch.Size([50, 256, 96, 96])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 96, 96])

Output Block 7:
Shape: torch.Size([50, 256, 96, 96])
Stats - mean: -0.6821, std: 3.4414

=== ResBlock _forward ===
Input x shape: torch.Size([50, 384, 96, 96])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 128, 96, 96])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 256])
Projected embedding shape after expansion: torch.Size([50, 256, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 128, 1, 1])
Shift shape: torch.Size([50, 128, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 128, 96, 96])

Output Block 8:
Shape: torch.Size([50, 128, 96, 96])
Stats - mean: 0.1456, std: 4.0352

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 96, 96])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 128, 96, 96])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 256])
Projected embedding shape after expansion: torch.Size([50, 256, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 128, 1, 1])
Shift shape: torch.Size([50, 128, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 128, 96, 96])

Output Block 9:
Shape: torch.Size([50, 128, 96, 96])
Stats - mean: 0.6919, std: 5.1289

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 96, 96])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 128, 96, 96])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 256])
Projected embedding shape after expansion: torch.Size([50, 256, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 128, 1, 1])
Shift shape: torch.Size([50, 128, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 128, 96, 96])

Output Block 10:
Shape: torch.Size([50, 128, 96, 96])
Stats - mean: -0.6587, std: 10.4609

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 96, 96])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 128, 96, 96])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 256])
Projected embedding shape after expansion: torch.Size([50, 256, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 128, 1, 1])
Shift shape: torch.Size([50, 128, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 128, 96, 96])

Output Block 11:
Shape: torch.Size([50, 128, 96, 96])
Stats - mean: -2.8848, std: 21.2188

=== Final Output ===
Shape: torch.Size([50, 128, 96, 96])
Stats - mean: -2.8848, std: 21.2188

=== UNet Forward Pass ===
Input shape: torch.Size([50, 1, 96, 96])
Timesteps: tensor([499, 499, 499, 499, 499, 499, 499, 499, 499, 499, 499, 499, 499, 499,
        499, 499, 499, 499, 499, 499, 499, 499, 499, 499, 499, 499, 499, 499,
        499, 499, 499, 499, 499, 499, 499, 499, 499, 499, 499, 499, 499, 499,
        499, 499, 499, 499, 499, 499, 499, 499], device='cuda:0')
Conditioning shape: torch.Size([50, 512])

=== Time Embedding ===
Time embedding shape: torch.Size([50, 512])
Time embedding stats - mean: -0.0212, std: 0.5400

=== Combined Time+Label Embedding ===
Combined embedding shape: torch.Size([50, 1024])

=== Block Outputs ===

Input Block 0:
Shape: torch.Size([50, 128, 96, 96])
Stats - mean: -0.0104, std: 0.4666

=== ResBlock _forward ===
Input x shape: torch.Size([50, 128, 96, 96])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 128, 96, 96])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 256])
Projected embedding shape after expansion: torch.Size([50, 256, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 128, 1, 1])
Shift shape: torch.Size([50, 128, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 128, 96, 96])

Input Block 1:
Shape: torch.Size([50, 128, 96, 96])
Stats - mean: -0.0266, std: 0.5977

=== ResBlock _forward ===
Input x shape: torch.Size([50, 128, 96, 96])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 128, 96, 96])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 256])
Projected embedding shape after expansion: torch.Size([50, 256, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 128, 1, 1])
Shift shape: torch.Size([50, 128, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 128, 96, 96])

Input Block 2:
Shape: torch.Size([50, 128, 96, 96])
Stats - mean: -0.0415, std: 1.0928

=== ResBlock _forward ===
Input x shape: torch.Size([50, 128, 96, 96])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 128, 96, 96])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 256])
Projected embedding shape after expansion: torch.Size([50, 256, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 128, 1, 1])
Shift shape: torch.Size([50, 128, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 128, 96, 96])

Input Block 3:
Shape: torch.Size([50, 128, 96, 96])
Stats - mean: 0.0637, std: 1.5605

=== ResBlock _forward ===
Input x shape: torch.Size([50, 128, 96, 96])
Input embedding shape: torch.Size([50, 1024])

Updown processing:
After in_rest shape: torch.Size([50, 128, 96, 96])
After h_upd shape: torch.Size([50, 128, 48, 48])
After x_upd shape: torch.Size([50, 128, 48, 48])
After final conv shape: torch.Size([50, 128, 48, 48])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 256])
Projected embedding shape after expansion: torch.Size([50, 256, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 128, 1, 1])
Shift shape: torch.Size([50, 128, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 128, 48, 48])

Input Block 4:
Shape: torch.Size([50, 128, 48, 48])
Stats - mean: -0.1104, std: 1.8525

=== ResBlock _forward ===
Input x shape: torch.Size([50, 128, 48, 48])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 48, 48])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 48, 48])

Input Block 5:
Shape: torch.Size([50, 256, 48, 48])
Stats - mean: -0.0707, std: 2.0391

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 48, 48])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 48, 48])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 48, 48])

Input Block 6:
Shape: torch.Size([50, 256, 48, 48])
Stats - mean: -0.1335, std: 2.2246

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 48, 48])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 48, 48])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 48, 48])

Input Block 7:
Shape: torch.Size([50, 256, 48, 48])
Stats - mean: -0.0787, std: 2.4219

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 48, 48])
Input embedding shape: torch.Size([50, 1024])

Updown processing:
After in_rest shape: torch.Size([50, 256, 48, 48])
After h_upd shape: torch.Size([50, 256, 24, 24])
After x_upd shape: torch.Size([50, 256, 24, 24])
After final conv shape: torch.Size([50, 256, 24, 24])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 24, 24])

Input Block 8:
Shape: torch.Size([50, 256, 24, 24])
Stats - mean: -0.2294, std: 3.1582

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 24, 24])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 24, 24])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 24, 24])

Input Block 9:
Shape: torch.Size([50, 256, 24, 24])
Stats - mean: -0.6650, std: 4.4180

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 24, 24])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 24, 24])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 24, 24])

Input Block 10:
Shape: torch.Size([50, 256, 24, 24])
Stats - mean: -0.7505, std: 5.4727

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 24, 24])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 24, 24])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 24, 24])

Input Block 11:
Shape: torch.Size([50, 256, 24, 24])
Stats - mean: -0.5137, std: 6.6523

Middle Block:
Shape: torch.Size([50, 256, 24, 24])
Stats - mean: -0.5137, std: 6.6523

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 24, 24])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 24, 24])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 24, 24])

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 24, 24])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 24, 24])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 24, 24])

=== ResBlock _forward ===
Input x shape: torch.Size([50, 512, 24, 24])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 24, 24])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 24, 24])

Output Block 0:
Shape: torch.Size([50, 256, 24, 24])
Stats - mean: 0.9233, std: 6.5781

=== ResBlock _forward ===
Input x shape: torch.Size([50, 512, 24, 24])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 24, 24])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 24, 24])

Output Block 1:
Shape: torch.Size([50, 256, 24, 24])
Stats - mean: 0.0325, std: 6.2578

=== ResBlock _forward ===
Input x shape: torch.Size([50, 512, 24, 24])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 24, 24])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 24, 24])

Output Block 2:
Shape: torch.Size([50, 256, 24, 24])
Stats - mean: -0.4690, std: 5.8789

=== ResBlock _forward ===
Input x shape: torch.Size([50, 512, 24, 24])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 24, 24])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 24, 24])

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 24, 24])
Input embedding shape: torch.Size([50, 1024])

Updown processing:
After in_rest shape: torch.Size([50, 256, 24, 24])
After h_upd shape: torch.Size([50, 256, 48, 48])
After x_upd shape: torch.Size([50, 256, 48, 48])
After final conv shape: torch.Size([50, 256, 48, 48])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 48, 48])

Output Block 3:
Shape: torch.Size([50, 256, 48, 48])
Stats - mean: -0.1256, std: 6.3477

=== ResBlock _forward ===
Input x shape: torch.Size([50, 512, 48, 48])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 48, 48])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 48, 48])

Output Block 4:
Shape: torch.Size([50, 256, 48, 48])
Stats - mean: -0.0930, std: 4.3906

=== ResBlock _forward ===
Input x shape: torch.Size([50, 512, 48, 48])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 48, 48])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 48, 48])

Output Block 5:
Shape: torch.Size([50, 256, 48, 48])
Stats - mean: 0.1877, std: 3.0000

=== ResBlock _forward ===
Input x shape: torch.Size([50, 512, 48, 48])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 48, 48])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 48, 48])

Output Block 6:
Shape: torch.Size([50, 256, 48, 48])
Stats - mean: -0.0670, std: 2.7266

=== ResBlock _forward ===
Input x shape: torch.Size([50, 384, 48, 48])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 48, 48])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 48, 48])

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 48, 48])
Input embedding shape: torch.Size([50, 1024])

Updown processing:
After in_rest shape: torch.Size([50, 256, 48, 48])
After h_upd shape: torch.Size([50, 256, 96, 96])
After x_upd shape: torch.Size([50, 256, 96, 96])
After final conv shape: torch.Size([50, 256, 96, 96])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 96, 96])

Output Block 7:
Shape: torch.Size([50, 256, 96, 96])
Stats - mean: -0.6396, std: 3.8926

=== ResBlock _forward ===
Input x shape: torch.Size([50, 384, 96, 96])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 128, 96, 96])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 256])
Projected embedding shape after expansion: torch.Size([50, 256, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 128, 1, 1])
Shift shape: torch.Size([50, 128, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 128, 96, 96])

Output Block 8:
Shape: torch.Size([50, 128, 96, 96])
Stats - mean: 0.1390, std: 4.7695

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 96, 96])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 128, 96, 96])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 256])
Projected embedding shape after expansion: torch.Size([50, 256, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 128, 1, 1])
Shift shape: torch.Size([50, 128, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 128, 96, 96])

Output Block 9:
Shape: torch.Size([50, 128, 96, 96])
Stats - mean: 0.7031, std: 5.0820

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 96, 96])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 128, 96, 96])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 256])
Projected embedding shape after expansion: torch.Size([50, 256, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 128, 1, 1])
Shift shape: torch.Size([50, 128, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 128, 96, 96])

Output Block 10:
Shape: torch.Size([50, 128, 96, 96])
Stats - mean: -0.5190, std: 9.1875

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 96, 96])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 128, 96, 96])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 256])
Projected embedding shape after expansion: torch.Size([50, 256, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 128, 1, 1])
Shift shape: torch.Size([50, 128, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 128, 96, 96])

Output Block 11:
Shape: torch.Size([50, 128, 96, 96])
Stats - mean: -2.5508, std: 18.3125

=== Final Output ===
Shape: torch.Size([50, 128, 96, 96])
Stats - mean: -2.5508, std: 18.3125

=== UNet Forward Pass ===
Input shape: torch.Size([50, 1, 96, 96])
Timesteps: tensor([749, 749, 749, 749, 749, 749, 749, 749, 749, 749, 749, 749, 749, 749,
        749, 749, 749, 749, 749, 749, 749, 749, 749, 749, 749, 749, 749, 749,
        749, 749, 749, 749, 749, 749, 749, 749, 749, 749, 749, 749, 749, 749,
        749, 749, 749, 749, 749, 749, 749, 749], device='cuda:0')
Conditioning shape: torch.Size([50, 512])

=== Time Embedding ===
Time embedding shape: torch.Size([50, 512])
Time embedding stats - mean: -0.0521, std: 0.2510

=== Combined Time+Label Embedding ===
Combined embedding shape: torch.Size([50, 1024])

=== Block Outputs ===

Input Block 0:
Shape: torch.Size([50, 128, 96, 96])
Stats - mean: -0.0045, std: 0.3708

=== ResBlock _forward ===
Input x shape: torch.Size([50, 128, 96, 96])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 128, 96, 96])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 256])
Projected embedding shape after expansion: torch.Size([50, 256, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 128, 1, 1])
Shift shape: torch.Size([50, 128, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 128, 96, 96])

Input Block 1:
Shape: torch.Size([50, 128, 96, 96])
Stats - mean: -0.0165, std: 0.5537

=== ResBlock _forward ===
Input x shape: torch.Size([50, 128, 96, 96])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 128, 96, 96])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 256])
Projected embedding shape after expansion: torch.Size([50, 256, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 128, 1, 1])
Shift shape: torch.Size([50, 128, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 128, 96, 96])

Input Block 2:
Shape: torch.Size([50, 128, 96, 96])
Stats - mean: -0.0098, std: 0.7769

=== ResBlock _forward ===
Input x shape: torch.Size([50, 128, 96, 96])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 128, 96, 96])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 256])
Projected embedding shape after expansion: torch.Size([50, 256, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 128, 1, 1])
Shift shape: torch.Size([50, 128, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 128, 96, 96])

Input Block 3:
Shape: torch.Size([50, 128, 96, 96])
Stats - mean: 0.1048, std: 1.3604

=== ResBlock _forward ===
Input x shape: torch.Size([50, 128, 96, 96])
Input embedding shape: torch.Size([50, 1024])

Updown processing:
After in_rest shape: torch.Size([50, 128, 96, 96])
After h_upd shape: torch.Size([50, 128, 48, 48])
After x_upd shape: torch.Size([50, 128, 48, 48])
After final conv shape: torch.Size([50, 128, 48, 48])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 256])
Projected embedding shape after expansion: torch.Size([50, 256, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 128, 1, 1])
Shift shape: torch.Size([50, 128, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 128, 48, 48])

Input Block 4:
Shape: torch.Size([50, 128, 48, 48])
Stats - mean: -0.0981, std: 1.6885

=== ResBlock _forward ===
Input x shape: torch.Size([50, 128, 48, 48])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 48, 48])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 48, 48])

Input Block 5:
Shape: torch.Size([50, 256, 48, 48])
Stats - mean: -0.0630, std: 1.9033

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 48, 48])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 48, 48])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 48, 48])

Input Block 6:
Shape: torch.Size([50, 256, 48, 48])
Stats - mean: -0.1451, std: 2.0840

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 48, 48])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 48, 48])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 48, 48])

Input Block 7:
Shape: torch.Size([50, 256, 48, 48])
Stats - mean: -0.1371, std: 2.3320

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 48, 48])
Input embedding shape: torch.Size([50, 1024])

Updown processing:
After in_rest shape: torch.Size([50, 256, 48, 48])
After h_upd shape: torch.Size([50, 256, 24, 24])
After x_upd shape: torch.Size([50, 256, 24, 24])
After final conv shape: torch.Size([50, 256, 24, 24])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 24, 24])

Input Block 8:
Shape: torch.Size([50, 256, 24, 24])
Stats - mean: -0.2449, std: 3.0098

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 24, 24])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 24, 24])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 24, 24])

Input Block 9:
Shape: torch.Size([50, 256, 24, 24])
Stats - mean: -0.5928, std: 4.1523

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 24, 24])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 24, 24])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 24, 24])

Input Block 10:
Shape: torch.Size([50, 256, 24, 24])
Stats - mean: -0.6235, std: 5.1055

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 24, 24])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 24, 24])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 24, 24])

Input Block 11:
Shape: torch.Size([50, 256, 24, 24])
Stats - mean: -0.2025, std: 6.3008

Middle Block:
Shape: torch.Size([50, 256, 24, 24])
Stats - mean: -0.2025, std: 6.3008

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 24, 24])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 24, 24])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 24, 24])

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 24, 24])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 24, 24])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 24, 24])

=== ResBlock _forward ===
Input x shape: torch.Size([50, 512, 24, 24])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 24, 24])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 24, 24])

Output Block 0:
Shape: torch.Size([50, 256, 24, 24])
Stats - mean: 1.0010, std: 6.7812

=== ResBlock _forward ===
Input x shape: torch.Size([50, 512, 24, 24])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 24, 24])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 24, 24])

Output Block 1:
Shape: torch.Size([50, 256, 24, 24])
Stats - mean: 0.1327, std: 6.3203

=== ResBlock _forward ===
Input x shape: torch.Size([50, 512, 24, 24])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 24, 24])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 24, 24])

Output Block 2:
Shape: torch.Size([50, 256, 24, 24])
Stats - mean: -0.4971, std: 5.9844

=== ResBlock _forward ===
Input x shape: torch.Size([50, 512, 24, 24])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 24, 24])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 24, 24])

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 24, 24])
Input embedding shape: torch.Size([50, 1024])

Updown processing:
After in_rest shape: torch.Size([50, 256, 24, 24])
After h_upd shape: torch.Size([50, 256, 48, 48])
After x_upd shape: torch.Size([50, 256, 48, 48])
After final conv shape: torch.Size([50, 256, 48, 48])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 48, 48])

Output Block 3:
Shape: torch.Size([50, 256, 48, 48])
Stats - mean: -0.2146, std: 6.6602

=== ResBlock _forward ===
Input x shape: torch.Size([50, 512, 48, 48])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 48, 48])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 48, 48])

Output Block 4:
Shape: torch.Size([50, 256, 48, 48])
Stats - mean: -0.0930, std: 4.7109

=== ResBlock _forward ===
Input x shape: torch.Size([50, 512, 48, 48])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 48, 48])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 48, 48])

Output Block 5:
Shape: torch.Size([50, 256, 48, 48])
Stats - mean: 0.2114, std: 3.1133

=== ResBlock _forward ===
Input x shape: torch.Size([50, 512, 48, 48])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 48, 48])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 48, 48])

Output Block 6:
Shape: torch.Size([50, 256, 48, 48])
Stats - mean: -0.1383, std: 2.8359

=== ResBlock _forward ===
Input x shape: torch.Size([50, 384, 48, 48])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 48, 48])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 48, 48])

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 48, 48])
Input embedding shape: torch.Size([50, 1024])

Updown processing:
After in_rest shape: torch.Size([50, 256, 48, 48])
After h_upd shape: torch.Size([50, 256, 96, 96])
After x_upd shape: torch.Size([50, 256, 96, 96])
After final conv shape: torch.Size([50, 256, 96, 96])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 96, 96])

Output Block 7:
Shape: torch.Size([50, 256, 96, 96])
Stats - mean: -0.6152, std: 4.3555

=== ResBlock _forward ===
Input x shape: torch.Size([50, 384, 96, 96])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 128, 96, 96])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 256])
Projected embedding shape after expansion: torch.Size([50, 256, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 128, 1, 1])
Shift shape: torch.Size([50, 128, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 128, 96, 96])

Output Block 8:
Shape: torch.Size([50, 128, 96, 96])
Stats - mean: 0.1041, std: 5.3555

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 96, 96])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 128, 96, 96])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 256])
Projected embedding shape after expansion: torch.Size([50, 256, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 128, 1, 1])
Shift shape: torch.Size([50, 128, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 128, 96, 96])

Output Block 9:
Shape: torch.Size([50, 128, 96, 96])
Stats - mean: 0.7109, std: 4.9883

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 96, 96])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 128, 96, 96])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 256])
Projected embedding shape after expansion: torch.Size([50, 256, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 128, 1, 1])
Shift shape: torch.Size([50, 128, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 128, 96, 96])

Output Block 10:
Shape: torch.Size([50, 128, 96, 96])
Stats - mean: -0.3279, std: 7.5977

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 96, 96])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 128, 96, 96])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 256])
Projected embedding shape after expansion: torch.Size([50, 256, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 128, 1, 1])
Shift shape: torch.Size([50, 128, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 128, 96, 96])

Output Block 11:
Shape: torch.Size([50, 128, 96, 96])
Stats - mean: -2.1406, std: 14.4453

=== Final Output ===
Shape: torch.Size([50, 128, 96, 96])
Stats - mean: -2.1406, std: 14.4453
Testing:   5%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                                                                                                                                                                             | 2/44 [00:16<05:03,  7.22s/it]Context vector c shape: torch.Size([50, 512])
Context vector c: tensor([[-1.0869, -0.3918,  0.3711,  ...,  4.2031, -0.3550, -1.0869],
        [-1.0537, -0.4143,  0.4102,  ...,  4.0664, -0.3608, -1.0977],
        [-0.9497, -0.4497,  0.4358,  ...,  4.0469, -0.4280, -1.2412],
        ...,
        [-1.7334, -1.5000,  1.0039,  ...,  4.3086, -0.1062, -0.4487],
        [-1.8252, -1.4365,  0.9360,  ...,  4.3203, -0.0241, -0.4585],
        [-2.1074, -1.4424,  0.8691,  ...,  4.4492,  0.1283, -0.3613]],
       device='cuda:0', dtype=torch.float16)

=== UNet Forward Pass ===
Input shape: torch.Size([50, 1, 96, 96])
Timesteps: tensor([249, 249, 249, 249, 249, 249, 249, 249, 249, 249, 249, 249, 249, 249,
        249, 249, 249, 249, 249, 249, 249, 249, 249, 249, 249, 249, 249, 249,
        249, 249, 249, 249, 249, 249, 249, 249, 249, 249, 249, 249, 249, 249,
        249, 249, 249, 249, 249, 249, 249, 249], device='cuda:0')
Conditioning shape: torch.Size([50, 512])

=== Time Embedding ===
Time embedding shape: torch.Size([50, 512])
Time embedding stats - mean: 0.0208, std: 0.7222

=== Combined Time+Label Embedding ===
Combined embedding shape: torch.Size([50, 1024])

=== Block Outputs ===

Input Block 0:
Shape: torch.Size([50, 128, 96, 96])
Stats - mean: -0.0091, std: 0.4910

=== ResBlock _forward ===
Input x shape: torch.Size([50, 128, 96, 96])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 128, 96, 96])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 256])
Projected embedding shape after expansion: torch.Size([50, 256, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 128, 1, 1])
Shift shape: torch.Size([50, 128, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 128, 96, 96])

Input Block 1:
Shape: torch.Size([50, 128, 96, 96])
Stats - mean: -0.0542, std: 0.7554

=== ResBlock _forward ===
Input x shape: torch.Size([50, 128, 96, 96])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 128, 96, 96])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 256])
Projected embedding shape after expansion: torch.Size([50, 256, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 128, 1, 1])
Shift shape: torch.Size([50, 128, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 128, 96, 96])

Input Block 2:
Shape: torch.Size([50, 128, 96, 96])
Stats - mean: -0.0483, std: 1.2627

=== ResBlock _forward ===
Input x shape: torch.Size([50, 128, 96, 96])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 128, 96, 96])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 256])
Projected embedding shape after expansion: torch.Size([50, 256, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 128, 1, 1])
Shift shape: torch.Size([50, 128, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 128, 96, 96])

Input Block 3:
Shape: torch.Size([50, 128, 96, 96])
Stats - mean: 0.0583, std: 1.6465

=== ResBlock _forward ===
Input x shape: torch.Size([50, 128, 96, 96])
Input embedding shape: torch.Size([50, 1024])

Updown processing:
After in_rest shape: torch.Size([50, 128, 96, 96])
After h_upd shape: torch.Size([50, 128, 48, 48])
After x_upd shape: torch.Size([50, 128, 48, 48])
After final conv shape: torch.Size([50, 128, 48, 48])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 256])
Projected embedding shape after expansion: torch.Size([50, 256, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 128, 1, 1])
Shift shape: torch.Size([50, 128, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 128, 48, 48])

Input Block 4:
Shape: torch.Size([50, 128, 48, 48])
Stats - mean: -0.0563, std: 1.8711

=== ResBlock _forward ===
Input x shape: torch.Size([50, 128, 48, 48])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 48, 48])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 48, 48])

Input Block 5:
Shape: torch.Size([50, 256, 48, 48])
Stats - mean: -0.0078, std: 2.0410

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 48, 48])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 48, 48])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 48, 48])

Input Block 6:
Shape: torch.Size([50, 256, 48, 48])
Stats - mean: -0.0724, std: 2.2891

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 48, 48])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 48, 48])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 48, 48])

Input Block 7:
Shape: torch.Size([50, 256, 48, 48])
Stats - mean: -0.0097, std: 2.5801

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 48, 48])
Input embedding shape: torch.Size([50, 1024])

Updown processing:
After in_rest shape: torch.Size([50, 256, 48, 48])
After h_upd shape: torch.Size([50, 256, 24, 24])
After x_upd shape: torch.Size([50, 256, 24, 24])
After final conv shape: torch.Size([50, 256, 24, 24])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 24, 24])

Input Block 8:
Shape: torch.Size([50, 256, 24, 24])
Stats - mean: -0.2017, std: 3.2812

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 24, 24])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 24, 24])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 24, 24])

Input Block 9:
Shape: torch.Size([50, 256, 24, 24])
Stats - mean: -0.6841, std: 4.6484

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 24, 24])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 24, 24])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 24, 24])

Input Block 10:
Shape: torch.Size([50, 256, 24, 24])
Stats - mean: -0.8232, std: 5.7852

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 24, 24])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 24, 24])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 24, 24])

Input Block 11:
Shape: torch.Size([50, 256, 24, 24])
Stats - mean: -0.7148, std: 7.0430

Middle Block:
Shape: torch.Size([50, 256, 24, 24])
Stats - mean: -0.7148, std: 7.0430

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 24, 24])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 24, 24])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 24, 24])

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 24, 24])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 24, 24])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 24, 24])

=== ResBlock _forward ===
Input x shape: torch.Size([50, 512, 24, 24])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 24, 24])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 24, 24])

Output Block 0:
Shape: torch.Size([50, 256, 24, 24])
Stats - mean: 0.8364, std: 6.4336

=== ResBlock _forward ===
Input x shape: torch.Size([50, 512, 24, 24])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 24, 24])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 24, 24])

Output Block 1:
Shape: torch.Size([50, 256, 24, 24])
Stats - mean: -0.0591, std: 6.1250

=== ResBlock _forward ===
Input x shape: torch.Size([50, 512, 24, 24])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 24, 24])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 24, 24])

Output Block 2:
Shape: torch.Size([50, 256, 24, 24])
Stats - mean: -0.4514, std: 5.7070

=== ResBlock _forward ===
Input x shape: torch.Size([50, 512, 24, 24])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 24, 24])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 24, 24])

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 24, 24])
Input embedding shape: torch.Size([50, 1024])

Updown processing:
After in_rest shape: torch.Size([50, 256, 24, 24])
After h_upd shape: torch.Size([50, 256, 48, 48])
After x_upd shape: torch.Size([50, 256, 48, 48])
After final conv shape: torch.Size([50, 256, 48, 48])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 48, 48])

Output Block 3:
Shape: torch.Size([50, 256, 48, 48])
Stats - mean: -0.1178, std: 5.7773

=== ResBlock _forward ===
Input x shape: torch.Size([50, 512, 48, 48])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 48, 48])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 48, 48])

Output Block 4:
Shape: torch.Size([50, 256, 48, 48])
Stats - mean: -0.1111, std: 3.9863

=== ResBlock _forward ===
Input x shape: torch.Size([50, 512, 48, 48])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 48, 48])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 48, 48])

Output Block 5:
Shape: torch.Size([50, 256, 48, 48])
Stats - mean: 0.1807, std: 2.8223

=== ResBlock _forward ===
Input x shape: torch.Size([50, 512, 48, 48])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 48, 48])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 48, 48])

Output Block 6:
Shape: torch.Size([50, 256, 48, 48])
Stats - mean: 0.0029, std: 2.5410

=== ResBlock _forward ===
Input x shape: torch.Size([50, 384, 48, 48])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 48, 48])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 48, 48])

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 48, 48])
Input embedding shape: torch.Size([50, 1024])

Updown processing:
After in_rest shape: torch.Size([50, 256, 48, 48])
After h_upd shape: torch.Size([50, 256, 96, 96])
After x_upd shape: torch.Size([50, 256, 96, 96])
After final conv shape: torch.Size([50, 256, 96, 96])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 96, 96])

Output Block 7:
Shape: torch.Size([50, 256, 96, 96])
Stats - mean: -0.7080, std: 3.4883

=== ResBlock _forward ===
Input x shape: torch.Size([50, 384, 96, 96])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 128, 96, 96])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 256])
Projected embedding shape after expansion: torch.Size([50, 256, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 128, 1, 1])
Shift shape: torch.Size([50, 128, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 128, 96, 96])

Output Block 8:
Shape: torch.Size([50, 128, 96, 96])
Stats - mean: 0.1530, std: 4.0898

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 96, 96])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 128, 96, 96])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 256])
Projected embedding shape after expansion: torch.Size([50, 256, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 128, 1, 1])
Shift shape: torch.Size([50, 128, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 128, 96, 96])

Output Block 9:
Shape: torch.Size([50, 128, 96, 96])
Stats - mean: 0.6963, std: 5.1758

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 96, 96])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 128, 96, 96])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 256])
Projected embedding shape after expansion: torch.Size([50, 256, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 128, 1, 1])
Shift shape: torch.Size([50, 128, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 128, 96, 96])

Output Block 10:
Shape: torch.Size([50, 128, 96, 96])
Stats - mean: -0.6548, std: 10.5234

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 96, 96])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 128, 96, 96])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 256])
Projected embedding shape after expansion: torch.Size([50, 256, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 128, 1, 1])
Shift shape: torch.Size([50, 128, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 128, 96, 96])

Output Block 11:
Shape: torch.Size([50, 128, 96, 96])
Stats - mean: -2.9082, std: 21.4062

=== Final Output ===
Shape: torch.Size([50, 128, 96, 96])
Stats - mean: -2.9082, std: 21.4062

=== UNet Forward Pass ===
Input shape: torch.Size([50, 1, 96, 96])
Timesteps: tensor([499, 499, 499, 499, 499, 499, 499, 499, 499, 499, 499, 499, 499, 499,
        499, 499, 499, 499, 499, 499, 499, 499, 499, 499, 499, 499, 499, 499,
        499, 499, 499, 499, 499, 499, 499, 499, 499, 499, 499, 499, 499, 499,
        499, 499, 499, 499, 499, 499, 499, 499], device='cuda:0')
Conditioning shape: torch.Size([50, 512])

=== Time Embedding ===
Time embedding shape: torch.Size([50, 512])
Time embedding stats - mean: -0.0212, std: 0.5400

=== Combined Time+Label Embedding ===
Combined embedding shape: torch.Size([50, 1024])

=== Block Outputs ===

Input Block 0:
Shape: torch.Size([50, 128, 96, 96])
Stats - mean: -0.0077, std: 0.4666

=== ResBlock _forward ===
Input x shape: torch.Size([50, 128, 96, 96])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 128, 96, 96])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 256])
Projected embedding shape after expansion: torch.Size([50, 256, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 128, 1, 1])
Shift shape: torch.Size([50, 128, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 128, 96, 96])

Input Block 1:
Shape: torch.Size([50, 128, 96, 96])
Stats - mean: -0.0266, std: 0.5874

=== ResBlock _forward ===
Input x shape: torch.Size([50, 128, 96, 96])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 128, 96, 96])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 256])
Projected embedding shape after expansion: torch.Size([50, 256, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 128, 1, 1])
Shift shape: torch.Size([50, 128, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 128, 96, 96])

Input Block 2:
Shape: torch.Size([50, 128, 96, 96])
Stats - mean: -0.0391, std: 1.0557

=== ResBlock _forward ===
Input x shape: torch.Size([50, 128, 96, 96])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 128, 96, 96])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 256])
Projected embedding shape after expansion: torch.Size([50, 256, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 128, 1, 1])
Shift shape: torch.Size([50, 128, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 128, 96, 96])

Input Block 3:
Shape: torch.Size([50, 128, 96, 96])
Stats - mean: 0.0774, std: 1.5615

=== ResBlock _forward ===
Input x shape: torch.Size([50, 128, 96, 96])
Input embedding shape: torch.Size([50, 1024])

Updown processing:
After in_rest shape: torch.Size([50, 128, 96, 96])
After h_upd shape: torch.Size([50, 128, 48, 48])
After x_upd shape: torch.Size([50, 128, 48, 48])
After final conv shape: torch.Size([50, 128, 48, 48])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 256])
Projected embedding shape after expansion: torch.Size([50, 256, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 128, 1, 1])
Shift shape: torch.Size([50, 128, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 128, 48, 48])

Input Block 4:
Shape: torch.Size([50, 128, 48, 48])
Stats - mean: -0.0870, std: 1.8594

=== ResBlock _forward ===
Input x shape: torch.Size([50, 128, 48, 48])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 48, 48])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 48, 48])

Input Block 5:
Shape: torch.Size([50, 256, 48, 48])
Stats - mean: -0.0685, std: 2.0312

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 48, 48])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 48, 48])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 48, 48])

Input Block 6:
Shape: torch.Size([50, 256, 48, 48])
Stats - mean: -0.1396, std: 2.2227

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 48, 48])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 48, 48])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 48, 48])

Input Block 7:
Shape: torch.Size([50, 256, 48, 48])
Stats - mean: -0.0916, std: 2.4492

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 48, 48])
Input embedding shape: torch.Size([50, 1024])

Updown processing:
After in_rest shape: torch.Size([50, 256, 48, 48])
After h_upd shape: torch.Size([50, 256, 24, 24])
After x_upd shape: torch.Size([50, 256, 24, 24])
After final conv shape: torch.Size([50, 256, 24, 24])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 24, 24])

Input Block 8:
Shape: torch.Size([50, 256, 24, 24])
Stats - mean: -0.2438, std: 3.1348

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 24, 24])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 24, 24])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 24, 24])

Input Block 9:
Shape: torch.Size([50, 256, 24, 24])
Stats - mean: -0.6846, std: 4.3945

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 24, 24])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 24, 24])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 24, 24])

Input Block 10:
Shape: torch.Size([50, 256, 24, 24])
Stats - mean: -0.7847, std: 5.4531

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 24, 24])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 24, 24])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 24, 24])

Input Block 11:
Shape: torch.Size([50, 256, 24, 24])
Stats - mean: -0.5215, std: 6.6484

Middle Block:
Shape: torch.Size([50, 256, 24, 24])
Stats - mean: -0.5215, std: 6.6484

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 24, 24])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 24, 24])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 24, 24])

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 24, 24])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 24, 24])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 24, 24])

=== ResBlock _forward ===
Input x shape: torch.Size([50, 512, 24, 24])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 24, 24])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 24, 24])

Output Block 0:
Shape: torch.Size([50, 256, 24, 24])
Stats - mean: 0.9517, std: 6.5898

=== ResBlock _forward ===
Input x shape: torch.Size([50, 512, 24, 24])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 24, 24])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 24, 24])

Output Block 1:
Shape: torch.Size([50, 256, 24, 24])
Stats - mean: 0.0083, std: 6.2812

=== ResBlock _forward ===
Input x shape: torch.Size([50, 512, 24, 24])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 24, 24])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 24, 24])

Output Block 2:
Shape: torch.Size([50, 256, 24, 24])
Stats - mean: -0.4763, std: 5.8516

=== ResBlock _forward ===
Input x shape: torch.Size([50, 512, 24, 24])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 24, 24])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 24, 24])

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 24, 24])
Input embedding shape: torch.Size([50, 1024])

Updown processing:
After in_rest shape: torch.Size([50, 256, 24, 24])
After h_upd shape: torch.Size([50, 256, 48, 48])
After x_upd shape: torch.Size([50, 256, 48, 48])
After final conv shape: torch.Size([50, 256, 48, 48])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 48, 48])

Output Block 3:
Shape: torch.Size([50, 256, 48, 48])
Stats - mean: -0.1238, std: 6.1953

=== ResBlock _forward ===
Input x shape: torch.Size([50, 512, 48, 48])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 48, 48])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 48, 48])

Output Block 4:
Shape: torch.Size([50, 256, 48, 48])
Stats - mean: -0.1047, std: 4.2969

=== ResBlock _forward ===
Input x shape: torch.Size([50, 512, 48, 48])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 48, 48])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 48, 48])

Output Block 5:
Shape: torch.Size([50, 256, 48, 48])
Stats - mean: 0.1982, std: 2.9609

=== ResBlock _forward ===
Input x shape: torch.Size([50, 512, 48, 48])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 48, 48])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 48, 48])

Output Block 6:
Shape: torch.Size([50, 256, 48, 48])
Stats - mean: -0.0725, std: 2.7207

=== ResBlock _forward ===
Input x shape: torch.Size([50, 384, 48, 48])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 48, 48])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 48, 48])

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 48, 48])
Input embedding shape: torch.Size([50, 1024])

Updown processing:
After in_rest shape: torch.Size([50, 256, 48, 48])
After h_upd shape: torch.Size([50, 256, 96, 96])
After x_upd shape: torch.Size([50, 256, 96, 96])
After final conv shape: torch.Size([50, 256, 96, 96])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 96, 96])

Output Block 7:
Shape: torch.Size([50, 256, 96, 96])
Stats - mean: -0.6772, std: 3.9512

=== ResBlock _forward ===
Input x shape: torch.Size([50, 384, 96, 96])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 128, 96, 96])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 256])
Projected embedding shape after expansion: torch.Size([50, 256, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 128, 1, 1])
Shift shape: torch.Size([50, 128, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 128, 96, 96])

Output Block 8:
Shape: torch.Size([50, 128, 96, 96])
Stats - mean: 0.1278, std: 4.8359

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 96, 96])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 128, 96, 96])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 256])
Projected embedding shape after expansion: torch.Size([50, 256, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 128, 1, 1])
Shift shape: torch.Size([50, 128, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 128, 96, 96])

Output Block 9:
Shape: torch.Size([50, 128, 96, 96])
Stats - mean: 0.7109, std: 5.1367

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 96, 96])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 128, 96, 96])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 256])
Projected embedding shape after expansion: torch.Size([50, 256, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 128, 1, 1])
Shift shape: torch.Size([50, 128, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 128, 96, 96])

Output Block 10:
Shape: torch.Size([50, 128, 96, 96])
Stats - mean: -0.5112, std: 9.2656

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 96, 96])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 128, 96, 96])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 256])
Projected embedding shape after expansion: torch.Size([50, 256, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 128, 1, 1])
Shift shape: torch.Size([50, 128, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 128, 96, 96])

Output Block 11:
Shape: torch.Size([50, 128, 96, 96])
Stats - mean: -2.5879, std: 18.5156

=== Final Output ===
Shape: torch.Size([50, 128, 96, 96])
Stats - mean: -2.5879, std: 18.5156

=== UNet Forward Pass ===
Input shape: torch.Size([50, 1, 96, 96])
Timesteps: tensor([749, 749, 749, 749, 749, 749, 749, 749, 749, 749, 749, 749, 749, 749,
        749, 749, 749, 749, 749, 749, 749, 749, 749, 749, 749, 749, 749, 749,
        749, 749, 749, 749, 749, 749, 749, 749, 749, 749, 749, 749, 749, 749,
        749, 749, 749, 749, 749, 749, 749, 749], device='cuda:0')
Conditioning shape: torch.Size([50, 512])

=== Time Embedding ===
Time embedding shape: torch.Size([50, 512])
Time embedding stats - mean: -0.0521, std: 0.2510

=== Combined Time+Label Embedding ===
Combined embedding shape: torch.Size([50, 1024])

=== Block Outputs ===

Input Block 0:
Shape: torch.Size([50, 128, 96, 96])
Stats - mean: -0.0065, std: 0.4136

=== ResBlock _forward ===
Input x shape: torch.Size([50, 128, 96, 96])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 128, 96, 96])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 256])
Projected embedding shape after expansion: torch.Size([50, 256, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 128, 1, 1])
Shift shape: torch.Size([50, 128, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 128, 96, 96])

Input Block 1:
Shape: torch.Size([50, 128, 96, 96])
Stats - mean: -0.0128, std: 0.5571

=== ResBlock _forward ===
Input x shape: torch.Size([50, 128, 96, 96])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 128, 96, 96])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 256])
Projected embedding shape after expansion: torch.Size([50, 256, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 128, 1, 1])
Shift shape: torch.Size([50, 128, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 128, 96, 96])

Input Block 2:
Shape: torch.Size([50, 128, 96, 96])
Stats - mean: 0.0011, std: 0.7710

=== ResBlock _forward ===
Input x shape: torch.Size([50, 128, 96, 96])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 128, 96, 96])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 256])
Projected embedding shape after expansion: torch.Size([50, 256, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 128, 1, 1])
Shift shape: torch.Size([50, 128, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 128, 96, 96])

Input Block 3:
Shape: torch.Size([50, 128, 96, 96])
Stats - mean: 0.1208, std: 1.3535

=== ResBlock _forward ===
Input x shape: torch.Size([50, 128, 96, 96])
Input embedding shape: torch.Size([50, 1024])

Updown processing:
After in_rest shape: torch.Size([50, 128, 96, 96])
After h_upd shape: torch.Size([50, 128, 48, 48])
After x_upd shape: torch.Size([50, 128, 48, 48])
After final conv shape: torch.Size([50, 128, 48, 48])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 256])
Projected embedding shape after expansion: torch.Size([50, 256, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 128, 1, 1])
Shift shape: torch.Size([50, 128, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 128, 48, 48])

Input Block 4:
Shape: torch.Size([50, 128, 48, 48])
Stats - mean: -0.0584, std: 1.6836

=== ResBlock _forward ===
Input x shape: torch.Size([50, 128, 48, 48])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 48, 48])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 48, 48])

Input Block 5:
Shape: torch.Size([50, 256, 48, 48])
Stats - mean: -0.0543, std: 1.8799

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 48, 48])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 48, 48])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 48, 48])

Input Block 6:
Shape: torch.Size([50, 256, 48, 48])
Stats - mean: -0.1453, std: 2.0723

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 48, 48])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 48, 48])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 48, 48])

Input Block 7:
Shape: torch.Size([50, 256, 48, 48])
Stats - mean: -0.1433, std: 2.3574

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 48, 48])
Input embedding shape: torch.Size([50, 1024])

Updown processing:
After in_rest shape: torch.Size([50, 256, 48, 48])
After h_upd shape: torch.Size([50, 256, 24, 24])
After x_upd shape: torch.Size([50, 256, 24, 24])
After final conv shape: torch.Size([50, 256, 24, 24])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 24, 24])

Input Block 8:
Shape: torch.Size([50, 256, 24, 24])
Stats - mean: -0.2498, std: 3.0254

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 24, 24])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 24, 24])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 24, 24])

Input Block 9:
Shape: torch.Size([50, 256, 24, 24])
Stats - mean: -0.6084, std: 4.1602

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 24, 24])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 24, 24])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 24, 24])

Input Block 10:
Shape: torch.Size([50, 256, 24, 24])
Stats - mean: -0.6465, std: 5.1172

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 24, 24])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 24, 24])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 24, 24])

Input Block 11:
Shape: torch.Size([50, 256, 24, 24])
Stats - mean: -0.1976, std: 6.3438

Middle Block:
Shape: torch.Size([50, 256, 24, 24])
Stats - mean: -0.1976, std: 6.3438

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 24, 24])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 24, 24])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 24, 24])

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 24, 24])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 24, 24])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 24, 24])

=== ResBlock _forward ===
Input x shape: torch.Size([50, 512, 24, 24])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 24, 24])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 24, 24])

Output Block 0:
Shape: torch.Size([50, 256, 24, 24])
Stats - mean: 1.0176, std: 6.8750

=== ResBlock _forward ===
Input x shape: torch.Size([50, 512, 24, 24])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 24, 24])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 24, 24])

Output Block 1:
Shape: torch.Size([50, 256, 24, 24])
Stats - mean: 0.0977, std: 6.3984

=== ResBlock _forward ===
Input x shape: torch.Size([50, 512, 24, 24])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 24, 24])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 24, 24])

Output Block 2:
Shape: torch.Size([50, 256, 24, 24])
Stats - mean: -0.5156, std: 5.9961

=== ResBlock _forward ===
Input x shape: torch.Size([50, 512, 24, 24])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 24, 24])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 24, 24])

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 24, 24])
Input embedding shape: torch.Size([50, 1024])

Updown processing:
After in_rest shape: torch.Size([50, 256, 24, 24])
After h_upd shape: torch.Size([50, 256, 48, 48])
After x_upd shape: torch.Size([50, 256, 48, 48])
After final conv shape: torch.Size([50, 256, 48, 48])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 48, 48])

Output Block 3:
Shape: torch.Size([50, 256, 48, 48])
Stats - mean: -0.2266, std: 6.5234

=== ResBlock _forward ===
Input x shape: torch.Size([50, 512, 48, 48])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 48, 48])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 48, 48])

Output Block 4:
Shape: torch.Size([50, 256, 48, 48])
Stats - mean: -0.1221, std: 4.6055

=== ResBlock _forward ===
Input x shape: torch.Size([50, 512, 48, 48])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 48, 48])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 48, 48])

Output Block 5:
Shape: torch.Size([50, 256, 48, 48])
Stats - mean: 0.2112, std: 3.0859

=== ResBlock _forward ===
Input x shape: torch.Size([50, 512, 48, 48])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 48, 48])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 48, 48])

Output Block 6:
Shape: torch.Size([50, 256, 48, 48])
Stats - mean: -0.1490, std: 2.8242

=== ResBlock _forward ===
Input x shape: torch.Size([50, 384, 48, 48])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 48, 48])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 48, 48])

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 48, 48])
Input embedding shape: torch.Size([50, 1024])

Updown processing:
After in_rest shape: torch.Size([50, 256, 48, 48])
After h_upd shape: torch.Size([50, 256, 96, 96])
After x_upd shape: torch.Size([50, 256, 96, 96])
After final conv shape: torch.Size([50, 256, 96, 96])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 96, 96])

Output Block 7:
Shape: torch.Size([50, 256, 96, 96])
Stats - mean: -0.6333, std: 4.4375

=== ResBlock _forward ===
Input x shape: torch.Size([50, 384, 96, 96])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 128, 96, 96])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 256])
Projected embedding shape after expansion: torch.Size([50, 256, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 128, 1, 1])
Shift shape: torch.Size([50, 128, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 128, 96, 96])

Output Block 8:
Shape: torch.Size([50, 128, 96, 96])
Stats - mean: 0.0682, std: 5.4141

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 96, 96])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 128, 96, 96])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 256])
Projected embedding shape after expansion: torch.Size([50, 256, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 128, 1, 1])
Shift shape: torch.Size([50, 128, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 128, 96, 96])

Output Block 9:
Shape: torch.Size([50, 128, 96, 96])
Stats - mean: 0.7217, std: 5.0117

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 96, 96])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 128, 96, 96])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 256])
Projected embedding shape after expansion: torch.Size([50, 256, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 128, 1, 1])
Shift shape: torch.Size([50, 128, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 128, 96, 96])

Output Block 10:
Shape: torch.Size([50, 128, 96, 96])
Stats - mean: -0.3076, std: 7.6602

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 96, 96])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 128, 96, 96])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 256])
Projected embedding shape after expansion: torch.Size([50, 256, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 128, 1, 1])
Shift shape: torch.Size([50, 128, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 128, 96, 96])

Output Block 11:
Shape: torch.Size([50, 128, 96, 96])
Stats - mean: -2.1914, std: 14.6250

=== Final Output ===
Shape: torch.Size([50, 128, 96, 96])
Stats - mean: -2.1914, std: 14.6250
Testing:   7%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                                                                                                                                                                        | 3/44 [00:19<03:34,  5.24s/it]Context vector c shape: torch.Size([50, 512])
Context vector c: tensor([[-1.1523, -0.4639,  0.4233,  ...,  4.2031, -0.3113, -0.9712],
        [-1.0488, -0.4451,  0.4519,  ...,  4.0195, -0.3301, -0.9160],
        [-0.9639, -0.4360,  0.4778,  ...,  3.8027, -0.3235, -0.8237],
        ...,
        [-1.4102, -1.5049,  1.1074,  ...,  3.8359, -0.2106, -0.2732],
        [-1.4189, -1.3340,  0.9844,  ...,  3.8340, -0.1475, -0.3977],
        [-1.5430, -1.3213,  0.9341,  ...,  3.9453, -0.1063, -0.4182]],
       device='cuda:0', dtype=torch.float16)

=== UNet Forward Pass ===
Input shape: torch.Size([50, 1, 96, 96])
Timesteps: tensor([249, 249, 249, 249, 249, 249, 249, 249, 249, 249, 249, 249, 249, 249,
        249, 249, 249, 249, 249, 249, 249, 249, 249, 249, 249, 249, 249, 249,
        249, 249, 249, 249, 249, 249, 249, 249, 249, 249, 249, 249, 249, 249,
        249, 249, 249, 249, 249, 249, 249, 249], device='cuda:0')
Conditioning shape: torch.Size([50, 512])

=== Time Embedding ===
Time embedding shape: torch.Size([50, 512])
Time embedding stats - mean: 0.0208, std: 0.7222

=== Combined Time+Label Embedding ===
Combined embedding shape: torch.Size([50, 1024])

=== Block Outputs ===

Input Block 0:
Shape: torch.Size([50, 128, 96, 96])
Stats - mean: -0.0122, std: 0.4785

=== ResBlock _forward ===
Input x shape: torch.Size([50, 128, 96, 96])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 128, 96, 96])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 256])
Projected embedding shape after expansion: torch.Size([50, 256, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 128, 1, 1])
Shift shape: torch.Size([50, 128, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 128, 96, 96])

Input Block 1:
Shape: torch.Size([50, 128, 96, 96])
Stats - mean: -0.0507, std: 0.7598

=== ResBlock _forward ===
Input x shape: torch.Size([50, 128, 96, 96])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 128, 96, 96])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 256])
Projected embedding shape after expansion: torch.Size([50, 256, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 128, 1, 1])
Shift shape: torch.Size([50, 128, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 128, 96, 96])

Input Block 2:
Shape: torch.Size([50, 128, 96, 96])
Stats - mean: -0.0448, std: 1.3066

=== ResBlock _forward ===
Input x shape: torch.Size([50, 128, 96, 96])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 128, 96, 96])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 256])
Projected embedding shape after expansion: torch.Size([50, 256, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 128, 1, 1])
Shift shape: torch.Size([50, 128, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 128, 96, 96])

Input Block 3:
Shape: torch.Size([50, 128, 96, 96])
Stats - mean: 0.0474, std: 1.6338

=== ResBlock _forward ===
Input x shape: torch.Size([50, 128, 96, 96])
Input embedding shape: torch.Size([50, 1024])

Updown processing:
After in_rest shape: torch.Size([50, 128, 96, 96])
After h_upd shape: torch.Size([50, 128, 48, 48])
After x_upd shape: torch.Size([50, 128, 48, 48])
After final conv shape: torch.Size([50, 128, 48, 48])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 256])
Projected embedding shape after expansion: torch.Size([50, 256, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 128, 1, 1])
Shift shape: torch.Size([50, 128, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 128, 48, 48])

Input Block 4:
Shape: torch.Size([50, 128, 48, 48])
Stats - mean: -0.0770, std: 1.8604

=== ResBlock _forward ===
Input x shape: torch.Size([50, 128, 48, 48])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 48, 48])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 48, 48])

Input Block 5:
Shape: torch.Size([50, 256, 48, 48])
Stats - mean: -0.0171, std: 2.0605

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 48, 48])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 48, 48])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 48, 48])

Input Block 6:
Shape: torch.Size([50, 256, 48, 48])
Stats - mean: -0.0740, std: 2.3125

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 48, 48])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 48, 48])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 48, 48])

Input Block 7:
Shape: torch.Size([50, 256, 48, 48])
Stats - mean: -0.0097, std: 2.6016

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 48, 48])
Input embedding shape: torch.Size([50, 1024])

Updown processing:
After in_rest shape: torch.Size([50, 256, 48, 48])
After h_upd shape: torch.Size([50, 256, 24, 24])
After x_upd shape: torch.Size([50, 256, 24, 24])
After final conv shape: torch.Size([50, 256, 24, 24])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 24, 24])

Input Block 8:
Shape: torch.Size([50, 256, 24, 24])
Stats - mean: -0.1901, std: 3.3164

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 24, 24])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 24, 24])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 24, 24])

Input Block 9:
Shape: torch.Size([50, 256, 24, 24])
Stats - mean: -0.6470, std: 4.6797

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 24, 24])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 24, 24])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 24, 24])

Input Block 10:
Shape: torch.Size([50, 256, 24, 24])
Stats - mean: -0.7710, std: 5.7773

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 24, 24])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 24, 24])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 24, 24])

Input Block 11:
Shape: torch.Size([50, 256, 24, 24])
Stats - mean: -0.6899, std: 6.9844

Middle Block:
Shape: torch.Size([50, 256, 24, 24])
Stats - mean: -0.6899, std: 6.9844

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 24, 24])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 24, 24])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 24, 24])

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 24, 24])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 24, 24])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 24, 24])

=== ResBlock _forward ===
Input x shape: torch.Size([50, 512, 24, 24])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 24, 24])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 24, 24])

Output Block 0:
Shape: torch.Size([50, 256, 24, 24])
Stats - mean: 0.8237, std: 6.3672

=== ResBlock _forward ===
Input x shape: torch.Size([50, 512, 24, 24])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 24, 24])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 24, 24])

Output Block 1:
Shape: torch.Size([50, 256, 24, 24])
Stats - mean: -0.0288, std: 6.1094

=== ResBlock _forward ===
Input x shape: torch.Size([50, 512, 24, 24])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 24, 24])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 24, 24])

Output Block 2:
Shape: torch.Size([50, 256, 24, 24])
Stats - mean: -0.4299, std: 5.7500

=== ResBlock _forward ===
Input x shape: torch.Size([50, 512, 24, 24])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 24, 24])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 24, 24])

=== ResBlock _forward ===
Input x shape: torch.Size([50, 256, 24, 24])
Input embedding shape: torch.Size([50, 1024])

Updown processing:
After in_rest shape: torch.Size([50, 256, 24, 24])
After h_upd shape: torch.Size([50, 256, 48, 48])
After x_upd shape: torch.Size([50, 256, 48, 48])
After final conv shape: torch.Size([50, 256, 48, 48])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 48, 48])

Output Block 3:
Shape: torch.Size([50, 256, 48, 48])
Stats - mean: -0.1516, std: 5.9961

=== ResBlock _forward ===
Input x shape: torch.Size([50, 512, 48, 48])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 48, 48])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 48, 48])

Output Block 4:
Shape: torch.Size([50, 256, 48, 48])
Stats - mean: -0.0759, std: 4.1172

=== ResBlock _forward ===
Input x shape: torch.Size([50, 512, 48, 48])
Input embedding shape: torch.Size([50, 1024])

Regular processing:
After in_layers shape: torch.Size([50, 256, 48, 48])

=== Embedding Projection ===
Projected embedding shape before expansion: torch.Size([50, 512])
Projected embedding shape after expansion: torch.Size([50, 512, 1, 1])

=== Scale-Shift Values ===
Scale shape: torch.Size([50, 256, 1, 1])
Shift shape: torch.Size([50, 256, 1, 1])

=== ResBlock Output ===
Output shape: torch.Size([50, 256, 48, 48])

Output Block 5:
Shape: torch.Size([50, 256, 48, 48])
^C/home/rd81/miniconda3/envs/cddpm/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:685: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...
  rank_zero_warn("Detected KeyboardInterrupt, attempting graceful shutdown...")
[2024-11-26 13:48:05,708][src.train][INFO] - Test of Datamodules_train.IXI!